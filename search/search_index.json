{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to St. Jude Cloud Documentation! Overview \u00b6 The St. Jude Cloud documentation includes authoritative guides for accessing St. Jude Cloud data, creating and running analysis workflows on the cloud, and exploring curated data from numerous published studies by St. Jude and our collaborating institutions.To learn more about our ecosystem, read this guide . Sign up here to receive email notifications when we add new datasets, analysis pipelines, or other exciting features. Features \u00b6 You can apply many different capabilities of St. Jude Cloud to your research, such as: Explore the raw genomics data we currently offer. You can browse by diagnosis, publication, or curated dataset while applying a number of different filters. For more information, see our data request guide . Run your tools on our data by requesting data and packaging your tools in a secure cloud environment. See this guide for an example. Run our in house analysis workflows on your data by moving your data to the cloud and selecting a workflow to run. See this guide for an example. Explore St. Jude datasets through interactive visualizations that we have packaged for the community. For example, visit PeCan to visually investigate pediatric cancer mutation data. Create manuscript quality figures with your data to use in publications or to host on your website with ProteinPaint or GenomePaint . See the ProteinPaint documentation and GenomePaint documentation for help. Note Please note that while it is free to receive and store our data in St. Jude Cloud, there are compute and storage fees associated with working in the cloud, as well as egress fees for downloading data . Apps \u00b6 St. Jude Cloud provides a number of applications which you can use for various purposes. Click on the links below to checkout one or more of our applications. Genomics Platform Browse our publicly available genomics datasets, make a data request, and run analyses in a secure cloud environment. View the documentation for this app here . Pediatric Cancer Portal (PeCan) Interactively explore mutational recurrence and pathogenicity assessment of variants in pediatric cancer using a wide variety of St. Jude + publicly available data. View the documentation for this app here . Visualization Community Explore, create, and share interactive visualizations using tools such as ProteinPaint and GenomePaint. View the documentation for this app here . Studies \u00b6 The following projects currently distribute data through St. Jude Cloud. Click here for a brief description of each project listed below. Or click on a project in the bulleted list below to go straight to the corresponding Study page. Pediatric Cancer Genome Project (PCGP) St. Jude Lifetime (SJLIFE) Clinical Genomics (Clinical Pilot and G4K) Sickle Cell Genome Project (SGP) Childhood Cancer Survivor Study (CCSS) Analysis Workflows \u00b6 St. Jude shares a number of end-to-end analysis workflows as part of the Genomics Platform application. Click on the links below to learn more about the workflow. ChIP-Seq Peak Calling Rapid RNA-Seq Fusion Detection WARDEN Differential Expression Analysis Mutational Signatures SequencErr M2A (coming soon) Contact Us \u00b6 Any questions, comments, or concerns can be directed to our \"Contact Us\" form or you can email us directly at support@stjude.cloud .","title":"Overview"},{"location":"#overview","text":"The St. Jude Cloud documentation includes authoritative guides for accessing St. Jude Cloud data, creating and running analysis workflows on the cloud, and exploring curated data from numerous published studies by St. Jude and our collaborating institutions.To learn more about our ecosystem, read this guide . Sign up here to receive email notifications when we add new datasets, analysis pipelines, or other exciting features.","title":"Overview"},{"location":"#features","text":"You can apply many different capabilities of St. Jude Cloud to your research, such as: Explore the raw genomics data we currently offer. You can browse by diagnosis, publication, or curated dataset while applying a number of different filters. For more information, see our data request guide . Run your tools on our data by requesting data and packaging your tools in a secure cloud environment. See this guide for an example. Run our in house analysis workflows on your data by moving your data to the cloud and selecting a workflow to run. See this guide for an example. Explore St. Jude datasets through interactive visualizations that we have packaged for the community. For example, visit PeCan to visually investigate pediatric cancer mutation data. Create manuscript quality figures with your data to use in publications or to host on your website with ProteinPaint or GenomePaint . See the ProteinPaint documentation and GenomePaint documentation for help. Note Please note that while it is free to receive and store our data in St. Jude Cloud, there are compute and storage fees associated with working in the cloud, as well as egress fees for downloading data .","title":"Features"},{"location":"#apps","text":"St. Jude Cloud provides a number of applications which you can use for various purposes. Click on the links below to checkout one or more of our applications. Genomics Platform Browse our publicly available genomics datasets, make a data request, and run analyses in a secure cloud environment. View the documentation for this app here . Pediatric Cancer Portal (PeCan) Interactively explore mutational recurrence and pathogenicity assessment of variants in pediatric cancer using a wide variety of St. Jude + publicly available data. View the documentation for this app here . Visualization Community Explore, create, and share interactive visualizations using tools such as ProteinPaint and GenomePaint. View the documentation for this app here .","title":"Apps"},{"location":"#studies","text":"The following projects currently distribute data through St. Jude Cloud. Click here for a brief description of each project listed below. Or click on a project in the bulleted list below to go straight to the corresponding Study page. Pediatric Cancer Genome Project (PCGP) St. Jude Lifetime (SJLIFE) Clinical Genomics (Clinical Pilot and G4K) Sickle Cell Genome Project (SGP) Childhood Cancer Survivor Study (CCSS)","title":"Studies"},{"location":"#analysis-workflows","text":"St. Jude shares a number of end-to-end analysis workflows as part of the Genomics Platform application. Click on the links below to learn more about the workflow. ChIP-Seq Peak Calling Rapid RNA-Seq Fusion Detection WARDEN Differential Expression Analysis Mutational Signatures SequencErr M2A (coming soon)","title":"Analysis Workflows"},{"location":"#contact-us","text":"Any questions, comments, or concerns can be directed to our \"Contact Us\" form or you can email us directly at support@stjude.cloud .","title":"Contact Us"},{"location":"citing-stjude-cloud/","text":"Citing St. Jude Cloud The St. Jude Cloud manuscript is currently under review. Until further notice, when St. Jude Cloud or data accessed therein is used in your work, please ensure that you: Cite the St. Jude Cloud manuscript preprint on BioRxiv: St. Jude Cloud - a Pediatric Cancer Genomic Data Sharing Ecosystem Cite the relevant paper for each dataset and/or resource that you used in your study (see \u2018Dataset\u2019 and \u2018Resource\u2019 reference tables below) State in the Results and/or Methods section that the relevant data and/or resource was obtained from St. Jude Cloud. Example statement: \"Whole genome sequencing data for relapse tumor samples from 345 pediatric patients were obtained from St. Jude Cloud.\" State in the Data availability section of the manuscript that data and/or resource can be accessed via St. Jude Cloud. Example statement: \"Whole genome sequencing data for pediatric relapse tumor samples used for analysis in this study were obtained from St. Jude Cloud ( https://www.stjude.cloud ) \u2013 a publicly accessible pediatric genomic data resource requiring approval for controlled data access.\" Dataset Reference Table \u00b6 Please download the Schedule 1(s) (linked in table below) to find dataset specific wording of acknowledgement(s). St. Jude Cloud Dataset Reference Pediatric Cancer Genome Project (PCGP) dataset PCGP perspectives paper and the relevant tumor type paper(s) ; file_download PCGP Schedule 1 St. Jude Lifetime (SJLIFE) dataset SJLIFE paper ; file_download SJLIFE Schedule 1 Clinical Genomics (Clinical Pilot, Genomes for Kids, Real-Time Clinical Genomics) dataset Clinical Pilot paper ; file_download Clinical Genomics Schedule 1 Sickle Cell Genome Project (SGP) dataset paper in progress; file_download SGP Schedule 1 Childhood Cancer Survivor Study (CCSS) dataset CCSS study design paper ; file_download CCSS Schedule 1 Pan-Acute Lymphoblastic Leukemia (PanALL) dataset file_download PanALL Schedule 1 Note If you are unsure what dataset(s) the data that you have been vended belongs to, you can find this information in the sj_datasets column of the SAMPLE_INFO.txt file. Warning Publishing using any of the data files before the embargo date has passed is strictly prohibited as outlined in the Data Access Agreement (DAA) . Resource Reference Table \u00b6 St. Jude Cloud Resource Reference ProteinPaint ProteinPaint paper GenomePaint paper in progress PeCan Pie PeCan Pie paper ChIP-Seq Peak Calling unpublished Rapid RNA-Seq Fusion Detection paper in progress WARDEN unpublished Mutational Signatures Mutational Patterns paper cis-x paper in progress XenoCP paper in progress Contact Us \u00b6 Any questions, comments, or concerns can be directed to our \"Contact Us\" form or you can email us directly at support@stjude.cloud .","title":"Citing St. Jude Cloud"},{"location":"citing-stjude-cloud/#dataset-reference-table","text":"Please download the Schedule 1(s) (linked in table below) to find dataset specific wording of acknowledgement(s). St. Jude Cloud Dataset Reference Pediatric Cancer Genome Project (PCGP) dataset PCGP perspectives paper and the relevant tumor type paper(s) ; file_download PCGP Schedule 1 St. Jude Lifetime (SJLIFE) dataset SJLIFE paper ; file_download SJLIFE Schedule 1 Clinical Genomics (Clinical Pilot, Genomes for Kids, Real-Time Clinical Genomics) dataset Clinical Pilot paper ; file_download Clinical Genomics Schedule 1 Sickle Cell Genome Project (SGP) dataset paper in progress; file_download SGP Schedule 1 Childhood Cancer Survivor Study (CCSS) dataset CCSS study design paper ; file_download CCSS Schedule 1 Pan-Acute Lymphoblastic Leukemia (PanALL) dataset file_download PanALL Schedule 1 Note If you are unsure what dataset(s) the data that you have been vended belongs to, you can find this information in the sj_datasets column of the SAMPLE_INFO.txt file. Warning Publishing using any of the data files before the embargo date has passed is strictly prohibited as outlined in the Data Access Agreement (DAA) .","title":"Dataset Reference Table"},{"location":"citing-stjude-cloud/#resource-reference-table","text":"St. Jude Cloud Resource Reference ProteinPaint ProteinPaint paper GenomePaint paper in progress PeCan Pie PeCan Pie paper ChIP-Seq Peak Calling unpublished Rapid RNA-Seq Fusion Detection paper in progress WARDEN unpublished Mutational Signatures Mutational Patterns paper cis-x paper in progress XenoCP paper in progress","title":"Resource Reference Table"},{"location":"citing-stjude-cloud/#contact-us","text":"Any questions, comments, or concerns can be directed to our \"Contact Us\" form or you can email us directly at support@stjude.cloud .","title":"Contact Us"},{"location":"ecosystem/","text":"About our Ecosystem Overview \u00b6 The St. Jude Cloud ecosystem has been designed with three main entry points, called Research Domains, to guide users along a path of content that will be most relevant to their research interests. Cards for these top-level Research Domains (Pediatric Cancer, Cancer Survivorship, and Non-Cancerous Diseases) are the first selections you will be presented with on our homepage . The diagram below shows an abstraction of our ecosystem. Research Domains are presented as vertical panels which cascade down through the sets of Apps and Studies, the building blocks of content along the Research Domains. Apps are interactive and facilitate data sharing and discovery. Studies are static pages of content that discuss how St. Jude has generated and used a particular dataset. Apps and Studies are disjoint ecosystem elements, yet they are distributed non-uniquely among the Research Domains in order to facilitate a focused sharing of content. For a complete list of Applications and Studies please visit the Welcome to St. Jude documentation page. Migration to new structure \u00b6 St. Jude Cloud's original architecture of Data, Tools, and Visualizations has been retired. You can learn more about what changed in the announcement blog post . We hope this redesigned ecosystem will better facilitate data sharing, discovery, and community engagement.","title":"About our Ecosystem"},{"location":"ecosystem/#overview","text":"The St. Jude Cloud ecosystem has been designed with three main entry points, called Research Domains, to guide users along a path of content that will be most relevant to their research interests. Cards for these top-level Research Domains (Pediatric Cancer, Cancer Survivorship, and Non-Cancerous Diseases) are the first selections you will be presented with on our homepage . The diagram below shows an abstraction of our ecosystem. Research Domains are presented as vertical panels which cascade down through the sets of Apps and Studies, the building blocks of content along the Research Domains. Apps are interactive and facilitate data sharing and discovery. Studies are static pages of content that discuss how St. Jude has generated and used a particular dataset. Apps and Studies are disjoint ecosystem elements, yet they are distributed non-uniquely among the Research Domains in order to facilitate a focused sharing of content. For a complete list of Applications and Studies please visit the Welcome to St. Jude documentation page.","title":"Overview"},{"location":"ecosystem/#migration-to-new-structure","text":"St. Jude Cloud's original architecture of Data, Tools, and Visualizations has been retired. You can learn more about what changed in the announcement blog post . We hope this redesigned ecosystem will better facilitate data sharing, discovery, and community engagement.","title":"Migration to new structure"},{"location":"faq/","text":"Frequently Asked Questions Info This page contains information about site-wide St. Jude Cloud frequently asked questions. For more detailed information, we highly recommend that you also visit the dedicated frequently asked questions page for the application you are using. St. Jude Cloud Genomics Platform FAQ St. Jude Cloud PeCan FAQ St. Jude Cloud Visualization Community FAQ General Questions Where can I find the Terms of Service or the Privacy Policy? How can I sign up for updates? Billing Questions Will I be charged for using St. Jude Cloud? Publication Questions How do I cite St. Jude Cloud? When can I publish my findings using St. Jude Cloud data? General Questions \u00b6 Where can I find the Terms of Service or the Privacy Policy? \u00b6 You can find the Terms of Service here and the Privacy Policy here . They are updated regularly, so as we note out in the text there, please check back regularly! How can I sign up for updates? \u00b6 To receive updates on St. Jude Cloud, such as new data releases and new applications released, please subscribe to our email list . Billing Questions \u00b6 Will I be charged for using St. Jude Cloud? \u00b6 Please see the following questions in each application's dedicated frequently asked questions page. St. Jude Cloud Genomics Platform St. Jude Cloud PeCan St. Jude Cloud Visualization Community Publication Questions \u00b6 How do I cite St. Jude Cloud? \u00b6 The manuscript for St. Jude Cloud is currently in preparation. In the meantime, please refer to the citation guide . When can I publish my findings using St. Jude Cloud data? \u00b6 Within St. Jude Cloud Genomics Platform, all of the samples are marked with an embargo date . Once the embargo date has passed for all of the data sets you've used in your research, you are permitted to publish results based on that data. You can find this by looking at the tags for each file or in the SAMPLE_INFO.txt file that is included with each data request. To learn more, please visit the dedicated section in our guide . Any data in St. Jude Cloud Visualization Community or St. Jude Cloud PeCan is considered published. For any data not covered here, or if you have any questions, please contact us .","title":"Frequently Asked Questions"},{"location":"faq/#general-questions","text":"","title":"General Questions"},{"location":"faq/#where-can-i-find-the-terms-of-service-or-the-privacy-policy","text":"You can find the Terms of Service here and the Privacy Policy here . They are updated regularly, so as we note out in the text there, please check back regularly!","title":"Where can I find the Terms of Service or the Privacy Policy?"},{"location":"faq/#how-can-i-sign-up-for-updates","text":"To receive updates on St. Jude Cloud, such as new data releases and new applications released, please subscribe to our email list .","title":"How can I sign up for updates?"},{"location":"faq/#billing-questions","text":"","title":"Billing Questions"},{"location":"faq/#will-i-be-charged-for-using-st-jude-cloud","text":"Please see the following questions in each application's dedicated frequently asked questions page. St. Jude Cloud Genomics Platform St. Jude Cloud PeCan St. Jude Cloud Visualization Community","title":"Will I be charged for using St. Jude Cloud?"},{"location":"faq/#publication-questions","text":"","title":"Publication Questions"},{"location":"faq/#how-do-i-cite-st-jude-cloud","text":"The manuscript for St. Jude Cloud is currently in preparation. In the meantime, please refer to the citation guide .","title":"How do I cite St. Jude Cloud?"},{"location":"faq/#when-can-i-publish-my-findings-using-st-jude-cloud-data","text":"Within St. Jude Cloud Genomics Platform, all of the samples are marked with an embargo date . Once the embargo date has passed for all of the data sets you've used in your research, you are permitted to publish results based on that data. You can find this by looking at the tags for each file or in the SAMPLE_INFO.txt file that is included with each data request. To learn more, please visit the dedicated section in our guide . Any data in St. Jude Cloud Visualization Community or St. Jude Cloud PeCan is considered published. For any data not covered here, or if you have any questions, please contact us .","title":"When can I publish my findings using St. Jude Cloud data?"},{"location":"guides/cstn/","text":"Note This page was just released and documentation is coming soon! If you have any questions, please contact us at support@stjude.cloud . Thank you!","title":"Childhood Solid Tumor Network Portal"},{"location":"guides/pbtp/","text":"Note This page was just released and documentation is coming soon! If you have any questions, please contact us at support@stjude.cloud . Thank you!","title":"Pediatric Brain Tumor Portal"},{"location":"guides/genomepaint/","text":"Tip This guide is still being written! Check back often for updates. Introduction \u00b6 GenomePaint officially hosts the pediatric cancer mutation and gene expression dataset, available for the human hg19 reference genome. Accessing GenomePaint \u00b6 GenomePaint is accessible from https://proteinpaint.stjude.org/genomepaint . This front page provides following contents: Visualization of the pediatric cancer dataset over the hg19 reference genome Custom track submission available for multiple species and genome assemblies. Links to live Figures of the manuscript, this tutorial, and the user community on Google Group. Genome browser navigation \u00b6 By default, the pediatric cancer dataset is shown in a ProteinPaint genome browser. Following are instructions to navigate the genome browser. To pan left or right, drag on the middle part of the track. To zoom in, drag on the genomic coordinate ruler on top, or click the \"In\" button. To zoom out, click a zoom out button on top of the genome browser. From the protein view \u00b6 To view the dataset in a protein view, go to https://proteinpaint.stjude.org . At the top search bar, type in the gene name and display the gene. Make sure \"hg19\" is selected at the drop down menu. Then click \"Pediatric2\" on top, and select \"Pediatric tumor mutation\" to show the dataset over the protein view of the gene. Transitioning from genome view to protein view \u00b6 When viewing a gene locus using the genome browser, ProteinPaint offers to easily transition into protein view, so you can examine the GenomePaint track or any other current set of tracks over the protein view. Three viewpoints \u00b6 GenomePaint offers Cohort View , Sample View , and Matrix View , connected as below. Cohort View : showing mutations from all samples over a genomic region, along with the gene expression ranks for each of the samples. Dense mode : a compact display showing density plots for SVs and SNV/indels Expanded mode : all types of mutations are aligned by samples, one row per sample Sample View : showing mutations for one sample alone, along with any available genomic assay tracks. Matrix View : combining the mutation profiles of multiple genomic regions in one view, in the form of a sample-by-region matrix. Cohort View \u00b6 Cohort View connects DNA alterations with gene expression across a cohort. It shows in either \"dense\" or \"expanded\" mode. Dense mode \u00b6 By default, the \"Pediatric tumor mutation\" track displays the cohort-view compactly in \"dense\" mode. This view is consisted of following parts: SNV/indel and SV/fusion breakpoint density plots on top; Cancer group labels on left; CNV and LOH segment plots in the center; Gene expression ranking on right; Legends at bottom. Mutation and breakpoint density plot in dense mode \u00b6 At the top, dots indicate the density of SV breakpoints and SNV/indels from every sample combined. Dot size represents the number of samples. For SNV/indel, dot colors represent mutation classes. For SV, each dot represents one or more samples from the same cancer type. Hover over a dot for details: Above example shows KRAS gene locus at a low resolution and its exon as a thin sliver. All missense mutations from that exon are represented by one big dot. Zoom in on the exon and the large dot will break up to smaller dots. Zooming in at base-pair level, each dot now represents the collection of all mutations at one base-pair; it's also positioned to that base-pair. Clicking on a dot to show the actual list of mutations. From this panel, hover over a sample to see sample-level information about this mutation. dbSNP and ClinVar matching \u00b6 At the bottom of the mutation tooltip shows if any dbSNP or ClinVar entry matches with the mutation. Either match will be shown as URL links to their respective databases. (You can't click the link in a mouse-hover tooltip; simply click on the mutation from GenomePaint to show the information panel with this information, there you will be able to click the dbSNP or ClinVar link. The panel will only go away if you choose to hide it) This matching is conducted on-the-fly using GenomePaint's backend databases, and is also available to a hg19 or hg38 custom GenomePaint track which does not need to pre-annotate its variants with the dbSNP or ClinVar. CNV/LOH in dense mode \u00b6 In this part, GenomePaint shows CNV/LOH and expression rank aligned by rows, one row per sample. CNV and LOH events are shown as thin horizontal lines, identified by color: Red: copy number gain Blue: copy number loss Gray: LOH In all cases, the color darkness represents the degree of the event, see color scales in legend. Samples are grouped by cancer type, as shown by the cancer type names on the left. Each cancer type is labeled by abbreviations. Hover over the label for details. You can filter mutation data by cancer type. See section Cancer type filter . Expanded mode \u00b6 On the top right, click \"CONFIG\" to show the configuration menu, then choose \"Expanded\" to go into expanded mode: The expanded mode looks like below: In expanded mode, all mutations for each sample are shown in the same row. Circles represent SV/fusion breakpoints, and x marks represent SNV/indels, all overlaying with CNV/LOH. SNV/indels and breakpoints are always shown on top of CNV and LOH. Text labels can be shown for SV/fusion/SNV/indel, if available. CNV display and configuration \u00b6 This section applies to both dense and expanded modes. CNVs are horizontal bars, with red for gain and blue for loss, and darkness by the log2(ratio). Hover over a CNV for details: The log2(ratio) color scale from CNVs in the view range is shown in the legend: To prevent outlier log2(ratio) value from skewing the view, the cutoff value is set by the upper whisker value of boxplot ( (3 rd quartile) + 1.5*(interquartile range), if smaller than the maximum value). A size limit may be used to show only focal events but not arm-level events. By default, the size limit is 2 Mb, and CNV segments wider than 2 Mb will not be shown. Click the \"CONFIG\" label at the right of the track to change this cutoff. By setting the size limit to 0, the limit will be disabled and CNV of all sizes will be shown. Similarly, CNVs can be filtered by log2(ratio) value, where CNV with absolute log2(ratio) lower than the cutoff will not be shown. Click on a CNV segment to launch the Sample View, see the section on Sample View . Copy-neutral LOH, display and configuration \u00b6 Same as CNV, the copy-neutral LOH is displayed and configured the same way in both dense and expanded modes. Following example shows the somatic copy-neutral LOH of entire chromosome 17 in adrenal cortical tumors (ACT), retaining the mutant allele of the TP53 germline mutation R337H (blue x). To arrive at this view, you need to disable the LOH segment size limit by setting it to 0. The degree of LOH is determined by the \"seg.mean\" value, see the color scale in the legend: As in CNV, you can choose to show focal LOH using the segment size filter. You can also set a minimum seg.mean value cutoff to drop low-value items. SV and fusion breakpoints in expanded mode \u00b6 In expanded mode, SV and fusion breakpoints are indicated by circles. A text label may be shown on the left or right of the circle. The different colors represent translocating chromosomes, as indicated in legend. The occurrence of multiple breakpoints in a sample are indicated by multiple circles in the same row. Following example shows the translocation hotspot in TCF3 in BALL. The text labels are shown for RNA fusion transcripts, but not genomic SV. Use the CONFIG menu to toggle the label visibility for SV and fusion separately. SNV/indel in expanded mode \u00b6 Here SNV/indels are represented as cross marks, using \"X\" for somatic mutations, and \"+\" for germline mutations. Colors correspond to mutation class (mostly for coding mutations, see \"Mutation\" in legend). For genic mutations, a HGVS styled label can be shown, as is generated by VEP. Toggle label visibility in the CONFIG menu. ITD in the expanded mode \u00b6 ITD is represented as magenta bars over gene coding regions. Gene expression \u00b6 A subset of the pediatric tumors have gene expression profiled by RNA-seq. GenomePaint supports displaying following aspects of gene expression data: Gene expression rank based on FPKM values Allele-specific expression status (ASE) Outlier high expression status RNA-seq coverage and splice junctions (in Sample View) Expression rank \u00b6 This shows the ranking of gene expression in each sample, amongst all samples from the same cancer group: Expression level from a neuroblastoma sample will be compared to expression of this gene in all neuroblastoma samples, but not expression from other cancers. All neuroblastoma samples with available expression data will be used to evaluate the ranking. Expression rankings are rendered as bar plots under the 0 to 100 scale, 0 for lowest among the group, 100 for highest. Hover over a bar to see the actual rank, FPKM value, along with sample attributes. Blank row indicates either there is no expression data for selected gene from that sample, or the sample has no expression data at all. Expression rank for multiple genes \u00b6 It is possible to show expression rank for multiple genes like below. See the section on Fixed genes . Find expression rank when there are no genes in view range \u00b6 When there are no genes in view range, no expression ranking will be shown. In its place, the \"ADD GENE\" phrase will be shown. Clicking \"ADD GENE\" to show a search box; type in gene name to search for a gene. By selecting a gene from the list, the expression ranking of this gene will be added. See the section Fixed genes for details. Allele-specific expression status (ASE) \u00b6 The pediatric tumor gene expression is annotated with the ASE status. This is indicated using bar colors: Hover over a bar to see details about the ASE status. At the bottom of the tooltip, the ASE call is further explained with four fields: #SNPs heterozygous in DNA Total number of heterozygous SNPs in tumor genome over the gene body of this gene, as determined by tumor DNA sequencing #SNPs showing ASE in RNA Number of such heterozygous markers showing mono-allelic expression. A binomial test with p-value cutoff is used to determine if one heterozygous SNP sufficiently deviates from 50%, if so this SNP is \"ASE\". There should be 0 ASE SNPs for bi-allelic expressing genes, and >=1 for mono-allelic expressing genes. Mean delta of ASE SNPs Mean value of (BAF-0.5) for all the markers. BAF: RNA B-allele frequency Q-value First, the binomial p-values of all ASE SNPs for a gene are combined into one value using geometric mean; then, the combined p-values for all genes from a tumor are multiple-test corrected, to obtain this q-value for each gene. GenomePaint uses a decision tree to determine the ASE status of a gene in a sample (mono-allelic, bi-allelic, uncertain). To customize the cutoff values, click the gene label and select \"Customize ASE/OHE parameters\": In the ASE decision tree, three cutoff values are customizable: For ASE, values for number of heterozygous SNPs, number of ASE SNPs, mean delta, and q-value are precomputed (Cis-X, Yu et. al., in submission) and cannot be recomputed on-the-fly. \"Automatic\" genes \u00b6 While you pan and zoom the view range, genes update automatically on the right in the expression column. It always shows the first gene in the view range. When you zoom out and there are multiple genes in the view range, you may want to view some other gene rather than the default leftmost one. Click on the gene label on top of the rank axis and find a list of gene names from the view range. Choose a gene to change. By choosing a gene here, whenever this gene is in the view range, it will always be shown irrespective of its order of appearance. \"Fixed\" genes \u00b6 GenomePaint allows you to show the expression of multiple genes side-by-side: The gene on the left is \"automatic\". The gene on right is added by user, and will be always shown irrespective of the view range, hence the fixed genes . To add a fixed gene, click the gene label on top of the automatic expression rank axis to show the menu. Type into the search box on top of the menu to find matching gene names: Select a gene from the list, and its expression rank will appear as a new column. More than 1 fixed genes can be added. The samples are aligned for both automatic and fixed genes. To remove a fixed gene, click the gene label and select \"Remove\". As an example, while browsing the recurrently duplicated NOTCH1 MYC enhancer locus in TALL, the distal target gene MYC is not in view range, thus its expression is not shown automatically. By adding MYC as a \"fixed gene\", its expression is shown for TALL tumors with enhancer duplication: Filters for samples and genomic variants \u00b6 Here we introduce filters for samples and mutations in Cohort View. Some of these filters can be found in the track legend at the bottom of the page, where the filters are listed as legend entries. Some filters are hidden by default, click \"MORE\" at bottom to show them: Cancer type filter \u00b6 In cohort view, one or more cancer types will be shown on the left of the mutation data display. Click on a cancer name to show a menu: Click \"Hide\" to hide samples of this cancer type; click \"Show only\" to only show samples of this cancer type. In the legend, hidden cancer types are indicated with a strikethrough; click a striked label to turn it back on: Other sample filters \u00b6 You can filter samples by cancer group, sample type, gender, and race, in the same way as cancer type. Mutation class filter \u00b6 Mutation class legend is shown as below. You can select a class and hide it or show it only. Mutation attribute filter \u00b6 Following are attributes describing mutations in each particular sample. Unlike mutation class which annotates a mutation no matter if it is germline or somatic, these attributes are assigned to mutations in each sample. Custom sample subsetting \u00b6 In addition to grouping tumors with predefined cancer types, users can choose to limit the Cohort View to a customly defined sample subset. To do that, click CONFIG, then select the \"Use a sample list\" button. An input box is displayed prompting the user to enter the set of samples. For the moment, space character is reserved for dividing the sample and group names, and cannot be used in either sample or group name. As an example, use the following list of samples that are divided into two groups. SJTALL002030_D1-PARVHY T-ALLs SJALL015249_D1-PARPHB T-ALLs SJALL015260_D1-PARMKK T-ALLs SJALL015268_D1-PASFHR T-ALLs SJALL015278_D1-PARJPL T-ALLs SJALL015280_D1-PARNMV T-ALLs SJALL015285_D1-PASKTG T-ALLs SJTALL002072_D1-PATHJF T-ALLs SJALL015269_D1-PASFKA T-ALLs SJBALL020492_D2-PANKGK B-ALLs SJERG009_D B-ALLs SJPHALL006_D B-ALLs SJBALL020795_D2-PAPIRZ B-ALLs SJETV088_D B-ALLs SJHYPER143_D B-ALLs SJETV059_D B-ALLs SJETV069_D B-ALLs SJHYPER052_D B-ALLs SJBALL020469_D1 B-ALLs SJHYPER013_D B-ALLs The Cohort View will be transformed to showing only these samples in two groups: Click a group label to see options: After submission, a sample set can be edited. To do that, inside the CONFIG menu click on the \"Edit\" button following the \"Restricted to xx samples\" phrase, and open the same input box allowing to edit the list of samples. Click on the \"Remove\" button to cancel the sample subsetting and go back to full Cohort View. Sample subsetting can be applied to custom track as well. Assay availability table \u00b6 The Pediatric cancer dataset is equipped with a feature to show assay availability information for each cancer type. This is important in providing a precise total sample count based on assay type. As an example, T-ALL displays 78 samples with alterations at the TAL1 locus. The \"21%\" percentage is imprecise and only servers as a rough guide, as it doesn't account for assay availability. The track legend shows two DNA assay types for these alterations: SNP6 and \"amplicon sequencing\". In addition there are also fusion events from RNA-seq. Thus, to compute the percentage of T-ALLs with TAL1 locus alteration, one needs the total number of T-ALLs with either SNP6, amplicon sequencing, or RNA-seq. To get the actual total number, click the \"HM, TALL\" label on the left and select \"Assay summary\" option. The assay availability for T-ALL is displayed as a map below. The map is an assay-by-sample matrix, with assays as rows and samples as columns. All assays available for T-ALLs are included. By default, the assays are arranged from top to bottom in descending order of sample counts (RNA and WES being the most abundant). Inside the matrix, a gray box indicates a set of samples having a particular assay type. The number of samples are always printed out for each box. The sample columns are sorted by their presence of each assay type, by the order of assays from top to bottom. In the T-ALL case, the samples are first sorted by RNA-seq, with 267 that have RNA-seq and 86 without (number not printed). Next, WES availability is sorted separately for the box and blank from the first row, resulting in two boxes and two blanks. Next, the SNP6 availability is sorted separately in each box and blank in the second row. So on for every other assay type. Importantly, the width of the gray boxes are not scaled by the number of samples, but rather symbolic representations of the cohort partitioning. Though not to scale, the boxes are vertically aligned with columns being groups of samples. Better than a Venn diagram, this assay availability map solidifies a comprehensible view with as many as 6 assay types. As the order of assay types is important for the map, users can adjust the row order by dragging a label up or down. As below, the RNA-seq, SNP6, and Capture-seq rows are moved to the top, yielding a total of 337 samples (267+70) for the samples with TAL1 locus alterations. Kaplan-Meier plot \u00b6 Patient outcome (event-free and overall survival) information is available for 1102 samples (6 histotypes) from the \"Pan-TARGET\" study (Ma, X. et al. Nature 2018). GenomePaint provides following ways to stratify this cohort using genomic alteration or gene expression, and to perform the Kaplan-Meier analysis to assess what clinical outcome does the genomic feature lead to. The analysis will compute the p value using the G-rho family of tests (the \"survdiff\" function in R), as well as plotting the survival curves. Kaplan-Meier analysis is performed on each individual cancer type. With genomic alterations \u00b6 This usually applies to recurrent mutations/alterations, or frequently mutated regions, as sufficient number of mutated samples may be required for the analysis. With a specific mutation/alteration \u00b6 CDKN2A/2B is recurrently deleted in acute lymphoblastic leukemia. To see how this deletion may impact clinical outcome, visit CDKN2A locus in GenomePaint, and select a deletion spanning the locus to show a panel (left). On top of this panel, select the \"Survival plot\". This will use the range of this particular deletion to stratify tumors: samples with deletions overlapping with this range will be separated from samples that don't. As a result, a survival curve like below can be shown for BALL. Such procedure can be applied to other types of mutation/alteration as well. If a CNV is selected, samples may be divided to up to three groups (gain, loss, no change). If any other type of alteration is selected, samples will be divided into just two groups (with mutation, no mutation). With any alterations from a chosen genomic interval \u00b6 MYB is subject to multiple types of genomic alterations in TALL, including amplification, activating mutation, intragenic and intergenic translocations. To collectively consider the effect of these alterations on TALL patient outcome, view data in the range chr6:135482339-135674218 (hg19), a 190 Kb region around MYB, which will include coding mutations, amplification, and intergenic translocations that have been found to cause MYB activation. Then, click on the \"HM, TALL\" label on the left and select the \"Survival plot\" option. This will select TALL patients with any variant in the view range into the \"mutated\" group, for comparing with the \"no mutation\" group in the Kaplan-Meier analysis. CNV, LOH parameter settings and mutation class filter will be applied to filter alteration events in the survival plot. With FPKM values of a chosen gene \u00b6 MDM2 overexpression may lead to shortened half-life of P53 protein, thus may lead to worse outcome in cancer patients. To test this hypothesis, show MDM2 in GenomePaint. On the right of gene expression rank plot, click \"MDM2\" label, then select \"Survival plot by MDM2 FPKM\". This will perform the analysis on BALL by default, using MDM2 median expression as cutoff to divide the samples to two groups. Switch the cancer type to AML, and median into quartile, to view the plot showing high MDM2 expression is correlated with worse outcome in AML. Sample View \u00b6 From Cohort View, click any type of mutation to show a panel; at the left of this panel, click the \"Sample View\" button to show a new browser view showing data tracks from this sample in a region surrounding the mutation: Pediatric tumors in Sample View \u00b6 Mutation data in Sample View \u00b6 The Sample View shows a number of tracks, one of them is the mutations, named \"Pediatric tumor mutation, \". In the example below, a Wilms' tumor shows 4 different types of mutations over the MYCN gene, including copy number gain, LOH (not copy-neutral), SV supporting this CNV, and a coding mutation in MYCN. Mutation signature \u00b6 In the above example, the missense mutation is colored in green because of its mutation signature assignment in that sample. Mutation signature is available for 915 tumors from the Pan-TARGET study (Ma, X et al. Nature 2018). For such tumors, their mutations in Sample View will be colored by assigned signatures. Users can also view the mutation signature abundance for a sample by clicking the \"Mutation signature\" button on top. Multi-region display for inter-chromosomal SV \u00b6 When a user clicks on an inter-chromosomal SV and launches Sample View, the view will contain a pair of regions each containing one breakpoint, from two chromosomes. Regions are spaced by a vertical gray bar. The following example shows a pair of genomic regions upon clicking the ETV6-ABL1 fusion transcript in a TALL sample; the left region with ETV6 is chr12, and the right-side region with ABL1 is chr9. To zoom in on either region, drag on the coordinate ruler on top of one region. To zoom out on the left-side region, click the \"zoom out\" buttons. To zoom out on the right-side region, instead of clicking on the \"zoom out\" buttons, hover and show an option on top, click that option to zoom the right-side region. Sequencing coverage and allelic-imbalance tracks in single-sample view \u00b6 GenomePaint aims to provide comprehensive genomics information to assist in interpreting mutations from individual tumors. This includes additional genomic assay tracks on individual tumors if they are available to us. Following is a typical example: In the above example, it shows coverage of WGS and RNA-seq of tumor, and the allelic-imbalance from the tumor-normal paired WGS results. Learn more about the allelic-imbalance track . Hi-C data from pediatric cancer cell lines \u00b6 GenomePaint provides the detailed genomic and epigenomic assaying results of a set of pediatric cancer cell lines to supplement the primary tumor mutation dataset. Currently there are six neuroblastoma cell lines (SKNAS, NB69, Kelly, BE2C, NGP, SH-SY5Y) and one BALL cell line (NALM6), all grouped with primary tumors of the same cancer type. When a cell line appears in the genomic mutation data panel, it will be marked by a black notch on left: These cell lines all come with in-situ Hi-C data, in addition to the histone modification ChIP-seq. These tracks will be shown in the single-sample view of these cell lines. Learn more about the Hi-C track . Matrix View \u00b6 Matrix View is a light-weight method for combining multiple genomic regions into one view so as to compare their mutational profiles over a group of samples, via a sample-by-region matrix: Such a matrix can be generated for samples from one cancer type. Following demonstrates how to use the Matrix View to observe the MYCN-ATRX mutual exclusivity in neuroblastoma. First, show the NBL mutation profile at the MYCN locus. By default MYCNOS gene is showing for the expression rank, change it to MYCN. This can allow the region to be named as \"MYCN\" rather than \"MYCNOS\" in the Matrix View. Click on the \"ST, NBL\" label on left, and select \"Matrix view\". This gathers the group of NBL tumors with mutations in MYCN into a single-column matrix. Back to the Cohort View. Type \"atrx\" into the coordinate box and press ENTER. Cohort View now shows ATRX mutations from NBL. Click the \"ST, NBL\" label on the left, and select \"Matrix View\". This will add ATRX as a new column alongside MYCN in the Matrix View. It shows that the majority of NBL tumors only display alteration at one gene. Custom track \u00b6 Feature availability \u00b6 Features available for custom track: All types of mutations are supported, including SNV/indel, CNV, LOH, SV, fusion, ITD. Gene expression FPKM values and ranking are supported, together with ASE status. Customizing ASE parameters. Cohort View: Showing mutation profile. Mutation annotation with user-defined attributes; this is for display only and cannot be used for filtering. Computing and displaying gene expression rank among all samples. Custom sample subsetting. Sample View: Displaying mutation track, as well as multi-region view triggered by inter-chromosomal SV. Gene expression rank from all samples. Joining of SV breakpoint regions. Matrix View. Customizing CNV/LOH parameters (log2ratio, seg.mean, max size limit) and mutation class in all Views Works for any supported genome assemblies, including hg19, hg38, mm9, mm10 Features not available for custom track: Predefined sample grouping and filtering by cancer types. Mutation filtering. Mutation signature. Support of genomic assay tracks in Sample View. Kaplan-Meier analysis. Example \u00b6 This URL shows the TCGA DLBC (diffuse large B-cell lymphoma) as a custom track in the human hg38 genome. https://proteinpaint.stjude.org/?block=on&genome=hg38&position=chr9:21843776-22119276&svcnvfpkmurl=TCGA_DLBC,svcnv,https://pecan.stjude.cloud/static/hg38/tcga-gdc/DLBC/TCGA_DLBC.CNV.gz,fpkm,https://pecan.stjude.cloud/static/hg38/tcga-gdc/DLBC/TCGA_DLBC.fpkm.gz,vcf,https://pecan.stjude.cloud/static/hg38/tcga-gdc/DLBC/TCGA_DLBC.vcf.gz It consists of SNV/indels (VCF format), SVCNV (tailored JSON-BED format), and FPKM (tailored JSON-BED format). The URLs for each file: SVCNV https://pecan.stjude.cloud/static/hg38/tcga-gdc/DLBC/TCGA_DLBC.CNV.gz FPKM https://pecan.stjude.cloud/static/hg38/tcga-gdc/DLBC/TCGA_DLBC.fpkm.gz VCF https://pecan.stjude.cloud/static/hg38/tcga-gdc/DLBC/TCGA_DLBC.vcf.gz Either SVCNV or VCF track is required to launch a custom track; FPKM track is optional. Tools required \u00b6 bcftools , 1.9 tabix and bgzip , 1.9 Download all from http://www.htslib.org/download/ VCF file \u00b6 The VCF file stores SNV/indel mutations for a group of samples. GenomePaint requires VCF format version 4.2: https://samtools.github.io/hts-specs/VCFv4.2.pdf Functional annotation of variants using VEP \u00b6 Functional annotation of variants is optional but helpful. VEP is recommended. See details at https://useast.ensembl.org/info/docs/tools/vep/index.html Preparing a VCF track file \u00b6 The VCF text file needs to be sorted, then compressed and indexed to make the track file. bcftools sort FILE.vcf -o FILE.sorted.vcf bgzip FILE.sorted.vcf tabix -p vcf FILE.sorted.vcf.gz The resulting files \"FILE.sorted.vcf.gz\" and \"FILE.sorted.vcf.gz.tbi\" are the VCF track files. Put both under the same directory to be used as custom tracks. SVCNV file \u00b6 \"SVCNV\" is the nickname for the file storing all other types mutations except SNV/indel, which are CNV, LOH, SV, fusion, ITD, for a group of samples. The file uses a uniform format to represent different mutation data, which consists of 4 tab-separated columns. Each line represents one variant in a sample. First three columns are genomic positions for indexing (chr, start, stop, 0-based), the fourth column is a JSON object. CNV example: chr1 10000 10927712 {\"dt\": 4, \"sample\": \"SJMB015_D\", \"value\": -0.45} chr1 10000 151005400 {\"dt\": 4, \"sample\": \"SJMB008_D\", \"value\": 0.585} chr1 10000 25392551 {\"dt\": 4, \"sample\": \"SJRB003_D\", \"value\": -0.4150} \"dt\":4 identifies this item is a CNV \"value\" is log2(ratio) LOH example: chr1 55976 185392845 {\"dt\":10,\"sample\":\"SJCOGALL010918_D2-PAPJXI\",\"segmean\":0.068} chr1 55976 249195965 {\"dt\":10,\"sample\":\"SJAML040586_D1-PARFAL\",\"segmean\":0.068} chr1 55976 249208343 {\"dt\":10,\"sample\":\"SJAML040508_D1-PAKERZ\",\"segmean\":0.073} \"dt\":10 identifies this item is LOH \"segmean\" is the seg.mean value, range between 0 and 0.5 Your file can contain all the LOH segments, they don't need to be limited to copy-neutral ones; GenomePaint will always show copy-neutral LOH by on-the-fly comparison to CNV, in cohort view. SV example: chr12 12029972 12029972 {\"chrB\": \"chr21\", \"dt\": 5, \"posB\": 36417895, \"sample\": \"SJETV039_D\", \"strandA\": \"+\", \"strandB\": \"-\"} chr21 36417895 36417895 {\"chrA\": \"chr12\", \"dt\": 5, \"posA\": 12029972, \"sample\": \"SJETV039_D\", \"strandA\": \"+\", \"strandB\": \"-\"} \"dt\":5 identifies this item is structural variation in DNA (as opposed to RNA fusion) Each SV has two breakpoints: chrA:posA \u2192 chrB:posB; it must be represented as two lines in the data file, no matter if chrA is the same as chrB or not. Line 1 chrA \\t posA \\t posA \\t {\"dt\":5, \"chrB\":.., \"posB\":..., \"strandA\": \"+\", \"strandB\": \"-\", ... } Line 2 chrB \\t posB \\t posB \\t {\"dt\":5, \"chrA\":.., \"posA\":..., \"strandA\": \"+\", \"strandB\": \"-\", ... } Fusion example: chr1 19157328 19157328 {\"chrB\": \"chr13\", \"dt\": 2, \"geneA\": \"chr1\", \"geneB\": \"VWA8\", \"posB\": 42278669, \"sample\": \"SJRHB009_D\", \"strandA\": \"-\", \"strandB\": \"+\"} chr1 19157486 19157486 {\"chrA\": \"chr13\", \"dt\": 2, \"geneA\": \"VWA8\", \"geneB\": \"chr1\", \"posA\": 42278658, \"sample\": \"SJRHB009_D\", \"strandA\": \"+\", \"strandB\": \"-\"} Fusion is the same as SV except dt is 2. ITD example: chr8 128752721 128753187 {\"dt\": 6, \"gene\": \"MYC\", \"isoform\": \"NM_002467\", \"sample\": \"SJTALL002080_D1-PATHWV\"} chr8 128752763 128753183 {\"dt\": 6, \"gene\": \"MYC\", \"isoform\": \"NM_002467\", \"sample\": \"SJERG029_D\"} chr8 128752802 128753109 {\"dt\": 6, \"gene\": \"MYC\", \"isoform\": \"NM_002467\", \"sample\": \"SJAML040570_D1-PAPXRJ\"} chr8 128752821 128753186 {\"dt\": 6, \"gene\": \"MYC\", \"isoform\": \"NM_002467\", \"sample\": \"SJCOGALL010220_D1-PANTSM\"} Preparing a SVCNV track file \u00b6 For a group of samples, concatenate the 4-column text data of every type of mutation into a single text file. Do the following to prepare the track file. sort -k1,1 -k2,2n FILE > FILE.sorted bgzip FILE.sorted tabix -p bed FILE.sorted.gz The resulting files \"FILE.sorted.gz\" and \"FILE.sorted.gz.tbi\" are the SVCNV track files. Put both under the same directory to be used as custom tracks. Annotating variants in SVCNV file \u00b6 Variant annotation provides a useful way to record attributes pertinent to each particular variant. Suppose we want to process the CNV calls from a group of tumors. Some of the tumors are analyzed by SNP array, others by sequencing, still others by both. When browsing such CNV data, it may be useful to tell the assaying type for a CNV. For that we can annotate the CNV in the following way: {\"dt\":4,\"sample\":\"sample\",\"value\":0.5, \"mattr\":{\"dna_assay\":\"snp6\"} } In the JSON object of this CNV, the \" mattr \" attribute points to a key-value pair. Here \"dna_assay\" is used to indicate the assay type, which will show up in the tooltip like below. FPKM gene expression \u00b6 Gene expression value such as FPKM is optional in a GenomePaint track. If provided, it should be encoded in a text format like below: chr1 69090 70008 {\"value\":0.00109218,\"sample\":\"SJBALL021486_D1\",\"gene\":\"OR4F5\"} chr1 69090 70008 {\"value\":0.00109218,\"sample\":\"SJHGG075_A\",\"gene\":\"OR4F5\"} chr1 69090 70008 {\"value\":0.00109335,\"sample\":\"SJRHB044_M\",\"gene\":\"OR4F5\"} chr1 69090 70008 {\"value\":0.00109946,\"sample\":\"SJEPD007_D\",\"gene\":\"OR4F5\"} chr1 69090 70008 {\"value\":0.00110745,\"sample\":\"SJHGG015_D\",\"gene\":\"OR4F5\"} chr1 69090 70008 {\"value\":0.00111458,\"sample\":\"SJHGG103_D\",\"gene\":\"OR4F5\"} Each line represents the FPKM value of one gene in one sample. File has 4 columns, separated by tabs: Chromosome name of the gene Start position of the gene, 0-based Stop position of the gene, non-inclusive JSON object with keys: \" value \": FLOAT FPKM value for this gene in this sample, positive real number \" sample \": STR Sample name \" gene \": STR Gene name Preparing a FPKM track file \u00b6 Use the same procedure as the SVCNV track. Annotating gene expression with ASE/OHE status \u00b6 ASE (allele-specific expression) status can be indicated using the \" ase \" key in the JSON object of FPKM data: { \"sample\" : \"SJTALL002124_D1-PATWYL\" , \"value\" : 17.2244 , \"gene\" : \"TAL1\" , \"ase\" : { \"markers\" : 1 , \"ase_markers\" : 1 , \"mean_delta\" : 0.5 , \"qvalue\" : 0.00163916385535038 } } See Allele-specific expression status on how the ASE status is determined based on the constituent values from \"ase\". OHE (outlier high expression) status can be indicated as below in the JSON object of FPKM data. { \"sample\" : \"SJTALL022442_D2-PATFRM\" , \"value\" : 3.8905 , \"gene\" : \"TAL1\" , \"outlier\" : { \"test_entirecohort\" : { \"size\" : 263 , \"pvalue\" : 0.353723919266382 , \"rank\" : 111 }, \"test_whitelist\" : { \"size\" : 166 , \"pvalue\" : 0.0810415523178093 , \"rank\" : 22 } } } Hosting custom track \u00b6 SVCNV, VCF, and FPKM track files all have the .tbi index file; put each pair of files inside the same folder on a web server. Obtain the URL to each of the .gz file for submitting the custom track. E.g. given this URL: http://domain/path/to/file.gz The corresponding index file should be found at http://domain/path/to/file.gz.tbi Displaying custom track \u00b6 URLs of the SVCNV, VCF, and FPKM .gz files can be submitted to https://proteinpaint.stjude.org for display, provided that the hosting server is publicly accessible on the Internet. By showing your custom track, ProteinPaint server will download the index files, which do not contain actual mutations or expression data stored in the .gz files. ProteinPaint will not download the .gz files. Via URL \u00b6 The track URLs can be appended to the \"svcnvfpkmurl\" parameter like below: https://proteinpaint.stjude.org?block=on&genome=[GENOME]&svcnvfpkmurl=[TRACKNAME],svcnv,[svcnv_URL],vcf,[vcf_URL],fpkm,[fpkm_URL] [GENOME] The name of a reference genome e.g. hg19 or hg38 [TRACKNAME] Track name, no comma [svcnv_URL] URL to the SVCNV .gz file [vcf_URL] URL to the VCF .gz file [fpkm_URL] URL to the FPKM .gz file There is no required order of precedence for \"svcnv\", \"vcf\", and \"fpkm\". However, each must be followed by the respective URL. Example: https://proteinpaint.stjude.org/?block=on&genome=hg38&position=chr9:21843776-22119276&svcnvfpkmurl=TCGA_DLBC,svcnv,https://pecan.stjude.cloud/static/hg38/tcga-gdc/DLBC/TCGA_DLBC.CNV.gz,fpkm,https://pecan.stjude.cloud/static/hg38/tcga-gdc/DLBC/TCGA_DLBC.fpkm.gz,vcf,https://pecan.stjude.cloud/static/hg38/tcga-gdc/DLBC/TCGA_DLBC.vcf.gz Either svcnv_URL or vcf_URL is required; FPKM URL is optional. E.g. a SVCNV track with FPKM but not VCF would be like: https://proteinpaint.stjude.org?block=on&genome=[GENOME]&svcnvfpkmurl=[TRACKNAME],svcnv,[svcnv_URL],fpkm,[fpkm_URL] Such URLs can be bookmarked, emailed, shared, or tweeted. More on the ProteinPaint URL parameters . Via embedding API \u00b6 This API allows the visualization to be customized and embedded into another web page. Example: <!DOCTYPE html> < html > < head > < meta charset = \"utf-8\" > </ head > < body > < script src = \"https://proteinpaint.stjude.org/bin/proteinpaint.js\" charset = \"utf-8\" ></ script > < div id = aaa style = \"margin:10px\" ></ div > < script > runproteinpaint ({ host : 'https://proteinpaint.stjude.org' , holder : document . getElementById ( 'aaa' ), genome : 'hg38' , block : 1 , position : 'chr9:21953975-22009075' , tracks : [ { type : 'mdssvcnv' , name : 'TCGA DLBC' , url : 'https://pecan.stjude.cloud/static/hg38/tcga-gdc/DLBC/TCGA_DLBC.CNV.gz' , checkexpressionrank : { datatype : 'FPKM' , url : 'https://pecan.stjude.cloud/static/hg38/tcga-gdc/DLBC/TCGA_DLBC.fpkm.gz' }, checkvcf : { url : 'https://pecan.stjude.cloud/static/hg38/tcga-gdc/DLBC/TCGA_DLBC.vcf.gz' }, mutationAttribute : { attributes : { dna_assay : { label : 'DNA assay' , values : { snp6 : { name : 'SNP 6.0' , label : 'genotyping array' } } } } } } ], nativetracks : 'RefGene' , noheader : true , nobox : true }) </ script > </ body > </ html > Save above contents to an HTML file (as a text file, not MS Word). Open the HTML file in a web browser and the track should load up. Substitute the example URLs with your actual ones to show your data. More on the ProteinPaint embedding API . Hosting and launching custom GenomePaint track from DNAnexus \u00b6 DNAnexus provides a secure way to host unpublished/sensitive genomics data to be used as custom GenomePaint track. In doing so, randomized URLs are produced to point to your files hosted in the DNAnexus platform, expiring in 24 hours. Through the FileViewer mechanism , GenomePaint accesses these URLs and launches the track. Only the index portions of your files will be downloaded to the GenomePaint server, but not any actual genomics data. The index files do not contain actual genomics data. To begin, you need to sign up on DNAnexus at https://www.dnanexus.com/ . Next, store your track files on the platform by uploading them to a \"project folder\". For example, following files \"TCGA_DLBC.*\" have been stored in the folder. Follow the instructions in the next section to obtain the GenomePaint FileViewer . Once obtained, the FileViewer looks like below in your account. Click the FileViewer to open up the file selection interface. Select the necessary track files. Click the button \"Launch viewer\" at bottom right. The Viewer will start up by prompting you to select the correct genome build for your data. By selecting a genome build, GenomePaint will launch and show your custom track. Obtaining the GenomePaint FileViewer on DNAnexus \u00b6 Install the \"dx-toolkit\" on your computer by following instructions on https://documentation.dnanexus.com/downloads Once installed, you will be able to run the \"dx\" command on your computer. Next, login at the dx-toolkit with your token. To obtain a token, at a web browser, log yourself in at https://platform.dnanexus.com/ . Click the top-right user icon and select \"My Profile\". Then, click the \"API Tokens\" tab. Then click the \"+ New Token\" button. At the prompt, enter a label and click \"Generate Token\". The token is now displayed. Select and copy it. At the terminal of your computer, log into \"dx\" with the token. dx login --token TvmrnvgkHeyYouCanChargeYourElectricCarForFreeAtWork # Available projects (CONTRIBUTE or higher): # \u2026 here lists your projects \u2026 # Pick a numbered choice: Enter a number to select a project. You are now logged into your account. Run dx ls to do a directory listing on the selected project. Next, upload the GenomePaint FileViewer to this project. Run this command to download the FileViewer source code, to a file named \"GenomePaint (SVCNV, VCF, FPKM)\". wget 'https://pecan.stjude.cloud/static/fileviewers/GenomePaint%20(SVCNV%2C%20VCF%2C%20FPKM)' Run this command to upload the file to your DNAnexus project as a FileViewer. dx upload --type FileViewer 'GenomePaint (SVCNV, VCF, FPKM)' # [===========================================================>] Uploaded 5,257 of 5,257 bytes (100%) /.../GenomePaint (SVCNV, VCF, FPKM) # ID file-Fjypgf... # Class file # Project project-F0QQBv... # Folder / # Name GenomePaint (SVCNV, VCF, FPKM) # State closing # Visibility visible # Types FileViewer # Properties - # Tags - # Outgoing links - # Created Fri Feb 7 12:26:32 2020 # Created by xzhou # Last modified Fri Feb 7 12:26:33 2020 # archivalState \"live\" # Media type With this, you have successfully obtained the GenomePaint FileViewer on your DNAnexus account. Hosting and launching custom GenomePaint track from Amazon AWS \u00b6 Amazon S3 Introduction \u00b6 Amazon AWS has secure and highly available storage service known as S3. Amazon S3 stores data as objects within buckets. An object consists of a file and optional metadata. To store an object in Amazon S3, you upload a file to a bucket. When uploading, you can set permissions on the object and any metadata. Likewise many settings can be configured for a bucket. To get familiarized with common terminologies used for Amazon S3, checkout the official guide . Sign Up for Amazon S3 \u00b6 Go to https://aws.amazon.com/s3/ and click \"Create an AWS account\". Once created, AWS will notify you by email when your account is active and available for you to use. Create a new Bucket on S3 \u00b6 Login to your account and access the \"S3 Management Console\" at https://console.aws.amazon.com/s3/ . Here, click the \"+ Create bucket\" button. A new window pops up with details required for creating a new bucket. In the 'Bucket name' box enter a unique DNS-compliant name. This name should be unique across all buckets on Amazon S3. The URL for the objects inside the bucket will include the bucket name as well. At \"Configure options\", you can change the settings or keep default as per requirements. At \"Set permissions\", make the bucket public so files can be accessible from GenomePaint. To make the Bucket public, leave all the checkboxes unchecked. Next page will summarize all settings for the new bucket. After confirming, click \"Create bucket\". Add custom track files to a Bucket \u00b6 Select the bucket you want files to upload to. Then, click the \"Upload\" button. On the next page, select all the GenomePaint track files and associated index files for uploading. Once a file is selected, it will appear in the menu. Click 'Upload' at the bottom. Make sure to add index files (.tbi and .csi) with the vcf, svcnv or fpkm files. Enable public access to the track files \u00b6 Once the file is uploaded to the bucket, it will appear in the list of files. Select all the files you want to visualize in the GenomePaint. Click \"Actions\" and select \"Make public\" option. A window will pop-up to confirm the action. Submit a custom track from S3 to GenomePaint \u00b6 First, obtain the URLs to the SVCNV, VCF, FPKM \".gz\" files. Click on a \".gz\" file to see a detailed page and find its URL at the bottom. Add the URLs as parameters of the following GenomePaint URL. https://proteinpaint.stjude.org?block=on&genome=[GENOME]&svcnvfpkmurl=[TRACKNAME],svcnv,[svcnv_URL],vcf,[vcf_URL],fpkm,[fpkm_URL] For example, https://proteinpaint.stjude.org/?block=on&genome=hg38&position=chr9:21843776-22119276&svcnvfpkmurl=TCGA_DLBC,svcnv,https://genomepaint-test.s3.amazonaws.com/TCGA_DLBC.CNV.gz,vcf,https://genomepaint-test.s3.amazonaws.com/TCGA_DLBC.vcf.gz This URL will serve as visualization access point for your files in the Amazon S3.","title":"User Guide"},{"location":"guides/genomepaint/#introduction","text":"GenomePaint officially hosts the pediatric cancer mutation and gene expression dataset, available for the human hg19 reference genome.","title":"Introduction"},{"location":"guides/genomepaint/#accessing-genomepaint","text":"GenomePaint is accessible from https://proteinpaint.stjude.org/genomepaint . This front page provides following contents: Visualization of the pediatric cancer dataset over the hg19 reference genome Custom track submission available for multiple species and genome assemblies. Links to live Figures of the manuscript, this tutorial, and the user community on Google Group.","title":"Accessing GenomePaint"},{"location":"guides/genomepaint/#genome-browser-navigation","text":"By default, the pediatric cancer dataset is shown in a ProteinPaint genome browser. Following are instructions to navigate the genome browser. To pan left or right, drag on the middle part of the track. To zoom in, drag on the genomic coordinate ruler on top, or click the \"In\" button. To zoom out, click a zoom out button on top of the genome browser.","title":"Genome browser navigation"},{"location":"guides/genomepaint/#from-the-protein-view","text":"To view the dataset in a protein view, go to https://proteinpaint.stjude.org . At the top search bar, type in the gene name and display the gene. Make sure \"hg19\" is selected at the drop down menu. Then click \"Pediatric2\" on top, and select \"Pediatric tumor mutation\" to show the dataset over the protein view of the gene.","title":"From the protein view"},{"location":"guides/genomepaint/#transitioning-from-genome-view-to-protein-view","text":"When viewing a gene locus using the genome browser, ProteinPaint offers to easily transition into protein view, so you can examine the GenomePaint track or any other current set of tracks over the protein view.","title":"Transitioning from genome view to protein view"},{"location":"guides/genomepaint/#three-viewpoints","text":"GenomePaint offers Cohort View , Sample View , and Matrix View , connected as below. Cohort View : showing mutations from all samples over a genomic region, along with the gene expression ranks for each of the samples. Dense mode : a compact display showing density plots for SVs and SNV/indels Expanded mode : all types of mutations are aligned by samples, one row per sample Sample View : showing mutations for one sample alone, along with any available genomic assay tracks. Matrix View : combining the mutation profiles of multiple genomic regions in one view, in the form of a sample-by-region matrix.","title":"Three viewpoints"},{"location":"guides/genomepaint/#cohort-view","text":"Cohort View connects DNA alterations with gene expression across a cohort. It shows in either \"dense\" or \"expanded\" mode.","title":"Cohort View"},{"location":"guides/genomepaint/#dense-mode","text":"By default, the \"Pediatric tumor mutation\" track displays the cohort-view compactly in \"dense\" mode. This view is consisted of following parts: SNV/indel and SV/fusion breakpoint density plots on top; Cancer group labels on left; CNV and LOH segment plots in the center; Gene expression ranking on right; Legends at bottom.","title":"Dense mode"},{"location":"guides/genomepaint/#mutation-and-breakpoint-density-plot-in-dense-mode","text":"At the top, dots indicate the density of SV breakpoints and SNV/indels from every sample combined. Dot size represents the number of samples. For SNV/indel, dot colors represent mutation classes. For SV, each dot represents one or more samples from the same cancer type. Hover over a dot for details: Above example shows KRAS gene locus at a low resolution and its exon as a thin sliver. All missense mutations from that exon are represented by one big dot. Zoom in on the exon and the large dot will break up to smaller dots. Zooming in at base-pair level, each dot now represents the collection of all mutations at one base-pair; it's also positioned to that base-pair. Clicking on a dot to show the actual list of mutations. From this panel, hover over a sample to see sample-level information about this mutation.","title":"Mutation and breakpoint density plot in dense mode"},{"location":"guides/genomepaint/#dbsnp-and-clinvar-matching","text":"At the bottom of the mutation tooltip shows if any dbSNP or ClinVar entry matches with the mutation. Either match will be shown as URL links to their respective databases. (You can't click the link in a mouse-hover tooltip; simply click on the mutation from GenomePaint to show the information panel with this information, there you will be able to click the dbSNP or ClinVar link. The panel will only go away if you choose to hide it) This matching is conducted on-the-fly using GenomePaint's backend databases, and is also available to a hg19 or hg38 custom GenomePaint track which does not need to pre-annotate its variants with the dbSNP or ClinVar.","title":"dbSNP and ClinVar matching"},{"location":"guides/genomepaint/#cnvloh-in-dense-mode","text":"In this part, GenomePaint shows CNV/LOH and expression rank aligned by rows, one row per sample. CNV and LOH events are shown as thin horizontal lines, identified by color: Red: copy number gain Blue: copy number loss Gray: LOH In all cases, the color darkness represents the degree of the event, see color scales in legend. Samples are grouped by cancer type, as shown by the cancer type names on the left. Each cancer type is labeled by abbreviations. Hover over the label for details. You can filter mutation data by cancer type. See section Cancer type filter .","title":"CNV/LOH in dense mode"},{"location":"guides/genomepaint/#expanded-mode","text":"On the top right, click \"CONFIG\" to show the configuration menu, then choose \"Expanded\" to go into expanded mode: The expanded mode looks like below: In expanded mode, all mutations for each sample are shown in the same row. Circles represent SV/fusion breakpoints, and x marks represent SNV/indels, all overlaying with CNV/LOH. SNV/indels and breakpoints are always shown on top of CNV and LOH. Text labels can be shown for SV/fusion/SNV/indel, if available.","title":"Expanded mode"},{"location":"guides/genomepaint/#cnv-display-and-configuration","text":"This section applies to both dense and expanded modes. CNVs are horizontal bars, with red for gain and blue for loss, and darkness by the log2(ratio). Hover over a CNV for details: The log2(ratio) color scale from CNVs in the view range is shown in the legend: To prevent outlier log2(ratio) value from skewing the view, the cutoff value is set by the upper whisker value of boxplot ( (3 rd quartile) + 1.5*(interquartile range), if smaller than the maximum value). A size limit may be used to show only focal events but not arm-level events. By default, the size limit is 2 Mb, and CNV segments wider than 2 Mb will not be shown. Click the \"CONFIG\" label at the right of the track to change this cutoff. By setting the size limit to 0, the limit will be disabled and CNV of all sizes will be shown. Similarly, CNVs can be filtered by log2(ratio) value, where CNV with absolute log2(ratio) lower than the cutoff will not be shown. Click on a CNV segment to launch the Sample View, see the section on Sample View .","title":"CNV display and configuration"},{"location":"guides/genomepaint/#copy-neutral-loh-display-and-configuration","text":"Same as CNV, the copy-neutral LOH is displayed and configured the same way in both dense and expanded modes. Following example shows the somatic copy-neutral LOH of entire chromosome 17 in adrenal cortical tumors (ACT), retaining the mutant allele of the TP53 germline mutation R337H (blue x). To arrive at this view, you need to disable the LOH segment size limit by setting it to 0. The degree of LOH is determined by the \"seg.mean\" value, see the color scale in the legend: As in CNV, you can choose to show focal LOH using the segment size filter. You can also set a minimum seg.mean value cutoff to drop low-value items.","title":"Copy-neutral LOH, display and configuration"},{"location":"guides/genomepaint/#sv-and-fusion-breakpoints-in-expanded-mode","text":"In expanded mode, SV and fusion breakpoints are indicated by circles. A text label may be shown on the left or right of the circle. The different colors represent translocating chromosomes, as indicated in legend. The occurrence of multiple breakpoints in a sample are indicated by multiple circles in the same row. Following example shows the translocation hotspot in TCF3 in BALL. The text labels are shown for RNA fusion transcripts, but not genomic SV. Use the CONFIG menu to toggle the label visibility for SV and fusion separately.","title":"SV and fusion breakpoints in expanded mode"},{"location":"guides/genomepaint/#snvindel-in-expanded-mode","text":"Here SNV/indels are represented as cross marks, using \"X\" for somatic mutations, and \"+\" for germline mutations. Colors correspond to mutation class (mostly for coding mutations, see \"Mutation\" in legend). For genic mutations, a HGVS styled label can be shown, as is generated by VEP. Toggle label visibility in the CONFIG menu.","title":"SNV/indel in expanded mode"},{"location":"guides/genomepaint/#itd-in-the-expanded-mode","text":"ITD is represented as magenta bars over gene coding regions.","title":"ITD in the expanded mode"},{"location":"guides/genomepaint/#gene-expression","text":"A subset of the pediatric tumors have gene expression profiled by RNA-seq. GenomePaint supports displaying following aspects of gene expression data: Gene expression rank based on FPKM values Allele-specific expression status (ASE) Outlier high expression status RNA-seq coverage and splice junctions (in Sample View)","title":"Gene expression"},{"location":"guides/genomepaint/#expression-rank","text":"This shows the ranking of gene expression in each sample, amongst all samples from the same cancer group: Expression level from a neuroblastoma sample will be compared to expression of this gene in all neuroblastoma samples, but not expression from other cancers. All neuroblastoma samples with available expression data will be used to evaluate the ranking. Expression rankings are rendered as bar plots under the 0 to 100 scale, 0 for lowest among the group, 100 for highest. Hover over a bar to see the actual rank, FPKM value, along with sample attributes. Blank row indicates either there is no expression data for selected gene from that sample, or the sample has no expression data at all.","title":"Expression rank"},{"location":"guides/genomepaint/#expression-rank-for-multiple-genes","text":"It is possible to show expression rank for multiple genes like below. See the section on Fixed genes .","title":"Expression rank for multiple genes"},{"location":"guides/genomepaint/#find-expression-rank-when-there-are-no-genes-in-view-range","text":"When there are no genes in view range, no expression ranking will be shown. In its place, the \"ADD GENE\" phrase will be shown. Clicking \"ADD GENE\" to show a search box; type in gene name to search for a gene. By selecting a gene from the list, the expression ranking of this gene will be added. See the section Fixed genes for details.","title":"Find expression rank when there are no genes in view range"},{"location":"guides/genomepaint/#allele-specific-expression-status-ase","text":"The pediatric tumor gene expression is annotated with the ASE status. This is indicated using bar colors: Hover over a bar to see details about the ASE status. At the bottom of the tooltip, the ASE call is further explained with four fields: #SNPs heterozygous in DNA Total number of heterozygous SNPs in tumor genome over the gene body of this gene, as determined by tumor DNA sequencing #SNPs showing ASE in RNA Number of such heterozygous markers showing mono-allelic expression. A binomial test with p-value cutoff is used to determine if one heterozygous SNP sufficiently deviates from 50%, if so this SNP is \"ASE\". There should be 0 ASE SNPs for bi-allelic expressing genes, and >=1 for mono-allelic expressing genes. Mean delta of ASE SNPs Mean value of (BAF-0.5) for all the markers. BAF: RNA B-allele frequency Q-value First, the binomial p-values of all ASE SNPs for a gene are combined into one value using geometric mean; then, the combined p-values for all genes from a tumor are multiple-test corrected, to obtain this q-value for each gene. GenomePaint uses a decision tree to determine the ASE status of a gene in a sample (mono-allelic, bi-allelic, uncertain). To customize the cutoff values, click the gene label and select \"Customize ASE/OHE parameters\": In the ASE decision tree, three cutoff values are customizable: For ASE, values for number of heterozygous SNPs, number of ASE SNPs, mean delta, and q-value are precomputed (Cis-X, Yu et. al., in submission) and cannot be recomputed on-the-fly.","title":"Allele-specific expression status (ASE)"},{"location":"guides/genomepaint/#automatic-genes","text":"While you pan and zoom the view range, genes update automatically on the right in the expression column. It always shows the first gene in the view range. When you zoom out and there are multiple genes in the view range, you may want to view some other gene rather than the default leftmost one. Click on the gene label on top of the rank axis and find a list of gene names from the view range. Choose a gene to change. By choosing a gene here, whenever this gene is in the view range, it will always be shown irrespective of its order of appearance.","title":"\"Automatic\" genes"},{"location":"guides/genomepaint/#fixed-genes","text":"GenomePaint allows you to show the expression of multiple genes side-by-side: The gene on the left is \"automatic\". The gene on right is added by user, and will be always shown irrespective of the view range, hence the fixed genes . To add a fixed gene, click the gene label on top of the automatic expression rank axis to show the menu. Type into the search box on top of the menu to find matching gene names: Select a gene from the list, and its expression rank will appear as a new column. More than 1 fixed genes can be added. The samples are aligned for both automatic and fixed genes. To remove a fixed gene, click the gene label and select \"Remove\". As an example, while browsing the recurrently duplicated NOTCH1 MYC enhancer locus in TALL, the distal target gene MYC is not in view range, thus its expression is not shown automatically. By adding MYC as a \"fixed gene\", its expression is shown for TALL tumors with enhancer duplication:","title":"\"Fixed\" genes"},{"location":"guides/genomepaint/#filters-for-samples-and-genomic-variants","text":"Here we introduce filters for samples and mutations in Cohort View. Some of these filters can be found in the track legend at the bottom of the page, where the filters are listed as legend entries. Some filters are hidden by default, click \"MORE\" at bottom to show them:","title":"Filters for samples and genomic variants"},{"location":"guides/genomepaint/#cancer-type-filter","text":"In cohort view, one or more cancer types will be shown on the left of the mutation data display. Click on a cancer name to show a menu: Click \"Hide\" to hide samples of this cancer type; click \"Show only\" to only show samples of this cancer type. In the legend, hidden cancer types are indicated with a strikethrough; click a striked label to turn it back on:","title":"Cancer type filter"},{"location":"guides/genomepaint/#other-sample-filters","text":"You can filter samples by cancer group, sample type, gender, and race, in the same way as cancer type.","title":"Other sample filters"},{"location":"guides/genomepaint/#mutation-class-filter","text":"Mutation class legend is shown as below. You can select a class and hide it or show it only.","title":"Mutation class filter"},{"location":"guides/genomepaint/#mutation-attribute-filter","text":"Following are attributes describing mutations in each particular sample. Unlike mutation class which annotates a mutation no matter if it is germline or somatic, these attributes are assigned to mutations in each sample.","title":"Mutation attribute filter"},{"location":"guides/genomepaint/#custom-sample-subsetting","text":"In addition to grouping tumors with predefined cancer types, users can choose to limit the Cohort View to a customly defined sample subset. To do that, click CONFIG, then select the \"Use a sample list\" button. An input box is displayed prompting the user to enter the set of samples. For the moment, space character is reserved for dividing the sample and group names, and cannot be used in either sample or group name. As an example, use the following list of samples that are divided into two groups. SJTALL002030_D1-PARVHY T-ALLs SJALL015249_D1-PARPHB T-ALLs SJALL015260_D1-PARMKK T-ALLs SJALL015268_D1-PASFHR T-ALLs SJALL015278_D1-PARJPL T-ALLs SJALL015280_D1-PARNMV T-ALLs SJALL015285_D1-PASKTG T-ALLs SJTALL002072_D1-PATHJF T-ALLs SJALL015269_D1-PASFKA T-ALLs SJBALL020492_D2-PANKGK B-ALLs SJERG009_D B-ALLs SJPHALL006_D B-ALLs SJBALL020795_D2-PAPIRZ B-ALLs SJETV088_D B-ALLs SJHYPER143_D B-ALLs SJETV059_D B-ALLs SJETV069_D B-ALLs SJHYPER052_D B-ALLs SJBALL020469_D1 B-ALLs SJHYPER013_D B-ALLs The Cohort View will be transformed to showing only these samples in two groups: Click a group label to see options: After submission, a sample set can be edited. To do that, inside the CONFIG menu click on the \"Edit\" button following the \"Restricted to xx samples\" phrase, and open the same input box allowing to edit the list of samples. Click on the \"Remove\" button to cancel the sample subsetting and go back to full Cohort View. Sample subsetting can be applied to custom track as well.","title":"Custom sample subsetting"},{"location":"guides/genomepaint/#assay-availability-table","text":"The Pediatric cancer dataset is equipped with a feature to show assay availability information for each cancer type. This is important in providing a precise total sample count based on assay type. As an example, T-ALL displays 78 samples with alterations at the TAL1 locus. The \"21%\" percentage is imprecise and only servers as a rough guide, as it doesn't account for assay availability. The track legend shows two DNA assay types for these alterations: SNP6 and \"amplicon sequencing\". In addition there are also fusion events from RNA-seq. Thus, to compute the percentage of T-ALLs with TAL1 locus alteration, one needs the total number of T-ALLs with either SNP6, amplicon sequencing, or RNA-seq. To get the actual total number, click the \"HM, TALL\" label on the left and select \"Assay summary\" option. The assay availability for T-ALL is displayed as a map below. The map is an assay-by-sample matrix, with assays as rows and samples as columns. All assays available for T-ALLs are included. By default, the assays are arranged from top to bottom in descending order of sample counts (RNA and WES being the most abundant). Inside the matrix, a gray box indicates a set of samples having a particular assay type. The number of samples are always printed out for each box. The sample columns are sorted by their presence of each assay type, by the order of assays from top to bottom. In the T-ALL case, the samples are first sorted by RNA-seq, with 267 that have RNA-seq and 86 without (number not printed). Next, WES availability is sorted separately for the box and blank from the first row, resulting in two boxes and two blanks. Next, the SNP6 availability is sorted separately in each box and blank in the second row. So on for every other assay type. Importantly, the width of the gray boxes are not scaled by the number of samples, but rather symbolic representations of the cohort partitioning. Though not to scale, the boxes are vertically aligned with columns being groups of samples. Better than a Venn diagram, this assay availability map solidifies a comprehensible view with as many as 6 assay types. As the order of assay types is important for the map, users can adjust the row order by dragging a label up or down. As below, the RNA-seq, SNP6, and Capture-seq rows are moved to the top, yielding a total of 337 samples (267+70) for the samples with TAL1 locus alterations.","title":"Assay availability table"},{"location":"guides/genomepaint/#kaplan-meier-plot","text":"Patient outcome (event-free and overall survival) information is available for 1102 samples (6 histotypes) from the \"Pan-TARGET\" study (Ma, X. et al. Nature 2018). GenomePaint provides following ways to stratify this cohort using genomic alteration or gene expression, and to perform the Kaplan-Meier analysis to assess what clinical outcome does the genomic feature lead to. The analysis will compute the p value using the G-rho family of tests (the \"survdiff\" function in R), as well as plotting the survival curves. Kaplan-Meier analysis is performed on each individual cancer type.","title":"Kaplan-Meier plot"},{"location":"guides/genomepaint/#with-genomic-alterations","text":"This usually applies to recurrent mutations/alterations, or frequently mutated regions, as sufficient number of mutated samples may be required for the analysis.","title":"With genomic alterations"},{"location":"guides/genomepaint/#with-a-specific-mutationalteration","text":"CDKN2A/2B is recurrently deleted in acute lymphoblastic leukemia. To see how this deletion may impact clinical outcome, visit CDKN2A locus in GenomePaint, and select a deletion spanning the locus to show a panel (left). On top of this panel, select the \"Survival plot\". This will use the range of this particular deletion to stratify tumors: samples with deletions overlapping with this range will be separated from samples that don't. As a result, a survival curve like below can be shown for BALL. Such procedure can be applied to other types of mutation/alteration as well. If a CNV is selected, samples may be divided to up to three groups (gain, loss, no change). If any other type of alteration is selected, samples will be divided into just two groups (with mutation, no mutation).","title":"With a specific mutation/alteration"},{"location":"guides/genomepaint/#with-any-alterations-from-a-chosen-genomic-interval","text":"MYB is subject to multiple types of genomic alterations in TALL, including amplification, activating mutation, intragenic and intergenic translocations. To collectively consider the effect of these alterations on TALL patient outcome, view data in the range chr6:135482339-135674218 (hg19), a 190 Kb region around MYB, which will include coding mutations, amplification, and intergenic translocations that have been found to cause MYB activation. Then, click on the \"HM, TALL\" label on the left and select the \"Survival plot\" option. This will select TALL patients with any variant in the view range into the \"mutated\" group, for comparing with the \"no mutation\" group in the Kaplan-Meier analysis. CNV, LOH parameter settings and mutation class filter will be applied to filter alteration events in the survival plot.","title":"With any alterations from a chosen genomic interval"},{"location":"guides/genomepaint/#with-fpkm-values-of-a-chosen-gene","text":"MDM2 overexpression may lead to shortened half-life of P53 protein, thus may lead to worse outcome in cancer patients. To test this hypothesis, show MDM2 in GenomePaint. On the right of gene expression rank plot, click \"MDM2\" label, then select \"Survival plot by MDM2 FPKM\". This will perform the analysis on BALL by default, using MDM2 median expression as cutoff to divide the samples to two groups. Switch the cancer type to AML, and median into quartile, to view the plot showing high MDM2 expression is correlated with worse outcome in AML.","title":"With FPKM values of a chosen gene"},{"location":"guides/genomepaint/#sample-view","text":"From Cohort View, click any type of mutation to show a panel; at the left of this panel, click the \"Sample View\" button to show a new browser view showing data tracks from this sample in a region surrounding the mutation:","title":"Sample View"},{"location":"guides/genomepaint/#pediatric-tumors-in-sample-view","text":"","title":"Pediatric tumors in Sample View"},{"location":"guides/genomepaint/#mutation-data-in-sample-view","text":"The Sample View shows a number of tracks, one of them is the mutations, named \"Pediatric tumor mutation, \". In the example below, a Wilms' tumor shows 4 different types of mutations over the MYCN gene, including copy number gain, LOH (not copy-neutral), SV supporting this CNV, and a coding mutation in MYCN.","title":"Mutation data in Sample View"},{"location":"guides/genomepaint/#mutation-signature","text":"In the above example, the missense mutation is colored in green because of its mutation signature assignment in that sample. Mutation signature is available for 915 tumors from the Pan-TARGET study (Ma, X et al. Nature 2018). For such tumors, their mutations in Sample View will be colored by assigned signatures. Users can also view the mutation signature abundance for a sample by clicking the \"Mutation signature\" button on top.","title":"Mutation signature"},{"location":"guides/genomepaint/#multi-region-display-for-inter-chromosomal-sv","text":"When a user clicks on an inter-chromosomal SV and launches Sample View, the view will contain a pair of regions each containing one breakpoint, from two chromosomes. Regions are spaced by a vertical gray bar. The following example shows a pair of genomic regions upon clicking the ETV6-ABL1 fusion transcript in a TALL sample; the left region with ETV6 is chr12, and the right-side region with ABL1 is chr9. To zoom in on either region, drag on the coordinate ruler on top of one region. To zoom out on the left-side region, click the \"zoom out\" buttons. To zoom out on the right-side region, instead of clicking on the \"zoom out\" buttons, hover and show an option on top, click that option to zoom the right-side region.","title":"Multi-region display for inter-chromosomal SV"},{"location":"guides/genomepaint/#sequencing-coverage-and-allelic-imbalance-tracks-in-single-sample-view","text":"GenomePaint aims to provide comprehensive genomics information to assist in interpreting mutations from individual tumors. This includes additional genomic assay tracks on individual tumors if they are available to us. Following is a typical example: In the above example, it shows coverage of WGS and RNA-seq of tumor, and the allelic-imbalance from the tumor-normal paired WGS results. Learn more about the allelic-imbalance track .","title":"Sequencing coverage and allelic-imbalance tracks in single-sample view"},{"location":"guides/genomepaint/#hi-c-data-from-pediatric-cancer-cell-lines","text":"GenomePaint provides the detailed genomic and epigenomic assaying results of a set of pediatric cancer cell lines to supplement the primary tumor mutation dataset. Currently there are six neuroblastoma cell lines (SKNAS, NB69, Kelly, BE2C, NGP, SH-SY5Y) and one BALL cell line (NALM6), all grouped with primary tumors of the same cancer type. When a cell line appears in the genomic mutation data panel, it will be marked by a black notch on left: These cell lines all come with in-situ Hi-C data, in addition to the histone modification ChIP-seq. These tracks will be shown in the single-sample view of these cell lines. Learn more about the Hi-C track .","title":"Hi-C data from pediatric cancer cell lines"},{"location":"guides/genomepaint/#matrix-view","text":"Matrix View is a light-weight method for combining multiple genomic regions into one view so as to compare their mutational profiles over a group of samples, via a sample-by-region matrix: Such a matrix can be generated for samples from one cancer type. Following demonstrates how to use the Matrix View to observe the MYCN-ATRX mutual exclusivity in neuroblastoma. First, show the NBL mutation profile at the MYCN locus. By default MYCNOS gene is showing for the expression rank, change it to MYCN. This can allow the region to be named as \"MYCN\" rather than \"MYCNOS\" in the Matrix View. Click on the \"ST, NBL\" label on left, and select \"Matrix view\". This gathers the group of NBL tumors with mutations in MYCN into a single-column matrix. Back to the Cohort View. Type \"atrx\" into the coordinate box and press ENTER. Cohort View now shows ATRX mutations from NBL. Click the \"ST, NBL\" label on the left, and select \"Matrix View\". This will add ATRX as a new column alongside MYCN in the Matrix View. It shows that the majority of NBL tumors only display alteration at one gene.","title":"Matrix View"},{"location":"guides/genomepaint/#custom-track","text":"","title":"Custom track"},{"location":"guides/genomepaint/#feature-availability","text":"Features available for custom track: All types of mutations are supported, including SNV/indel, CNV, LOH, SV, fusion, ITD. Gene expression FPKM values and ranking are supported, together with ASE status. Customizing ASE parameters. Cohort View: Showing mutation profile. Mutation annotation with user-defined attributes; this is for display only and cannot be used for filtering. Computing and displaying gene expression rank among all samples. Custom sample subsetting. Sample View: Displaying mutation track, as well as multi-region view triggered by inter-chromosomal SV. Gene expression rank from all samples. Joining of SV breakpoint regions. Matrix View. Customizing CNV/LOH parameters (log2ratio, seg.mean, max size limit) and mutation class in all Views Works for any supported genome assemblies, including hg19, hg38, mm9, mm10 Features not available for custom track: Predefined sample grouping and filtering by cancer types. Mutation filtering. Mutation signature. Support of genomic assay tracks in Sample View. Kaplan-Meier analysis.","title":"Feature availability"},{"location":"guides/genomepaint/#example","text":"This URL shows the TCGA DLBC (diffuse large B-cell lymphoma) as a custom track in the human hg38 genome. https://proteinpaint.stjude.org/?block=on&genome=hg38&position=chr9:21843776-22119276&svcnvfpkmurl=TCGA_DLBC,svcnv,https://pecan.stjude.cloud/static/hg38/tcga-gdc/DLBC/TCGA_DLBC.CNV.gz,fpkm,https://pecan.stjude.cloud/static/hg38/tcga-gdc/DLBC/TCGA_DLBC.fpkm.gz,vcf,https://pecan.stjude.cloud/static/hg38/tcga-gdc/DLBC/TCGA_DLBC.vcf.gz It consists of SNV/indels (VCF format), SVCNV (tailored JSON-BED format), and FPKM (tailored JSON-BED format). The URLs for each file: SVCNV https://pecan.stjude.cloud/static/hg38/tcga-gdc/DLBC/TCGA_DLBC.CNV.gz FPKM https://pecan.stjude.cloud/static/hg38/tcga-gdc/DLBC/TCGA_DLBC.fpkm.gz VCF https://pecan.stjude.cloud/static/hg38/tcga-gdc/DLBC/TCGA_DLBC.vcf.gz Either SVCNV or VCF track is required to launch a custom track; FPKM track is optional.","title":"Example"},{"location":"guides/genomepaint/#tools-required","text":"bcftools , 1.9 tabix and bgzip , 1.9 Download all from http://www.htslib.org/download/","title":"Tools required"},{"location":"guides/genomepaint/#vcf-file","text":"The VCF file stores SNV/indel mutations for a group of samples. GenomePaint requires VCF format version 4.2: https://samtools.github.io/hts-specs/VCFv4.2.pdf","title":"VCF file"},{"location":"guides/genomepaint/#functional-annotation-of-variants-using-vep","text":"Functional annotation of variants is optional but helpful. VEP is recommended. See details at https://useast.ensembl.org/info/docs/tools/vep/index.html","title":"Functional annotation of variants using VEP"},{"location":"guides/genomepaint/#preparing-a-vcf-track-file","text":"The VCF text file needs to be sorted, then compressed and indexed to make the track file. bcftools sort FILE.vcf -o FILE.sorted.vcf bgzip FILE.sorted.vcf tabix -p vcf FILE.sorted.vcf.gz The resulting files \"FILE.sorted.vcf.gz\" and \"FILE.sorted.vcf.gz.tbi\" are the VCF track files. Put both under the same directory to be used as custom tracks.","title":"Preparing a VCF track file"},{"location":"guides/genomepaint/#svcnv-file","text":"\"SVCNV\" is the nickname for the file storing all other types mutations except SNV/indel, which are CNV, LOH, SV, fusion, ITD, for a group of samples. The file uses a uniform format to represent different mutation data, which consists of 4 tab-separated columns. Each line represents one variant in a sample. First three columns are genomic positions for indexing (chr, start, stop, 0-based), the fourth column is a JSON object. CNV example: chr1 10000 10927712 {\"dt\": 4, \"sample\": \"SJMB015_D\", \"value\": -0.45} chr1 10000 151005400 {\"dt\": 4, \"sample\": \"SJMB008_D\", \"value\": 0.585} chr1 10000 25392551 {\"dt\": 4, \"sample\": \"SJRB003_D\", \"value\": -0.4150} \"dt\":4 identifies this item is a CNV \"value\" is log2(ratio) LOH example: chr1 55976 185392845 {\"dt\":10,\"sample\":\"SJCOGALL010918_D2-PAPJXI\",\"segmean\":0.068} chr1 55976 249195965 {\"dt\":10,\"sample\":\"SJAML040586_D1-PARFAL\",\"segmean\":0.068} chr1 55976 249208343 {\"dt\":10,\"sample\":\"SJAML040508_D1-PAKERZ\",\"segmean\":0.073} \"dt\":10 identifies this item is LOH \"segmean\" is the seg.mean value, range between 0 and 0.5 Your file can contain all the LOH segments, they don't need to be limited to copy-neutral ones; GenomePaint will always show copy-neutral LOH by on-the-fly comparison to CNV, in cohort view. SV example: chr12 12029972 12029972 {\"chrB\": \"chr21\", \"dt\": 5, \"posB\": 36417895, \"sample\": \"SJETV039_D\", \"strandA\": \"+\", \"strandB\": \"-\"} chr21 36417895 36417895 {\"chrA\": \"chr12\", \"dt\": 5, \"posA\": 12029972, \"sample\": \"SJETV039_D\", \"strandA\": \"+\", \"strandB\": \"-\"} \"dt\":5 identifies this item is structural variation in DNA (as opposed to RNA fusion) Each SV has two breakpoints: chrA:posA \u2192 chrB:posB; it must be represented as two lines in the data file, no matter if chrA is the same as chrB or not. Line 1 chrA \\t posA \\t posA \\t {\"dt\":5, \"chrB\":.., \"posB\":..., \"strandA\": \"+\", \"strandB\": \"-\", ... } Line 2 chrB \\t posB \\t posB \\t {\"dt\":5, \"chrA\":.., \"posA\":..., \"strandA\": \"+\", \"strandB\": \"-\", ... } Fusion example: chr1 19157328 19157328 {\"chrB\": \"chr13\", \"dt\": 2, \"geneA\": \"chr1\", \"geneB\": \"VWA8\", \"posB\": 42278669, \"sample\": \"SJRHB009_D\", \"strandA\": \"-\", \"strandB\": \"+\"} chr1 19157486 19157486 {\"chrA\": \"chr13\", \"dt\": 2, \"geneA\": \"VWA8\", \"geneB\": \"chr1\", \"posA\": 42278658, \"sample\": \"SJRHB009_D\", \"strandA\": \"+\", \"strandB\": \"-\"} Fusion is the same as SV except dt is 2. ITD example: chr8 128752721 128753187 {\"dt\": 6, \"gene\": \"MYC\", \"isoform\": \"NM_002467\", \"sample\": \"SJTALL002080_D1-PATHWV\"} chr8 128752763 128753183 {\"dt\": 6, \"gene\": \"MYC\", \"isoform\": \"NM_002467\", \"sample\": \"SJERG029_D\"} chr8 128752802 128753109 {\"dt\": 6, \"gene\": \"MYC\", \"isoform\": \"NM_002467\", \"sample\": \"SJAML040570_D1-PAPXRJ\"} chr8 128752821 128753186 {\"dt\": 6, \"gene\": \"MYC\", \"isoform\": \"NM_002467\", \"sample\": \"SJCOGALL010220_D1-PANTSM\"}","title":"SVCNV file"},{"location":"guides/genomepaint/#preparing-a-svcnv-track-file","text":"For a group of samples, concatenate the 4-column text data of every type of mutation into a single text file. Do the following to prepare the track file. sort -k1,1 -k2,2n FILE > FILE.sorted bgzip FILE.sorted tabix -p bed FILE.sorted.gz The resulting files \"FILE.sorted.gz\" and \"FILE.sorted.gz.tbi\" are the SVCNV track files. Put both under the same directory to be used as custom tracks.","title":"Preparing a SVCNV track file"},{"location":"guides/genomepaint/#annotating-variants-in-svcnv-file","text":"Variant annotation provides a useful way to record attributes pertinent to each particular variant. Suppose we want to process the CNV calls from a group of tumors. Some of the tumors are analyzed by SNP array, others by sequencing, still others by both. When browsing such CNV data, it may be useful to tell the assaying type for a CNV. For that we can annotate the CNV in the following way: {\"dt\":4,\"sample\":\"sample\",\"value\":0.5, \"mattr\":{\"dna_assay\":\"snp6\"} } In the JSON object of this CNV, the \" mattr \" attribute points to a key-value pair. Here \"dna_assay\" is used to indicate the assay type, which will show up in the tooltip like below.","title":"Annotating variants in SVCNV file"},{"location":"guides/genomepaint/#fpkm-gene-expression","text":"Gene expression value such as FPKM is optional in a GenomePaint track. If provided, it should be encoded in a text format like below: chr1 69090 70008 {\"value\":0.00109218,\"sample\":\"SJBALL021486_D1\",\"gene\":\"OR4F5\"} chr1 69090 70008 {\"value\":0.00109218,\"sample\":\"SJHGG075_A\",\"gene\":\"OR4F5\"} chr1 69090 70008 {\"value\":0.00109335,\"sample\":\"SJRHB044_M\",\"gene\":\"OR4F5\"} chr1 69090 70008 {\"value\":0.00109946,\"sample\":\"SJEPD007_D\",\"gene\":\"OR4F5\"} chr1 69090 70008 {\"value\":0.00110745,\"sample\":\"SJHGG015_D\",\"gene\":\"OR4F5\"} chr1 69090 70008 {\"value\":0.00111458,\"sample\":\"SJHGG103_D\",\"gene\":\"OR4F5\"} Each line represents the FPKM value of one gene in one sample. File has 4 columns, separated by tabs: Chromosome name of the gene Start position of the gene, 0-based Stop position of the gene, non-inclusive JSON object with keys: \" value \": FLOAT FPKM value for this gene in this sample, positive real number \" sample \": STR Sample name \" gene \": STR Gene name","title":"FPKM gene expression"},{"location":"guides/genomepaint/#preparing-a-fpkm-track-file","text":"Use the same procedure as the SVCNV track.","title":"Preparing a FPKM track file"},{"location":"guides/genomepaint/#annotating-gene-expression-with-aseohe-status","text":"ASE (allele-specific expression) status can be indicated using the \" ase \" key in the JSON object of FPKM data: { \"sample\" : \"SJTALL002124_D1-PATWYL\" , \"value\" : 17.2244 , \"gene\" : \"TAL1\" , \"ase\" : { \"markers\" : 1 , \"ase_markers\" : 1 , \"mean_delta\" : 0.5 , \"qvalue\" : 0.00163916385535038 } } See Allele-specific expression status on how the ASE status is determined based on the constituent values from \"ase\". OHE (outlier high expression) status can be indicated as below in the JSON object of FPKM data. { \"sample\" : \"SJTALL022442_D2-PATFRM\" , \"value\" : 3.8905 , \"gene\" : \"TAL1\" , \"outlier\" : { \"test_entirecohort\" : { \"size\" : 263 , \"pvalue\" : 0.353723919266382 , \"rank\" : 111 }, \"test_whitelist\" : { \"size\" : 166 , \"pvalue\" : 0.0810415523178093 , \"rank\" : 22 } } }","title":"Annotating gene expression with ASE/OHE status"},{"location":"guides/genomepaint/#hosting-custom-track","text":"SVCNV, VCF, and FPKM track files all have the .tbi index file; put each pair of files inside the same folder on a web server. Obtain the URL to each of the .gz file for submitting the custom track. E.g. given this URL: http://domain/path/to/file.gz The corresponding index file should be found at http://domain/path/to/file.gz.tbi","title":"Hosting custom track"},{"location":"guides/genomepaint/#displaying-custom-track","text":"URLs of the SVCNV, VCF, and FPKM .gz files can be submitted to https://proteinpaint.stjude.org for display, provided that the hosting server is publicly accessible on the Internet. By showing your custom track, ProteinPaint server will download the index files, which do not contain actual mutations or expression data stored in the .gz files. ProteinPaint will not download the .gz files.","title":"Displaying custom track"},{"location":"guides/genomepaint/#via-url","text":"The track URLs can be appended to the \"svcnvfpkmurl\" parameter like below: https://proteinpaint.stjude.org?block=on&genome=[GENOME]&svcnvfpkmurl=[TRACKNAME],svcnv,[svcnv_URL],vcf,[vcf_URL],fpkm,[fpkm_URL] [GENOME] The name of a reference genome e.g. hg19 or hg38 [TRACKNAME] Track name, no comma [svcnv_URL] URL to the SVCNV .gz file [vcf_URL] URL to the VCF .gz file [fpkm_URL] URL to the FPKM .gz file There is no required order of precedence for \"svcnv\", \"vcf\", and \"fpkm\". However, each must be followed by the respective URL. Example: https://proteinpaint.stjude.org/?block=on&genome=hg38&position=chr9:21843776-22119276&svcnvfpkmurl=TCGA_DLBC,svcnv,https://pecan.stjude.cloud/static/hg38/tcga-gdc/DLBC/TCGA_DLBC.CNV.gz,fpkm,https://pecan.stjude.cloud/static/hg38/tcga-gdc/DLBC/TCGA_DLBC.fpkm.gz,vcf,https://pecan.stjude.cloud/static/hg38/tcga-gdc/DLBC/TCGA_DLBC.vcf.gz Either svcnv_URL or vcf_URL is required; FPKM URL is optional. E.g. a SVCNV track with FPKM but not VCF would be like: https://proteinpaint.stjude.org?block=on&genome=[GENOME]&svcnvfpkmurl=[TRACKNAME],svcnv,[svcnv_URL],fpkm,[fpkm_URL] Such URLs can be bookmarked, emailed, shared, or tweeted. More on the ProteinPaint URL parameters .","title":"Via URL"},{"location":"guides/genomepaint/#via-embedding-api","text":"This API allows the visualization to be customized and embedded into another web page. Example: <!DOCTYPE html> < html > < head > < meta charset = \"utf-8\" > </ head > < body > < script src = \"https://proteinpaint.stjude.org/bin/proteinpaint.js\" charset = \"utf-8\" ></ script > < div id = aaa style = \"margin:10px\" ></ div > < script > runproteinpaint ({ host : 'https://proteinpaint.stjude.org' , holder : document . getElementById ( 'aaa' ), genome : 'hg38' , block : 1 , position : 'chr9:21953975-22009075' , tracks : [ { type : 'mdssvcnv' , name : 'TCGA DLBC' , url : 'https://pecan.stjude.cloud/static/hg38/tcga-gdc/DLBC/TCGA_DLBC.CNV.gz' , checkexpressionrank : { datatype : 'FPKM' , url : 'https://pecan.stjude.cloud/static/hg38/tcga-gdc/DLBC/TCGA_DLBC.fpkm.gz' }, checkvcf : { url : 'https://pecan.stjude.cloud/static/hg38/tcga-gdc/DLBC/TCGA_DLBC.vcf.gz' }, mutationAttribute : { attributes : { dna_assay : { label : 'DNA assay' , values : { snp6 : { name : 'SNP 6.0' , label : 'genotyping array' } } } } } } ], nativetracks : 'RefGene' , noheader : true , nobox : true }) </ script > </ body > </ html > Save above contents to an HTML file (as a text file, not MS Word). Open the HTML file in a web browser and the track should load up. Substitute the example URLs with your actual ones to show your data. More on the ProteinPaint embedding API .","title":"Via embedding API"},{"location":"guides/genomepaint/#hosting-and-launching-custom-genomepaint-track-from-dnanexus","text":"DNAnexus provides a secure way to host unpublished/sensitive genomics data to be used as custom GenomePaint track. In doing so, randomized URLs are produced to point to your files hosted in the DNAnexus platform, expiring in 24 hours. Through the FileViewer mechanism , GenomePaint accesses these URLs and launches the track. Only the index portions of your files will be downloaded to the GenomePaint server, but not any actual genomics data. The index files do not contain actual genomics data. To begin, you need to sign up on DNAnexus at https://www.dnanexus.com/ . Next, store your track files on the platform by uploading them to a \"project folder\". For example, following files \"TCGA_DLBC.*\" have been stored in the folder. Follow the instructions in the next section to obtain the GenomePaint FileViewer . Once obtained, the FileViewer looks like below in your account. Click the FileViewer to open up the file selection interface. Select the necessary track files. Click the button \"Launch viewer\" at bottom right. The Viewer will start up by prompting you to select the correct genome build for your data. By selecting a genome build, GenomePaint will launch and show your custom track.","title":"Hosting and launching custom GenomePaint track from DNAnexus"},{"location":"guides/genomepaint/#obtaining-the-genomepaint-fileviewer-on-dnanexus","text":"Install the \"dx-toolkit\" on your computer by following instructions on https://documentation.dnanexus.com/downloads Once installed, you will be able to run the \"dx\" command on your computer. Next, login at the dx-toolkit with your token. To obtain a token, at a web browser, log yourself in at https://platform.dnanexus.com/ . Click the top-right user icon and select \"My Profile\". Then, click the \"API Tokens\" tab. Then click the \"+ New Token\" button. At the prompt, enter a label and click \"Generate Token\". The token is now displayed. Select and copy it. At the terminal of your computer, log into \"dx\" with the token. dx login --token TvmrnvgkHeyYouCanChargeYourElectricCarForFreeAtWork # Available projects (CONTRIBUTE or higher): # \u2026 here lists your projects \u2026 # Pick a numbered choice: Enter a number to select a project. You are now logged into your account. Run dx ls to do a directory listing on the selected project. Next, upload the GenomePaint FileViewer to this project. Run this command to download the FileViewer source code, to a file named \"GenomePaint (SVCNV, VCF, FPKM)\". wget 'https://pecan.stjude.cloud/static/fileviewers/GenomePaint%20(SVCNV%2C%20VCF%2C%20FPKM)' Run this command to upload the file to your DNAnexus project as a FileViewer. dx upload --type FileViewer 'GenomePaint (SVCNV, VCF, FPKM)' # [===========================================================>] Uploaded 5,257 of 5,257 bytes (100%) /.../GenomePaint (SVCNV, VCF, FPKM) # ID file-Fjypgf... # Class file # Project project-F0QQBv... # Folder / # Name GenomePaint (SVCNV, VCF, FPKM) # State closing # Visibility visible # Types FileViewer # Properties - # Tags - # Outgoing links - # Created Fri Feb 7 12:26:32 2020 # Created by xzhou # Last modified Fri Feb 7 12:26:33 2020 # archivalState \"live\" # Media type With this, you have successfully obtained the GenomePaint FileViewer on your DNAnexus account.","title":"Obtaining the GenomePaint FileViewer on DNAnexus"},{"location":"guides/genomepaint/#hosting-and-launching-custom-genomepaint-track-from-amazon-aws","text":"","title":"Hosting and launching custom GenomePaint track from Amazon AWS"},{"location":"guides/genomepaint/#amazon-s3-introduction","text":"Amazon AWS has secure and highly available storage service known as S3. Amazon S3 stores data as objects within buckets. An object consists of a file and optional metadata. To store an object in Amazon S3, you upload a file to a bucket. When uploading, you can set permissions on the object and any metadata. Likewise many settings can be configured for a bucket. To get familiarized with common terminologies used for Amazon S3, checkout the official guide .","title":"Amazon S3 Introduction"},{"location":"guides/genomepaint/#sign-up-for-amazon-s3","text":"Go to https://aws.amazon.com/s3/ and click \"Create an AWS account\". Once created, AWS will notify you by email when your account is active and available for you to use.","title":"Sign Up for Amazon S3"},{"location":"guides/genomepaint/#create-a-new-bucket-on-s3","text":"Login to your account and access the \"S3 Management Console\" at https://console.aws.amazon.com/s3/ . Here, click the \"+ Create bucket\" button. A new window pops up with details required for creating a new bucket. In the 'Bucket name' box enter a unique DNS-compliant name. This name should be unique across all buckets on Amazon S3. The URL for the objects inside the bucket will include the bucket name as well. At \"Configure options\", you can change the settings or keep default as per requirements. At \"Set permissions\", make the bucket public so files can be accessible from GenomePaint. To make the Bucket public, leave all the checkboxes unchecked. Next page will summarize all settings for the new bucket. After confirming, click \"Create bucket\".","title":"Create a new Bucket on S3"},{"location":"guides/genomepaint/#add-custom-track-files-to-a-bucket","text":"Select the bucket you want files to upload to. Then, click the \"Upload\" button. On the next page, select all the GenomePaint track files and associated index files for uploading. Once a file is selected, it will appear in the menu. Click 'Upload' at the bottom. Make sure to add index files (.tbi and .csi) with the vcf, svcnv or fpkm files.","title":"Add custom track files to a Bucket"},{"location":"guides/genomepaint/#enable-public-access-to-the-track-files","text":"Once the file is uploaded to the bucket, it will appear in the list of files. Select all the files you want to visualize in the GenomePaint. Click \"Actions\" and select \"Make public\" option. A window will pop-up to confirm the action.","title":"Enable public access to the track files"},{"location":"guides/genomepaint/#submit-a-custom-track-from-s3-to-genomepaint","text":"First, obtain the URLs to the SVCNV, VCF, FPKM \".gz\" files. Click on a \".gz\" file to see a detailed page and find its URL at the bottom. Add the URLs as parameters of the following GenomePaint URL. https://proteinpaint.stjude.org?block=on&genome=[GENOME]&svcnvfpkmurl=[TRACKNAME],svcnv,[svcnv_URL],vcf,[vcf_URL],fpkm,[fpkm_URL] For example, https://proteinpaint.stjude.org/?block=on&genome=hg38&position=chr9:21843776-22119276&svcnvfpkmurl=TCGA_DLBC,svcnv,https://genomepaint-test.s3.amazonaws.com/TCGA_DLBC.CNV.gz,vcf,https://genomepaint-test.s3.amazonaws.com/TCGA_DLBC.vcf.gz This URL will serve as visualization access point for your files in the Amazon S3.","title":"Submit a custom track from S3 to GenomePaint"},{"location":"guides/genomics-platform/","text":"St. Jude Cloud Genomics Platform Genomics Platform is an app that allows you to browse, request, host, and analyze raw next-generation sequencing data. This app is a collaboration between St. Jude Children's Research Hospital , Microsoft Azure , and DNAnexus . We provide high quality next generation Whole Genome (WGS), Whole Exome (WES), and RNA-Seq data to researchers around the world. There is a request process to protect this data even though it is de-identified. One of the benefits of partnering with DNAnexus is that users can not only access our data, but also upload their own. Click here to learn how . Our homepage offers our most popular actions, including visiting our data browser, accessing our analysis workflows, or managing your current access through your dashboard. Browsing our data and workflows is free and does not require an account. If you would like to access the data or workflows, you will have to make a free account so that you can access them through your dashboard. Once approved for access to our data or workflows, you will not be charged for any associated storage fees. See here how to request data and our process for approval. St. Jude Employee Quick Start \u00b6 The information displayed below this point is primarily intended for employees of St. Jude Children's Research Hospital. Please complete the following check-list to get started with using St. Jude Cloud. Join St. Jude Cloud helpdesk channel on Slack ( link ). Log in to your St. Jude Cloud account ( link ). Enable Microsoft Azure ( link ). Create your first project ( link ). Set up your billing account ( link ). Joining Slack \u00b6 The St. Jude Cloud team uses Slack to communicate on a day-to-day basis. When standing up a help desk, we decided to offer that functionality on Slack to allow our community to answer questions alongside our team. If you are an employee at SJCRH, you already have a Slack account (at no cost to you) \u2014 you might even like it so much, you decide to use it during this work from home period! If you have any issues with the instructions below, you can email helpdesk@stjude.org or support@stjude.cloud . Steps Navigate to https://stjude.slack.com , click \"Sign in with your St. Jude Account\", and enter your St. Jude credentials. Congrats! You're now on Slack. Download the desktop app by visiting https://slack.com/download . The instructions differ depending on whether you are on a Windows/Mac/Linux machine. Once you install and start up the app, the sign-in process should look the same as step 1. To join the #stjudecloud-helpdesk channel, you can click the word \"Channels\" in the left sidebar and search for #stjudecloud-helpdesk . If you have issues, please see the official Slack guide on joining a channel. You should now see a screen similar to the one included below. You can type your questions into the chat box at the bottom. See you there! Login to St. Jude Cloud \u00b6 Signing in to St. Jude Cloud is similarly easy \u2014 if you have a SJCRH account, you already have a St. Jude Cloud account. Steps Visit https://cloud.stjude.org , log in with your St. Jude credentials, and fill in the basic profile page to your satisfaction if prompted. Congrats! You're now logged in to St. Jude Cloud. This should be sufficient for the purposes of this guide. For more detailed information, see our standard guide on accounts and billing . Tip As you navigate around St. Jude Cloud, you can click the DNAnexus logo in the top left to go back to the home screen at any time. Enable Microsoft Azure \u00b6 Steps Change your preferences to pull cloud resources from Microsoft Azure instead of Amazon AWS by default. To do this, (i) click on your profile in the top right corner, (ii) select \"My Profile\", and (iii) ensure \"Azure US (West)\" is checked. See the pictures below for more detail. Create your First Project \u00b6 Steps Select \"New Project\" in the upper left part of the screen, fill in the form as instructed in the image below, and click \"Create Project\". You should be redirected to your first DNAnexus project. We highly recommend you read through DNAnexus's dedicated guide to learn about projects: how you can navigate them, how you can share them with collaborators, and how they are billed. Set Up your Billing Account \u00b6 Billing is handled in St. Jude Cloud by creating and managing a DNAnexus billing organization (or \"org\"). Each project in DNAnexus is associated with a single org (you had to specify one when you created a project in the last step), and all compute and storage costs are billed to that org. By default, each new user on St. Jude Cloud gets a billing org called user-[username] with $50 of trial credit. You can view the billing orgs available to your account here . Info There is the potential for additional funds to be available. If you are a lab that would like to use the cloud but do not have funds available, please let us know at support@stjude.cloud . Steps Your lab will need to set up a billing org for itself. Please see our Account and Billing sections below. Billing for St. Jude Employees Billing for Non-St. Jude Employees","title":"Getting Started"},{"location":"guides/genomics-platform/#st-jude-employee-quick-start","text":"The information displayed below this point is primarily intended for employees of St. Jude Children's Research Hospital. Please complete the following check-list to get started with using St. Jude Cloud. Join St. Jude Cloud helpdesk channel on Slack ( link ). Log in to your St. Jude Cloud account ( link ). Enable Microsoft Azure ( link ). Create your first project ( link ). Set up your billing account ( link ).","title":"St. Jude Employee Quick Start"},{"location":"guides/genomics-platform/#joining-slack","text":"The St. Jude Cloud team uses Slack to communicate on a day-to-day basis. When standing up a help desk, we decided to offer that functionality on Slack to allow our community to answer questions alongside our team. If you are an employee at SJCRH, you already have a Slack account (at no cost to you) \u2014 you might even like it so much, you decide to use it during this work from home period! If you have any issues with the instructions below, you can email helpdesk@stjude.org or support@stjude.cloud . Steps Navigate to https://stjude.slack.com , click \"Sign in with your St. Jude Account\", and enter your St. Jude credentials. Congrats! You're now on Slack. Download the desktop app by visiting https://slack.com/download . The instructions differ depending on whether you are on a Windows/Mac/Linux machine. Once you install and start up the app, the sign-in process should look the same as step 1. To join the #stjudecloud-helpdesk channel, you can click the word \"Channels\" in the left sidebar and search for #stjudecloud-helpdesk . If you have issues, please see the official Slack guide on joining a channel. You should now see a screen similar to the one included below. You can type your questions into the chat box at the bottom. See you there!","title":"Joining Slack"},{"location":"guides/genomics-platform/#login-to-st-jude-cloud","text":"Signing in to St. Jude Cloud is similarly easy \u2014 if you have a SJCRH account, you already have a St. Jude Cloud account. Steps Visit https://cloud.stjude.org , log in with your St. Jude credentials, and fill in the basic profile page to your satisfaction if prompted. Congrats! You're now logged in to St. Jude Cloud. This should be sufficient for the purposes of this guide. For more detailed information, see our standard guide on accounts and billing . Tip As you navigate around St. Jude Cloud, you can click the DNAnexus logo in the top left to go back to the home screen at any time.","title":"Login to St. Jude Cloud"},{"location":"guides/genomics-platform/#enable-microsoft-azure","text":"Steps Change your preferences to pull cloud resources from Microsoft Azure instead of Amazon AWS by default. To do this, (i) click on your profile in the top right corner, (ii) select \"My Profile\", and (iii) ensure \"Azure US (West)\" is checked. See the pictures below for more detail.","title":"Enable Microsoft Azure"},{"location":"guides/genomics-platform/#create-your-first-project","text":"Steps Select \"New Project\" in the upper left part of the screen, fill in the form as instructed in the image below, and click \"Create Project\". You should be redirected to your first DNAnexus project. We highly recommend you read through DNAnexus's dedicated guide to learn about projects: how you can navigate them, how you can share them with collaborators, and how they are billed.","title":"Create your First Project"},{"location":"guides/genomics-platform/#set-up-your-billing-account","text":"Billing is handled in St. Jude Cloud by creating and managing a DNAnexus billing organization (or \"org\"). Each project in DNAnexus is associated with a single org (you had to specify one when you created a project in the last step), and all compute and storage costs are billed to that org. By default, each new user on St. Jude Cloud gets a billing org called user-[username] with $50 of trial credit. You can view the billing orgs available to your account here . Info There is the potential for additional funds to be available. If you are a lab that would like to use the cloud but do not have funds available, please let us know at support@stjude.cloud . Steps Your lab will need to set up a billing org for itself. Please see our Account and Billing sections below. Billing for St. Jude Employees Billing for Non-St. Jude Employees","title":"Set Up your Billing Account"},{"location":"guides/genomics-platform/accounts-and-billing/","text":"Accounts and Billing St. Jude Cloud is built on top of DNAnexus , a data-analysis and management platform that specializes in the field of bioinformatics. All of our account management is shared between St. Jude Cloud and DNAnexus. In other words, if you have a DNAnexus account, you automatically have a St. Jude Cloud account, and vice versa. Each new user receives a $50 credit upon creation of their St. Jude Cloud account with DNAnexus (see the note in the Billing Setup section). If you use this initial credit and are interested in additional funding, please reach out to support@stjude.cloud as additional collaboration funds may be available. St. Jude Employees The account creation and login process is slightly different if you are an internal user (you work at St. Jude). Internal users please go to the intranet home page and type 'Bioinformatics Self-Service' into the search bar. From there, click on the link that says 'Bioinformatics Self-Service on St. Jude Cloud' to access the internal guide to creating an account. St. Jude Employees \u00b6 Create An Account \u00b6 Go to the St. Jude Employee login page and log in with your current St. Jude credentials. Note If you are unable to log in at this link, and you know you have been on St. Jude Cloud before, you may have already set up a DNAnexus account through the DNANexus log in page using your St. Jude email address. To continue using this account, you will need to log in through the DNAnexus log in page . You can request that your accounts be merged by contacting DNAnexus support . Example Email to DNAnexus Support Hello DNAnexus support, I am a St. Jude employee and I would like to have my account switched over so I can use my St. Jude credentials to log in. Thank you, Billing \u00b6 Go to the Bioinformatics Self Service page on the Intranet for information on how to set up your billing account. If your account is already set up and you would like to access your Billing information: Click on the drop down next to your user name in the far right of the DNAnexus navigation bar, and select 'Profile'. Click on 'Billing Account' from the tabs listed just under the navigation bar. Non-St. Jude Employees \u00b6 Create An Account \u00b6 Go to the St. Jude Cloud log in page on DNAnexus. Click \"Create an Account\". Fill in your information. On the Create New Account page, make sure to select \"Microsoft Azure (westus)\" as the Default Cloud Region. Click 'CREATE ACCOUNT' Billing \u00b6 Click on the drop down next to your user name in the far right of the DNAnexus navigation bar, and select 'Profile'. Click on 'Billing Account' from the tabs listed just under the navigation bar. Click on the green 'ADD BILLING INFO' button to the right of your account name. A window labeled 'ACCOUNT UPGRADE' will pop up. In this window agree to DNAnexus's Terms of Service, agree to DNAnexus's pricing model, review your account information, and finally enter your billing information. Click 'Upgrade Account'. This will send an email to the individual listed as the billing contact requesting that they verify the change. Note On step 4, you must enter the billing contact's name, physical address, email address and phone number. You do not need to enter any credit card information. Once the billing contact has verified the account upgrade request, your account will be credited $50. Please contact us for help if you encounter any problems creating an account.","title":"Accounts and Billing"},{"location":"guides/genomics-platform/accounts-and-billing/#st-jude-employees","text":"","title":"St. Jude Employees"},{"location":"guides/genomics-platform/accounts-and-billing/#create-an-account","text":"Go to the St. Jude Employee login page and log in with your current St. Jude credentials. Note If you are unable to log in at this link, and you know you have been on St. Jude Cloud before, you may have already set up a DNAnexus account through the DNANexus log in page using your St. Jude email address. To continue using this account, you will need to log in through the DNAnexus log in page . You can request that your accounts be merged by contacting DNAnexus support . Example Email to DNAnexus Support Hello DNAnexus support, I am a St. Jude employee and I would like to have my account switched over so I can use my St. Jude credentials to log in. Thank you,","title":"Create An Account"},{"location":"guides/genomics-platform/accounts-and-billing/#billing","text":"Go to the Bioinformatics Self Service page on the Intranet for information on how to set up your billing account. If your account is already set up and you would like to access your Billing information: Click on the drop down next to your user name in the far right of the DNAnexus navigation bar, and select 'Profile'. Click on 'Billing Account' from the tabs listed just under the navigation bar.","title":"Billing"},{"location":"guides/genomics-platform/accounts-and-billing/#non-st-jude-employees","text":"","title":"Non-St. Jude Employees"},{"location":"guides/genomics-platform/accounts-and-billing/#create-an-account_1","text":"Go to the St. Jude Cloud log in page on DNAnexus. Click \"Create an Account\". Fill in your information. On the Create New Account page, make sure to select \"Microsoft Azure (westus)\" as the Default Cloud Region. Click 'CREATE ACCOUNT'","title":"Create An Account"},{"location":"guides/genomics-platform/accounts-and-billing/#billing_1","text":"Click on the drop down next to your user name in the far right of the DNAnexus navigation bar, and select 'Profile'. Click on 'Billing Account' from the tabs listed just under the navigation bar. Click on the green 'ADD BILLING INFO' button to the right of your account name. A window labeled 'ACCOUNT UPGRADE' will pop up. In this window agree to DNAnexus's Terms of Service, agree to DNAnexus's pricing model, review your account information, and finally enter your billing information. Click 'Upgrade Account'. This will send an email to the individual listed as the billing contact requesting that they verify the change. Note On step 4, you must enter the billing contact's name, physical address, email address and phone number. You do not need to enter any credit card information. Once the billing contact has verified the account upgrade request, your account will be credited $50. Please contact us for help if you encounter any problems creating an account.","title":"Billing"},{"location":"guides/genomics-platform/faq/","text":"Frequently Asked Questions Will I be charged for using St. Jude Cloud Genomics Platform? How can I set up billing for my lab? Does St. Jude Cloud allow for-profit companies to access genomics data? Why do I need to sign the Data Access Agreement (DAA)? How do I submit edits/revisions to the DAA? Can I get a Microsoft Word version of the DAA? Where can I find the latest version of the Data Access Agreement (DAA)? Where do I submit the Data Access Agreement (DAA)? What if I did not fill out the Data Download Permission section of the original DAA, but now I want to download data? What clinical information is available about samples in St. Jude Cloud? Can I gain access to further clinical information than what is currently available? Can I get a copy of IRB consent forms? Can I request FASTQ files on St. Jude Cloud? How can I run an analysis workflow on multiple sample files at the same time? How can I work with genomics data in the cloud? Why am I getting a connectivity error when connecting to DNAnexus API via SSH? How can I delete my account? Will I be charged for using St. Jude Cloud Genomics Platform? \u00b6 Within St. Jude Cloud Genomics Platform, any St. Jude data you receive through a data request is sponsored , meaning that you do not have to pay a fee to store this data in St. Jude Cloud. You will not incur any costs except in the following situations: Any other files, such as input files uploaded to or results produced by St. Jude Cloud, will incur a monthly fee. See your DNAnexus billing information for the cost per GB. Any analysis workflows, including those provided by St. Jude or your own that you have uploaded and packaged into the cloud, will incur a charge. The charge depends on the underlying compute resources used and the amount of time taken. Documentation for specific workflows we provide should contain guidance on how much the workflow costs. See your DNAnexus billing information for the price of each VM size per hour. At the current time, downloading data is free to end-users. Note, however, that downloading is not without cost to St. Jude. All cloud environments charge an egress fee for anyone downloading data outside of the cloud. At the current time, St. Jude has chosen to sponsor any egress fees associated with downloading data. However, we reserve the right to alter this in the future. How can I set up billing for my lab? \u00b6 Billing setup is different based on whether you are an internal user (you work at St. Jude) or an external user. If you are a St. Jude Employee, please refer to the dedicated intranet page for instructions. If you are not a St. Jude Employee, please refer to our Create an Account guide. Does St. Jude Cloud allow for-profit companies to access genomics data? \u00b6 We do not allow for-profit companies to access any of our restricted access genomics data. We are persistently working with our institution to create a path forward for companies. If you work for a for-profit company and would like to be notified if this rule changes, feel free to email us at support@stjude.cloud . Why do I need to sign the Data Access Agreement (DAA)? \u00b6 The data access agreement serves many purposes. Ultimately, the terms included in the data access agreement are in place to protect our patients. We take patient security very seriously, and we require that requesters are committed to protecting that privacy to the fullest extent. How do I submit edits/revisions to the DAA? \u00b6 We do not alter the terms of the data access agreement for any reason except when the terms are found to be directly in conflict with state or national law. In this case, please send a reference to law and a short description to support@stjude.cloud . Otherwise, please understand that simply cannot manage the operational overhead of differing agreements with different parties. Can I get a Microsoft Word version of the DAA? \u00b6 We do not provide any editable format of the DAA, as we do not accept edits or revisions from external parties. Where can I find the latest version of the Data Access Agreement (DAA)? \u00b6 You can download the latest version of the DAA here . Where do I submit the Data Access Agreement (DAA)? \u00b6 You can submit your Data Access Agreement in the drag and drop box on the last step of the data request process . What if I did not fill out the Data Download Permission section of the original DAA, but now I want to download data? \u00b6 This would be a change in terms from the original agreement, you would need to fill out a new DAA (including the Data Download Permission section for any data sets you want to download. What clinical information is available about samples in St. Jude Cloud? \u00b6 You can view the basic clinical and phenotypic information we currently provide here . Can I gain access to further clinical information than what is currently available? \u00b6 We are working towards being able to provide additional clinical annotations such as treatment, outcome, and survival data in the future. Unfortunately, we do not offer it today and we do not have a timeline for when it will be available. Can I get a copy of IRB consent forms? \u00b6 We do not provide individual consent forms or blank consent forms for any samples on St. Jude Cloud. We have chosen to remain consistent with the requirements of the other major genomic data repositories in that (1) there is an internal vetting process by the St. Jude IRB to ensure samples may be shared with the research community, but (2) we do not share the informed consents with data requesters. Can I request FASTQ files on St. Jude Cloud? \u00b6 We do not store FASTQ files in St. Jude Cloud because it would double the storage cost without any benefit. Several tools exist that you can leverage to revert BAM to FASTQ files \u2014 we recommend using Picard SamToFastq to revert BAM files. You can efficiently revert BAMs to FASTQs in the cloud by wrapping the conversion tool of your choice into a Cloud App How can I run an analysis workflow on multiple sample files at the same time? \u00b6 The DNAnexus interface does have a batch tool available; however, it is in early testing, so we recommend using dx-toolkit on the command line as the most reliable and user friendly approach to batch and submit jobs. You can find our documentation on how to install and get started with dx-toolkit here . You may also refer to the sample script below that loops through all the BAM files in the data folder and submits a job using the BAM and matching index file. for bam in $(dx ls '/data/*.bam'); do dx run \\ --yes \\ --input \"0.BAM=/data/$bam\" \\ --input \"0.BAM_INDEX=/data/$bam.bai\" \\ \"$PROJECT_ID:/Rapid RNA-Seq (BAM)\" done Note that this sample script assumes that the BAM and index files are in the data folder and the Rapid RNA-Seq analysis workflow is in the project. $PROJECT_ID can be set to your project dxid, and Rapid RNA-Seq (BAM) can be changed to the workflow you want to run. How can I work with genomics data in the cloud? \u00b6 You can view this guide to learn how create a cloud application. Why am I getting a connectivity error when connecting to DNAnexus API via SSH? \u00b6 If you are trying to run something like $ dx run --ssh <executable> and are getting a connectivity error, it may be that your firewall is too restrictive. Are you able to perform the command from an unrestricted network (like a home network)? If yes, you can resolve this issue by asking your network administrator to whitelist connections to Azure US West. All subnets (Region Name=\"uswest\") are provided here . How can I delete my account? \u00b6 Today, a St. Jude Cloud Genomics Platform account is simply a DNAnexus account. Thus, of you'd like to delete your account, you'll need to email DNAnexus asking for it to be removed. You can do so by contacting DNAnexus support at support@dnanexus.com with the following email. Subject: St. Jude Cloud account deletion Hi DNAnexus, Would you please assist me in deleting my St. Jude Cloud account? My username is _____. Thank you!","title":"Frequently Asked Questions"},{"location":"guides/genomics-platform/faq/#will-i-be-charged-for-using-st-jude-cloud-genomics-platform","text":"Within St. Jude Cloud Genomics Platform, any St. Jude data you receive through a data request is sponsored , meaning that you do not have to pay a fee to store this data in St. Jude Cloud. You will not incur any costs except in the following situations: Any other files, such as input files uploaded to or results produced by St. Jude Cloud, will incur a monthly fee. See your DNAnexus billing information for the cost per GB. Any analysis workflows, including those provided by St. Jude or your own that you have uploaded and packaged into the cloud, will incur a charge. The charge depends on the underlying compute resources used and the amount of time taken. Documentation for specific workflows we provide should contain guidance on how much the workflow costs. See your DNAnexus billing information for the price of each VM size per hour. At the current time, downloading data is free to end-users. Note, however, that downloading is not without cost to St. Jude. All cloud environments charge an egress fee for anyone downloading data outside of the cloud. At the current time, St. Jude has chosen to sponsor any egress fees associated with downloading data. However, we reserve the right to alter this in the future.","title":"Will I be charged for using St. Jude Cloud Genomics Platform?"},{"location":"guides/genomics-platform/faq/#how-can-i-set-up-billing-for-my-lab","text":"Billing setup is different based on whether you are an internal user (you work at St. Jude) or an external user. If you are a St. Jude Employee, please refer to the dedicated intranet page for instructions. If you are not a St. Jude Employee, please refer to our Create an Account guide.","title":"How can I set up billing for my lab?"},{"location":"guides/genomics-platform/faq/#does-st-jude-cloud-allow-for-profit-companies-to-access-genomics-data","text":"We do not allow for-profit companies to access any of our restricted access genomics data. We are persistently working with our institution to create a path forward for companies. If you work for a for-profit company and would like to be notified if this rule changes, feel free to email us at support@stjude.cloud .","title":"Does St. Jude Cloud allow for-profit companies to access genomics data?"},{"location":"guides/genomics-platform/faq/#why-do-i-need-to-sign-the-data-access-agreement-daa","text":"The data access agreement serves many purposes. Ultimately, the terms included in the data access agreement are in place to protect our patients. We take patient security very seriously, and we require that requesters are committed to protecting that privacy to the fullest extent.","title":"Why do I need to sign the Data Access Agreement (DAA)?"},{"location":"guides/genomics-platform/faq/#how-do-i-submit-editsrevisions-to-the-daa","text":"We do not alter the terms of the data access agreement for any reason except when the terms are found to be directly in conflict with state or national law. In this case, please send a reference to law and a short description to support@stjude.cloud . Otherwise, please understand that simply cannot manage the operational overhead of differing agreements with different parties.","title":"How do I submit edits/revisions to the DAA?"},{"location":"guides/genomics-platform/faq/#can-i-get-a-microsoft-word-version-of-the-daa","text":"We do not provide any editable format of the DAA, as we do not accept edits or revisions from external parties.","title":"Can I get a Microsoft Word version of the DAA?"},{"location":"guides/genomics-platform/faq/#where-can-i-find-the-latest-version-of-the-data-access-agreement-daa","text":"You can download the latest version of the DAA here .","title":"Where can I find the latest version of the Data Access Agreement (DAA)?"},{"location":"guides/genomics-platform/faq/#where-do-i-submit-the-data-access-agreement-daa","text":"You can submit your Data Access Agreement in the drag and drop box on the last step of the data request process .","title":"Where do I submit the Data Access Agreement (DAA)?"},{"location":"guides/genomics-platform/faq/#what-if-i-did-not-fill-out-the-data-download-permission-section-of-the-original-daa-but-now-i-want-to-download-data","text":"This would be a change in terms from the original agreement, you would need to fill out a new DAA (including the Data Download Permission section for any data sets you want to download.","title":"What if I did not fill out the Data Download Permission section of the original DAA, but now I want to download data?"},{"location":"guides/genomics-platform/faq/#what-clinical-information-is-available-about-samples-in-st-jude-cloud","text":"You can view the basic clinical and phenotypic information we currently provide here .","title":"What clinical information is available about samples in St. Jude Cloud?"},{"location":"guides/genomics-platform/faq/#can-i-gain-access-to-further-clinical-information-than-what-is-currently-available","text":"We are working towards being able to provide additional clinical annotations such as treatment, outcome, and survival data in the future. Unfortunately, we do not offer it today and we do not have a timeline for when it will be available.","title":"Can I gain access to further clinical information than what is currently available?"},{"location":"guides/genomics-platform/faq/#can-i-get-a-copy-of-irb-consent-forms","text":"We do not provide individual consent forms or blank consent forms for any samples on St. Jude Cloud. We have chosen to remain consistent with the requirements of the other major genomic data repositories in that (1) there is an internal vetting process by the St. Jude IRB to ensure samples may be shared with the research community, but (2) we do not share the informed consents with data requesters.","title":"Can I get a copy of IRB consent forms?"},{"location":"guides/genomics-platform/faq/#can-i-request-fastq-files-on-st-jude-cloud","text":"We do not store FASTQ files in St. Jude Cloud because it would double the storage cost without any benefit. Several tools exist that you can leverage to revert BAM to FASTQ files \u2014 we recommend using Picard SamToFastq to revert BAM files. You can efficiently revert BAMs to FASTQs in the cloud by wrapping the conversion tool of your choice into a Cloud App","title":"Can I request FASTQ files on St. Jude Cloud?"},{"location":"guides/genomics-platform/faq/#how-can-i-run-an-analysis-workflow-on-multiple-sample-files-at-the-same-time","text":"The DNAnexus interface does have a batch tool available; however, it is in early testing, so we recommend using dx-toolkit on the command line as the most reliable and user friendly approach to batch and submit jobs. You can find our documentation on how to install and get started with dx-toolkit here . You may also refer to the sample script below that loops through all the BAM files in the data folder and submits a job using the BAM and matching index file. for bam in $(dx ls '/data/*.bam'); do dx run \\ --yes \\ --input \"0.BAM=/data/$bam\" \\ --input \"0.BAM_INDEX=/data/$bam.bai\" \\ \"$PROJECT_ID:/Rapid RNA-Seq (BAM)\" done Note that this sample script assumes that the BAM and index files are in the data folder and the Rapid RNA-Seq analysis workflow is in the project. $PROJECT_ID can be set to your project dxid, and Rapid RNA-Seq (BAM) can be changed to the workflow you want to run.","title":"How can I run an analysis workflow on multiple sample files at the same time?"},{"location":"guides/genomics-platform/faq/#how-can-i-work-with-genomics-data-in-the-cloud","text":"You can view this guide to learn how create a cloud application.","title":"How can I work with genomics data in the cloud?"},{"location":"guides/genomics-platform/faq/#why-am-i-getting-a-connectivity-error-when-connecting-to-dnanexus-api-via-ssh","text":"If you are trying to run something like $ dx run --ssh <executable> and are getting a connectivity error, it may be that your firewall is too restrictive. Are you able to perform the command from an unrestricted network (like a home network)? If yes, you can resolve this issue by asking your network administrator to whitelist connections to Azure US West. All subnets (Region Name=\"uswest\") are provided here .","title":"Why am I getting a connectivity error when connecting to DNAnexus API via SSH?"},{"location":"guides/genomics-platform/faq/#how-can-i-delete-my-account","text":"Today, a St. Jude Cloud Genomics Platform account is simply a DNAnexus account. Thus, of you'd like to delete your account, you'll need to email DNAnexus asking for it to be removed. You can do so by contacting DNAnexus support at support@dnanexus.com with the following email. Subject: St. Jude Cloud account deletion Hi DNAnexus, Would you please assist me in deleting my St. Jude Cloud account? My username is _____. Thank you!","title":"How can I delete my account?"},{"location":"guides/genomics-platform/analyzing-data/chipseq/","text":"Authors Xing Tang, Yong Cheng Publication N/A (not published) Technical Support Contact Us Overview \u00b6 The ChIP-Seq Peak Calling workflow follows ENCODE best practices to call broad or narrow peaks on Illumina-generated ChIP-Seq data. Here, a Gzipped FastQ file from an Immunoprecipitation (IP) experiment is considered the \"case sample file\" and a Gzipped FastQ file from a control experiment is considered the \"control sample file\". The pipeline can run on matched case/control samples (recommended for better results) or just a case sample. Inputs \u00b6 Name Type Description Example FastQ files ( required if using FastQ inputs) Input file Gzipped FastQ files generated by experiment. Sample_R1.fastq.gz and Sample_R2.fastq.gz Outputs \u00b6 Name Format Description BED file .bed Peak calls Binary file .bb Binary format for BED file BigWig file .bw Shows read coverage Metrics file .txt Shows mapping and duplication rate Cross correlation plot .pdf Quality plot showing if the forward and reverse reads tend to be centered around binding sites. Workflow Steps \u00b6 The reads of the FastQ file(s) are aligned to the specified reference genome. The aligned reads are then post-processed based on best-practice QC techniques (removing multiple mapped reads, removing duplicated reads, etc). Peaks are called by SICER (broad peak analysis) or MACS2 (narrow peak analysis). Qualified peaks will be output as BED (.bed) and big BED (.bb) files. The coverage information will be output as a bigWig (.bw) file. A cross correlation plot and general metrics file are generated to help check the quality of experiment. Creating a workspace \u00b6 Before you can run one of our workflows, you must first create a workspace in DNAnexus for the run. Refer to the general workflow guide to learn how to create a DNAnexus workspace for each workflow run. You can navigate to the ChIP-Seq Peak Calling workflow page here . Uploading Input Files \u00b6 The ChIP-Seq Peak Caller takes Gzipped FastQ files generated from an IP experiment as input . Refer to the general workflow guide to learn how to upload input files to the workspace you just created. Running the Workflow \u00b6 Refer to the general workflow guide to learn how to launch the workflow, hook up input files, adjust parameters, start a run, and monitor run progress. For the ChIP-Seq workflow, you will see special preset options in the \"Launch Tool\" dropdown. These are explained below. You'll need to decide (1) whether you'd like to run broad OR narrow peak calling and (2) whether you have a case sample and a control sample (preferred) OR just a case sample. This will determine which preset you should click in this dropdown. Note that if you are not doing a case/control run, when you get to the hooking up inputs step you only need to hook up the case sample. Broad vs. narrow peak calling \u00b6 Choosing between broad and narrow peak calling depends on the experiment design. The following are good rules of thumb for choosing between the two configurations. If you are not sure which configuration to use, please consult with an expert at your institution or contact us . Narrow Peak Calling If your target protein is a transcription factor, you should probably choose narrow peak calling. You can also try the narrow peak calling workflows for the following histone marks: H3K4me3 H3K4me2 H3K9-14ac H3K27ac H2A.Z Broad Peak Calling You should try the broad peak calling workflows for the following histone marks: H3K36me3 H3K79me2 H3K27me3 H3K9me3 H3K9me1 Special Cases In some scenarios, H3K4me1, H3K9me2 and H3K9me3 might behave between narrow and broad shape, you might need to look into each peak region and consult experts. Warning If your fragment size is less than 50 base pairs, please refer to the frequently asked questions . Selecting parameters \u00b6 The following are the parameters that can be set, a short description of each parameter, and an example value. How to customize parameters is covered in the general workflow guide . If you have questions, please contact us . Parameter Name Description Example Output prefix ( required ) A name used a prefix for all outputs in the run SAMPLE1 Reference genome ( required ) Supported reference genome from one of hg19, GRCh38, mm9, mm10, dm3 GRCh38 Output bigWig Whether or not to include a bigwig file in the output True Remove blacklist peaks Whether or not to remove known problem areas True Fragment length Hardcoded fragment length of your reads. 'NA' for auto-detect. NA Caution Please be aware of the following stumbling points when setting parameters: Do not use spaces anywhere in your input file names, your output prefix, or any of the other parameters. This is generally bad practice and doesn't play well with the pipeline (consider using \"_\" instead). Do not change the output directory when you run the pipeline. At the top of parameter input page, there is a text box that allows you to change the output folder. Please ignore that setting . You only need to specify an output prefix as described above. All of the results will be put under /Results/[OUTPUT_PREFIX] . Analysis of Results \u00b6 Today, the ChIP-Seq pipeline does not produce an interactive visualization. We are working on adding this! In the meantime, you can view the cross-correlation plot(s) as outlined in the sections below. Refer to the general workflow guide to learn how to access raw results files. ChIP-Seq results will be in the Results folder. Select the output folder name you specified in the parameters part of this workflow run. Interpreting results \u00b6 For the ChIP-Seq pipeline, every pipeline run outputs a README.doc file which contains the latest information on which results are included. You can refer to that file for the most up to date information on raw outputs. Frequently asked questions \u00b6 If you have any questions not covered here, feel free to contact us . Q: Should I choose narrow peak calling pipeline or broad peak calling pipeline? A. We built two workflows: one for narrow peak calling and another broad peak calling. If your target protein is a transcription factor, please use narrow peak calling workflow. For histone marks H3K4me3, H3K4me2, H3K9-14ac, H3K27ac and H2A.Z, you could try narrow peak calling workflow. For histone marks H3K36me3, H3K79me2, H3K27me3, H3K9me3 and H3K9me1, you could try broad peak calling workflow. In some scenario, H3K4me1, H3K9me2 and H3K9me3 might behave between narrow and broad shape, you might need to look into each peak region and consult experts. Q. What to do if your fragment size is less than 50 base pairs? A. We estimate fragment size from the data based on the cross correlation plot. Usually the fragment size is above 50bp. If the estimated fragment size lower than 50bp, the workflow will stop at the peak calling stage (MACS2/SICER) after BWA mapping finishes. You can rerun the analysis with a specified fragment length. Similar Topics \u00b6 Running our Workflows Working with our Data Overview Upload/Download Data (local)","title":"ChIP-Seq Peak Calling"},{"location":"guides/genomics-platform/analyzing-data/chipseq/#overview","text":"The ChIP-Seq Peak Calling workflow follows ENCODE best practices to call broad or narrow peaks on Illumina-generated ChIP-Seq data. Here, a Gzipped FastQ file from an Immunoprecipitation (IP) experiment is considered the \"case sample file\" and a Gzipped FastQ file from a control experiment is considered the \"control sample file\". The pipeline can run on matched case/control samples (recommended for better results) or just a case sample.","title":"Overview"},{"location":"guides/genomics-platform/analyzing-data/chipseq/#inputs","text":"Name Type Description Example FastQ files ( required if using FastQ inputs) Input file Gzipped FastQ files generated by experiment. Sample_R1.fastq.gz and Sample_R2.fastq.gz","title":"Inputs"},{"location":"guides/genomics-platform/analyzing-data/chipseq/#outputs","text":"Name Format Description BED file .bed Peak calls Binary file .bb Binary format for BED file BigWig file .bw Shows read coverage Metrics file .txt Shows mapping and duplication rate Cross correlation plot .pdf Quality plot showing if the forward and reverse reads tend to be centered around binding sites.","title":"Outputs"},{"location":"guides/genomics-platform/analyzing-data/chipseq/#workflow-steps","text":"The reads of the FastQ file(s) are aligned to the specified reference genome. The aligned reads are then post-processed based on best-practice QC techniques (removing multiple mapped reads, removing duplicated reads, etc). Peaks are called by SICER (broad peak analysis) or MACS2 (narrow peak analysis). Qualified peaks will be output as BED (.bed) and big BED (.bb) files. The coverage information will be output as a bigWig (.bw) file. A cross correlation plot and general metrics file are generated to help check the quality of experiment.","title":"Workflow Steps"},{"location":"guides/genomics-platform/analyzing-data/chipseq/#creating-a-workspace","text":"Before you can run one of our workflows, you must first create a workspace in DNAnexus for the run. Refer to the general workflow guide to learn how to create a DNAnexus workspace for each workflow run. You can navigate to the ChIP-Seq Peak Calling workflow page here .","title":"Creating a workspace"},{"location":"guides/genomics-platform/analyzing-data/chipseq/#uploading-input-files","text":"The ChIP-Seq Peak Caller takes Gzipped FastQ files generated from an IP experiment as input . Refer to the general workflow guide to learn how to upload input files to the workspace you just created.","title":"Uploading Input Files"},{"location":"guides/genomics-platform/analyzing-data/chipseq/#running-the-workflow","text":"Refer to the general workflow guide to learn how to launch the workflow, hook up input files, adjust parameters, start a run, and monitor run progress. For the ChIP-Seq workflow, you will see special preset options in the \"Launch Tool\" dropdown. These are explained below. You'll need to decide (1) whether you'd like to run broad OR narrow peak calling and (2) whether you have a case sample and a control sample (preferred) OR just a case sample. This will determine which preset you should click in this dropdown. Note that if you are not doing a case/control run, when you get to the hooking up inputs step you only need to hook up the case sample.","title":"Running the Workflow"},{"location":"guides/genomics-platform/analyzing-data/chipseq/#broad-vs-narrow-peak-calling","text":"Choosing between broad and narrow peak calling depends on the experiment design. The following are good rules of thumb for choosing between the two configurations. If you are not sure which configuration to use, please consult with an expert at your institution or contact us . Narrow Peak Calling If your target protein is a transcription factor, you should probably choose narrow peak calling. You can also try the narrow peak calling workflows for the following histone marks: H3K4me3 H3K4me2 H3K9-14ac H3K27ac H2A.Z Broad Peak Calling You should try the broad peak calling workflows for the following histone marks: H3K36me3 H3K79me2 H3K27me3 H3K9me3 H3K9me1 Special Cases In some scenarios, H3K4me1, H3K9me2 and H3K9me3 might behave between narrow and broad shape, you might need to look into each peak region and consult experts. Warning If your fragment size is less than 50 base pairs, please refer to the frequently asked questions .","title":"Broad vs. narrow peak calling"},{"location":"guides/genomics-platform/analyzing-data/chipseq/#selecting-parameters","text":"The following are the parameters that can be set, a short description of each parameter, and an example value. How to customize parameters is covered in the general workflow guide . If you have questions, please contact us . Parameter Name Description Example Output prefix ( required ) A name used a prefix for all outputs in the run SAMPLE1 Reference genome ( required ) Supported reference genome from one of hg19, GRCh38, mm9, mm10, dm3 GRCh38 Output bigWig Whether or not to include a bigwig file in the output True Remove blacklist peaks Whether or not to remove known problem areas True Fragment length Hardcoded fragment length of your reads. 'NA' for auto-detect. NA Caution Please be aware of the following stumbling points when setting parameters: Do not use spaces anywhere in your input file names, your output prefix, or any of the other parameters. This is generally bad practice and doesn't play well with the pipeline (consider using \"_\" instead). Do not change the output directory when you run the pipeline. At the top of parameter input page, there is a text box that allows you to change the output folder. Please ignore that setting . You only need to specify an output prefix as described above. All of the results will be put under /Results/[OUTPUT_PREFIX] .","title":"Selecting parameters"},{"location":"guides/genomics-platform/analyzing-data/chipseq/#analysis-of-results","text":"Today, the ChIP-Seq pipeline does not produce an interactive visualization. We are working on adding this! In the meantime, you can view the cross-correlation plot(s) as outlined in the sections below. Refer to the general workflow guide to learn how to access raw results files. ChIP-Seq results will be in the Results folder. Select the output folder name you specified in the parameters part of this workflow run.","title":"Analysis of Results"},{"location":"guides/genomics-platform/analyzing-data/chipseq/#interpreting-results","text":"For the ChIP-Seq pipeline, every pipeline run outputs a README.doc file which contains the latest information on which results are included. You can refer to that file for the most up to date information on raw outputs.","title":"Interpreting results"},{"location":"guides/genomics-platform/analyzing-data/chipseq/#frequently-asked-questions","text":"If you have any questions not covered here, feel free to contact us . Q: Should I choose narrow peak calling pipeline or broad peak calling pipeline? A. We built two workflows: one for narrow peak calling and another broad peak calling. If your target protein is a transcription factor, please use narrow peak calling workflow. For histone marks H3K4me3, H3K4me2, H3K9-14ac, H3K27ac and H2A.Z, you could try narrow peak calling workflow. For histone marks H3K36me3, H3K79me2, H3K27me3, H3K9me3 and H3K9me1, you could try broad peak calling workflow. In some scenario, H3K4me1, H3K9me2 and H3K9me3 might behave between narrow and broad shape, you might need to look into each peak region and consult experts. Q. What to do if your fragment size is less than 50 base pairs? A. We estimate fragment size from the data based on the cross correlation plot. Usually the fragment size is above 50bp. If the estimated fragment size lower than 50bp, the workflow will stop at the peak calling stage (MACS2/SICER) after BWA mapping finishes. You can rerun the analysis with a specified fragment length.","title":"Frequently asked questions"},{"location":"guides/genomics-platform/analyzing-data/chipseq/#similar-topics","text":"Running our Workflows Working with our Data Overview Upload/Download Data (local)","title":"Similar Topics"},{"location":"guides/genomics-platform/analyzing-data/cis-x/","text":"Authors Yu Liu 1,2,*,# , Chunliang Li 3,* , Shuhong Shen 1,4,* , Xiaolong Chen 2 , Karol Szlachta 2 , Michael N. Edmonson 2 , Ying Shao 2 , Xiaotu Ma 2 , Judith Hyle 3 , Shaela Wright 3 , Bensheng Ju 2 , Michael C. Rusch 2 , Yanling Liu 2 , Benshang Li 1,4 , Michael Macias 2 , Liqing Tian 2 , John Easton 2 , Maoxiang Qian 5 , Jun J. Yang 5,6,7 , Shaoyan Hu 8 , A. Thomas Look 9,10 and Jinghui Zhang 2,# Publication \"Discovery of regulatory non-coding variants in individual cancer genomes using cis-X\" (in submission) Technical Support Contact Us Overview \u00b6 Activating regular variants usually cause the cis-activation of target genes. To find cis-activated genes, allelic specific/imbalance expressions (ASE) and outlier high expression (OHE) signals are used. Variants in the same topologically associated domains with the candidates can then be searched, including structural variants (SV), copy number aberrations (CNA), and single nucleotide variations (SNV) and insertion/deletions (indel). A transcription factor binding analysis is also done, using motifs from HOCOMOCO v10 models. cis-X currently only works with hg19 (GRCh37). Inputs \u00b6 Name Type Description Example Sample ID String The ID of the input sample SJALL018373_D1 Disease subtype String The disease name under analysis. Must be either NBL or TALL. TALL Single nucleotide variants File Tab-delimited file containing raw sequence variants *.txt CNV/LOH regions File Tab-delimited file containing any aneuploidy region existing in the tumor genome under analysis *.txt RNA-seq BAM File BAM file aligned to hg19 (GRCh37) *.bam RNA-seq BAM index File BAM index for the given BAM *.bam.bai Gene expression table File Tab-delimited file containing gene level expressions for the tumor under analysis in FPKM *.txt Somatic SNV/indels File Tab-delimited file containing somatic SNV/indels in the tumor genome *.txt Somatic SVs File Tab-delimited file containing somatic acquired structural variants in the tumor genome *.txt Somatic CNVs File Tab-delimited file containing copy number aberrations in the tumor genome *.txt CNV/LOH action String The behavior when handling markers in CNV/LOH regions. Can be either keep or drop . [default: keep] drop Minimum coverage for WGS Integer The minimum coverage in WGS to be included in the analysis [default: 10] 10 Minimum coverage for RNA-seq Integer The minimum coverage in RNA-seq to be included in the analysis [default: 10] 5 Candidate FPKM threshold Float The FPKM threshold for the nomination of a cis-activated candidate [default: 5.0] 0.1 User annotations File User applied annotations [optional] *.bed chr Prefix String Whether the names in the reference sequence dictionary are prefixed with \"chr\". Must be either TRUE or FALSE . [default: TRUE] TRUE TAD annotations File TAD annotations [optional] *.bed Input file configuration \u00b6 cis-X requires six tab-delimited input files to be prepared in advance. These files can be uploaded via the command line . Note Even though CNV/LOH regions, somatic SNV/indels, somatic SVs, and somatic CNVs can be \"empty\", using such inputs will produce results with a much higher false positive rate. Single nucleotide variants A list of single nucleotide markers is a tab-delimited file with the following columns: Chr : chromosome name for the marker Pos : genomic start location for the marker Chr_Allele : reference allele Alternative_Allele : alternative allele reference_tumor_count : reference allele count in the tumor genome alternative_tumor_count : alternative allele count in the tumor genome reference_normal_count : reference allele count in the matched normal genome alternative_normal_count : alternative count in the matched normal genome This file can be generated with Bambino. Example Chr Pos Chr_Allele Alternative_Allele reference_tumor_count alternative_tumor_count reference_normal_count alternative_normal_count chr11 61396 TT 0 3 0 10 chr11 72981 T 1 3 2 3 CNV/LOH regions The CNV/LOH regions are all the genomic regions carrying copy number variations (CNV) or loss of heterozygosity (LOH), which will be filtered out during analysis. This is a tab-delimited file in the bed format. It must have at least the following three columns: chrom : chromosome name loc.start : genomic start location loc.end : genomic end location If no CNV/LOH are in the genome under analysis, a file with no rows (but including headers) can be provided. This file can be generated with CONSERTING. Example chrom loc.start loc.end Sample seg.mean LogRatio source chr9 10712 37855747 SJALL018373_D1 0.471181417 LOH chr9 20276901 20703900 SJALL018373_D1 -0.978 -5.696 CNV Gene expression table The gene expression table is a tab-delimited file containing gene level expressions for the tumor under analysis. The expressions are in FPKM (fragments per kilobase of transcript per million mapped reads). GeneID : gene Ensembl ID GeneName : gene symbol Type : transcript type Status : transcript status (must be KNOWN , NOVEL , or PUTATIVE ) Chr : chromosome name Start genomic start location End : genomic end location [SampleID...]: FPKM for the given sample This file can be generated with the output of HTseq-count preprocessed through mergeData_geneName.pl (available with the distribution of cis-X). The data must be able to match values in the given gene specific reference expression matrices generated from a larger cohort. Example GeneID GeneName Type Status Chr Start End SJALL018373_D1 ENSG00000261122.2 5S_rRNA lincRNA NOVEL chr16 34977639 34990886 0.0000 ENSG00000249352.3 7SK lincRNA NOVEL chr5 68266266 68325992 4.5937 Somatic SNV/indels This is a tab-delimited file containing somatic sequence mutations present in the genome under analysis. It includes both single nucleotide variants (SNV) and small insertion/deletions (indel). The file must have the following columns: chr : chromosome name pos : genomic start location ref : reference nucleotide mutant : mutant nucleotide type : mutation type (must be either snv or indel ) Note that the coordinate used for an indel is after the inserted sequence. If no SNV/indels are in the sample under analysis, a file with no rows (but including headers) can be provided. This file can can be created with Bambino and then preprocessed using the steps taken in \" The genetic basis of early T-cell precursor acute lymphoblastic leukaemia \". Example chr pos ref mut type chr1 24782720 G A snv chr11 82896176 T C snv Somatic SVs This is a tab-delimited file containing somatic-acquired structural variants (SV) in the cancer genome. The file must have the following columns: chrA : chromosome name of the left breakpoint posA : genomic location of the left breakpoint ortA : strand orientation of the left breakpoint chrB : chromosome name of the right breakpoint posB : genomic location of the right breakpoint ortB : strand orientation of the right breakpoint Strand orientations are denoted with a + for a sense or coding strand and - for a antisense or non-coding strand. If no somatic SVs are in the sample under analysis, a file with no rows (but including headers) can be provided. This file can be generated by CREST. Example chrA posA ortA chrB posB ortB type chr11 33913169 + chr7 142494049 - CTX chr11 64219334 + chr2 205042527 - CTX Somatic CNVs This is a tab-delimited file containing the genomic regions with somatic-acquired copy number aberrations (CNA) in the cancer genome. chr : chromosome name start : genomic start location end : genomic end location logR : log2 ratio If no somatic CNVs are in the sample under analysis, a file with no rows (but including headers) can be provided. This file can be generating by CONSERTING. Example chr start end logR chr9 20276901 20703900 -5.696 Outputs \u00b6 Name Description cis-activated candidates cis-activated candidates in the tumor genome under analysis SV candidates Structural variant (SV) candidates predicted as the causal for the cis-activated genes in the regulatory territory CNA candidates Copy number aberrations (CNA) predicted as the causal for the cis-activated genes in the regulatory territory SNV/indel candidates SNV/indel candidates predicted as functional and predicted transcription factors OHE results Raw outlier high expression (OHE) results Gene level ASE results Raw gene level allelic specific expression (ASE) results Single marker ASE results Raw single marker allelic specific expression (ASE) results Creating a workspace \u00b6 Before you can run one of our workflows, you must first create a workspace in DNAnexus for the run. Refer to the general workflow guide to learn how to create a DNAnexus workspace for each workflow run. You can navigate to the Cis-X workflow page here Uploading Input Files \u00b6 cis-X requires a total of eight files to be uploaded, as input . Refer to the general workflow guide to learn how to upload input files to the workspace you just created. Running the Workflow \u00b6 Refer to the general workflow guide to learn how to launch the workflow, hook up input files, adjust parameters, start a run, and monitor run progress. Analysis of Results \u00b6 Each tool in St. Jude Cloud produces a visualization that makes understanding results more accessible than working with excel spreadsheet or tab delimited files. This is the primary way we recommend you work with your results. Refer to the general workflow guide to learn how to access these visualizations. We also include the raw output files for you to dig into if the visualization is not sufficient to answer your research question. Refer to the general workflow guide to learn how to access raw results files. Interpreting results \u00b6 cis-activated candidates \u00b6 The main result file contains the cis-activated candidates in the tumor genome under analysis. gene : gene accession number ( RefSeq ID) gsym : gene symbol chrom : chromosome name strand : strand orientation start : genomic start location end : genomic end location cdsStartStat : coding sequence (CDS) start status cdsEndStat : coding sequence (CDS) end status markers : number of heterozygous markers in this gene ase_markers : number of heterozygous markers showing allelic specific expressions (ASE) average_ai_all : average B-allele frequency (BAF) difference between RNA and DNA for all heterozygous markers average_ai_ase : average BAF difference between RNA and DNA for ASE markers pval_all_markers : p-value for each marker in the ASE test pval_ase_markers : p-value for ASE markers in the ASE test ai_all_markers : BAF difference between RNA and DNA for all heterozygrous markers ai_ase_markers : BAF difference between RNA and DNA for ASE markers comb.pval : combined p-value for the ASE test mean.delta : average BAF difference between RNA and DNA for all markers rawp : raw p-value for the ASE test Bonferroni : adjusted p-value for the ASE test (single-step Bonferroni) ABH : adjusted p-value for the ASE test (Benjamini-Hochberg) FPKM : FPKM value loo.source : which reference expression matrix was used in the outlier high expression (OHE) test loo.cohort.size : number of cases in the reference expression matrix for this gene loo.pval : p-value of the OHE test loo.rank : rank of the case under analysis among the reference cases imprinting.status : imprinting status of the gene candidate.group : status of the gene, combining both ASE and outlier tests Strand orientations are denoted with a + for a sense or coding strand and - for a antisense or non-coding strand. Coding sequence status is typically one of \"none\" (not specified), \"unk\" (unknown), \"incmpl\" (incomplete), or \"cmpl\" (complete). Example gene gsym chrom strand start end cdsStartStat cdsEndStat markers ase_markers average_ai_all average_ai_ase pval_all_markers pval_ase_markers ai_all_markers ai_ase_markers comb.pval mean.delta rawp Bonferroni ABH FPKM loo.source loo.cohort.size loo.pval loo.rank imprinting.status candidate.group NM_145804 ABTB2 chr11 - 34172533 34379555 cmpl cmpl 5 5 0.5 0.500 0.001953125,0.001953125,0.001953125,6.10351562500001e-05,0.000244140625 0.001953125,0.001953125,0.001953125,6.10351562500001e-05,0.000244140625 0.5,0.5,0.5,0.5,0.5 0.5,0.5,0.5,0.5,0.5 0.000644290972057077 0.5 0.000644290972057077 0.632049443587993 0.0110866672927557 7.6776 bi_cohort 40 0.0367241086505276 1 ase_outlier NM_003189 TAL1 chr1 - 47681961 47698007 cmpl cmpl 2 2 0.482 0.482 6.66361745922277e-28,3.30872245021211e-24 6.66361745922277e-28,3.30872245021211e-24 0.464912280701754,0.5 0.464912280701754,0.5 4.69553625126628e-26 0.482456140350877 4.69553625126628e-26 4.60632106249222e-23 6.11761294450693e-24 8.8168 white_list 167 0.0139385771987089 1 ase_outlier SV candidates \u00b6 Structural variant (SV) candidates include candidates predicted as the causal for the cis-activated genes in the regulatory territory. left.candidate.inTAD : cis-activated candidate near the left breakpoint right.candidate.inTAD : cis-activated candidate near the right breakpoint chrA : chromosome name of the left breakpoint posA : genomic location of the left breakpoint ortA : strand orientation of the left breakpoint chrB : chromosome name of the right breakpoint posB : genomic location of the right breakpoint ortB : strand orientation of the right breakpoint type : type of translocation Example left.candidate.inTAD right.candidate.inTAD chrA posA ortA chrB posB ortB type LMO2 chr11 33913169 + chr7 142494049 - CTX CNA candidates \u00b6 Copy number aberration (CNA) candidates include candidates predicted as the causal for the cis-activated genes in the regulatory territory. candidate.inTAD : cis-activated candidate by the CNA chr : chromosome name start : genomic start position end : genomic end location logR : log ratio of the CNA SNV/indel candidates \u00b6 SNV/indel candidates include predicted candidates as functional and predicted transcription factors. The mutations are also annotated for known regulatory elements reported by the NIH Roadmap Epigenomics Project by collecting 111 cell lines. chrom : chromosome name pos : genomic start position ref : reference allele genotype mut : mutant allele genotype type : mutation type (either snv or indel ) target : cis-activated candidate dist : distance between the mutation and transcription start sites of the target gene tf : transcription factors predicted to have the binding motif introduced by the mutation EpiRoadmap_enhancer : enhancer regions that overlap with the mutation (from the NIH Roadmap Epigenomics Project ) EpiRoadmap_promoter : promoter regions that overlap with the mutation (from the NIH Roadmap Epigenomics Project ) EpiRoadmap_dyadic : dyadic regions that overlap with the mutation (from the NIH Roadmap Epigenomics Project ) Example chrom pos ref mut type target dist tf EpiRoadmap_enhancer EpiRoadmap_promoter EpiRoadmap_dyadic chr1 47696311 C T snv TAL1 1696 BCL11A,CEBPG,PBX2,YY1,ZBTB4 Brain,Digestive,ES-deriv,ESC,HSC & B-cell,Heart,Muscle,Other,Sm. Muscle,iPSC OHE results \u00b6 OHE results are the raw results for the outlier expression test. Gene : gene symbol fpkm.raw : FPKM value size.bi : number of cases in the bi-allelic reference cohort p.bi : p-value in the outlier test using the bi-allelic reference cohort rank.bi : rank of the expression level in the case under analysis compared to the bi-allelic reference cohort size.cohort : number of cases in the entire reference cohort p.cohort : p-value in the outlier test using the entire reference cohort rank.cohort : rank of the expression level in the case under analysis compared to the entire reference cohort size.white : number of cases in the whitelist reference cohort p.white : p-value in the outlier test using the whitelist reference cohort rank.white : rank of the expression level in the case under analysis compared to the whitelist reference cohort Example Gene fpkm.raw size.bi p.bi rank.bi size.cohort p.cohort rank.cohort size.white p.white rank.white 7SK 4.5937 na na na 264 0.716284011918374 162 na na na A1BG 0.2312 24 0.900132642257996 21 264 0.84055666600945 222 na na na Gene level ASE results \u00b6 Gene level ASE results are the raw results from the gene level ASE test. gene : gene accession number ( RefSeq ID) gsym : gene symbol chrom : chromosome name strand : strand orientation start : genomic start location end : genomic end location cdsStartStat : coding sequence (CDS) start status cdsEndStat : coding sequence (CDS) end status markers : number of heterozygous markers in this gene ase_markers : number of heterozygous markers showing allelic specific expressions (ASE) average_ai_all : average B-allele frequency (BAF) difference between RNA and DNA for all heterozygous markers average_ai_ase : average BAF difference between RNA and DNA for ASE markers pval_all_markers : p-value for each marker in the ASE test pval_ase_markers : p-value for ASE markers in the ASE test ai_all_markers : BAF difference between RNA and DNA for all heterozygrous markers ai_ase_markers : BAF difference between RNA and DNA for ASE markers comb.pval : combined p-value for the ASE test mean.delta : average BAF difference between RNA and DNA for all markers rawp : raw p-value for the ASE test Bonferroni : adjusted p-value for the ASE test (single-step Bonferroni) ABH : adjusted p-value for the ASE test (Benjamini-Hochberg) Example gene gsym chrom strand start end cdsStartStat cdsEndStat markers ase_markers average_ai_all average_ai_ase pval_all_markers pval_ase_markers ai_all_markers ai_ase_markers comb.pval mean.delta rawp Bonferroni ABH NM_024684 AAMDC chr11 + 77532207 77583398 cmpl cmpl 2 0 0.079 na 0.924775093657227,0.0331439677875056 na 0.00892857142857145,0.149122807017544 na 0.175073458624837 0.0790256892230577 0.175073458624837 1 0.480780882445856 NM_015423 AASDHPPT chr11 + 105948291 105969419 cmpl cmpl 2 0 0.023 na 0.749258624760841,1 na 0.0384615384615384,0.00769230769230766 na 0.86559726476049 0.023076923076923 0.86559726476049 1 0.873257417545981 Single marker ASE results \u00b6 Single marker ASE results are the raw results from the single marker ASE test. chrom : chromosome name pos : genomic start position ref : reference allele genotype mut : non-reference allele genotype cvg_wgs : coverage of the marker from the whole genome sequence (WGS) mut_freq_wgs : non-reference allele fraction in the WGS cvg_rna : coverage of the marker from the RNA-seq mut_freq_rna : non-reference allele fraction in the RNA-seq ref.1 : read count of the reference allele in the RNA-seq var : read count of the non-reference allele in the RNA-seq pvalue : p-value from the binomial test delta.abs : absolute difference of the non-reference allele fraction between the WGS and RNA-seq Example chrom pos ref mut cvg_wgs mut_freq_wgs cvg_rna mut_freq_rna ref.1 var pvalue delta.abs chr11 204147 G A 36 0.472 85 0.553 38 47 0.385669420119278 0.0529411764705883 chr11 205198 C A 23 0.522 83 0.313 57 26 0.000877551780002863 0.186746987951807 Frequently asked questions \u00b6 None yet! If you have any questions not covered here, feel free to reach out on our contact form . Similar Topics \u00b6 Running our Workflows Working with our Data Overview Upload/Download Data (local) Footnotes 1 Pediatric Translational Medicine Institute, Shanghai Children's Medical Center, Shanghai Jiao Tong University School of Medicine, Shanghai, China 2 Department of Computational Biology, St. Jude Children's Research Hospital, Memphis, TN 38105, USA 3 Department of Tumor Cell Biology, St. Jude Children's Research Hospital, Memphis, TN 38105, USA 4 Key Laboratory of Pediatric Hematology & Oncology Ministry of Health, Department of Hematology & Oncology, Shanghai Children's Medical Center, Shanghai Jiao Tong University School of Medicine, Shanghai, China 5 Department of Pharmaceutical Sciences, St. Jude Children's Research Hospital, Memphis, TN 38105, USA 6 Hematological Malignancies Program, St. Jude Children's Research Hospital, Memphis, TN 38105, USA 7 Department of Oncology, St. Jude Children's Research Hospital, Memphis, TN 38105, USA 8 Children's Hospital of Soochow University, Suzhou, Jiangsu, China 9 Department of Pediatric Oncology, Dana-Farber Cancer Institute, Harvard Medical School, Boston, MA 02215, USA 10 Division of Pediatric Hematology-Oncology, Boston Children's Hospital, MA 02115, USA * Contributed equally to this work. # Correspondence should be addressed to Y.L. ( liuyu@scmc.com.cn ) or J.Z. ( jinghui.zhang@stjude.org ).","title":"cis-X"},{"location":"guides/genomics-platform/analyzing-data/cis-x/#overview","text":"Activating regular variants usually cause the cis-activation of target genes. To find cis-activated genes, allelic specific/imbalance expressions (ASE) and outlier high expression (OHE) signals are used. Variants in the same topologically associated domains with the candidates can then be searched, including structural variants (SV), copy number aberrations (CNA), and single nucleotide variations (SNV) and insertion/deletions (indel). A transcription factor binding analysis is also done, using motifs from HOCOMOCO v10 models. cis-X currently only works with hg19 (GRCh37).","title":"Overview"},{"location":"guides/genomics-platform/analyzing-data/cis-x/#inputs","text":"Name Type Description Example Sample ID String The ID of the input sample SJALL018373_D1 Disease subtype String The disease name under analysis. Must be either NBL or TALL. TALL Single nucleotide variants File Tab-delimited file containing raw sequence variants *.txt CNV/LOH regions File Tab-delimited file containing any aneuploidy region existing in the tumor genome under analysis *.txt RNA-seq BAM File BAM file aligned to hg19 (GRCh37) *.bam RNA-seq BAM index File BAM index for the given BAM *.bam.bai Gene expression table File Tab-delimited file containing gene level expressions for the tumor under analysis in FPKM *.txt Somatic SNV/indels File Tab-delimited file containing somatic SNV/indels in the tumor genome *.txt Somatic SVs File Tab-delimited file containing somatic acquired structural variants in the tumor genome *.txt Somatic CNVs File Tab-delimited file containing copy number aberrations in the tumor genome *.txt CNV/LOH action String The behavior when handling markers in CNV/LOH regions. Can be either keep or drop . [default: keep] drop Minimum coverage for WGS Integer The minimum coverage in WGS to be included in the analysis [default: 10] 10 Minimum coverage for RNA-seq Integer The minimum coverage in RNA-seq to be included in the analysis [default: 10] 5 Candidate FPKM threshold Float The FPKM threshold for the nomination of a cis-activated candidate [default: 5.0] 0.1 User annotations File User applied annotations [optional] *.bed chr Prefix String Whether the names in the reference sequence dictionary are prefixed with \"chr\". Must be either TRUE or FALSE . [default: TRUE] TRUE TAD annotations File TAD annotations [optional] *.bed","title":"Inputs"},{"location":"guides/genomics-platform/analyzing-data/cis-x/#input-file-configuration","text":"cis-X requires six tab-delimited input files to be prepared in advance. These files can be uploaded via the command line . Note Even though CNV/LOH regions, somatic SNV/indels, somatic SVs, and somatic CNVs can be \"empty\", using such inputs will produce results with a much higher false positive rate.","title":"Input file configuration"},{"location":"guides/genomics-platform/analyzing-data/cis-x/#outputs","text":"Name Description cis-activated candidates cis-activated candidates in the tumor genome under analysis SV candidates Structural variant (SV) candidates predicted as the causal for the cis-activated genes in the regulatory territory CNA candidates Copy number aberrations (CNA) predicted as the causal for the cis-activated genes in the regulatory territory SNV/indel candidates SNV/indel candidates predicted as functional and predicted transcription factors OHE results Raw outlier high expression (OHE) results Gene level ASE results Raw gene level allelic specific expression (ASE) results Single marker ASE results Raw single marker allelic specific expression (ASE) results","title":"Outputs"},{"location":"guides/genomics-platform/analyzing-data/cis-x/#creating-a-workspace","text":"Before you can run one of our workflows, you must first create a workspace in DNAnexus for the run. Refer to the general workflow guide to learn how to create a DNAnexus workspace for each workflow run. You can navigate to the Cis-X workflow page here","title":"Creating a workspace"},{"location":"guides/genomics-platform/analyzing-data/cis-x/#uploading-input-files","text":"cis-X requires a total of eight files to be uploaded, as input . Refer to the general workflow guide to learn how to upload input files to the workspace you just created.","title":"Uploading Input Files"},{"location":"guides/genomics-platform/analyzing-data/cis-x/#running-the-workflow","text":"Refer to the general workflow guide to learn how to launch the workflow, hook up input files, adjust parameters, start a run, and monitor run progress.","title":"Running the Workflow"},{"location":"guides/genomics-platform/analyzing-data/cis-x/#analysis-of-results","text":"Each tool in St. Jude Cloud produces a visualization that makes understanding results more accessible than working with excel spreadsheet or tab delimited files. This is the primary way we recommend you work with your results. Refer to the general workflow guide to learn how to access these visualizations. We also include the raw output files for you to dig into if the visualization is not sufficient to answer your research question. Refer to the general workflow guide to learn how to access raw results files.","title":"Analysis of Results"},{"location":"guides/genomics-platform/analyzing-data/cis-x/#interpreting-results","text":"","title":"Interpreting results"},{"location":"guides/genomics-platform/analyzing-data/cis-x/#cis-activated-candidates","text":"The main result file contains the cis-activated candidates in the tumor genome under analysis. gene : gene accession number ( RefSeq ID) gsym : gene symbol chrom : chromosome name strand : strand orientation start : genomic start location end : genomic end location cdsStartStat : coding sequence (CDS) start status cdsEndStat : coding sequence (CDS) end status markers : number of heterozygous markers in this gene ase_markers : number of heterozygous markers showing allelic specific expressions (ASE) average_ai_all : average B-allele frequency (BAF) difference between RNA and DNA for all heterozygous markers average_ai_ase : average BAF difference between RNA and DNA for ASE markers pval_all_markers : p-value for each marker in the ASE test pval_ase_markers : p-value for ASE markers in the ASE test ai_all_markers : BAF difference between RNA and DNA for all heterozygrous markers ai_ase_markers : BAF difference between RNA and DNA for ASE markers comb.pval : combined p-value for the ASE test mean.delta : average BAF difference between RNA and DNA for all markers rawp : raw p-value for the ASE test Bonferroni : adjusted p-value for the ASE test (single-step Bonferroni) ABH : adjusted p-value for the ASE test (Benjamini-Hochberg) FPKM : FPKM value loo.source : which reference expression matrix was used in the outlier high expression (OHE) test loo.cohort.size : number of cases in the reference expression matrix for this gene loo.pval : p-value of the OHE test loo.rank : rank of the case under analysis among the reference cases imprinting.status : imprinting status of the gene candidate.group : status of the gene, combining both ASE and outlier tests Strand orientations are denoted with a + for a sense or coding strand and - for a antisense or non-coding strand. Coding sequence status is typically one of \"none\" (not specified), \"unk\" (unknown), \"incmpl\" (incomplete), or \"cmpl\" (complete).","title":"cis-activated candidates"},{"location":"guides/genomics-platform/analyzing-data/cis-x/#sv-candidates","text":"Structural variant (SV) candidates include candidates predicted as the causal for the cis-activated genes in the regulatory territory. left.candidate.inTAD : cis-activated candidate near the left breakpoint right.candidate.inTAD : cis-activated candidate near the right breakpoint chrA : chromosome name of the left breakpoint posA : genomic location of the left breakpoint ortA : strand orientation of the left breakpoint chrB : chromosome name of the right breakpoint posB : genomic location of the right breakpoint ortB : strand orientation of the right breakpoint type : type of translocation","title":"SV candidates"},{"location":"guides/genomics-platform/analyzing-data/cis-x/#cna-candidates","text":"Copy number aberration (CNA) candidates include candidates predicted as the causal for the cis-activated genes in the regulatory territory. candidate.inTAD : cis-activated candidate by the CNA chr : chromosome name start : genomic start position end : genomic end location logR : log ratio of the CNA","title":"CNA candidates"},{"location":"guides/genomics-platform/analyzing-data/cis-x/#snvindel-candidates","text":"SNV/indel candidates include predicted candidates as functional and predicted transcription factors. The mutations are also annotated for known regulatory elements reported by the NIH Roadmap Epigenomics Project by collecting 111 cell lines. chrom : chromosome name pos : genomic start position ref : reference allele genotype mut : mutant allele genotype type : mutation type (either snv or indel ) target : cis-activated candidate dist : distance between the mutation and transcription start sites of the target gene tf : transcription factors predicted to have the binding motif introduced by the mutation EpiRoadmap_enhancer : enhancer regions that overlap with the mutation (from the NIH Roadmap Epigenomics Project ) EpiRoadmap_promoter : promoter regions that overlap with the mutation (from the NIH Roadmap Epigenomics Project ) EpiRoadmap_dyadic : dyadic regions that overlap with the mutation (from the NIH Roadmap Epigenomics Project )","title":"SNV/indel candidates"},{"location":"guides/genomics-platform/analyzing-data/cis-x/#ohe-results","text":"OHE results are the raw results for the outlier expression test. Gene : gene symbol fpkm.raw : FPKM value size.bi : number of cases in the bi-allelic reference cohort p.bi : p-value in the outlier test using the bi-allelic reference cohort rank.bi : rank of the expression level in the case under analysis compared to the bi-allelic reference cohort size.cohort : number of cases in the entire reference cohort p.cohort : p-value in the outlier test using the entire reference cohort rank.cohort : rank of the expression level in the case under analysis compared to the entire reference cohort size.white : number of cases in the whitelist reference cohort p.white : p-value in the outlier test using the whitelist reference cohort rank.white : rank of the expression level in the case under analysis compared to the whitelist reference cohort","title":"OHE results"},{"location":"guides/genomics-platform/analyzing-data/cis-x/#gene-level-ase-results","text":"Gene level ASE results are the raw results from the gene level ASE test. gene : gene accession number ( RefSeq ID) gsym : gene symbol chrom : chromosome name strand : strand orientation start : genomic start location end : genomic end location cdsStartStat : coding sequence (CDS) start status cdsEndStat : coding sequence (CDS) end status markers : number of heterozygous markers in this gene ase_markers : number of heterozygous markers showing allelic specific expressions (ASE) average_ai_all : average B-allele frequency (BAF) difference between RNA and DNA for all heterozygous markers average_ai_ase : average BAF difference between RNA and DNA for ASE markers pval_all_markers : p-value for each marker in the ASE test pval_ase_markers : p-value for ASE markers in the ASE test ai_all_markers : BAF difference between RNA and DNA for all heterozygrous markers ai_ase_markers : BAF difference between RNA and DNA for ASE markers comb.pval : combined p-value for the ASE test mean.delta : average BAF difference between RNA and DNA for all markers rawp : raw p-value for the ASE test Bonferroni : adjusted p-value for the ASE test (single-step Bonferroni) ABH : adjusted p-value for the ASE test (Benjamini-Hochberg)","title":"Gene level ASE results"},{"location":"guides/genomics-platform/analyzing-data/cis-x/#single-marker-ase-results","text":"Single marker ASE results are the raw results from the single marker ASE test. chrom : chromosome name pos : genomic start position ref : reference allele genotype mut : non-reference allele genotype cvg_wgs : coverage of the marker from the whole genome sequence (WGS) mut_freq_wgs : non-reference allele fraction in the WGS cvg_rna : coverage of the marker from the RNA-seq mut_freq_rna : non-reference allele fraction in the RNA-seq ref.1 : read count of the reference allele in the RNA-seq var : read count of the non-reference allele in the RNA-seq pvalue : p-value from the binomial test delta.abs : absolute difference of the non-reference allele fraction between the WGS and RNA-seq","title":"Single marker ASE results"},{"location":"guides/genomics-platform/analyzing-data/cis-x/#frequently-asked-questions","text":"None yet! If you have any questions not covered here, feel free to reach out on our contact form .","title":"Frequently asked questions"},{"location":"guides/genomics-platform/analyzing-data/cis-x/#similar-topics","text":"Running our Workflows Working with our Data Overview Upload/Download Data (local)","title":"Similar Topics"},{"location":"guides/genomics-platform/analyzing-data/command-line/","text":"Command Line Interaction Before you begin interacting with St. Jude Cloud Platform from the command line, you'll need to understand some details on the underlying architecture of the platform. The St. Jude Cloud Platform is built on top of a genomics cloud ecosystem provided by DNAnexus . Overview \u00b6 Workspaces in DNAnexus are organized by projects, which are essentially folders in the cloud. Each data request and tool in St. Jude Cloud creates its own unique cloud workspace (DNAnexus project). For instance, a data request creates a DNAnexus project behind the scenes with the same name as the request name you specify when you request data. Installation \u00b6 Open-source software provided by DNAnexus called the dx-toolkit is used to interact with the St. Jude Cloud Platform from the command line. You can use this to create these projects, upload and download data, and many other operations. You'll need to install that software on your computer by following this guide . Tip A quickstart to getting up and running with the dx-toolkit: Install Python 2.7.13+. Note that using the system-level Python is usually not a good idea (by default, system level Python is typically too old/does not support the latest security protocols required). You can install using Anaconda (recommended) or using the default Python installer . Run pip install dxpy . Type dx --help at the command line. A quick tour \u00b6 Logging in \u00b6 To log in using the dx-toolkit, run the following command: dx login --noprojects # enter username and password when prompted Note If you are a St. Jude employee, you'll need to follow this guide to log in instead. Selecting a project \u00b6 First, you'll need to choose which cloud workspace you would like to access. This depends on if you are downloading data from a request or working with input/output files from a tool. You can see the workspaces available to you by running the following command in your terminal: dx select This will present with a prompt similar to the below screenshot. A list of your available cloud workspaces will be shown with a number out to the left of each. You should enter the number corresponding to the workspace you are wanting to interact with. In the example below, the user has selected the Rapid RNA-Seq tool. Some useful commands \u00b6 Moving data back and forth between the cloud and your local computer is simple once you have selected the correct project for your tool. You will find that many common Linux commands with dx prepended work as expected. # list available files for the tool for the main folder dx ls # list all available files for the tool dx find . # list all commands dx --help Uploading data \u00b6 You can use the following process to upload data to be used by St. Jude Cloud Platform tools: First, click \"View\" on the tool you'd like to run from this page . In this example, we will choose the Rapid RNA-Seq tool. If you have not already, click \"Start\" on the tool you'd like to run. This will create a cloud workspace for you to upload your data to with the same name as the tool. Open up your terminal application and select the cloud workspace with the same name as the tool you are trying to run. Last, navigate to the local files you'd like to upload to the cloud and use the dx upload command as specified in [upload-download-data]{role=\"ref\"} to upload your data to St. Jude Cloud. Downloading data \u00b6 Warning To download data from a St. Jude Cloud data request, you must have indicated that you wished to download the data in your Data Access Agreement (DAA) during your submission. Any downloading of St. Jude data without completing this step is strictly PROHIBITED. You can use the following steps to download data from a St. Jude Cloud data request: Complete a data request using the Genomics Platform application. See this guide for instructions. Open up your terminal application and select the cloud workspace relevant to your data request. For instance, in this case we would type dx select \"Retinoblastoma Data\" . You can use typical commands like dx ls , dx pwd , and dx cd to navigate around your cloud folder as you would a local folder. Your project may look different based on what data you requested and whether you were previously approved to access the data. Your data should either be in the restricted folder (if this is your first time requesting access) or the immediate folder (if you were previously granted access permission). In the root of every data request is a file called SAMPLE_INFO.txt . This should contain all of the information about the samples you checked out as well as the associated metadata we provide. To download data from the cloud to local storage, use the dx download command as specified in [upload-download-data]{role=\"ref\"}. For instance, if I wanted to download all of the BAM files to my local computer, I would type dx download immediate/bam/* . Similar Topics \u00b6 About our Data Making a Data Request Working with our Data Overview Upload/Download Data (local)","title":"Command Line Interaction"},{"location":"guides/genomics-platform/analyzing-data/command-line/#overview","text":"Workspaces in DNAnexus are organized by projects, which are essentially folders in the cloud. Each data request and tool in St. Jude Cloud creates its own unique cloud workspace (DNAnexus project). For instance, a data request creates a DNAnexus project behind the scenes with the same name as the request name you specify when you request data.","title":"Overview"},{"location":"guides/genomics-platform/analyzing-data/command-line/#installation","text":"Open-source software provided by DNAnexus called the dx-toolkit is used to interact with the St. Jude Cloud Platform from the command line. You can use this to create these projects, upload and download data, and many other operations. You'll need to install that software on your computer by following this guide . Tip A quickstart to getting up and running with the dx-toolkit: Install Python 2.7.13+. Note that using the system-level Python is usually not a good idea (by default, system level Python is typically too old/does not support the latest security protocols required). You can install using Anaconda (recommended) or using the default Python installer . Run pip install dxpy . Type dx --help at the command line.","title":"Installation"},{"location":"guides/genomics-platform/analyzing-data/command-line/#a-quick-tour","text":"","title":"A quick tour"},{"location":"guides/genomics-platform/analyzing-data/command-line/#logging-in","text":"To log in using the dx-toolkit, run the following command: dx login --noprojects # enter username and password when prompted Note If you are a St. Jude employee, you'll need to follow this guide to log in instead.","title":"Logging in"},{"location":"guides/genomics-platform/analyzing-data/command-line/#selecting-a-project","text":"First, you'll need to choose which cloud workspace you would like to access. This depends on if you are downloading data from a request or working with input/output files from a tool. You can see the workspaces available to you by running the following command in your terminal: dx select This will present with a prompt similar to the below screenshot. A list of your available cloud workspaces will be shown with a number out to the left of each. You should enter the number corresponding to the workspace you are wanting to interact with. In the example below, the user has selected the Rapid RNA-Seq tool.","title":"Selecting a project"},{"location":"guides/genomics-platform/analyzing-data/command-line/#some-useful-commands","text":"Moving data back and forth between the cloud and your local computer is simple once you have selected the correct project for your tool. You will find that many common Linux commands with dx prepended work as expected. # list available files for the tool for the main folder dx ls # list all available files for the tool dx find . # list all commands dx --help","title":"Some useful commands"},{"location":"guides/genomics-platform/analyzing-data/command-line/#uploading-data","text":"You can use the following process to upload data to be used by St. Jude Cloud Platform tools: First, click \"View\" on the tool you'd like to run from this page . In this example, we will choose the Rapid RNA-Seq tool. If you have not already, click \"Start\" on the tool you'd like to run. This will create a cloud workspace for you to upload your data to with the same name as the tool. Open up your terminal application and select the cloud workspace with the same name as the tool you are trying to run. Last, navigate to the local files you'd like to upload to the cloud and use the dx upload command as specified in [upload-download-data]{role=\"ref\"} to upload your data to St. Jude Cloud.","title":"Uploading data"},{"location":"guides/genomics-platform/analyzing-data/command-line/#downloading-data","text":"Warning To download data from a St. Jude Cloud data request, you must have indicated that you wished to download the data in your Data Access Agreement (DAA) during your submission. Any downloading of St. Jude data without completing this step is strictly PROHIBITED. You can use the following steps to download data from a St. Jude Cloud data request: Complete a data request using the Genomics Platform application. See this guide for instructions. Open up your terminal application and select the cloud workspace relevant to your data request. For instance, in this case we would type dx select \"Retinoblastoma Data\" . You can use typical commands like dx ls , dx pwd , and dx cd to navigate around your cloud folder as you would a local folder. Your project may look different based on what data you requested and whether you were previously approved to access the data. Your data should either be in the restricted folder (if this is your first time requesting access) or the immediate folder (if you were previously granted access permission). In the root of every data request is a file called SAMPLE_INFO.txt . This should contain all of the information about the samples you checked out as well as the associated metadata we provide. To download data from the cloud to local storage, use the dx download command as specified in [upload-download-data]{role=\"ref\"}. For instance, if I wanted to download all of the BAM files to my local computer, I would type dx download immediate/bam/* .","title":"Downloading data"},{"location":"guides/genomics-platform/analyzing-data/command-line/#similar-topics","text":"About our Data Making a Data Request Working with our Data Overview Upload/Download Data (local)","title":"Similar Topics"},{"location":"guides/genomics-platform/analyzing-data/creating-a-cloud-app/","text":"Creating a Cloud Application Info If you came here from the remote work quickstart guide, you can use this link to quickly jump back to your place in that guide. This guide will take you through the process of writing an application for working with and manipulating the St. Jude data you've requested. By creating your own application, you will be able to wrap genomic tools and packages from external sources, as well as any tool or application you might have written yourself. Tip We have created a wide variety of example cloud applications which you can view at this GitHub repo . The completed source code for the particular application created here is available in the dx-fastqc-example-app folder. You are welcome to clone the repository and use it as a reference while following this tutorial or try building the application and running it on your own project. Overview \u00b6 The biggest difference between running an application in the cloud (as opposed to running it in a local environment) is the way we access that data and manipulate it. Writing and running your own cloud application grants numerous benefits. It allows you to submit numerous jobs in parallel, access your data from anywhere with an Internet connection, and utilize resources and compute power at a fraction of the cost (when compared to building your own infrastructure). Writing your own application will allow you to wrap custom tools to manipulate any data that you have previously requested. When you run your application, the request gets sent to a virtualized Linux container (Ubuntu 14.04 or 16.04) where any dependencies are installed and where your script will be run. Any tools or packages that you include (either through the included package managers, or bundled together in your project) will be available locally on the virtual Linux machine. However, there are differences in how we manage our data. When a job is submitted, a virtual machine is provisioned specifically for that job request, meaning that it is spun up at-will or when needed. It also implies that once the job has completed, the virtual machine will be reprovisioned or deleted. Any job output or data must be uploaded back to the project space. In this tutorial, we will be wrapping the FastQC , a quality control tool for raw sequence data, into our application. This will allow us to run FastQC on any of the St. Jude next generation sequencing data in the cloud. For specific information about how FastQC works, please refer to the FastQC documentation . Data \u00b6 For this tutorial I have requested the PCGP dataset, and once my access request has been approved, my project directory space will look like the following. Note If you do not yet have data in a DNAnexus project, you may request data from St. Jude Cloud by following the directions here or you may upload your own data using the command line . In order to make a data request or upload your own data using the command line, you must first create a St. Jude Cloud account . Writing the Application \u00b6 Requirements \u00b6 Tool Download Website Version dx-toolkit Source DNAnexus v0.291.1 FastQC Source Babraham Bioinformatics v0.11.8 Installing the dx-toolkit requires Python to be installed locally. Using the system provided version of Python can be problematic for a number of reasons, so we recommend using the Anaconda environment manager to install Python. You can view the following guides for how to install conda on your system. Windows. https://docs.anaconda.com/anaconda/install/windows/ Mac OS. https://docs.anaconda.com/anaconda/install/mac-os/ Linux. https://docs.anaconda.com/anaconda/install/linux/ Once you have conda installed, run the following commands to create a new environment with Python, activate it, and install the dx-toolkit. conda create -n dx python = 3 .7 conda activate dx pip install dxpy Now whenever you want to develop something for the cloud using dx-toolkit , just open your terminal and type conda activate dx . To access your DNAnexus projects from the commandline, you must login using dx-toolkit . For users not affiliated with St. Jude, simply type dx login and enter your username and password when prompted. Users with a St. Jude account will need to generate an API token for authentication. Instructions can be found here . Getting started \u00b6 The easiest way to install dx-toolkit is through pip , the Python package manager. Simply run the following command in your terminal: pip install dxpy --upgrade For this application, we will be using the dx-app-wizard command that is included in the dx-toolkit . dx-app-wizard is an interactive prompt that creates a boilerplate project that will allow you to quickly create an application. For more on dx-app-wizard , refer to the DNAnexus wiki article on Intro to Building Apps . Before continuing, be sure to refer to the command line interaction page for a walkthrough on how to install dx-toolkit and how to select your project workspace. Tip It is not necessary to use dx-app-wizard . All the necessary files and project directory structure can be created manually. However, dx-app-wizard provides a quick and easy way to get started. For more information, refer to the Advanced App Tutorial . All DNAnexus project applications will have the following structure: dx-fastqc-example-app/ \u251c\u2500\u2500 dxapp.json \u251c\u2500\u2500 resources/ \u2502 \u2514\u2500\u2500 usr/ \u2502 \u2514\u2500\u2500 bin/ \u2514\u2500\u2500 src/ \u2514\u2500\u2500 dx-fastqc-example-app.sh The dxapp.json file is a JSON file that contains metadata about the application we are writing that are needed to build and run the app on the DNAnexus Platform. Most notably, you will need to specify all of the inputs your app requires (both input files or any settings you can tune), output files, and other options such as the number of cores and memory required to run the tool. To see the full list of fields, refer to the DNAnexus wiki guide on the application metadata. The dx-fastqc-example-app.sh file is a bash script is what will be executed when the application is run. Any executable binaries that accompany the application, such as other tools or scripts, are placed in the resources folder. From there, we can call the executable from within the app when it is run. Creating the Project \u00b6 Start by running the dx-app-wizard command from your terminal. Info This helper tool will create a local directory on your machine. Any code changes we make will be done inside this local project directory created by dx-app-wizard . This is because we can write our application locally, build the application , and then run the application in the cloud. Building the application will compile dx-fastqc-example-app and then upload it into the project space on the cloud. When we run an application, it will be submitted as a job to be run in the cloud. With this process, we can write the application locally and run it on our data in the cloud, without ever having to utilize personal bandwidth and compute time. $ dx-app-wizard For our inputs, we will enter the following: $ App Name: dx-fastqc-example-app ... $ Title [] : FastQC Example Application ... $ Summary [] : Uses FastQC to generate quality control reports on raw sequence data. ... $ Version [ 0 .0.1 ] : 0 .0.1 ... $ 1st input name ( <ENTER> to finish ) : bam_file $ Label ( optional human-readable name ) [] : BAM File ... $ Choose a class ( <TAB> twice for choices ) : file $ This is an optional parameter [ y/n ] : n ... $ 1st output name ( <ENTER> to finish ) : fastqc_html $ Label ( optional human-readable name ) [] : FastQC HTML Report $ Choose a class ( <TAB> twice for choices ) : file $ 2nd output name ( <ENTER> to finish ) : fastqc_zip $ Label ( optional human-readable name ) [] : FastQC Zip File $ Choose a class ( <TAB> twice for choices ) : file ... $ Timeout policy [ 48h ] : 48h ... $ Programming language: bash ... $ Will this app need access to the Internet? [ y/N ] : N ... $ Will this app need access to the parent project? [ y/N ] : y ... $ Choose an instance type for your app [ mem1_ssd1_x4 ] : azure:mem1_ssd1_x4 Tip Although our app doesn't need any Internet access in this example, it may be required for your project. Also be sure to check what instance type you will need in the API Specifications . The FastQC executable supports a variety of file formats (BAM, SAM, FastQ, etc.), and outputs a HTML report and a zip file that contains all the graphs and data. We will use that knowledge to write the input and output parameters for our application. We can also specify other parameters such as the timeout policy, programming language, and instance type. For more information, refer to the IO and Run Specification guide. Integrating Tools and Packages \u00b6 Once we have finished creating the basic FastQC application using dx-app-wizard , the project structure should look like: dx-fastqc-example-app/ \u251c\u2500\u2500 Readme.developer.md \u251c\u2500\u2500 Readme.md \u251c\u2500\u2500 dxapp.json \u251c\u2500\u2500 resources/ \u251c\u2500\u2500 src/ \u2502 \u2514\u2500\u2500 dx-fastqc-example-app.sh \u2514\u2500\u2500 test/ Info Anything in the resources folder is unpacked into the root directory ( / ) of the virtual Linux machine that your application will run on. If we create the directory path dx-fastqc-example-app/resources/usr/bin/ , anything in the bin folder would be unpacked into /usr/bin/ on the Linux machine. This is handy because that path is included in the default $PATH environment variable. Your application's executable will use /home/dnanexus/ as its current working directory. Though dx-app-wizard does not create this, we can create it ourselves. Paste the following lines into your terminal. $ mkdir -p dx-fastqc-example-app/resources/usr/bin Packaging FastQC \u00b6 To incorporate FastQC into this project, we need to download the executable binary and package it within the dx-fastqc-example-app . Download the FastQC v0.11.8 (Win/Linux zip file) and unzip it. After unzipping, move the FastQC folder into the resources folder. $ unzip fastqc_v0.11.8.zip $ mv FastQC /path/to/project/dx-fastqc-example-app/resources/ Now, our project will look like this: dx-fastqc-example-app/ \u251c\u2500\u2500 LICENSE \u251c\u2500\u2500 README.md \u251c\u2500\u2500 Readme.developer.md \u251c\u2500\u2500 dxapp.json \u251c\u2500\u2500 test/ \u251c\u2500\u2500 resources/ \u2502 \u251c\u2500\u2500 FastQC/ \u2502 \u2502 \u251c\u2500\u2500 fastqc \u2502 \u2502 \u2514\u2500\u2500 ... \u2502 \u2514\u2500\u2500 usr/ \u2502 \u2514\u2500\u2500 bin/ \u2514\u2500\u2500 src/ \u2514\u2500\u2500 dx-fastqc-example-app.sh Installing Dependencies \u00b6 Tip If you are importing custom tools, or are using tools that rely on various packages and requirements, they can be specified in the \"runSpec\". For more information on installing dependencies and available software packages, refer to the Execution Environment Reference . Some external package managers that we can leverage when building an app include: Package Manager Application APT Advanced Packaging Tool for Ubuntu CPAN Comprehensive Perl Archive Network CRAN Comprehensive R Archive Network gem Package Manager for Ruby pip PyPI (Python Package Index) One requirement for FastQC is that it must have a suitable Java Runtime Environment . To include this in the app, we have to edit the dxapp.json file. Open dxapp.json and append the following line to \"runSpec\" : \"execDepends\" : [ { \"name\" : \"openjdk-7-jre-headless\" , \"package_manager\" : \"apt\" } ] Be sure to add a comma at the very end of the \"file\" object line to accommodate the new \"execDepends\" lines. Now, the \"runSpec\" object should look like the following: ... \"runSpec\" : { \"timeoutPolicy\" : { \"*\" : { \"hours\" : 48 } }, \"interpreter\" : \"bash\" , \"release\" : \"14.04\" , \"distribution\" : \"Ubuntu\" , \"file\" : \"src/dx-fastqc-example-app.sh\" , \"execDepends\" : [ { \"name\" : \"openjdk-7-jre-headless\" , \"package_manager\" : \"apt\" } ] } , ... When you build and run your application, the virtual environment will now download openjdk-7 from Ubuntu's APT package manager as a prerequisite. For more information on how to specify packages from Git, R, or Python, refer to the Software Packages wiki page. Calling FastQC \u00b6 The last step is to call the FastQC executable from within the app. Open up src/dx-fastqc-example-app.sh with a text editor. Inside this Bash script is where we will be working with FastQC and our data. Before we dive in, its a good idea to add a few useful parameters for the script execution. Right after the Bash shebang ( #!/bin/bash ), add the following line: set -e -x Below is a table describing what each flag does: Flag Description -e Exit immediately if a command exits with a non-zero status. -x Print each command to standard error before execution. Our first change has to do with how our BAM file is downloaded. Although dx-app-wizard automatically generates a line that will download the input file and rename it, we want to keep the original file name because FastQC uses the input file as part of the report name. Remove the -o bam_file portion so the line looks like the following: dx download \" $bam_file \" # Downloads our input BAM file without renaming After the application downloads the input file, we need to create the appropriate output directories and run FastQC on our BAM file. Add the following lines to the bash script within the main function: mkdir ~/fastqc-out/ # FastQC Output Folder /FastQC/fastqc \" $bam_file_name \" -o ~/fastqc-out # Runs FastQC on BAM File Tip Be sure to use \"$bam_file_name\" as our input for FastQC. Using \"$bam_file\" only returns the DNAnexus file-id associated with the input file. For more information on helper variables, refer to the Advanced App Tutorial . Uploading Files \u00b6 After FastQC finishes, the last thing to do is to upload the reports generated by FastQC to our project. These virtual Linux machines are provisioned at-will, meaning that they are only spun up when a job is submitted. When we create an application and run it in the cloud, we submit it as a job to be executed. When a job gets executed, a virtual machine will download all the necessary requirements (tools, packages, data, etc.) and run the job. Any output files on the machine must be uploaded back to the project space after a job finishes executing. Any information and data not uploaded to the project space will be inaccessible and lost. You will see two lines generated for us by dx-app-wizard when we specified the outputs for our application. We need to change these to upload the correct files from our output directory that we specified for FastQC. Otherwise, it assumes they are in the home directory. Before this, we can also (optionally) rename the files to be uploaded. Add the following lines, making sure to replace the two original upload lines. Lines to remove/overwrite: # Generated by dx-app-wizard fastqc_html = $( dx upload fastqc_html --brief ) fastqc_zip = $( dx upload fastqc_zip --brief ) Lines to add: # (Optional) Renames the FastQC reports mv ~/fastqc-out/*.html ~/fastqc-out/fastqc-report.html mv ~/fastqc-out/*.zip ~/fastqc-out/fastqc-report.zip # Uploads the respective HTML and Zip file (lines to change) fastqc_html = $( dx upload ~/fastqc-out/fastqc-report.html --brief ) fastqc_zip = $( dx upload ~/fastqc-out/fastqc-report.zip --brief ) In this step, we are also moving the HTML and Zip file generated by FastQC to the directories which will be uploaded. After this step, dx-fastqc-example-app.sh should look like: #!/bin/bash set -e -x main () { echo \"Value of bam_file: ' $bam_file '\" # Downloads file from project to virtual machine workspace dx download \" $bam_file \" # Creating output directory for FastQC mkdir ~/fastqc-out # Runs FastQC on BAM file /FastQC/fastqc \" $bam_file_name \" -o ~/fastqc-out # Renames the FastQC reports to include the BAM file prefix mv ~/fastqc-out/*.html ~/fastqc-out/fastqc-report.html mv ~/fastqc-out/*.zip ~/fastqc-out/fastqc-report.zip # Uploads the respective HTML and Zip file fastqc_html = $( dx upload ~/fastqc-out/fastqc-report.html --brief ) fastqc_zip = $( dx upload ~/fastqc-out/fastqc-report.zip --brief ) # Adds and formats appropriate output variables for your app dx-jobutil-add-output fastqc_html \" $fastqc_html \" --class = file dx-jobutil-add-output fastqc_zip \" $fastqc_zip \" --class = file } Building Your App \u00b6 Before building, ensure that you are in the parent directory of the local project folder generated by dx-app-wizard . To check, if you enter the command ls , you should see the project folder dx-fastqc-example-app/ appear in the output. To build your application, enter the following into your terminal: $ dx build dx-fastqc-example-app This command will package the tools and files as an application which can then be run on the DNAnexus Platform. In the screenshot below, you can see the compiled app in our project workspace selected and highlighted in blue. To verify that the build was completed successfully, you can enter dx ls . This should show you all the files in your project space in the cloud. # This will show what files are in your root directory for your project space in the cloud $ dx ls You should see something along the lines of this printed out in your terminal. Note that a compiled copy of our dx-fastqc-example-app now lives in the project. . \u251c\u2500\u2500 immediate/ \u2502 \u2514\u2500\u2500 ... \u251c\u2500\u2500 dx-fastqc-example-app \u2514\u2500\u2500 SAMPLE_INFO.txt You can also view the project directly from your browser. You will see a similar result. Any time you make any changes to the scripts or the application, you will need to rebuild the application. To overwrite a previous version of the app, specify the -f command. You can also inspect and configure the application by clicking on it. Running Your App \u00b6 To run the dx-fastqc-example-app , enter the following into the terminal: $ dx run dx-fastqc-example-app -i bam_file = /path/to/<bam-file>.bam For this example, I am using the PCGP dataset and my run command will look like the following: $ dx run dx-fastqc-example-app -i bam_file = /immediate/bam/SJBALL020073_D1.RNA-Seq.bam The input path will vary depending on how the data looks inside your DNAnexus project, but it might look like the following: /restricted/bam/<bam-file>.bam You will be prompted to confirm that you wish to run the application with the following JSON input and whether you would like to monitor the job in your terminal. Using input JSON: { \"bam_file\" : { \" $dnanexus_link \" : { \"project\" : \"project-FV9XFG0991ZbPVgQ2jx1vZv5\" , \"id\" : \"file-FV9gzf8991ZXQ1kv7V3BqgjV\" } } } Confirm running the executable with this input [ Y/n ] : Y Calling applet-FVbY8Qj991ZQ1863BGK6x0bk with output destination project-FV9XFG0991ZbPVgQ2jx1vZv5:/ Job ID: job-FVbY8Z0991ZXx5v1Fk3QgJPV Watch launched job now? [ Y/n ] Y Job Log ------- Watching job job-FVbY8Z0991ZXx5v1Fk3QgJPV. Press Ctrl+C to stop. You can also monitor active jobs by going to the project space and selecting the \"Monitor\" tab. Job Completion \u00b6 Once the job finishes, you will receive an email from DNAnexus ( notification@dnanexus.com ) about whether the job has completed successfully or failed. Make sure to check that these emails don't get sent to your spam folder. Clicking the links in the email should open up a new tab in your browser and take you to the appropriate project. Here, we can see that FastQC has run successfully and that the two files generated by FastQC have been uploaded back into our project space. Again, if we run the dx ls command, we can verify that two new files titled \"fastqc-report.html\" and \"fastqc-report.zip\" are in the root directory of our project. . \u251c\u2500\u2500 immediate/ \u2502 \u2514\u2500\u2500 ... \u251c\u2500\u2500 dx-fastqc-example-app \u251c\u2500\u2500 fastqc-report.html \u251c\u2500\u2500 fastqc-report.zip \u2514\u2500\u2500 SAMPLE_INFO.txt Conclusion \u00b6 If you have made it this far, you have likely wrapped your first genomic analysis tool for use in the cloud. For your reference, we have included the final FastQC application at the St. Jude App Tutorial Repository . If you have any questions or suggestions on how we can improve this tutorial, please file an issue , contact us at https://stjude.cloud/contact , or email us at support@stjude.cloud . Similar Topics \u00b6 About our Data Making a Data Request Working with our Data Overview Upload/Download Data (local) Command Line Interaction","title":"Creating your own Workflow"},{"location":"guides/genomics-platform/analyzing-data/creating-a-cloud-app/#overview","text":"The biggest difference between running an application in the cloud (as opposed to running it in a local environment) is the way we access that data and manipulate it. Writing and running your own cloud application grants numerous benefits. It allows you to submit numerous jobs in parallel, access your data from anywhere with an Internet connection, and utilize resources and compute power at a fraction of the cost (when compared to building your own infrastructure). Writing your own application will allow you to wrap custom tools to manipulate any data that you have previously requested. When you run your application, the request gets sent to a virtualized Linux container (Ubuntu 14.04 or 16.04) where any dependencies are installed and where your script will be run. Any tools or packages that you include (either through the included package managers, or bundled together in your project) will be available locally on the virtual Linux machine. However, there are differences in how we manage our data. When a job is submitted, a virtual machine is provisioned specifically for that job request, meaning that it is spun up at-will or when needed. It also implies that once the job has completed, the virtual machine will be reprovisioned or deleted. Any job output or data must be uploaded back to the project space. In this tutorial, we will be wrapping the FastQC , a quality control tool for raw sequence data, into our application. This will allow us to run FastQC on any of the St. Jude next generation sequencing data in the cloud. For specific information about how FastQC works, please refer to the FastQC documentation .","title":"Overview"},{"location":"guides/genomics-platform/analyzing-data/creating-a-cloud-app/#data","text":"For this tutorial I have requested the PCGP dataset, and once my access request has been approved, my project directory space will look like the following. Note If you do not yet have data in a DNAnexus project, you may request data from St. Jude Cloud by following the directions here or you may upload your own data using the command line . In order to make a data request or upload your own data using the command line, you must first create a St. Jude Cloud account .","title":"Data"},{"location":"guides/genomics-platform/analyzing-data/creating-a-cloud-app/#writing-the-application","text":"","title":"Writing the Application"},{"location":"guides/genomics-platform/analyzing-data/creating-a-cloud-app/#requirements","text":"Tool Download Website Version dx-toolkit Source DNAnexus v0.291.1 FastQC Source Babraham Bioinformatics v0.11.8 Installing the dx-toolkit requires Python to be installed locally. Using the system provided version of Python can be problematic for a number of reasons, so we recommend using the Anaconda environment manager to install Python. You can view the following guides for how to install conda on your system. Windows. https://docs.anaconda.com/anaconda/install/windows/ Mac OS. https://docs.anaconda.com/anaconda/install/mac-os/ Linux. https://docs.anaconda.com/anaconda/install/linux/ Once you have conda installed, run the following commands to create a new environment with Python, activate it, and install the dx-toolkit. conda create -n dx python = 3 .7 conda activate dx pip install dxpy Now whenever you want to develop something for the cloud using dx-toolkit , just open your terminal and type conda activate dx . To access your DNAnexus projects from the commandline, you must login using dx-toolkit . For users not affiliated with St. Jude, simply type dx login and enter your username and password when prompted. Users with a St. Jude account will need to generate an API token for authentication. Instructions can be found here .","title":"Requirements"},{"location":"guides/genomics-platform/analyzing-data/creating-a-cloud-app/#getting-started","text":"The easiest way to install dx-toolkit is through pip , the Python package manager. Simply run the following command in your terminal: pip install dxpy --upgrade For this application, we will be using the dx-app-wizard command that is included in the dx-toolkit . dx-app-wizard is an interactive prompt that creates a boilerplate project that will allow you to quickly create an application. For more on dx-app-wizard , refer to the DNAnexus wiki article on Intro to Building Apps . Before continuing, be sure to refer to the command line interaction page for a walkthrough on how to install dx-toolkit and how to select your project workspace. Tip It is not necessary to use dx-app-wizard . All the necessary files and project directory structure can be created manually. However, dx-app-wizard provides a quick and easy way to get started. For more information, refer to the Advanced App Tutorial . All DNAnexus project applications will have the following structure: dx-fastqc-example-app/ \u251c\u2500\u2500 dxapp.json \u251c\u2500\u2500 resources/ \u2502 \u2514\u2500\u2500 usr/ \u2502 \u2514\u2500\u2500 bin/ \u2514\u2500\u2500 src/ \u2514\u2500\u2500 dx-fastqc-example-app.sh The dxapp.json file is a JSON file that contains metadata about the application we are writing that are needed to build and run the app on the DNAnexus Platform. Most notably, you will need to specify all of the inputs your app requires (both input files or any settings you can tune), output files, and other options such as the number of cores and memory required to run the tool. To see the full list of fields, refer to the DNAnexus wiki guide on the application metadata. The dx-fastqc-example-app.sh file is a bash script is what will be executed when the application is run. Any executable binaries that accompany the application, such as other tools or scripts, are placed in the resources folder. From there, we can call the executable from within the app when it is run.","title":"Getting started"},{"location":"guides/genomics-platform/analyzing-data/creating-a-cloud-app/#creating-the-project","text":"Start by running the dx-app-wizard command from your terminal. Info This helper tool will create a local directory on your machine. Any code changes we make will be done inside this local project directory created by dx-app-wizard . This is because we can write our application locally, build the application , and then run the application in the cloud. Building the application will compile dx-fastqc-example-app and then upload it into the project space on the cloud. When we run an application, it will be submitted as a job to be run in the cloud. With this process, we can write the application locally and run it on our data in the cloud, without ever having to utilize personal bandwidth and compute time. $ dx-app-wizard For our inputs, we will enter the following: $ App Name: dx-fastqc-example-app ... $ Title [] : FastQC Example Application ... $ Summary [] : Uses FastQC to generate quality control reports on raw sequence data. ... $ Version [ 0 .0.1 ] : 0 .0.1 ... $ 1st input name ( <ENTER> to finish ) : bam_file $ Label ( optional human-readable name ) [] : BAM File ... $ Choose a class ( <TAB> twice for choices ) : file $ This is an optional parameter [ y/n ] : n ... $ 1st output name ( <ENTER> to finish ) : fastqc_html $ Label ( optional human-readable name ) [] : FastQC HTML Report $ Choose a class ( <TAB> twice for choices ) : file $ 2nd output name ( <ENTER> to finish ) : fastqc_zip $ Label ( optional human-readable name ) [] : FastQC Zip File $ Choose a class ( <TAB> twice for choices ) : file ... $ Timeout policy [ 48h ] : 48h ... $ Programming language: bash ... $ Will this app need access to the Internet? [ y/N ] : N ... $ Will this app need access to the parent project? [ y/N ] : y ... $ Choose an instance type for your app [ mem1_ssd1_x4 ] : azure:mem1_ssd1_x4 Tip Although our app doesn't need any Internet access in this example, it may be required for your project. Also be sure to check what instance type you will need in the API Specifications . The FastQC executable supports a variety of file formats (BAM, SAM, FastQ, etc.), and outputs a HTML report and a zip file that contains all the graphs and data. We will use that knowledge to write the input and output parameters for our application. We can also specify other parameters such as the timeout policy, programming language, and instance type. For more information, refer to the IO and Run Specification guide.","title":"Creating the Project"},{"location":"guides/genomics-platform/analyzing-data/creating-a-cloud-app/#integrating-tools-and-packages","text":"Once we have finished creating the basic FastQC application using dx-app-wizard , the project structure should look like: dx-fastqc-example-app/ \u251c\u2500\u2500 Readme.developer.md \u251c\u2500\u2500 Readme.md \u251c\u2500\u2500 dxapp.json \u251c\u2500\u2500 resources/ \u251c\u2500\u2500 src/ \u2502 \u2514\u2500\u2500 dx-fastqc-example-app.sh \u2514\u2500\u2500 test/ Info Anything in the resources folder is unpacked into the root directory ( / ) of the virtual Linux machine that your application will run on. If we create the directory path dx-fastqc-example-app/resources/usr/bin/ , anything in the bin folder would be unpacked into /usr/bin/ on the Linux machine. This is handy because that path is included in the default $PATH environment variable. Your application's executable will use /home/dnanexus/ as its current working directory. Though dx-app-wizard does not create this, we can create it ourselves. Paste the following lines into your terminal. $ mkdir -p dx-fastqc-example-app/resources/usr/bin","title":"Integrating Tools and Packages"},{"location":"guides/genomics-platform/analyzing-data/creating-a-cloud-app/#packaging-fastqc","text":"To incorporate FastQC into this project, we need to download the executable binary and package it within the dx-fastqc-example-app . Download the FastQC v0.11.8 (Win/Linux zip file) and unzip it. After unzipping, move the FastQC folder into the resources folder. $ unzip fastqc_v0.11.8.zip $ mv FastQC /path/to/project/dx-fastqc-example-app/resources/ Now, our project will look like this: dx-fastqc-example-app/ \u251c\u2500\u2500 LICENSE \u251c\u2500\u2500 README.md \u251c\u2500\u2500 Readme.developer.md \u251c\u2500\u2500 dxapp.json \u251c\u2500\u2500 test/ \u251c\u2500\u2500 resources/ \u2502 \u251c\u2500\u2500 FastQC/ \u2502 \u2502 \u251c\u2500\u2500 fastqc \u2502 \u2502 \u2514\u2500\u2500 ... \u2502 \u2514\u2500\u2500 usr/ \u2502 \u2514\u2500\u2500 bin/ \u2514\u2500\u2500 src/ \u2514\u2500\u2500 dx-fastqc-example-app.sh","title":"Packaging FastQC"},{"location":"guides/genomics-platform/analyzing-data/creating-a-cloud-app/#installing-dependencies","text":"Tip If you are importing custom tools, or are using tools that rely on various packages and requirements, they can be specified in the \"runSpec\". For more information on installing dependencies and available software packages, refer to the Execution Environment Reference . Some external package managers that we can leverage when building an app include: Package Manager Application APT Advanced Packaging Tool for Ubuntu CPAN Comprehensive Perl Archive Network CRAN Comprehensive R Archive Network gem Package Manager for Ruby pip PyPI (Python Package Index) One requirement for FastQC is that it must have a suitable Java Runtime Environment . To include this in the app, we have to edit the dxapp.json file. Open dxapp.json and append the following line to \"runSpec\" : \"execDepends\" : [ { \"name\" : \"openjdk-7-jre-headless\" , \"package_manager\" : \"apt\" } ] Be sure to add a comma at the very end of the \"file\" object line to accommodate the new \"execDepends\" lines. Now, the \"runSpec\" object should look like the following: ... \"runSpec\" : { \"timeoutPolicy\" : { \"*\" : { \"hours\" : 48 } }, \"interpreter\" : \"bash\" , \"release\" : \"14.04\" , \"distribution\" : \"Ubuntu\" , \"file\" : \"src/dx-fastqc-example-app.sh\" , \"execDepends\" : [ { \"name\" : \"openjdk-7-jre-headless\" , \"package_manager\" : \"apt\" } ] } , ... When you build and run your application, the virtual environment will now download openjdk-7 from Ubuntu's APT package manager as a prerequisite. For more information on how to specify packages from Git, R, or Python, refer to the Software Packages wiki page.","title":"Installing Dependencies"},{"location":"guides/genomics-platform/analyzing-data/creating-a-cloud-app/#calling-fastqc","text":"The last step is to call the FastQC executable from within the app. Open up src/dx-fastqc-example-app.sh with a text editor. Inside this Bash script is where we will be working with FastQC and our data. Before we dive in, its a good idea to add a few useful parameters for the script execution. Right after the Bash shebang ( #!/bin/bash ), add the following line: set -e -x Below is a table describing what each flag does: Flag Description -e Exit immediately if a command exits with a non-zero status. -x Print each command to standard error before execution. Our first change has to do with how our BAM file is downloaded. Although dx-app-wizard automatically generates a line that will download the input file and rename it, we want to keep the original file name because FastQC uses the input file as part of the report name. Remove the -o bam_file portion so the line looks like the following: dx download \" $bam_file \" # Downloads our input BAM file without renaming After the application downloads the input file, we need to create the appropriate output directories and run FastQC on our BAM file. Add the following lines to the bash script within the main function: mkdir ~/fastqc-out/ # FastQC Output Folder /FastQC/fastqc \" $bam_file_name \" -o ~/fastqc-out # Runs FastQC on BAM File Tip Be sure to use \"$bam_file_name\" as our input for FastQC. Using \"$bam_file\" only returns the DNAnexus file-id associated with the input file. For more information on helper variables, refer to the Advanced App Tutorial .","title":"Calling FastQC"},{"location":"guides/genomics-platform/analyzing-data/creating-a-cloud-app/#uploading-files","text":"After FastQC finishes, the last thing to do is to upload the reports generated by FastQC to our project. These virtual Linux machines are provisioned at-will, meaning that they are only spun up when a job is submitted. When we create an application and run it in the cloud, we submit it as a job to be executed. When a job gets executed, a virtual machine will download all the necessary requirements (tools, packages, data, etc.) and run the job. Any output files on the machine must be uploaded back to the project space after a job finishes executing. Any information and data not uploaded to the project space will be inaccessible and lost. You will see two lines generated for us by dx-app-wizard when we specified the outputs for our application. We need to change these to upload the correct files from our output directory that we specified for FastQC. Otherwise, it assumes they are in the home directory. Before this, we can also (optionally) rename the files to be uploaded. Add the following lines, making sure to replace the two original upload lines. Lines to remove/overwrite: # Generated by dx-app-wizard fastqc_html = $( dx upload fastqc_html --brief ) fastqc_zip = $( dx upload fastqc_zip --brief ) Lines to add: # (Optional) Renames the FastQC reports mv ~/fastqc-out/*.html ~/fastqc-out/fastqc-report.html mv ~/fastqc-out/*.zip ~/fastqc-out/fastqc-report.zip # Uploads the respective HTML and Zip file (lines to change) fastqc_html = $( dx upload ~/fastqc-out/fastqc-report.html --brief ) fastqc_zip = $( dx upload ~/fastqc-out/fastqc-report.zip --brief ) In this step, we are also moving the HTML and Zip file generated by FastQC to the directories which will be uploaded. After this step, dx-fastqc-example-app.sh should look like: #!/bin/bash set -e -x main () { echo \"Value of bam_file: ' $bam_file '\" # Downloads file from project to virtual machine workspace dx download \" $bam_file \" # Creating output directory for FastQC mkdir ~/fastqc-out # Runs FastQC on BAM file /FastQC/fastqc \" $bam_file_name \" -o ~/fastqc-out # Renames the FastQC reports to include the BAM file prefix mv ~/fastqc-out/*.html ~/fastqc-out/fastqc-report.html mv ~/fastqc-out/*.zip ~/fastqc-out/fastqc-report.zip # Uploads the respective HTML and Zip file fastqc_html = $( dx upload ~/fastqc-out/fastqc-report.html --brief ) fastqc_zip = $( dx upload ~/fastqc-out/fastqc-report.zip --brief ) # Adds and formats appropriate output variables for your app dx-jobutil-add-output fastqc_html \" $fastqc_html \" --class = file dx-jobutil-add-output fastqc_zip \" $fastqc_zip \" --class = file }","title":"Uploading Files"},{"location":"guides/genomics-platform/analyzing-data/creating-a-cloud-app/#building-your-app","text":"Before building, ensure that you are in the parent directory of the local project folder generated by dx-app-wizard . To check, if you enter the command ls , you should see the project folder dx-fastqc-example-app/ appear in the output. To build your application, enter the following into your terminal: $ dx build dx-fastqc-example-app This command will package the tools and files as an application which can then be run on the DNAnexus Platform. In the screenshot below, you can see the compiled app in our project workspace selected and highlighted in blue. To verify that the build was completed successfully, you can enter dx ls . This should show you all the files in your project space in the cloud. # This will show what files are in your root directory for your project space in the cloud $ dx ls You should see something along the lines of this printed out in your terminal. Note that a compiled copy of our dx-fastqc-example-app now lives in the project. . \u251c\u2500\u2500 immediate/ \u2502 \u2514\u2500\u2500 ... \u251c\u2500\u2500 dx-fastqc-example-app \u2514\u2500\u2500 SAMPLE_INFO.txt You can also view the project directly from your browser. You will see a similar result. Any time you make any changes to the scripts or the application, you will need to rebuild the application. To overwrite a previous version of the app, specify the -f command. You can also inspect and configure the application by clicking on it.","title":"Building Your App"},{"location":"guides/genomics-platform/analyzing-data/creating-a-cloud-app/#running-your-app","text":"To run the dx-fastqc-example-app , enter the following into the terminal: $ dx run dx-fastqc-example-app -i bam_file = /path/to/<bam-file>.bam For this example, I am using the PCGP dataset and my run command will look like the following: $ dx run dx-fastqc-example-app -i bam_file = /immediate/bam/SJBALL020073_D1.RNA-Seq.bam The input path will vary depending on how the data looks inside your DNAnexus project, but it might look like the following: /restricted/bam/<bam-file>.bam You will be prompted to confirm that you wish to run the application with the following JSON input and whether you would like to monitor the job in your terminal. Using input JSON: { \"bam_file\" : { \" $dnanexus_link \" : { \"project\" : \"project-FV9XFG0991ZbPVgQ2jx1vZv5\" , \"id\" : \"file-FV9gzf8991ZXQ1kv7V3BqgjV\" } } } Confirm running the executable with this input [ Y/n ] : Y Calling applet-FVbY8Qj991ZQ1863BGK6x0bk with output destination project-FV9XFG0991ZbPVgQ2jx1vZv5:/ Job ID: job-FVbY8Z0991ZXx5v1Fk3QgJPV Watch launched job now? [ Y/n ] Y Job Log ------- Watching job job-FVbY8Z0991ZXx5v1Fk3QgJPV. Press Ctrl+C to stop. You can also monitor active jobs by going to the project space and selecting the \"Monitor\" tab.","title":"Running Your App"},{"location":"guides/genomics-platform/analyzing-data/creating-a-cloud-app/#job-completion","text":"Once the job finishes, you will receive an email from DNAnexus ( notification@dnanexus.com ) about whether the job has completed successfully or failed. Make sure to check that these emails don't get sent to your spam folder. Clicking the links in the email should open up a new tab in your browser and take you to the appropriate project. Here, we can see that FastQC has run successfully and that the two files generated by FastQC have been uploaded back into our project space. Again, if we run the dx ls command, we can verify that two new files titled \"fastqc-report.html\" and \"fastqc-report.zip\" are in the root directory of our project. . \u251c\u2500\u2500 immediate/ \u2502 \u2514\u2500\u2500 ... \u251c\u2500\u2500 dx-fastqc-example-app \u251c\u2500\u2500 fastqc-report.html \u251c\u2500\u2500 fastqc-report.zip \u2514\u2500\u2500 SAMPLE_INFO.txt","title":"Job Completion"},{"location":"guides/genomics-platform/analyzing-data/creating-a-cloud-app/#conclusion","text":"If you have made it this far, you have likely wrapped your first genomic analysis tool for use in the cloud. For your reference, we have included the final FastQC application at the St. Jude App Tutorial Repository . If you have any questions or suggestions on how we can improve this tutorial, please file an issue , contact us at https://stjude.cloud/contact , or email us at support@stjude.cloud .","title":"Conclusion"},{"location":"guides/genomics-platform/analyzing-data/creating-a-cloud-app/#similar-topics","text":"About our Data Making a Data Request Working with our Data Overview Upload/Download Data (local) Command Line Interaction","title":"Similar Topics"},{"location":"guides/genomics-platform/analyzing-data/fkpm/","text":"FKPM Authors John Doe Publication N/A (not published) Technical Support Contact Us Overview \u00b6 abstract-type description of tool Inputs \u00b6 table of inputs; example below Name Type Description Example FastQ files ( required if using FastQ inputs) Input file Gzipped FastQ files generated by experiment. Sample_R1.fastq.gz and Sample_R2.fastq.gz BAM files ( required if using BAM inputs) Input file BAM files aligned against HG19/Hg38 (WGS, WES or RNA-Seq). Sample.bam BAM indices ( required if using BAM inputs) Input file Corresponding BAM index of the BAM files above. Sample.bam.bai Mutation file ( required ) Input file File describing the mutations present in the sample (special format, see below). *.txt (tab-delimited) SNV or fusion Parameter Specify the mutation file contains SNV or gene fusion. SNV Peptide size Parameter Size of the peptide. 9 Affinity threshold Parameter Affinity cutoff for epitope prediction report. 500 Input file configuration \u00b6 if needed Outputs \u00b6 table of outputs; example below Name Description Epitope affinity prediction (html) Epitope affinity. The peptide with affinity < cutoff will be highlighted. Epitope affinity prediction (xlsx) Excel tables for the information of all epitopes Affinity (raw output) Epitope affinity Peptide sequence (raw output) Peptide sequences in Fasta format Workflow Steps \u00b6 description of algorithm(s) or workflow steps Additional Info \u00b6 description of any additional information that the user might need to know/do before running the workflow Creating a workspace \u00b6 Before you can run one of our workflows, you must first create a workspace in DNAnexus for the run. Refer to the general workflow guide to learn how to create a DNAnexus workspace for each workflow run. You can navigate to the workflow name workflow page here . Uploading Input files \u00b6 note any additional information the user should know about what input files are required Refer to the general workflow guide to learn how to upload input files to the workspace you just created. Running the Workflow \u00b6 Refer to the general workflow guide to learn how to launch the workflow, hook up input files, adjust parameters, start a run, and monitor run progress. !!! caution any cautionary notes specific to running this workflow Analysis of Results \u00b6 Each tool in St. Jude Cloud produces a visualization that makes understanding results more accessible than working with excel spreadsheet or tab delimited files. This is the primary way we recommend you work with your results. Refer to the general workflow guide to learn how to access these visualizations. We also include the raw output files for you to dig into if the visualization is not sufficient to answer your research question. Refer to the general workflow guide to learn how to access raw results files. Interpreting results \u00b6 detailed explanations with helpful screenshots or gifs Frequently asked questions \u00b6 faqs If you have any questions not covered here, feel free to reach out on our contact form . Similar Topics \u00b6 Running our Workflows Working with our Data Overview Upload/Download Data (local)","title":"FKPM"},{"location":"guides/genomics-platform/analyzing-data/fkpm/#overview","text":"abstract-type description of tool","title":"Overview"},{"location":"guides/genomics-platform/analyzing-data/fkpm/#inputs","text":"table of inputs; example below Name Type Description Example FastQ files ( required if using FastQ inputs) Input file Gzipped FastQ files generated by experiment. Sample_R1.fastq.gz and Sample_R2.fastq.gz BAM files ( required if using BAM inputs) Input file BAM files aligned against HG19/Hg38 (WGS, WES or RNA-Seq). Sample.bam BAM indices ( required if using BAM inputs) Input file Corresponding BAM index of the BAM files above. Sample.bam.bai Mutation file ( required ) Input file File describing the mutations present in the sample (special format, see below). *.txt (tab-delimited) SNV or fusion Parameter Specify the mutation file contains SNV or gene fusion. SNV Peptide size Parameter Size of the peptide. 9 Affinity threshold Parameter Affinity cutoff for epitope prediction report. 500","title":"Inputs"},{"location":"guides/genomics-platform/analyzing-data/fkpm/#input-file-configuration","text":"if needed","title":"Input file configuration"},{"location":"guides/genomics-platform/analyzing-data/fkpm/#outputs","text":"table of outputs; example below Name Description Epitope affinity prediction (html) Epitope affinity. The peptide with affinity < cutoff will be highlighted. Epitope affinity prediction (xlsx) Excel tables for the information of all epitopes Affinity (raw output) Epitope affinity Peptide sequence (raw output) Peptide sequences in Fasta format","title":"Outputs"},{"location":"guides/genomics-platform/analyzing-data/fkpm/#workflow-steps","text":"description of algorithm(s) or workflow steps","title":"Workflow Steps"},{"location":"guides/genomics-platform/analyzing-data/fkpm/#additional-info","text":"description of any additional information that the user might need to know/do before running the workflow","title":"Additional Info"},{"location":"guides/genomics-platform/analyzing-data/fkpm/#creating-a-workspace","text":"Before you can run one of our workflows, you must first create a workspace in DNAnexus for the run. Refer to the general workflow guide to learn how to create a DNAnexus workspace for each workflow run. You can navigate to the workflow name workflow page here .","title":"Creating a workspace"},{"location":"guides/genomics-platform/analyzing-data/fkpm/#uploading-input-files","text":"note any additional information the user should know about what input files are required Refer to the general workflow guide to learn how to upload input files to the workspace you just created.","title":"Uploading Input files"},{"location":"guides/genomics-platform/analyzing-data/fkpm/#running-the-workflow","text":"Refer to the general workflow guide to learn how to launch the workflow, hook up input files, adjust parameters, start a run, and monitor run progress. !!! caution any cautionary notes specific to running this workflow","title":"Running the Workflow"},{"location":"guides/genomics-platform/analyzing-data/fkpm/#analysis-of-results","text":"Each tool in St. Jude Cloud produces a visualization that makes understanding results more accessible than working with excel spreadsheet or tab delimited files. This is the primary way we recommend you work with your results. Refer to the general workflow guide to learn how to access these visualizations. We also include the raw output files for you to dig into if the visualization is not sufficient to answer your research question. Refer to the general workflow guide to learn how to access raw results files.","title":"Analysis of Results"},{"location":"guides/genomics-platform/analyzing-data/fkpm/#interpreting-results","text":"detailed explanations with helpful screenshots or gifs","title":"Interpreting results"},{"location":"guides/genomics-platform/analyzing-data/fkpm/#frequently-asked-questions","text":"faqs If you have any questions not covered here, feel free to reach out on our contact form .","title":"Frequently asked questions"},{"location":"guides/genomics-platform/analyzing-data/fkpm/#similar-topics","text":"Running our Workflows Working with our Data Overview Upload/Download Data (local)","title":"Similar Topics"},{"location":"guides/genomics-platform/analyzing-data/interactive-node/","text":"Interactive Nodes in the Cloud Apart from creating and running cloud apps , you can request an interactive node in the cloud to use for iterative development. This can be particularly useful if you want to run some quick analyses on the cloud, want to run tools without creating an app, or want to submit jobs similar to bsub on the local St. Jude HPC. This guide assumes that you have a DNAnexus account and have dxpy installed on your machine (view the local data upload guide for instructions on how to install dxpy ). Warning All instructions in this guide should be run from your local machine, not the HPC cluster. Overview \u00b6 There are two different experiences for doing interactive or ad-hoc analysis in the cloud: Cloud Workstations . Cloud workstations are a mature offering in the DNAnexus ecosystem, and you can use them in your production work. DNAnexus has a full guide on how to use cloud workstations. Unfortunately, they do not fully replicate the experience of an interactive node on the cluster: each time you ssh into a new cloud workstation, you get a blank machine with no dependencies or data installed. Thus, you need to configure your environment, download data to the node using dx , and upload results back to DNAnexus using dx . Interactive Nodes . Interactive nodes were created very recently between a partnership with St. Jude and DNAnexus. They offer a more complete alternative to interactive nodes in the HPC cluster, but the experience is currently in alpha (meaning that there are likely to be bugs and it is not ready for production use). In this guide, we will briefly mention how to use Cloud Workstations and then spend the rest of the guide explaining how to use our new Interactive Node experience. Cloud Workstations \u00b6 A Cloud Workstation is a fresh node on the cloud that can be used to run any command with access to data in your projects. You will be given root access to the node so you can download and install any tool you require. Since this is an interactive session, you will be charged for the duration of the session so it is important to terminate the session after use. Configuring SSH \u00b6 Run dx ssh_config to configure your account to allow use of SSH connections to the node. Connecting to the workstation \u00b6 To start an interactive workstation, first select the project you would like to start it in. dx select \"project-alpha\" or just dx select to select from a list of your projects interactively. Next, run dx run app-cloud_workstation --ssh . You can set the maximum session length for this session or continue with the default options. Tip The default node size for the cloud workstations are mem1_ssd1_x2. If you want to request a larger node size, you can specify it by adding the --instance-type option. Check the advanced options section at the bottom for more information. Setting up workspace \u00b6 Once you are connected to the node, you will have access to download and install tools to the node and use them. The node is a clean linux environment with the dx command line tool already installed. In order to upload and download files from your DNAnexus project, you must first run the following commands. unset DX_WORKSPACE_ID dx cd \"project-alpha:/\" Downloading files from your DNAnexus project \u00b6 The node has access to the data in your projects. To download a file, test.bam , from your parent project, just run dx download test.bam . To download a file from any project you have access to, just specify the project and path to the file in your download command like dx download project-name:/path/to/test.bam . Once you have all the tools and data you require, you can use the workstation as a general-purpose workstation to run analyses. Note that in the Cloud Workstation, all files you want to use have to fit onto the local hard disk. Uploading files back to your project \u00b6 Since the node is transient and will be deleted after the session is terminated, it is important to upload any required files to your project. You can do that by running dx upload output.bam or dx upload --path \"$project-alpha:\" output.bam if you selected another project in the workstation. Terminating the session \u00b6 By default, the session will end after the max session time set when the workstation was first started. You can terminate the session when you are done working by exit ing out of the terminal. You will be asked whether you want to terminate the job, enter 'y' to terminate. You can also terminate the job by going to the Monitor tab of your project in DNAnexus and terminate the running job from the website. For more information about cloud workstations, please refer to the DNAnexus documentation . Interactive Nodes \u00b6 Danger The interactive node in the cloud experience was created specifically in response to the fully remote working situation. The experience is currently an alpha release and is not suitable for production use. Additionally, this guide will be updated each time we improve the experience, so please come back regularly to see how we are changing things. Cloud workstations are good for interactive work, but they require you to upload/download data from your projects. They also do not save your working environment so any tools you installed or changes you made to the machine will be lost when the session is terminated. The Interactive Node experience, sometimes referred to by its codename \"CWIC\" (cloud workstations in containers), solves these issues by saving your environment and letting you work with your data on the cloud without manually downloading it to the node. Setting up your Docker Hub account \u00b6 The workstation uses Docker images pushed to a Docker Hub repository to save your environment. To get started, go to Docker Hub and sign in or create an account. Every Docker Hub account is given one free private repository. It is highly recommended to use a private repository as this will be your working environment. Once you have a Docker Hub account, go to your \"Account Settings\", then \"Security\" and create a new access token. You can give it a descriptive name and copy the token. The access token will be needed for the credentials file below. Creating a credentials file \u00b6 Create a file with the template below and fill in your Docker Hub token and Docker Hub username in the appropriate places. { \"docker_registry\" : { \"token\" : \"<YOUR_DOCKERHUB_TOKEN>\" , \"organization\" : \"<YOUR_DOCKERHUB_USERNAME>\" , \"username\" : \"<YOUR_DOCKERHUB_USERNAME>\" , \"registry\" : \"docker.io\" } } Info If you would rather use a quay.io repository, you can use your quay credentials in the credentials file instead. Once you have made your credentials file on your computer, make a new DNAnexus project to save your credentials using dx new project . Upload the credentials file to your project by running dx upload creds.txt . It is recommended to save your credentials in a separate, private DNAnexus project to ensure that others do not have access to it. Starting an interactive terminal session \u00b6 The following command will run the app using the credentials you provided and will log you into the node after it boots up. dx run app-cwic -icredentials=mycredentials:creds.txt --ssh -y or replace mycredentials with the name of the DNAnexus project with your credentials file. If you have SSH issues while trying to connect to the job, make sure your SSH keys are configured properly . Working on the CWIC node \u00b6 Once the node starts, you will be taken to the home directory of the CWIC node. This node is an ubuntu environment and you can install or run any commands you want. For example, you can install samtools by running sudo apt install samtools . There are two main directories to work with data: /scratch/ - This is the directory local to the node. You can use this directory to save any intermediate or temporary results. You can run tools here but all the data in this directory will be deleted once the node is terminated. /project/ - This directory contains your DNAnexus project and the data in it. If you copy or move files to this directory, it saves to your DNAnexus project, which is a persistent storage. You can go to /project/<YOUR_DX_PROJECT_NAME> and see the files in your DNAnexus project. Upload some data to your project from a local machine for testing in the interactive node \u2014 here, we assume a BAM file uploaded from a laptop called sample.bam . Once data is uploaded to your DNAnexus project, you can access it on your CWIC node at /project/<YOUR_DX_PROJECT_NAME>/test.bam . For instance, when running samtools index /project/<YOUR_DX_PROJECT_NAME>/test.bam , you will find the index file samtools creates is saved to your cloud project. Adding bioinformatics tools to your environment \u00b6 We recommend installing Anaconda to manage any Python or R packages in your CWIC environment. To install miniconda (a minimal installation of anaconda), run curl -O https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh sh Miniconda3-latest-Linux-x86_64.sh source ~/.bashrc Follow the instructions and select 'yes' to install conda and initialize it. After installing conda, we recommend adding the bioconda channel, which provides many bioinformatics packages. conda config --add channels defaults conda config --add channels bioconda conda config --add channels conda-forge To install a package such as bwa , simply run conda install bwa -y You can also create a new environment with conda called bio and install available packages like so: conda create -n bio bwa bowtie star -y conda activate bio bwa Saving your environment \u00b6 If you installed samtools , or any other tool to the node and want to save your environment, you can run dx-save-cwic . This will save the environment to your Docker Hub repository. Unfortunately, this is a manual step at the moment: in a future iteration, we plan to have this save your environment automatically. The next time you launch a CWIC node in this project, it will put you in an node with your saved environment. Therefore you will not need to reinstall samtools or any other tool you had in your environment. Running batch jobs \u00b6 We can dispatch non-interactive jobs from the node to parallelize analyses similar to a bsub experience on the HPC. First, you need to login to DNAnexus on the node. dx login --noprojects --token <dnanexus-user-token-from-ui> You can use samtools to split the bam by chromosome like below by specifying a command with the CWIC app. This will run the specified command with the saved environment and you can save the outputs to the /project directory which will save it in your DNAnexus project. root@cwic:~# chromosomes =( 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 ) root@cwic:~# for chr in ${ chromosomes [@] } ; do echo $chr ; dx run app-cwic \\ -icredentials = <DX_PROJECT_WITH_CREDS>:creds.txt \\ -icmd = \"samtools view -b /project/<YOUR_DX_PROJECT_NAME>/test.bam ${ chr } -o /project/<YOUR_DX_PROJECT_NAME>/bam_ ${ chr } .bam;\" \\ -y ; done After your jobs have finished running. You can run dx-reload-project to refresh the /project directory and see the newly added chromosome slices. Reloading project directory \u00b6 You may not see the updated files in your /project/<YOUR_PROJECT_NAME> directory immediately after they are added. In order to reload the project directory on the CWIC node with the latest files from your DNAnexus project, run dx-reload-project and you will see any new files. Unfortunately, this is a manual step at the moment: in a future iteration, we plan to have this update your files automatically. If you get a message such as umount: /project: target is busy. , cd into a directory other than /project and try reloading again. Saving any project updates \u00b6 Updates to any files in the /project directory only occur every 5 minutes. In order to propagate any recent updates, run dx-save-project to save the files to the DNAnexus project. In the future, we plan to have file syncing happen automatically whenever you update a file. Terminating the CWIC node \u00b6 Since the CWIC node is an interactive job, it gets billed for the duration of the job. Therefore it is important to terminate the node once you are done working. Save your work and environment, if needed, by running dx-save-project and dx-save-cwic respectively. To quit the node, type exit twice to get into the app execution environment. Press Ctrl+c to quit the CWIC app and type exit twice to get out of the terminal completely. You will be prompted to terminate the job, type 'y' to terminate the job. You can check if the node is still running by checking the Monitor tab in your project on the DNAnexus website. Alternatively, you can terminate the job from the Monitor tab. Advanced options \u00b6 Changing instance type \u00b6 If you require more or less runtime requirements for your nodes, you can change the instance type by specifying the flag --instance-type with a valid instance type from this list . dx run app-cloud_workstation --instance-type azure:mem1_ssd1_x16 --ssh or dx run app-cwic -icredentials = <DX_PROJECT_NAME_WITH_CREDS>:creds.txt --instance-type mem1_ssd1_x4 --ssh -y This is useful when you want to run some non-interactive jobs that have different memory or storage requirements. If you have any questions or suggestions on how we can improve this guide, please file an issue , contact us at https://stjude.cloud/contact , or email us at support@stjude.cloud . Making a Docker Hub repository private \u00b6 By default, the workstation creates a new public repository in Docker Hub. It is best practice to use a private repository so that your work environment is not publicly visible on Docker Hub. Follow the steps below to update an existing public repository to a private one. This should be done after you have already run dx-save-cwic once in the interactive session. First, go to your repositories page and click on the repository you want to make private. Next, go to the 'Settings' tab and click on the 'Make private' button. Type the name of the repository and click on the 'Make private' button. Finally, you can see the repository is now set to private and you can continue using interactive sessions as normal.","title":"Interactive nodes"},{"location":"guides/genomics-platform/analyzing-data/interactive-node/#overview","text":"There are two different experiences for doing interactive or ad-hoc analysis in the cloud: Cloud Workstations . Cloud workstations are a mature offering in the DNAnexus ecosystem, and you can use them in your production work. DNAnexus has a full guide on how to use cloud workstations. Unfortunately, they do not fully replicate the experience of an interactive node on the cluster: each time you ssh into a new cloud workstation, you get a blank machine with no dependencies or data installed. Thus, you need to configure your environment, download data to the node using dx , and upload results back to DNAnexus using dx . Interactive Nodes . Interactive nodes were created very recently between a partnership with St. Jude and DNAnexus. They offer a more complete alternative to interactive nodes in the HPC cluster, but the experience is currently in alpha (meaning that there are likely to be bugs and it is not ready for production use). In this guide, we will briefly mention how to use Cloud Workstations and then spend the rest of the guide explaining how to use our new Interactive Node experience.","title":"Overview"},{"location":"guides/genomics-platform/analyzing-data/interactive-node/#cloud-workstations","text":"A Cloud Workstation is a fresh node on the cloud that can be used to run any command with access to data in your projects. You will be given root access to the node so you can download and install any tool you require. Since this is an interactive session, you will be charged for the duration of the session so it is important to terminate the session after use.","title":"Cloud Workstations"},{"location":"guides/genomics-platform/analyzing-data/interactive-node/#configuring-ssh","text":"Run dx ssh_config to configure your account to allow use of SSH connections to the node.","title":"Configuring SSH"},{"location":"guides/genomics-platform/analyzing-data/interactive-node/#connecting-to-the-workstation","text":"To start an interactive workstation, first select the project you would like to start it in. dx select \"project-alpha\" or just dx select to select from a list of your projects interactively. Next, run dx run app-cloud_workstation --ssh . You can set the maximum session length for this session or continue with the default options. Tip The default node size for the cloud workstations are mem1_ssd1_x2. If you want to request a larger node size, you can specify it by adding the --instance-type option. Check the advanced options section at the bottom for more information.","title":"Connecting to the workstation"},{"location":"guides/genomics-platform/analyzing-data/interactive-node/#setting-up-workspace","text":"Once you are connected to the node, you will have access to download and install tools to the node and use them. The node is a clean linux environment with the dx command line tool already installed. In order to upload and download files from your DNAnexus project, you must first run the following commands. unset DX_WORKSPACE_ID dx cd \"project-alpha:/\"","title":"Setting up workspace"},{"location":"guides/genomics-platform/analyzing-data/interactive-node/#downloading-files-from-your-dnanexus-project","text":"The node has access to the data in your projects. To download a file, test.bam , from your parent project, just run dx download test.bam . To download a file from any project you have access to, just specify the project and path to the file in your download command like dx download project-name:/path/to/test.bam . Once you have all the tools and data you require, you can use the workstation as a general-purpose workstation to run analyses. Note that in the Cloud Workstation, all files you want to use have to fit onto the local hard disk.","title":"Downloading files from your DNAnexus project"},{"location":"guides/genomics-platform/analyzing-data/interactive-node/#uploading-files-back-to-your-project","text":"Since the node is transient and will be deleted after the session is terminated, it is important to upload any required files to your project. You can do that by running dx upload output.bam or dx upload --path \"$project-alpha:\" output.bam if you selected another project in the workstation.","title":"Uploading files back to your project"},{"location":"guides/genomics-platform/analyzing-data/interactive-node/#terminating-the-session","text":"By default, the session will end after the max session time set when the workstation was first started. You can terminate the session when you are done working by exit ing out of the terminal. You will be asked whether you want to terminate the job, enter 'y' to terminate. You can also terminate the job by going to the Monitor tab of your project in DNAnexus and terminate the running job from the website. For more information about cloud workstations, please refer to the DNAnexus documentation .","title":"Terminating the session"},{"location":"guides/genomics-platform/analyzing-data/interactive-node/#interactive-nodes","text":"Danger The interactive node in the cloud experience was created specifically in response to the fully remote working situation. The experience is currently an alpha release and is not suitable for production use. Additionally, this guide will be updated each time we improve the experience, so please come back regularly to see how we are changing things. Cloud workstations are good for interactive work, but they require you to upload/download data from your projects. They also do not save your working environment so any tools you installed or changes you made to the machine will be lost when the session is terminated. The Interactive Node experience, sometimes referred to by its codename \"CWIC\" (cloud workstations in containers), solves these issues by saving your environment and letting you work with your data on the cloud without manually downloading it to the node.","title":"Interactive Nodes"},{"location":"guides/genomics-platform/analyzing-data/interactive-node/#setting-up-your-docker-hub-account","text":"The workstation uses Docker images pushed to a Docker Hub repository to save your environment. To get started, go to Docker Hub and sign in or create an account. Every Docker Hub account is given one free private repository. It is highly recommended to use a private repository as this will be your working environment. Once you have a Docker Hub account, go to your \"Account Settings\", then \"Security\" and create a new access token. You can give it a descriptive name and copy the token. The access token will be needed for the credentials file below.","title":"Setting up your Docker Hub account"},{"location":"guides/genomics-platform/analyzing-data/interactive-node/#creating-a-credentials-file","text":"Create a file with the template below and fill in your Docker Hub token and Docker Hub username in the appropriate places. { \"docker_registry\" : { \"token\" : \"<YOUR_DOCKERHUB_TOKEN>\" , \"organization\" : \"<YOUR_DOCKERHUB_USERNAME>\" , \"username\" : \"<YOUR_DOCKERHUB_USERNAME>\" , \"registry\" : \"docker.io\" } } Info If you would rather use a quay.io repository, you can use your quay credentials in the credentials file instead. Once you have made your credentials file on your computer, make a new DNAnexus project to save your credentials using dx new project . Upload the credentials file to your project by running dx upload creds.txt . It is recommended to save your credentials in a separate, private DNAnexus project to ensure that others do not have access to it.","title":"Creating a credentials file"},{"location":"guides/genomics-platform/analyzing-data/interactive-node/#starting-an-interactive-terminal-session","text":"The following command will run the app using the credentials you provided and will log you into the node after it boots up. dx run app-cwic -icredentials=mycredentials:creds.txt --ssh -y or replace mycredentials with the name of the DNAnexus project with your credentials file. If you have SSH issues while trying to connect to the job, make sure your SSH keys are configured properly .","title":"Starting an interactive terminal session"},{"location":"guides/genomics-platform/analyzing-data/interactive-node/#working-on-the-cwic-node","text":"Once the node starts, you will be taken to the home directory of the CWIC node. This node is an ubuntu environment and you can install or run any commands you want. For example, you can install samtools by running sudo apt install samtools . There are two main directories to work with data: /scratch/ - This is the directory local to the node. You can use this directory to save any intermediate or temporary results. You can run tools here but all the data in this directory will be deleted once the node is terminated. /project/ - This directory contains your DNAnexus project and the data in it. If you copy or move files to this directory, it saves to your DNAnexus project, which is a persistent storage. You can go to /project/<YOUR_DX_PROJECT_NAME> and see the files in your DNAnexus project. Upload some data to your project from a local machine for testing in the interactive node \u2014 here, we assume a BAM file uploaded from a laptop called sample.bam . Once data is uploaded to your DNAnexus project, you can access it on your CWIC node at /project/<YOUR_DX_PROJECT_NAME>/test.bam . For instance, when running samtools index /project/<YOUR_DX_PROJECT_NAME>/test.bam , you will find the index file samtools creates is saved to your cloud project.","title":"Working on the CWIC node"},{"location":"guides/genomics-platform/analyzing-data/interactive-node/#adding-bioinformatics-tools-to-your-environment","text":"We recommend installing Anaconda to manage any Python or R packages in your CWIC environment. To install miniconda (a minimal installation of anaconda), run curl -O https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh sh Miniconda3-latest-Linux-x86_64.sh source ~/.bashrc Follow the instructions and select 'yes' to install conda and initialize it. After installing conda, we recommend adding the bioconda channel, which provides many bioinformatics packages. conda config --add channels defaults conda config --add channels bioconda conda config --add channels conda-forge To install a package such as bwa , simply run conda install bwa -y You can also create a new environment with conda called bio and install available packages like so: conda create -n bio bwa bowtie star -y conda activate bio bwa","title":"Adding bioinformatics tools to your environment"},{"location":"guides/genomics-platform/analyzing-data/interactive-node/#saving-your-environment","text":"If you installed samtools , or any other tool to the node and want to save your environment, you can run dx-save-cwic . This will save the environment to your Docker Hub repository. Unfortunately, this is a manual step at the moment: in a future iteration, we plan to have this save your environment automatically. The next time you launch a CWIC node in this project, it will put you in an node with your saved environment. Therefore you will not need to reinstall samtools or any other tool you had in your environment.","title":"Saving your environment"},{"location":"guides/genomics-platform/analyzing-data/interactive-node/#running-batch-jobs","text":"We can dispatch non-interactive jobs from the node to parallelize analyses similar to a bsub experience on the HPC. First, you need to login to DNAnexus on the node. dx login --noprojects --token <dnanexus-user-token-from-ui> You can use samtools to split the bam by chromosome like below by specifying a command with the CWIC app. This will run the specified command with the saved environment and you can save the outputs to the /project directory which will save it in your DNAnexus project. root@cwic:~# chromosomes =( 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 ) root@cwic:~# for chr in ${ chromosomes [@] } ; do echo $chr ; dx run app-cwic \\ -icredentials = <DX_PROJECT_WITH_CREDS>:creds.txt \\ -icmd = \"samtools view -b /project/<YOUR_DX_PROJECT_NAME>/test.bam ${ chr } -o /project/<YOUR_DX_PROJECT_NAME>/bam_ ${ chr } .bam;\" \\ -y ; done After your jobs have finished running. You can run dx-reload-project to refresh the /project directory and see the newly added chromosome slices.","title":"Running batch jobs"},{"location":"guides/genomics-platform/analyzing-data/interactive-node/#reloading-project-directory","text":"You may not see the updated files in your /project/<YOUR_PROJECT_NAME> directory immediately after they are added. In order to reload the project directory on the CWIC node with the latest files from your DNAnexus project, run dx-reload-project and you will see any new files. Unfortunately, this is a manual step at the moment: in a future iteration, we plan to have this update your files automatically. If you get a message such as umount: /project: target is busy. , cd into a directory other than /project and try reloading again.","title":"Reloading project directory"},{"location":"guides/genomics-platform/analyzing-data/interactive-node/#saving-any-project-updates","text":"Updates to any files in the /project directory only occur every 5 minutes. In order to propagate any recent updates, run dx-save-project to save the files to the DNAnexus project. In the future, we plan to have file syncing happen automatically whenever you update a file.","title":"Saving any project updates"},{"location":"guides/genomics-platform/analyzing-data/interactive-node/#terminating-the-cwic-node","text":"Since the CWIC node is an interactive job, it gets billed for the duration of the job. Therefore it is important to terminate the node once you are done working. Save your work and environment, if needed, by running dx-save-project and dx-save-cwic respectively. To quit the node, type exit twice to get into the app execution environment. Press Ctrl+c to quit the CWIC app and type exit twice to get out of the terminal completely. You will be prompted to terminate the job, type 'y' to terminate the job. You can check if the node is still running by checking the Monitor tab in your project on the DNAnexus website. Alternatively, you can terminate the job from the Monitor tab.","title":"Terminating the CWIC node"},{"location":"guides/genomics-platform/analyzing-data/interactive-node/#advanced-options","text":"","title":"Advanced options"},{"location":"guides/genomics-platform/analyzing-data/interactive-node/#changing-instance-type","text":"If you require more or less runtime requirements for your nodes, you can change the instance type by specifying the flag --instance-type with a valid instance type from this list . dx run app-cloud_workstation --instance-type azure:mem1_ssd1_x16 --ssh or dx run app-cwic -icredentials = <DX_PROJECT_NAME_WITH_CREDS>:creds.txt --instance-type mem1_ssd1_x4 --ssh -y This is useful when you want to run some non-interactive jobs that have different memory or storage requirements. If you have any questions or suggestions on how we can improve this guide, please file an issue , contact us at https://stjude.cloud/contact , or email us at support@stjude.cloud .","title":"Changing instance type"},{"location":"guides/genomics-platform/analyzing-data/interactive-node/#making-a-docker-hub-repository-private","text":"By default, the workstation creates a new public repository in Docker Hub. It is best practice to use a private repository so that your work environment is not publicly visible on Docker Hub. Follow the steps below to update an existing public repository to a private one. This should be done after you have already run dx-save-cwic once in the interactive session. First, go to your repositories page and click on the repository you want to make private. Next, go to the 'Settings' tab and click on the 'Make private' button. Type the name of the repository and click on the 'Make private' button. Finally, you can see the repository is now set to private and you can continue using interactive sessions as normal.","title":"Making a Docker Hub repository private"},{"location":"guides/genomics-platform/analyzing-data/methylation-to-activity/","text":"MethylationToActivity (M2A) Authors Justin Williams, Beisi Xu, Daniel Putnam, Andrew Thrasher, Xiang Chen Publication In submission: \"MethylationToActivity: a deep-learning framework that reveals promoter activity landscapes from DNA methylomes in individual tumors\" Technical Support Contact Us Overview \u00b6 MethylationToActivity (M2A) is a machine learning framework using convolutional neural networks (CNN) to infer histone modification (HM) enrichment from whole genome bisulfite sequencing (WGBS). To date, both H3K27ac and H3K4me3 enrichment prediction from WGBS is supported, from a tab-delimited text file format of M-values. Optionally, we also support transfer-learning where a user may have matching H3K27ac or H3K4me3 data with appropriate controls in addition to WGBS data. Inputs \u00b6 Name Type Description Example Sample HM bigwig file (only if using M2A with Transfer) Input file HM ChIP-seq experiment bigwig track. SampleName_H3K27ac.bw OR SampleName_H3K4me3.bw Sample HM control (Input) bigwig (only if using M2A with Transfer) Input file ChIP-seq Experiment control (Input) bigwig track. SampleName_Input.bw WGBS data file Input file M-values by chromosome and position (non-standard format, see below). *.txt (tab-delimited) Promoter region definition file ( provided, or user defined ) Input file File describing promoter regions to be predicted. Provided regions include both hg19 and GRCh38 definitions (non-standard format, see below). *.txt (tab-delimited) App-provided model inputs: Model weights (.h5) file: 1) H3K27ac or 2) H3K4me3 Input file configuration \u00b6 Promoter region definition file (if user defined): \u00b6 Column Description EnsmblID_T Ensemble transcript ID (unique) EnsmblID_G Ensemble gene ID (not unique) Gene human readable gene name (abbrev, not unique) Strand +, - Chr chr1, chr2, ... chr22, etc. Start Beginning of transcript definition End End of transcript definition RStart TSS - 1000bp REnd TSS + 1000bp WGBS data file: \u00b6 Column Description chrom chromosome ID, e.g. 1,2,3 ...22 pos position of 5' cytosine of a CpG on the positive strand mval caluclated mvalue of a given CpG, typically M-value=log2(Beta/1-Beta) Outputs \u00b6 Name Description Predictions file The promoter region definition file with an additional Predicted_log2_ChipDivInput_\"YOUR HM MARK HERE\" column (tab-delimited). Transfer model The updated weights to the HM model (a .hdf5 file; only if using M2A with Transfer) Preparing to run M2A \u00b6 Before you can run one of our workflows, you must first create a workspace in DNAnexus for the run. Refer to the general workflow guide to learn how to create a DNAnexus workspace for each workflow run. Refer to the general workflow guide to learn how to upload input files to the workspace you just created. Refer to the general workflow guide to learn how to launch the workflow, hook up input files, adjust parameters, start a run, and monitor run progress. Analysis of Results \u00b6 Today, the M2A pipeline does not produce an interactive visualization. If M2A with Transfer was run, the easiest measurment of training prediction accuracy would be caluclating the Pearson's R 2 , or root mean square error (RMSE) between the measured and M2A predicted values. Furthermore, comparisons of sample-sample consistency with the same/similar cancer-type (as determiend by Pearson's R 2 ) is a good start for a contextual understanding of the predictions produced by M2A. Refer to the general workflow guide to learn how to access raw results files. Interpreting results \u00b6 For the M2A pipeline, every pipeline run outputs a predictions text file (tab-delimited) for each sample. These values represent the predicted selected HM (either H3K27ac or H3K4me3) promoter region enrichment. Frequently asked questions \u00b6 None yet! If you have any questions not covered here, feel free to reach out on our contact form . Similar Topics \u00b6 Running our Workflows Working with our Data Overview Upload/Download Data (local)","title":"MethylationToActivity"},{"location":"guides/genomics-platform/analyzing-data/methylation-to-activity/#overview","text":"MethylationToActivity (M2A) is a machine learning framework using convolutional neural networks (CNN) to infer histone modification (HM) enrichment from whole genome bisulfite sequencing (WGBS). To date, both H3K27ac and H3K4me3 enrichment prediction from WGBS is supported, from a tab-delimited text file format of M-values. Optionally, we also support transfer-learning where a user may have matching H3K27ac or H3K4me3 data with appropriate controls in addition to WGBS data.","title":"Overview"},{"location":"guides/genomics-platform/analyzing-data/methylation-to-activity/#inputs","text":"Name Type Description Example Sample HM bigwig file (only if using M2A with Transfer) Input file HM ChIP-seq experiment bigwig track. SampleName_H3K27ac.bw OR SampleName_H3K4me3.bw Sample HM control (Input) bigwig (only if using M2A with Transfer) Input file ChIP-seq Experiment control (Input) bigwig track. SampleName_Input.bw WGBS data file Input file M-values by chromosome and position (non-standard format, see below). *.txt (tab-delimited) Promoter region definition file ( provided, or user defined ) Input file File describing promoter regions to be predicted. Provided regions include both hg19 and GRCh38 definitions (non-standard format, see below). *.txt (tab-delimited) App-provided model inputs: Model weights (.h5) file: 1) H3K27ac or 2) H3K4me3","title":"Inputs"},{"location":"guides/genomics-platform/analyzing-data/methylation-to-activity/#input-file-configuration","text":"","title":"Input file configuration"},{"location":"guides/genomics-platform/analyzing-data/methylation-to-activity/#promoter-region-definition-file-if-user-defined","text":"Column Description EnsmblID_T Ensemble transcript ID (unique) EnsmblID_G Ensemble gene ID (not unique) Gene human readable gene name (abbrev, not unique) Strand +, - Chr chr1, chr2, ... chr22, etc. Start Beginning of transcript definition End End of transcript definition RStart TSS - 1000bp REnd TSS + 1000bp","title":"Promoter region definition file (if user defined):"},{"location":"guides/genomics-platform/analyzing-data/methylation-to-activity/#wgbs-data-file","text":"Column Description chrom chromosome ID, e.g. 1,2,3 ...22 pos position of 5' cytosine of a CpG on the positive strand mval caluclated mvalue of a given CpG, typically M-value=log2(Beta/1-Beta)","title":"WGBS data file:"},{"location":"guides/genomics-platform/analyzing-data/methylation-to-activity/#outputs","text":"Name Description Predictions file The promoter region definition file with an additional Predicted_log2_ChipDivInput_\"YOUR HM MARK HERE\" column (tab-delimited). Transfer model The updated weights to the HM model (a .hdf5 file; only if using M2A with Transfer)","title":"Outputs"},{"location":"guides/genomics-platform/analyzing-data/methylation-to-activity/#preparing-to-run-m2a","text":"Before you can run one of our workflows, you must first create a workspace in DNAnexus for the run. Refer to the general workflow guide to learn how to create a DNAnexus workspace for each workflow run. Refer to the general workflow guide to learn how to upload input files to the workspace you just created. Refer to the general workflow guide to learn how to launch the workflow, hook up input files, adjust parameters, start a run, and monitor run progress.","title":"Preparing to run M2A"},{"location":"guides/genomics-platform/analyzing-data/methylation-to-activity/#analysis-of-results","text":"Today, the M2A pipeline does not produce an interactive visualization. If M2A with Transfer was run, the easiest measurment of training prediction accuracy would be caluclating the Pearson's R 2 , or root mean square error (RMSE) between the measured and M2A predicted values. Furthermore, comparisons of sample-sample consistency with the same/similar cancer-type (as determiend by Pearson's R 2 ) is a good start for a contextual understanding of the predictions produced by M2A. Refer to the general workflow guide to learn how to access raw results files.","title":"Analysis of Results"},{"location":"guides/genomics-platform/analyzing-data/methylation-to-activity/#interpreting-results","text":"For the M2A pipeline, every pipeline run outputs a predictions text file (tab-delimited) for each sample. These values represent the predicted selected HM (either H3K27ac or H3K4me3) promoter region enrichment.","title":"Interpreting results"},{"location":"guides/genomics-platform/analyzing-data/methylation-to-activity/#frequently-asked-questions","text":"None yet! If you have any questions not covered here, feel free to reach out on our contact form .","title":"Frequently asked questions"},{"location":"guides/genomics-platform/analyzing-data/methylation-to-activity/#similar-topics","text":"Running our Workflows Working with our Data Overview Upload/Download Data (local)","title":"Similar Topics"},{"location":"guides/genomics-platform/analyzing-data/mutational-signatures/","text":"Overview \u00b6 Mutational Signatures (abbreviated as mtsg ) finds and quantifies COSMIC mutational signatures across samples. mtsg uses a base set of mutational signatures extracted by SigProfiler for single-base substitutions (SBS), i.e., single-nucleotide variants (SNV), using 2780 whole-genome variant calls from the ICGC/TCGA Pan-Cancer Analysis of Whole Genomes (PCAWG) project. Inputs \u00b6 Name Type Description Example VCF(s) Array of files One or more VCF sources. The files can be either uncompressed or gzipped. [ *.vcf , *.vcf.gz ] Genome build String The genome build used as reference. [default: \"GRCh38\"] GRCh38 Input configuration \u00b6 Mutational Signatures only requires VCFs as inputs. All other inputs are optional. VCF(s) VCF(s) is a list of VCF inputs. The inputs are expected to be single-sample and uncompressed or gzipped. The basename of the filename is used as the sample name. Outputs \u00b6 Name Type Description Raw signature activities File A tab-delimited file of the raw results with signature activities per sample Signature activities visualization File HTML file for interactive plotting Creating a workspace \u00b6 Before you can run one of our workflows, you must first create a workspace in DNAnexus for the run. Refer to the general workflow guide to learn how to create a DNAnexus workspace for each workflow run. You can navigate to the Mutational Signatures workflow page here . Uploading Input Files \u00b6 Mutational Signatures requires at least one VCF to be uploaded. Refer to the general workflow guide to learn how to upload input files to the workspace you just created. Running the Workflow \u00b6 Refer to the general workflow guide to learn how to launch the workflow, hook up input files, adjust parameters, start a run, and monitor run progress. Analysis of Results \u00b6 Each tool in St. Jude Cloud produces a visualization that makes understanding results more accessible than working with spreadsheets or tab-delimited files. This is the primary way we recommend you work with your results. Refer to the general workflow guide to learn how to access these visualizations. We also include the raw output files for you to dig into if the visualization is not sufficient to answer your research question. Refer to the general workflow guide to learn how to access raw results files. Interpreting results \u00b6 Upon a successful run of Mutational Signatures, two files are saved to the results directory: raw signature activities and a visualization file. Raw signature activities \u00b6 Raw signature activities is a tab-delimited file of the raw results with the signature activity counts for each input sample . Column 1 is the SBS signature identifier, and columns 2 through N are the counts of signature matches for each input sample. Signatures that have no matches across all samples are omitted. Example Samples SJMEL001001_D1 \u2026 SJNBL001_D Signature Subs-01 233 \u2026 13 Signature activities visualization \u00b6 Signature activities visualization is an HTML file that can be used for interactive plotting. When opened in a web browser, multiple sections of (stacked) bar charts are presented: Cohort Signature Contribution Means, Sample Signature Contributions, and Sample Signature Activities. The Cohort Signature Contribution Means section has proportion of SNVs of a mutational signature for an entire cohort. The reference cohort can be further divided into categories, selectable in the reference dropdown. Click on the tick labels to toggle between reference and query samples. Hover over a stacked bar to display the absolute count, signature name, and etiology. The Sample Signature Contributions section shows the proportion of SNVs of a mutational signature for a single sample. Like the Cohort Signature Contribution Means section, each stacked bar can be hovered over to display the absolute count, the signature name, and etiology. Each sample has a total mutation burden, which is shown in the Sample Signature Activities section. This is the factor used to sort the samples, i.e, in descending total mutational burden order. At the bottom is the legend, which shows any mutational signature present in either the reference or query cohort. The legend item may have a proposed etiology and, when clicked, opens that mutational signature on COSMIC Mutational Signatures. Frequently asked questions \u00b6 None yet! If you have any questions not covered here, feel free to reach out on our contact form . References Alexandrov, L.B., Kim, J., Haradhvala, N.J. et al . The repertoire of mutational signatures in human cancer. Nature 578 , 94\u2013101 (2020). https://doi.org/10.1038/s41586-020-1943-3 Bergstrom, E.N., Huang, M.N., Mahto, U. et al . SigProfilerMatrixGenerator: a tool for visualizing and exploring patterns of small mutational events. BMC Genomics 20 , 685 (2019). https://doi.org/10.1186/s12864-019-6041-2 Similar Topics \u00b6 Running our Workflows Working with our Data Overview Upload/Download Data (local)","title":"Mutational Signatures"},{"location":"guides/genomics-platform/analyzing-data/mutational-signatures/#overview","text":"Mutational Signatures (abbreviated as mtsg ) finds and quantifies COSMIC mutational signatures across samples. mtsg uses a base set of mutational signatures extracted by SigProfiler for single-base substitutions (SBS), i.e., single-nucleotide variants (SNV), using 2780 whole-genome variant calls from the ICGC/TCGA Pan-Cancer Analysis of Whole Genomes (PCAWG) project.","title":"Overview"},{"location":"guides/genomics-platform/analyzing-data/mutational-signatures/#inputs","text":"Name Type Description Example VCF(s) Array of files One or more VCF sources. The files can be either uncompressed or gzipped. [ *.vcf , *.vcf.gz ] Genome build String The genome build used as reference. [default: \"GRCh38\"] GRCh38","title":"Inputs"},{"location":"guides/genomics-platform/analyzing-data/mutational-signatures/#input-configuration","text":"Mutational Signatures only requires VCFs as inputs. All other inputs are optional.","title":"Input configuration"},{"location":"guides/genomics-platform/analyzing-data/mutational-signatures/#outputs","text":"Name Type Description Raw signature activities File A tab-delimited file of the raw results with signature activities per sample Signature activities visualization File HTML file for interactive plotting","title":"Outputs"},{"location":"guides/genomics-platform/analyzing-data/mutational-signatures/#creating-a-workspace","text":"Before you can run one of our workflows, you must first create a workspace in DNAnexus for the run. Refer to the general workflow guide to learn how to create a DNAnexus workspace for each workflow run. You can navigate to the Mutational Signatures workflow page here .","title":"Creating a workspace"},{"location":"guides/genomics-platform/analyzing-data/mutational-signatures/#uploading-input-files","text":"Mutational Signatures requires at least one VCF to be uploaded. Refer to the general workflow guide to learn how to upload input files to the workspace you just created.","title":"Uploading Input Files"},{"location":"guides/genomics-platform/analyzing-data/mutational-signatures/#running-the-workflow","text":"Refer to the general workflow guide to learn how to launch the workflow, hook up input files, adjust parameters, start a run, and monitor run progress.","title":"Running the Workflow"},{"location":"guides/genomics-platform/analyzing-data/mutational-signatures/#analysis-of-results","text":"Each tool in St. Jude Cloud produces a visualization that makes understanding results more accessible than working with spreadsheets or tab-delimited files. This is the primary way we recommend you work with your results. Refer to the general workflow guide to learn how to access these visualizations. We also include the raw output files for you to dig into if the visualization is not sufficient to answer your research question. Refer to the general workflow guide to learn how to access raw results files.","title":"Analysis of Results"},{"location":"guides/genomics-platform/analyzing-data/mutational-signatures/#interpreting-results","text":"Upon a successful run of Mutational Signatures, two files are saved to the results directory: raw signature activities and a visualization file.","title":"Interpreting results"},{"location":"guides/genomics-platform/analyzing-data/mutational-signatures/#raw-signature-activities","text":"Raw signature activities is a tab-delimited file of the raw results with the signature activity counts for each input sample . Column 1 is the SBS signature identifier, and columns 2 through N are the counts of signature matches for each input sample. Signatures that have no matches across all samples are omitted.","title":"Raw signature activities"},{"location":"guides/genomics-platform/analyzing-data/mutational-signatures/#signature-activities-visualization","text":"Signature activities visualization is an HTML file that can be used for interactive plotting. When opened in a web browser, multiple sections of (stacked) bar charts are presented: Cohort Signature Contribution Means, Sample Signature Contributions, and Sample Signature Activities. The Cohort Signature Contribution Means section has proportion of SNVs of a mutational signature for an entire cohort. The reference cohort can be further divided into categories, selectable in the reference dropdown. Click on the tick labels to toggle between reference and query samples. Hover over a stacked bar to display the absolute count, signature name, and etiology. The Sample Signature Contributions section shows the proportion of SNVs of a mutational signature for a single sample. Like the Cohort Signature Contribution Means section, each stacked bar can be hovered over to display the absolute count, the signature name, and etiology. Each sample has a total mutation burden, which is shown in the Sample Signature Activities section. This is the factor used to sort the samples, i.e, in descending total mutational burden order. At the bottom is the legend, which shows any mutational signature present in either the reference or query cohort. The legend item may have a proposed etiology and, when clicked, opens that mutational signature on COSMIC Mutational Signatures.","title":"Signature activities visualization"},{"location":"guides/genomics-platform/analyzing-data/mutational-signatures/#frequently-asked-questions","text":"None yet! If you have any questions not covered here, feel free to reach out on our contact form .","title":"Frequently asked questions"},{"location":"guides/genomics-platform/analyzing-data/mutational-signatures/#similar-topics","text":"Running our Workflows Working with our Data Overview Upload/Download Data (local)","title":"Similar Topics"},{"location":"guides/genomics-platform/analyzing-data/neoepitope/","text":"Authors Ti-Cheng Chang Publication The Neoepitope Landscape in Pediatric Cancers. Genome Medicine. 2017. 9.1: 78 . Technical Support Contact Us Overview \u00b6 Cancers are caused by somatically acquired alterations including single nucleotide variations (SNVs), small insertion/deletions (indels), translocations, and other types of rearrangements. The genes affected by these mutations may produce altered proteins, some of which may lead to the emergence of tumor-specific immunogenic epitopes. We developed an analytical workflow for identification of putative neoepitopes based on somatic missense mutations and gene fusions using whole genome sequencing data. The workflow has been used to characterize neoepitope landscape of 23 subtypes of pediatric cancer in the Pediatric Cancer Genome Project 1 . Inputs \u00b6 Name Type Description Example FastQ files ( required if using FastQ inputs) Input file Gzipped FastQ files generated by experiment. Sample_R1.fastq.gz and Sample_R2.fastq.gz BAM files ( required if using BAM inputs) Input file BAM files aligned against HG19/Hg38 (WGS, WES or RNA-Seq). Sample.bam BAM indices ( required if using BAM inputs) Input file Corresponding BAM index of the BAM files above. Sample.bam.bai Mutation file ( required ) Input file File describing the mutations present in the sample (special format, see below). *.txt (tab-delimited) SNV or fusion Parameter Specify the mutation file contains SNV or gene fusion. SNV Peptide size Parameter Size of the peptide. 9 Affinity threshold Parameter Affinity cutoff for epitope prediction report. 500 Input file configuration \u00b6 Users need to provide a mutation file for SNV or gene fusion. The format of the mutation file is shown in the following example. The file can be prepared in Excel and saved as a tab-delimited text file to use as input. The HLA alleles for testing will be derived from the HLA typing module using the workflow. The peptide size and affinity cutoff can be modified by users. Mutation file format GeneName Sample Chr Postion_hg19 Class AAChange mRNA_acc ReferenceAllele MutantAllele Gene1 SampleA chr10 106150600 missense R663H NM_00101 A T Gene2 SampleA chr2 32330151 missense N329N NM_00102 T G Notes on preparing the above file The chromosome requires a 'chr' prefix. The position requires a suffix of HG19/HG38 to indicate the human genome assembly version. Only the missense mutations/gene fusion is supported currently and the other types of mutations will not be processed. Mutation file example Outputs \u00b6 Name Description Epitope affinity prediction (html) Epitope affinity. The peptide with affinity < cutoff will be highlighted. Epitope affinity prediction (xlsx) Excel tables for the information of all epitopes Affinity (raw output) Epitope affinity Peptide sequence (raw output) Peptide sequences in Fasta format Workflow Steps \u00b6 HLA Typing Algorithm \u00b6 The HLA typing algorithm is used to predict the HLA class I alleles. Users can either provide FastQ (paired or single end reads) or a BAM file as input. When using a BAM file as input, the reads surrounding the HLA loci and unmapped reads will be extracted. The reads will be fed into Optitype for HLA typing. The default settings for Optitype are used. The output of the HLA type can be combined with the our epitope detection algorithm to perform affinity prediction of neoepitopes. If you use FastQ files as input: The input FastQs will be aligned against the Optitype HLA reference sequences using razers3 (see https://github.com/FRED-2/OptiType ). The fished FastQs will be used for HLA typing using Optitype. If you use BAM files as input: The reads falling within the HLA loci and their paralogous loci will be extracted. The reads unmapped to the human genome will be extracted. The reads from step 1 and 2 will be combined and deduplicated (in FastQ format). The input FastQs will be aligned against the Optitype HLA reference sequences using razers3 (see https://github.com/FRED-2/OptiType ). The fished FastQs will be used for HLA typing using Optitype. Epitope Prediction Algorithm \u00b6 The epitope prediction algorithm first extracts peptides covering an array of tiling peptides (size defined by users) overlapping each missense mutation or gene fusion. Fusion junctions can be identified using RNA-Seq by fusion detection tools (Li et. al, unpublished). NetMHCcons 3 is subsequently used to predict affinities of the peptide array for each HLA receptor in each sample. The neoepitope with affinity lower than the threshold will be highlighted in output file (default 500 nM). Below is an outline of internal steps the algorithm performs in order to generate the final report. Check the version of the genomic position of the input SNV/fusion file. Lift over the genomic coordinates if the reference genomic position is not HG19. Currently, the internal genome annotation was based on HG19 and the genome coordinates of the mutation files will be adjusted to HG19 for peptide extraction. Extract the peptide flanking the mutations. Run NetMHCcons to obtain the affinity prediction of the peptides. Produce the affinity report of each peptide. Creating a workspace \u00b6 Before you can run one of our workflows, you must first create a workspace in DNAnexus for the run. Refer to the general workflow guide to learn how to create a DNAnexus workspace for each workflow run. You can navigate to the NeoepitopePred workflow page here . Uploading Input files \u00b6 NeoepitopePred takes the following files as input : A pair of Gzipped FastQ files or an HG19/HG38 aligned BAM file. These can be generated from whole genome sequencing, whole exome sequencing, or RNA-Seq. A file describing the mutations in a sample. Refer to the general workflow guide to learn how to upload input files to the workspace you just created. Running the Workflow \u00b6 Refer to the general workflow guide to learn how to launch the workflow, hook up input files, adjust parameters, start a run, and monitor run progress. Caution This pipeline assumes HG19 coordinates in the mutation file. If the coordinates are based on HG38, the coordinates will lifted over to HG19 to perform epitope affinity prediction. Analysis of Results \u00b6 Each tool in St. Jude Cloud produces a visualization that makes understanding results more accessible than working with excel spreadsheet or tab delimited files. This is the primary way we recommend you work with your results. Refer to the general workflow guide to learn how to access these visualizations. We also include the raw output files for you to dig into if the visualization is not sufficient to answer your research question. Refer to the general workflow guide to learn how to access raw results files. Interpreting results \u00b6 HLA typing The output of this app contain the prediction of the HLA class I alleles from OptiType. A folder stamped with the time will present in the output folder (optitype), which contains the raw output. The file contains the predicted HLA alleles of the sample. Neoepitope prediction The output contains one summary HTML, one folder with raw output, and one folder with outputs in Excel formats: Epitope_affinity_prediction.html (shown below): This file provides a summary of the epitope prediction that can be visualized directly from web browser. The peptides with affinity lower than user-defined cutoff will be highlighted in green in the webpage. Raw_output (shown below): this folder contains the raw output of the affinity prediction. There will two major types files present here: affinity.out and flanking.seq. affinity.out : these files are the prediction results from the netMHCcons for each peptide. The following columns will be shown in the output: Column Description Gene name the name of the genes Sample the name of the samples Chromosome (chr) the chromosome location of the variation Position the chromosomal position of the variation. Currently, the position will be lifted over to HG19 to ensure correct translation of peptid sequences based on the internal annotation database of the pipeline. Therefore, the position will be labeled as HG19. Class class of the variation Reference allele reference allele at the position Mutant allele mutated allele at the position mRNA_acc NCBI accession number of the mRNA Allele HLA allele tested Peptide the neoepitope sequences tested Gene_variant the gene and variant residues 1-log50k Prediction score from netMHCcons nM Affinity as IC50 values in nM %Rank % Rank of prediction score to a set of 200.000 random natural 9mer peptides HLAtype All of the hla alleles predicted in the specific sample flanking.seq : these files contain the sequences used for the prediction. XLSX : this folder contains the raw output of the affinity prediction as described above in Excel files. The files can be downloaded and opened with Excel for downstream filtering and analyses. Frequently asked questions \u00b6 None yet! If you have any questions not covered here, feel free to reach out on our contact form . Similar Topics \u00b6 Running our Workflows Working with our Data Overview Upload/Download Data (local) Downing JR, Wilson RK, Zhang J, et al. The Pediatric Cancer Genome Project. Nature genetics. 2012;44(6):619-622. \u21a9 Szolek A, Schubert B, Mohr C, Sturm M, Feldhahn M, Kohlbacher O: OptiType: precision HLA typing from next-generation sequencing data. Bioinformatics 2014, 30:3310-3316. \u21a9 Karosiene E, Lundegaard C, Lund O, Nielsen M: NetMHCcons: a consensus method for the major histocompatibility complex class I predictions. Immunogenetics 2012, 64:177-186. \u21a9","title":"Neoepitope"},{"location":"guides/genomics-platform/analyzing-data/neoepitope/#overview","text":"Cancers are caused by somatically acquired alterations including single nucleotide variations (SNVs), small insertion/deletions (indels), translocations, and other types of rearrangements. The genes affected by these mutations may produce altered proteins, some of which may lead to the emergence of tumor-specific immunogenic epitopes. We developed an analytical workflow for identification of putative neoepitopes based on somatic missense mutations and gene fusions using whole genome sequencing data. The workflow has been used to characterize neoepitope landscape of 23 subtypes of pediatric cancer in the Pediatric Cancer Genome Project 1 .","title":"Overview"},{"location":"guides/genomics-platform/analyzing-data/neoepitope/#inputs","text":"Name Type Description Example FastQ files ( required if using FastQ inputs) Input file Gzipped FastQ files generated by experiment. Sample_R1.fastq.gz and Sample_R2.fastq.gz BAM files ( required if using BAM inputs) Input file BAM files aligned against HG19/Hg38 (WGS, WES or RNA-Seq). Sample.bam BAM indices ( required if using BAM inputs) Input file Corresponding BAM index of the BAM files above. Sample.bam.bai Mutation file ( required ) Input file File describing the mutations present in the sample (special format, see below). *.txt (tab-delimited) SNV or fusion Parameter Specify the mutation file contains SNV or gene fusion. SNV Peptide size Parameter Size of the peptide. 9 Affinity threshold Parameter Affinity cutoff for epitope prediction report. 500","title":"Inputs"},{"location":"guides/genomics-platform/analyzing-data/neoepitope/#input-file-configuration","text":"Users need to provide a mutation file for SNV or gene fusion. The format of the mutation file is shown in the following example. The file can be prepared in Excel and saved as a tab-delimited text file to use as input. The HLA alleles for testing will be derived from the HLA typing module using the workflow. The peptide size and affinity cutoff can be modified by users. Mutation file format GeneName Sample Chr Postion_hg19 Class AAChange mRNA_acc ReferenceAllele MutantAllele Gene1 SampleA chr10 106150600 missense R663H NM_00101 A T Gene2 SampleA chr2 32330151 missense N329N NM_00102 T G Notes on preparing the above file The chromosome requires a 'chr' prefix. The position requires a suffix of HG19/HG38 to indicate the human genome assembly version. Only the missense mutations/gene fusion is supported currently and the other types of mutations will not be processed. Mutation file example","title":"Input file configuration"},{"location":"guides/genomics-platform/analyzing-data/neoepitope/#outputs","text":"Name Description Epitope affinity prediction (html) Epitope affinity. The peptide with affinity < cutoff will be highlighted. Epitope affinity prediction (xlsx) Excel tables for the information of all epitopes Affinity (raw output) Epitope affinity Peptide sequence (raw output) Peptide sequences in Fasta format","title":"Outputs"},{"location":"guides/genomics-platform/analyzing-data/neoepitope/#workflow-steps","text":"","title":"Workflow Steps"},{"location":"guides/genomics-platform/analyzing-data/neoepitope/#hla-typing-algorithm","text":"The HLA typing algorithm is used to predict the HLA class I alleles. Users can either provide FastQ (paired or single end reads) or a BAM file as input. When using a BAM file as input, the reads surrounding the HLA loci and unmapped reads will be extracted. The reads will be fed into Optitype for HLA typing. The default settings for Optitype are used. The output of the HLA type can be combined with the our epitope detection algorithm to perform affinity prediction of neoepitopes. If you use FastQ files as input: The input FastQs will be aligned against the Optitype HLA reference sequences using razers3 (see https://github.com/FRED-2/OptiType ). The fished FastQs will be used for HLA typing using Optitype. If you use BAM files as input: The reads falling within the HLA loci and their paralogous loci will be extracted. The reads unmapped to the human genome will be extracted. The reads from step 1 and 2 will be combined and deduplicated (in FastQ format). The input FastQs will be aligned against the Optitype HLA reference sequences using razers3 (see https://github.com/FRED-2/OptiType ). The fished FastQs will be used for HLA typing using Optitype.","title":"HLA Typing Algorithm"},{"location":"guides/genomics-platform/analyzing-data/neoepitope/#epitope-prediction-algorithm","text":"The epitope prediction algorithm first extracts peptides covering an array of tiling peptides (size defined by users) overlapping each missense mutation or gene fusion. Fusion junctions can be identified using RNA-Seq by fusion detection tools (Li et. al, unpublished). NetMHCcons 3 is subsequently used to predict affinities of the peptide array for each HLA receptor in each sample. The neoepitope with affinity lower than the threshold will be highlighted in output file (default 500 nM). Below is an outline of internal steps the algorithm performs in order to generate the final report. Check the version of the genomic position of the input SNV/fusion file. Lift over the genomic coordinates if the reference genomic position is not HG19. Currently, the internal genome annotation was based on HG19 and the genome coordinates of the mutation files will be adjusted to HG19 for peptide extraction. Extract the peptide flanking the mutations. Run NetMHCcons to obtain the affinity prediction of the peptides. Produce the affinity report of each peptide.","title":"Epitope Prediction Algorithm"},{"location":"guides/genomics-platform/analyzing-data/neoepitope/#creating-a-workspace","text":"Before you can run one of our workflows, you must first create a workspace in DNAnexus for the run. Refer to the general workflow guide to learn how to create a DNAnexus workspace for each workflow run. You can navigate to the NeoepitopePred workflow page here .","title":"Creating a workspace"},{"location":"guides/genomics-platform/analyzing-data/neoepitope/#uploading-input-files","text":"NeoepitopePred takes the following files as input : A pair of Gzipped FastQ files or an HG19/HG38 aligned BAM file. These can be generated from whole genome sequencing, whole exome sequencing, or RNA-Seq. A file describing the mutations in a sample. Refer to the general workflow guide to learn how to upload input files to the workspace you just created.","title":"Uploading Input files"},{"location":"guides/genomics-platform/analyzing-data/neoepitope/#running-the-workflow","text":"Refer to the general workflow guide to learn how to launch the workflow, hook up input files, adjust parameters, start a run, and monitor run progress. Caution This pipeline assumes HG19 coordinates in the mutation file. If the coordinates are based on HG38, the coordinates will lifted over to HG19 to perform epitope affinity prediction.","title":"Running the Workflow"},{"location":"guides/genomics-platform/analyzing-data/neoepitope/#analysis-of-results","text":"Each tool in St. Jude Cloud produces a visualization that makes understanding results more accessible than working with excel spreadsheet or tab delimited files. This is the primary way we recommend you work with your results. Refer to the general workflow guide to learn how to access these visualizations. We also include the raw output files for you to dig into if the visualization is not sufficient to answer your research question. Refer to the general workflow guide to learn how to access raw results files.","title":"Analysis of Results"},{"location":"guides/genomics-platform/analyzing-data/neoepitope/#interpreting-results","text":"HLA typing The output of this app contain the prediction of the HLA class I alleles from OptiType. A folder stamped with the time will present in the output folder (optitype), which contains the raw output. The file contains the predicted HLA alleles of the sample. Neoepitope prediction The output contains one summary HTML, one folder with raw output, and one folder with outputs in Excel formats: Epitope_affinity_prediction.html (shown below): This file provides a summary of the epitope prediction that can be visualized directly from web browser. The peptides with affinity lower than user-defined cutoff will be highlighted in green in the webpage. Raw_output (shown below): this folder contains the raw output of the affinity prediction. There will two major types files present here: affinity.out and flanking.seq. affinity.out : these files are the prediction results from the netMHCcons for each peptide. The following columns will be shown in the output: Column Description Gene name the name of the genes Sample the name of the samples Chromosome (chr) the chromosome location of the variation Position the chromosomal position of the variation. Currently, the position will be lifted over to HG19 to ensure correct translation of peptid sequences based on the internal annotation database of the pipeline. Therefore, the position will be labeled as HG19. Class class of the variation Reference allele reference allele at the position Mutant allele mutated allele at the position mRNA_acc NCBI accession number of the mRNA Allele HLA allele tested Peptide the neoepitope sequences tested Gene_variant the gene and variant residues 1-log50k Prediction score from netMHCcons nM Affinity as IC50 values in nM %Rank % Rank of prediction score to a set of 200.000 random natural 9mer peptides HLAtype All of the hla alleles predicted in the specific sample flanking.seq : these files contain the sequences used for the prediction. XLSX : this folder contains the raw output of the affinity prediction as described above in Excel files. The files can be downloaded and opened with Excel for downstream filtering and analyses.","title":"Interpreting results"},{"location":"guides/genomics-platform/analyzing-data/neoepitope/#frequently-asked-questions","text":"None yet! If you have any questions not covered here, feel free to reach out on our contact form .","title":"Frequently asked questions"},{"location":"guides/genomics-platform/analyzing-data/neoepitope/#similar-topics","text":"Running our Workflows Working with our Data Overview Upload/Download Data (local) Downing JR, Wilson RK, Zhang J, et al. The Pediatric Cancer Genome Project. Nature genetics. 2012;44(6):619-622. \u21a9 Szolek A, Schubert B, Mohr C, Sturm M, Feldhahn M, Kohlbacher O: OptiType: precision HLA typing from next-generation sequencing data. Bioinformatics 2014, 30:3310-3316. \u21a9 Karosiene E, Lundegaard C, Lund O, Nielsen M: NetMHCcons: a consensus method for the major histocompatibility complex class I predictions. Immunogenetics 2012, 64:177-186. \u21a9","title":"Similar Topics"},{"location":"guides/genomics-platform/analyzing-data/rapid-rnaseq/","text":"Authors Scott Newman, Clay McLeod, Yongjin Li Publication N/A (not published) Technical Support Contact Us Overview \u00b6 Fusion genes are important for cancer diagnosis, subtype definition and targeted therapy. RNASeq is useful for detecting fusion transcripts; however, computational methods face challenges to identify fusion transcripts due to events such as internal tandem duplication (ITD), multiple genes, low expression, or non-templated insertions. To address some of these challenges, St. Jude Cloud offers \"Rapid RNA-Seq\", an end-to-end clinically validated pipeline that detects gene fusions and ITDs from human RNA-Seq. Inputs \u00b6 The input can be either of the two entries below, based on whether you want to start with FastQ files or a BAM file. Name Description Example Paired FastQ files Gzipped FastQ files generated by human RNA-Seq Sample_R1.fastq.gz and Sample_R2.fastq.gz BAM file Aligned reads file from human RNA-Seq Sample.bam Caution If you provide a BAM file to the pipeline, it must be aligned to GRCh37-lite. Running a BAM aligned to any other reference genome is not supported. Maybe more importantly, we do not check the genome build of the BAM, so errors in computation or the results can occur. If your BAM is not aligned to this genome build, we recommend converting the BAM back to FastQ files using Picard's SamToFastq functionality and using the FastQ version of the pipeline. Outputs \u00b6 The Rapid RNA-Seq pipeline produces the following outputs: Name Description Predicted gene fusions (.txt) File containing putative gene fusions. Coverage file (.bw) bigWig file containing coverage information. Splice junction read counts (.txt) Read counts for the splice junction detected. Interactive fusion visualization Fusion visualization produced by ProteinPaint. Interactive coverage visualization Coverage visualization produced by ProteinPaint. Workflow Steps \u00b6 The raw sequence data is aligned to GRCh37-lite using standard STAR mapping. A coverage bigWig (.bw) file is produced to allow the user to assess sample quality across the genome. Two gene fusion detection algorithms are run in parallel. The Fuzzion (Rice et al. unpublished data) fusion detection algorithm is run to provide high sensitivity for recurrent gene fusions. The RNAPEG (Edmonson et al. unpublished data) splice junction read counting algorithm is run to quantify read counts for splice junctions. These splice junction read counts are then used by Cicero (Li et al. unpublished data) to detect putative gene fusions. Custom visualizations for putative gene fusions and genome coverage are produced by ProteinPaint. Mapping We use the STAR aligner to rapidly map reads to the GRCh37 human reference genome. This step generally takes around one hour to complete assuming approximately 55-75 million paired reads are supplied. Coverage Internally developed scripts calculate the coverage of mapped reads genome wide. The resulting bigWig file can be viewed in ProteinPaint or used for quality control. Splice junction read quantification We use our RNAPEG software to quantify reads spanning known and novel splice junctions. RNAPEG also corrects improper mappings at splice junction boundaries for more accurate definition of novel splice junctions. The resulting junctions file can be viewed along with the coverage bigWig file to gain insights into gene expression and splicing patterns Genome-wide fusion prediction We developed an assembly-based algorithm CICERO (Clipped-reads Extended for RNA Optimization) that is able to extend the read-length spanning fusion junctions for detecting complex fusions. CICERO finds clipped reads and junction spanning reads, assembles them into a contig and maps the contig back to the reference genome. Mapped contigs are then annotated and filtered. Those with potential genic effects including gene fusion, ITD, readthrough or circular RNA are reported in the final_fusions.txt file. An interactive version of this file with predictions sorted by quality can be inspected with the ProteinPaint interactive fusion viewer. An abstract describing CICERO was presented at ASHG, 2014: http://www.ashg.org/2014meeting/abstracts/fulltext/f140120024.htm Low stringency fusion gene \"Hotpot\" search We have observed that certain fusions such as KIAA1549-BRAF in low-grade glioma have apparently limited read support in the bam file \u2014 either due to low expression or low tumor purity. In these cases, we use a secondary tool, FUZZION, that performs fuzzy matching for known fusion gene junctions for every read in the bam file (both mapped and unmapped). FUZZION can recover even a single low quality read potentially supporting a known fusion gene junction. The FUZZION output is a simple text file with read IDs and sequences supporting a particular gene fusion. The fusion point is indicated with square brackets [] . Creating a workspace \u00b6 Before you can run one of our workflows, you must first create a workspace in DNAnexus for the run. Refer to the general workflow guide to learn how to create a DNAnexus workspace for each workflow run. You can navigate to the Rapid RNA-Seq workflow page here . Uploading Input Files \u00b6 Caution This pipeline assumes GRCh37-lite coordinates. If your BAM is not aligned to this genome build, we recommend converting the BAM back to FastQ files using Picard's SamToFastq functionality. The Rapid RNA-Seq pipeline takes as input either a paired set of Gzipped FastQ files or a GRCh37-lite aligned BAM from human RNA-Seq. Refer to the general workflow guide to learn how to upload input files to the workspace you just created. Running the Workflow \u00b6 Refer to the general workflow guide to learn how to launch the workflow, hook up input files, adjust parameters, start a run, and monitor run progress. Analysis of Results \u00b6 Each tool in St. Jude Cloud produces a visualization that makes understanding results more accessible than working with excel spreadsheet or tab delimited files. This is the primary way we recommend you work with your results. Refer to the general workflow guide to learn how to access these visualizations. We also include the raw output files for you to dig into if the visualization is not sufficient to answer your research question. Refer to the general workflow guide to learn how to access raw results files. Interpreting results \u00b6 The complete output file specification is listed in the overview section of this guide. Here, we will discuss each of the different output files in more detail. Predicted gene fusions : The putative gene fusions will be contained in the file [SAMPLE].final_fusions.txt . This file is a tab-delimited file containing many fields for each of the predicted SV. The most important columns are the following. Field Name Description sample Sample name gene* Gene name chr* Chromosome name pos* Genomic Location ort* Strand reads* Supporting reads medal Estimated pathogenicity assessment using St. Jude Medal Ceremony Coverage file : A standard bigWig file used to describe genomic read coverage. Splice junction read counts : A custom file format describing the junction read counts. The following fields are included in the tab-delimited output file. Field Name Description junction Splice junction in the TCGA format \"chrX:start:+,chrX:end,+\". \"start\" and \"end\" are the 1-based position of the last mapped nucleotide before the skip and the first mapped nucleotide after the skip (i.e. the last base of the previous exon and the first base of the next exon). Note that in .bed output these coordinates will be different, see the .bed output section below. The \"+\" is currently hardcoded, though this may change in the future. count Raw count of reads supporting the junction. During correction counts for ambiguous junctions can be combined, though obviously these additional reads will not be visible in the raw BAM file. type Either \"known\" (matching a reference junction) or \"novel\" (not observed in the reference junction collection). genes Gene symbols from the junction calling process. These still need work in the raw junction calling process, it's recommended to use the \"annotated\" output files instead which assign matching HUGO gene symbols based on the UCSC refGene table. transcripts List of known transcript IDs matching the junction. qc_flanking Count of supporting reads passing flanking sequence checks (junctions observed adjacent to read ends require 18+ nt of flanking sequence, otherwise 10+ nt). qc_plus Count of supporting reads aligned to the + strand. qc_minus Count of supporting reads aligned to the - strand. qc_perfect_reads Count of supporting reads with perfect alignments (no reference mismatches of quality 15+, indels, or soft clips). qc_clean_reads Count of supporting reads whose alignments are not perfect but which have a ratio of <= 5% of reference mismatches of quality 15+, indels, or soft clips relative to the count of aligned bases on both the left and right flanking sequence. Note: qc_clean_reads does NOT include qc_perfect_reads: to get a count of \"perfect plus pretty good\" reads the two values must be added together. Known issues \u00b6 Adapter contamination This pipeline does not, at present, remove adapter sequences. If the sequencing library is contaminated with adapters, CICERO runtimes can increase exponentially. We recommend running FastQ files through a QC pipeline such as FastQC and trimming adapters with tools such as Trimmomatic if adapters are found. High coverage regions Certain cell types show very high transcription of certain loci, for example, the immunoglobulin heavy chain locus in plasma cells. The presence of very highly covered regions (typically 100,000-1,000,000+ X) has an adverse effect on CICERO runtimes. Presently, we have no good solution to this problem as strategies such as down-sampling may reduce sensitivity over important regions of the genome. Interactive Visualizations Exon vs Intron Nomenclature When a codon is split over a fusion gene junction, the annotation software marks the event as intronic when really, the event should be exonic. We are working to fix this bug. In the mean time, if a fusion is predicted to be in frame but the interactive plot shows \"intronic\", we suggest the user blat the contig shown just below to clarify if the true junction is either in the intron or exon. Frequently asked questions \u00b6 If you have any questions not covered here, feel free to reach out on our contact form . Submit batch jobs on command line \u00b6 See How can I run an analysis workflow on multiple sample files at the same time? Similar Topics \u00b6 Running our Workflows Working with our Data Overview Upload/Download Data (local)","title":"Rapid RNA-Seq Fusion Detection"},{"location":"guides/genomics-platform/analyzing-data/rapid-rnaseq/#overview","text":"Fusion genes are important for cancer diagnosis, subtype definition and targeted therapy. RNASeq is useful for detecting fusion transcripts; however, computational methods face challenges to identify fusion transcripts due to events such as internal tandem duplication (ITD), multiple genes, low expression, or non-templated insertions. To address some of these challenges, St. Jude Cloud offers \"Rapid RNA-Seq\", an end-to-end clinically validated pipeline that detects gene fusions and ITDs from human RNA-Seq.","title":"Overview"},{"location":"guides/genomics-platform/analyzing-data/rapid-rnaseq/#inputs","text":"The input can be either of the two entries below, based on whether you want to start with FastQ files or a BAM file. Name Description Example Paired FastQ files Gzipped FastQ files generated by human RNA-Seq Sample_R1.fastq.gz and Sample_R2.fastq.gz BAM file Aligned reads file from human RNA-Seq Sample.bam Caution If you provide a BAM file to the pipeline, it must be aligned to GRCh37-lite. Running a BAM aligned to any other reference genome is not supported. Maybe more importantly, we do not check the genome build of the BAM, so errors in computation or the results can occur. If your BAM is not aligned to this genome build, we recommend converting the BAM back to FastQ files using Picard's SamToFastq functionality and using the FastQ version of the pipeline.","title":"Inputs"},{"location":"guides/genomics-platform/analyzing-data/rapid-rnaseq/#outputs","text":"The Rapid RNA-Seq pipeline produces the following outputs: Name Description Predicted gene fusions (.txt) File containing putative gene fusions. Coverage file (.bw) bigWig file containing coverage information. Splice junction read counts (.txt) Read counts for the splice junction detected. Interactive fusion visualization Fusion visualization produced by ProteinPaint. Interactive coverage visualization Coverage visualization produced by ProteinPaint.","title":"Outputs"},{"location":"guides/genomics-platform/analyzing-data/rapid-rnaseq/#workflow-steps","text":"The raw sequence data is aligned to GRCh37-lite using standard STAR mapping. A coverage bigWig (.bw) file is produced to allow the user to assess sample quality across the genome. Two gene fusion detection algorithms are run in parallel. The Fuzzion (Rice et al. unpublished data) fusion detection algorithm is run to provide high sensitivity for recurrent gene fusions. The RNAPEG (Edmonson et al. unpublished data) splice junction read counting algorithm is run to quantify read counts for splice junctions. These splice junction read counts are then used by Cicero (Li et al. unpublished data) to detect putative gene fusions. Custom visualizations for putative gene fusions and genome coverage are produced by ProteinPaint. Mapping We use the STAR aligner to rapidly map reads to the GRCh37 human reference genome. This step generally takes around one hour to complete assuming approximately 55-75 million paired reads are supplied. Coverage Internally developed scripts calculate the coverage of mapped reads genome wide. The resulting bigWig file can be viewed in ProteinPaint or used for quality control. Splice junction read quantification We use our RNAPEG software to quantify reads spanning known and novel splice junctions. RNAPEG also corrects improper mappings at splice junction boundaries for more accurate definition of novel splice junctions. The resulting junctions file can be viewed along with the coverage bigWig file to gain insights into gene expression and splicing patterns Genome-wide fusion prediction We developed an assembly-based algorithm CICERO (Clipped-reads Extended for RNA Optimization) that is able to extend the read-length spanning fusion junctions for detecting complex fusions. CICERO finds clipped reads and junction spanning reads, assembles them into a contig and maps the contig back to the reference genome. Mapped contigs are then annotated and filtered. Those with potential genic effects including gene fusion, ITD, readthrough or circular RNA are reported in the final_fusions.txt file. An interactive version of this file with predictions sorted by quality can be inspected with the ProteinPaint interactive fusion viewer. An abstract describing CICERO was presented at ASHG, 2014: http://www.ashg.org/2014meeting/abstracts/fulltext/f140120024.htm Low stringency fusion gene \"Hotpot\" search We have observed that certain fusions such as KIAA1549-BRAF in low-grade glioma have apparently limited read support in the bam file \u2014 either due to low expression or low tumor purity. In these cases, we use a secondary tool, FUZZION, that performs fuzzy matching for known fusion gene junctions for every read in the bam file (both mapped and unmapped). FUZZION can recover even a single low quality read potentially supporting a known fusion gene junction. The FUZZION output is a simple text file with read IDs and sequences supporting a particular gene fusion. The fusion point is indicated with square brackets [] .","title":"Workflow Steps"},{"location":"guides/genomics-platform/analyzing-data/rapid-rnaseq/#creating-a-workspace","text":"Before you can run one of our workflows, you must first create a workspace in DNAnexus for the run. Refer to the general workflow guide to learn how to create a DNAnexus workspace for each workflow run. You can navigate to the Rapid RNA-Seq workflow page here .","title":"Creating a workspace"},{"location":"guides/genomics-platform/analyzing-data/rapid-rnaseq/#uploading-input-files","text":"Caution This pipeline assumes GRCh37-lite coordinates. If your BAM is not aligned to this genome build, we recommend converting the BAM back to FastQ files using Picard's SamToFastq functionality. The Rapid RNA-Seq pipeline takes as input either a paired set of Gzipped FastQ files or a GRCh37-lite aligned BAM from human RNA-Seq. Refer to the general workflow guide to learn how to upload input files to the workspace you just created.","title":"Uploading Input Files"},{"location":"guides/genomics-platform/analyzing-data/rapid-rnaseq/#running-the-workflow","text":"Refer to the general workflow guide to learn how to launch the workflow, hook up input files, adjust parameters, start a run, and monitor run progress.","title":"Running the Workflow"},{"location":"guides/genomics-platform/analyzing-data/rapid-rnaseq/#analysis-of-results","text":"Each tool in St. Jude Cloud produces a visualization that makes understanding results more accessible than working with excel spreadsheet or tab delimited files. This is the primary way we recommend you work with your results. Refer to the general workflow guide to learn how to access these visualizations. We also include the raw output files for you to dig into if the visualization is not sufficient to answer your research question. Refer to the general workflow guide to learn how to access raw results files.","title":"Analysis of Results"},{"location":"guides/genomics-platform/analyzing-data/rapid-rnaseq/#interpreting-results","text":"The complete output file specification is listed in the overview section of this guide. Here, we will discuss each of the different output files in more detail. Predicted gene fusions : The putative gene fusions will be contained in the file [SAMPLE].final_fusions.txt . This file is a tab-delimited file containing many fields for each of the predicted SV. The most important columns are the following. Field Name Description sample Sample name gene* Gene name chr* Chromosome name pos* Genomic Location ort* Strand reads* Supporting reads medal Estimated pathogenicity assessment using St. Jude Medal Ceremony Coverage file : A standard bigWig file used to describe genomic read coverage. Splice junction read counts : A custom file format describing the junction read counts. The following fields are included in the tab-delimited output file. Field Name Description junction Splice junction in the TCGA format \"chrX:start:+,chrX:end,+\". \"start\" and \"end\" are the 1-based position of the last mapped nucleotide before the skip and the first mapped nucleotide after the skip (i.e. the last base of the previous exon and the first base of the next exon). Note that in .bed output these coordinates will be different, see the .bed output section below. The \"+\" is currently hardcoded, though this may change in the future. count Raw count of reads supporting the junction. During correction counts for ambiguous junctions can be combined, though obviously these additional reads will not be visible in the raw BAM file. type Either \"known\" (matching a reference junction) or \"novel\" (not observed in the reference junction collection). genes Gene symbols from the junction calling process. These still need work in the raw junction calling process, it's recommended to use the \"annotated\" output files instead which assign matching HUGO gene symbols based on the UCSC refGene table. transcripts List of known transcript IDs matching the junction. qc_flanking Count of supporting reads passing flanking sequence checks (junctions observed adjacent to read ends require 18+ nt of flanking sequence, otherwise 10+ nt). qc_plus Count of supporting reads aligned to the + strand. qc_minus Count of supporting reads aligned to the - strand. qc_perfect_reads Count of supporting reads with perfect alignments (no reference mismatches of quality 15+, indels, or soft clips). qc_clean_reads Count of supporting reads whose alignments are not perfect but which have a ratio of <= 5% of reference mismatches of quality 15+, indels, or soft clips relative to the count of aligned bases on both the left and right flanking sequence. Note: qc_clean_reads does NOT include qc_perfect_reads: to get a count of \"perfect plus pretty good\" reads the two values must be added together.","title":"Interpreting results"},{"location":"guides/genomics-platform/analyzing-data/rapid-rnaseq/#known-issues","text":"Adapter contamination This pipeline does not, at present, remove adapter sequences. If the sequencing library is contaminated with adapters, CICERO runtimes can increase exponentially. We recommend running FastQ files through a QC pipeline such as FastQC and trimming adapters with tools such as Trimmomatic if adapters are found. High coverage regions Certain cell types show very high transcription of certain loci, for example, the immunoglobulin heavy chain locus in plasma cells. The presence of very highly covered regions (typically 100,000-1,000,000+ X) has an adverse effect on CICERO runtimes. Presently, we have no good solution to this problem as strategies such as down-sampling may reduce sensitivity over important regions of the genome. Interactive Visualizations Exon vs Intron Nomenclature When a codon is split over a fusion gene junction, the annotation software marks the event as intronic when really, the event should be exonic. We are working to fix this bug. In the mean time, if a fusion is predicted to be in frame but the interactive plot shows \"intronic\", we suggest the user blat the contig shown just below to clarify if the true junction is either in the intron or exon.","title":"Known issues"},{"location":"guides/genomics-platform/analyzing-data/rapid-rnaseq/#frequently-asked-questions","text":"If you have any questions not covered here, feel free to reach out on our contact form .","title":"Frequently asked questions"},{"location":"guides/genomics-platform/analyzing-data/rapid-rnaseq/#submit-batch-jobs-on-command-line","text":"See How can I run an analysis workflow on multiple sample files at the same time?","title":"Submit batch jobs on command line"},{"location":"guides/genomics-platform/analyzing-data/rapid-rnaseq/#similar-topics","text":"Running our Workflows Working with our Data Overview Upload/Download Data (local)","title":"Similar Topics"},{"location":"guides/genomics-platform/analyzing-data/rna-indel/","text":"RNA INDEL Authors John Doe Publication N/A (not published) Technical Support Contact Us Overview \u00b6 abstract-type description of tool Inputs \u00b6 table of inputs; example below Name Type Description Example FastQ files ( required if using FastQ inputs) Input file Gzipped FastQ files generated by experiment. Sample_R1.fastq.gz and Sample_R2.fastq.gz BAM files ( required if using BAM inputs) Input file BAM files aligned against HG19/Hg38 (WGS, WES or RNA-Seq). Sample.bam BAM indices ( required if using BAM inputs) Input file Corresponding BAM index of the BAM files above. Sample.bam.bai Mutation file ( required ) Input file File describing the mutations present in the sample (special format, see below). *.txt (tab-delimited) SNV or fusion Parameter Specify the mutation file contains SNV or gene fusion. SNV Peptide size Parameter Size of the peptide. 9 Affinity threshold Parameter Affinity cutoff for epitope prediction report. 500 Input file configuration \u00b6 if needed Outputs \u00b6 table of outputs; example below Name Description Epitope affinity prediction (html) Epitope affinity. The peptide with affinity < cutoff will be highlighted. Epitope affinity prediction (xlsx) Excel tables for the information of all epitopes Affinity (raw output) Epitope affinity Peptide sequence (raw output) Peptide sequences in Fasta format Workflow Steps \u00b6 description of algorithm(s) or workflow steps Additional Info \u00b6 description of any additional information that the user might need to know/do before running the workflow Creating a workspace \u00b6 Before you can run one of our workflows, you must first create a workspace in DNAnexus for the run. Refer to the general workflow guide to learn how to create a DNAnexus workspace for each workflow run. You can navigate to the workflow name workflow page here . Uploading Input files \u00b6 note any additional information the user should know about what input files are required Refer to the general workflow guide to learn how to upload input files to the workspace you just created. Running the Workflow \u00b6 Refer to the general workflow guide to learn how to launch the workflow, hook up input files, adjust parameters, start a run, and monitor run progress. !!! caution any cautionary notes specific to running this workflow Analysis of Results \u00b6 Each tool in St. Jude Cloud produces a visualization that makes understanding results more accessible than working with excel spreadsheet or tab delimited files. This is the primary way we recommend you work with your results. Refer to the general workflow guide to learn how to access these visualizations. We also include the raw output files for you to dig into if the visualization is not sufficient to answer your research question. Refer to the general workflow guide to learn how to access raw results files. Interpreting results \u00b6 detailed explanations with helpful screenshots or gifs Frequently asked questions \u00b6 faqs If you have any questions not covered here, feel free to reach out on our contact form . Similar Topics \u00b6 Running our Workflows Working with our Data Overview Upload/Download Data (local)","title":"RNA INDEL"},{"location":"guides/genomics-platform/analyzing-data/rna-indel/#overview","text":"abstract-type description of tool","title":"Overview"},{"location":"guides/genomics-platform/analyzing-data/rna-indel/#inputs","text":"table of inputs; example below Name Type Description Example FastQ files ( required if using FastQ inputs) Input file Gzipped FastQ files generated by experiment. Sample_R1.fastq.gz and Sample_R2.fastq.gz BAM files ( required if using BAM inputs) Input file BAM files aligned against HG19/Hg38 (WGS, WES or RNA-Seq). Sample.bam BAM indices ( required if using BAM inputs) Input file Corresponding BAM index of the BAM files above. Sample.bam.bai Mutation file ( required ) Input file File describing the mutations present in the sample (special format, see below). *.txt (tab-delimited) SNV or fusion Parameter Specify the mutation file contains SNV or gene fusion. SNV Peptide size Parameter Size of the peptide. 9 Affinity threshold Parameter Affinity cutoff for epitope prediction report. 500","title":"Inputs"},{"location":"guides/genomics-platform/analyzing-data/rna-indel/#input-file-configuration","text":"if needed","title":"Input file configuration"},{"location":"guides/genomics-platform/analyzing-data/rna-indel/#outputs","text":"table of outputs; example below Name Description Epitope affinity prediction (html) Epitope affinity. The peptide with affinity < cutoff will be highlighted. Epitope affinity prediction (xlsx) Excel tables for the information of all epitopes Affinity (raw output) Epitope affinity Peptide sequence (raw output) Peptide sequences in Fasta format","title":"Outputs"},{"location":"guides/genomics-platform/analyzing-data/rna-indel/#workflow-steps","text":"description of algorithm(s) or workflow steps","title":"Workflow Steps"},{"location":"guides/genomics-platform/analyzing-data/rna-indel/#additional-info","text":"description of any additional information that the user might need to know/do before running the workflow","title":"Additional Info"},{"location":"guides/genomics-platform/analyzing-data/rna-indel/#creating-a-workspace","text":"Before you can run one of our workflows, you must first create a workspace in DNAnexus for the run. Refer to the general workflow guide to learn how to create a DNAnexus workspace for each workflow run. You can navigate to the workflow name workflow page here .","title":"Creating a workspace"},{"location":"guides/genomics-platform/analyzing-data/rna-indel/#uploading-input-files","text":"note any additional information the user should know about what input files are required Refer to the general workflow guide to learn how to upload input files to the workspace you just created.","title":"Uploading Input files"},{"location":"guides/genomics-platform/analyzing-data/rna-indel/#running-the-workflow","text":"Refer to the general workflow guide to learn how to launch the workflow, hook up input files, adjust parameters, start a run, and monitor run progress. !!! caution any cautionary notes specific to running this workflow","title":"Running the Workflow"},{"location":"guides/genomics-platform/analyzing-data/rna-indel/#analysis-of-results","text":"Each tool in St. Jude Cloud produces a visualization that makes understanding results more accessible than working with excel spreadsheet or tab delimited files. This is the primary way we recommend you work with your results. Refer to the general workflow guide to learn how to access these visualizations. We also include the raw output files for you to dig into if the visualization is not sufficient to answer your research question. Refer to the general workflow guide to learn how to access raw results files.","title":"Analysis of Results"},{"location":"guides/genomics-platform/analyzing-data/rna-indel/#interpreting-results","text":"detailed explanations with helpful screenshots or gifs","title":"Interpreting results"},{"location":"guides/genomics-platform/analyzing-data/rna-indel/#frequently-asked-questions","text":"faqs If you have any questions not covered here, feel free to reach out on our contact form .","title":"Frequently asked questions"},{"location":"guides/genomics-platform/analyzing-data/rna-indel/#similar-topics","text":"Running our Workflows Working with our Data Overview Upload/Download Data (local)","title":"Similar Topics"},{"location":"guides/genomics-platform/analyzing-data/rnaseq-expression-classification/","text":"RNA-Seq Expression Classification Overview \u00b6 St. Jude Cloud provides functionality for generating RNA-Seq Expression Classification plots. This tool allows plotting of RNA-seq data by running through the St. Jude Cloud normalization pipeline . The generated count data is then compared to a reference set of data from a cohort of St. Jude samples and a plot is produced. Requirements \u00b6 The RNA-Seq Expression Classification pipeline reference data uses sequencing data from fresh, frozen tissue samples. It has not been evaluated for use with sequencing data generated from formalin-fixed paraffin-embedded (FFPE) specimens. If running the count-based pipeline, alignment must be done against the GRCh38_no_alt reference . It should use parameters as specified in our RNA-seq workflow to minimize any discrepancies caused by differing alignment specification. If running the count-based pipeline, feature counts should be generated with htseq-count as described in our RNA-seq workflow . This pipeline uses Gencode v31 annotations. Inputs \u00b6 The input can be either of the two entries below, based on whether you want to start with a counts file or a BAM file. Name Description Example BAM file Aligned reads file from human RNA-Seq Sample.bam Counts file htseq-count output feature counts file from human RNA-Seq Sample.counts.txt Caution If you provide counts data to the counts-based pipeline, it must be aligned to GRCh38_no_alt . Running a sample aligned to any other reference genome is not supported. Maybe more importantly, we do not check the genome build of the BAM, so errors in computation or the results can occur. If your sample is not aligned to this genome build, we recommend submitting the sample to the realignment-based workflow. Outputs \u00b6 The RNA-Seq Expression Classification pipeline produces the following outputs: Name Description Pipeline Version Interactive expression plot (.html) Visualization of RNA-Seq data all Aligned BAM (.bam) BAM file produced by our RNA-Seq pipeline for the input samples. Realignment Feature read counts (.txt) Read counts for the Gencode features. Realignment Workflow Steps \u00b6 [Only for realignment workflow] The aligned BAM is converted to FastQ and is aligned to GRCh38_no_alt using standard STAR mapping . [Only for realignment workflow] A feature count (.count.txt) file is produced for comparison to St. Jude Cloud reference data. A visualization for genomic features is produced. Mapping \u00b6 We use the STAR aligner to rapidly map reads to the GRCh38 human reference genome. Feature Counts \u00b6 We use htseq-count to produce genomic feature counts. Visualization \u00b6 A t-Distributed Stochastic Neighbor Embedding (t-SNE) visualization is produced using Rtsne . You can find the t-SNE paper here . Cost Estimation \u00b6 Workflow Name Per sample cost Outliers Realignment workflow $3-10 $25 Feature read counts workflow $0.30-0.40 Running the workflow \u00b6 Getting Started \u00b6 Caution If you provide counts data to the counts-based pipeline, it must be aligned to GRCh38_no_alt . Running a sample aligned to any other reference genome is not supported. Maybe more importantly, we do not check the genome build of the sample, so errors in computation or the results can occur. If your sample is not aligned to this genome build, we recommend submitting the sample to the realignment-based workflow. We provide two versions of the RNA-Seq Expression Classification tool depending on desired input. The full workflow allows a user to upload a sample in BAM format. That sample will then be converted to FastQ format, aligned with STAR two-pass alignment, and feature counts generated with htseq-count To get started, you need to navigate to the RNA-Seq Expression Classification tool page . You'll need to click the \"Start\" button in the left hand pane. This creates a cloud workspace in DNAnexus with the same name as the tool. After this, you will be able to upload your input files to that workspace. Obtaining reference data \u00b6 Reference feature count data is vended to the project folder along with the workflow. It can be found in the \u201ccounts\u201d folder. Reference data can also be retrieved through the Genomics Platform Data Browser These must then be provided to the workflow through the reference_counts parameter. By default, all reference files will be used by the app, but this can be restricted to one of the three tumor types [Blood, Brain, Solid] through the app settings. Caution The RNA-Seq Expression Classification tool does not allow the same sample name to be included more than once. If data from multiple projects is requested through St. Jude Cloud Genomics Platform, a sample may be included more than once. We offer an opinionated deduplication method at https://github.com/stjudecloud/utilities . Running the tool \u00b6 Once you've uploaded data to your cloud workspace, click \"Launch Tool\" on the tool's landing page. A dropdown will present the different presets for running the workflow. Here, you can select whether you wish to start with a counts file or a BAM file. Once the tool has been vended, copy the workflow to the project containing the reference data. Uploading data \u00b6 The RNA-Seq Expression Classification pipeline takes either a htseq-count count file or a GRCh38_no_alt aligned BAM from human RNA-Seq. You can upload your input file(s) through the command line. See Uploading Data from your Local Computer . Once you have the dx toolkit, to upload a sample HTSeq count file sample.counts.txt to the inputs folder of the project-rnaseq cloud project, you could use the following command: dx upload sample.counts.txt --destination \"project-rnaseq:/inputs/\" Preparing input data \u00b6 To run an input sample, certain properties need to be set on the file. These should be specified on the HTSeq count file for the counts-based pipeline or on the BAM file for the realignment-based workflow. Property Name Values sample_name should match filename up to first period (\".\") library_type PolyA or Total read_length integer, in bp strandedness Stranded-Forward, Stranded-Reverse, Unstranded pairing Paired-end or Single-end Properties can be set at the job-level for all input files that do not have properties set. These function as defaults and will not override existing values on files. The options are limited to values in our reference cohort to ensure reliable results. If a more granular control of covariates is needed, the input files can be annotated directly with properties. To input properties in DNAnexus, you can either use the web UI or the command line interface. Here, we provide a command line snippet to set properties on a file. # you can run the following code snippet after filling in your values # to successfully prepare the file. file_id = <DNAnexus file ID> # file ID or file path dx set_properties $file_id sample_name = \"<value>\" # Should match the file name up to the first period character dx set_properties $file_id strandedness = \"<value>\" # Stranded-Forward, Stranded-Reverse, or Unstranded dx set_properties $file_id library_type = \"<value>\" # PolyA or Total dx set_properties $file_id read_length = \"<value>\" # Integer number of base pairs in reads (e.g. 101, 126) dx set_properties $file_id pairing = \"<value>\" # Paired-end or Single-end The file ID can be retrieved from the DNAnexus web interface. Click on the file of interest and the file ID is displayed in the sidebar. Hooking up inputs \u00b6 You will need to select reference counts files from your project. These can be specified in the reference counts data input. When specifying the reference_counts , select all HTSeq count files in the reference dataset. For the St. Jude Cloud paper dataset, there are 1576 total files to select. The UI will then display the number of selected reference files. Next, you'll need to hook up either the counts file or the BAM file you uploaded in the upload data section. In this example, we are using the counts-based version of the pipeline, so you can hook up the inputs by clicking on the input_counts slot and selecting the respective files. If you are using the realignment-based workflow, the process is similar with BAM input. Additionally, a parameter selecting the tissue type to compare against can be selected. The available options are \"Blood Cancer\", \"Brain Tumor\", and \"Solid Tumor\". Based on the selection, a reference collection of tumors of that type will be selected from St. Jude Cloud data and the input samples will be compared against this reference collection. If running the realignment workflow, the input file should be specified as a BAM to realign. HTSeq will run on the realigned BAM and the result will be passed into the t-SNE app for plotting against the reference data. The reference data should be specified in the reference_counts parameter as an array of HTSeq count files. The BAM will be specified to the RNA-Seq V2 stage as input_bam . The BAM should have properties set as described above. These will automatically be applied to the new HTSeq count file. Starting the workflow \u00b6 Once your input files are hooked up, you should be able to start the workflow by clicking the \"Run Analysis\" button in the top right hand corner of the workflow dialog. Monitoring run progress \u00b6 Once you have started one or more RNA-Seq Expression Classification runs, you can safely close your browser and come back later to check the status of the jobs. To do this, navigate to the tool's landing page. Next, click \"View Results\" then select the \"View Running Jobs\" option. You will be redirected to the job monitoring page. Each job you kicked off gets one row in this table. You can click the \"+\" on any of the runs to check the status of individual steps of the RNA-Seq Expression Classification pipeline. Other information, such as time, cost of individual steps in the pipeline, and even viewing the job logs can accessed by clicking around the sub-items. Interpreting Results \u00b6 Once the resulting analysis job completes, an HTML plot of the results should be available. The plot is generated with the ProteinPaint library . The plot can be zoomed arbitrarily and group labels can be turned on/off for manual inspection. User input samples will be displayed in black marks with a label on the graph as well as an entry in the legend. Batch effect corrections \u00b6 When comparing numerous samples such as those included in this analysis, it is important to consider the variation in data created by obtaining from various sources and across time. Therefore the t-SNE visualization incorporates some batch effect corrections for the reference data. Currently we correct for batch effect based on strandedness of the RNA-Seq sample, library type, read pairing, and read length. Batch Variable Values Library Type PolyA or Total Read Length integer, in bp, e.g. 101, 126 Strandedness Stranded-Forward, Stranded-Reverse, Unstranded Pairing Paired-end or Single-end Known issues \u00b6 There are a few known cautions with the RNA-Seq Expression Classification workflow. Data must fit well defined values The RNA-Seq Expression Classification pipeline reference data is based on GRCh38 aligned, Gencode v31 annotated samples from fresh, frozen tissue samples. It has not been evaluated for samples that do not meet this criteria. The RNA-Seq Expression Classification pipeline reference data uses sequencing data from fresh, frozen tissue samples. It has not been evaluated for use with sequencing data generated from formalin-fixed paraffin-embedded (FFPE) specimens. If running the count-based RNA-Seq Expression Classification pipeline, alignment must be done against the GRCh38_no_alt reference . It should use parameters as specified in our RNA-seq workflow to minimize any discrepancies caused by differing alignment specification. If running the count-based RNA-Seq Expression Classification pipeline, feature counts should be generated with htseq-count as described in our RNA-seq workflow . This pipeline uses Gencode v31 annotations. Batch correction requires a minimum of two samples per batch to run properly. Introducing a single sample batch by adding an input sample with a unique protocol will cause unexpected results. Frequently asked questions \u00b6 If you have any questions not covered here, feel free to reach out on our contact form . Submit batch jobs on the command line \u00b6 See How can I run an analysis workflow on multiple sample files at the same time?","title":"RNA-Seq Expression Classification"},{"location":"guides/genomics-platform/analyzing-data/rnaseq-expression-classification/#overview","text":"St. Jude Cloud provides functionality for generating RNA-Seq Expression Classification plots. This tool allows plotting of RNA-seq data by running through the St. Jude Cloud normalization pipeline . The generated count data is then compared to a reference set of data from a cohort of St. Jude samples and a plot is produced.","title":"Overview"},{"location":"guides/genomics-platform/analyzing-data/rnaseq-expression-classification/#requirements","text":"The RNA-Seq Expression Classification pipeline reference data uses sequencing data from fresh, frozen tissue samples. It has not been evaluated for use with sequencing data generated from formalin-fixed paraffin-embedded (FFPE) specimens. If running the count-based pipeline, alignment must be done against the GRCh38_no_alt reference . It should use parameters as specified in our RNA-seq workflow to minimize any discrepancies caused by differing alignment specification. If running the count-based pipeline, feature counts should be generated with htseq-count as described in our RNA-seq workflow . This pipeline uses Gencode v31 annotations.","title":"Requirements"},{"location":"guides/genomics-platform/analyzing-data/rnaseq-expression-classification/#inputs","text":"The input can be either of the two entries below, based on whether you want to start with a counts file or a BAM file. Name Description Example BAM file Aligned reads file from human RNA-Seq Sample.bam Counts file htseq-count output feature counts file from human RNA-Seq Sample.counts.txt Caution If you provide counts data to the counts-based pipeline, it must be aligned to GRCh38_no_alt . Running a sample aligned to any other reference genome is not supported. Maybe more importantly, we do not check the genome build of the BAM, so errors in computation or the results can occur. If your sample is not aligned to this genome build, we recommend submitting the sample to the realignment-based workflow.","title":"Inputs"},{"location":"guides/genomics-platform/analyzing-data/rnaseq-expression-classification/#outputs","text":"The RNA-Seq Expression Classification pipeline produces the following outputs: Name Description Pipeline Version Interactive expression plot (.html) Visualization of RNA-Seq data all Aligned BAM (.bam) BAM file produced by our RNA-Seq pipeline for the input samples. Realignment Feature read counts (.txt) Read counts for the Gencode features. Realignment","title":"Outputs"},{"location":"guides/genomics-platform/analyzing-data/rnaseq-expression-classification/#workflow-steps","text":"[Only for realignment workflow] The aligned BAM is converted to FastQ and is aligned to GRCh38_no_alt using standard STAR mapping . [Only for realignment workflow] A feature count (.count.txt) file is produced for comparison to St. Jude Cloud reference data. A visualization for genomic features is produced.","title":"Workflow Steps"},{"location":"guides/genomics-platform/analyzing-data/rnaseq-expression-classification/#mapping","text":"We use the STAR aligner to rapidly map reads to the GRCh38 human reference genome.","title":"Mapping"},{"location":"guides/genomics-platform/analyzing-data/rnaseq-expression-classification/#feature-counts","text":"We use htseq-count to produce genomic feature counts.","title":"Feature Counts"},{"location":"guides/genomics-platform/analyzing-data/rnaseq-expression-classification/#visualization","text":"A t-Distributed Stochastic Neighbor Embedding (t-SNE) visualization is produced using Rtsne . You can find the t-SNE paper here .","title":"Visualization"},{"location":"guides/genomics-platform/analyzing-data/rnaseq-expression-classification/#cost-estimation","text":"Workflow Name Per sample cost Outliers Realignment workflow $3-10 $25 Feature read counts workflow $0.30-0.40","title":"Cost Estimation"},{"location":"guides/genomics-platform/analyzing-data/rnaseq-expression-classification/#running-the-workflow","text":"","title":"Running the workflow"},{"location":"guides/genomics-platform/analyzing-data/rnaseq-expression-classification/#getting-started","text":"Caution If you provide counts data to the counts-based pipeline, it must be aligned to GRCh38_no_alt . Running a sample aligned to any other reference genome is not supported. Maybe more importantly, we do not check the genome build of the sample, so errors in computation or the results can occur. If your sample is not aligned to this genome build, we recommend submitting the sample to the realignment-based workflow. We provide two versions of the RNA-Seq Expression Classification tool depending on desired input. The full workflow allows a user to upload a sample in BAM format. That sample will then be converted to FastQ format, aligned with STAR two-pass alignment, and feature counts generated with htseq-count To get started, you need to navigate to the RNA-Seq Expression Classification tool page . You'll need to click the \"Start\" button in the left hand pane. This creates a cloud workspace in DNAnexus with the same name as the tool. After this, you will be able to upload your input files to that workspace.","title":"Getting Started"},{"location":"guides/genomics-platform/analyzing-data/rnaseq-expression-classification/#obtaining-reference-data","text":"Reference feature count data is vended to the project folder along with the workflow. It can be found in the \u201ccounts\u201d folder. Reference data can also be retrieved through the Genomics Platform Data Browser These must then be provided to the workflow through the reference_counts parameter. By default, all reference files will be used by the app, but this can be restricted to one of the three tumor types [Blood, Brain, Solid] through the app settings. Caution The RNA-Seq Expression Classification tool does not allow the same sample name to be included more than once. If data from multiple projects is requested through St. Jude Cloud Genomics Platform, a sample may be included more than once. We offer an opinionated deduplication method at https://github.com/stjudecloud/utilities .","title":"Obtaining reference data"},{"location":"guides/genomics-platform/analyzing-data/rnaseq-expression-classification/#running-the-tool","text":"Once you've uploaded data to your cloud workspace, click \"Launch Tool\" on the tool's landing page. A dropdown will present the different presets for running the workflow. Here, you can select whether you wish to start with a counts file or a BAM file. Once the tool has been vended, copy the workflow to the project containing the reference data.","title":"Running the tool"},{"location":"guides/genomics-platform/analyzing-data/rnaseq-expression-classification/#uploading-data","text":"The RNA-Seq Expression Classification pipeline takes either a htseq-count count file or a GRCh38_no_alt aligned BAM from human RNA-Seq. You can upload your input file(s) through the command line. See Uploading Data from your Local Computer . Once you have the dx toolkit, to upload a sample HTSeq count file sample.counts.txt to the inputs folder of the project-rnaseq cloud project, you could use the following command: dx upload sample.counts.txt --destination \"project-rnaseq:/inputs/\"","title":"Uploading data"},{"location":"guides/genomics-platform/analyzing-data/rnaseq-expression-classification/#preparing-input-data","text":"To run an input sample, certain properties need to be set on the file. These should be specified on the HTSeq count file for the counts-based pipeline or on the BAM file for the realignment-based workflow. Property Name Values sample_name should match filename up to first period (\".\") library_type PolyA or Total read_length integer, in bp strandedness Stranded-Forward, Stranded-Reverse, Unstranded pairing Paired-end or Single-end Properties can be set at the job-level for all input files that do not have properties set. These function as defaults and will not override existing values on files. The options are limited to values in our reference cohort to ensure reliable results. If a more granular control of covariates is needed, the input files can be annotated directly with properties. To input properties in DNAnexus, you can either use the web UI or the command line interface. Here, we provide a command line snippet to set properties on a file. # you can run the following code snippet after filling in your values # to successfully prepare the file. file_id = <DNAnexus file ID> # file ID or file path dx set_properties $file_id sample_name = \"<value>\" # Should match the file name up to the first period character dx set_properties $file_id strandedness = \"<value>\" # Stranded-Forward, Stranded-Reverse, or Unstranded dx set_properties $file_id library_type = \"<value>\" # PolyA or Total dx set_properties $file_id read_length = \"<value>\" # Integer number of base pairs in reads (e.g. 101, 126) dx set_properties $file_id pairing = \"<value>\" # Paired-end or Single-end The file ID can be retrieved from the DNAnexus web interface. Click on the file of interest and the file ID is displayed in the sidebar.","title":"Preparing input data"},{"location":"guides/genomics-platform/analyzing-data/rnaseq-expression-classification/#hooking-up-inputs","text":"You will need to select reference counts files from your project. These can be specified in the reference counts data input. When specifying the reference_counts , select all HTSeq count files in the reference dataset. For the St. Jude Cloud paper dataset, there are 1576 total files to select. The UI will then display the number of selected reference files. Next, you'll need to hook up either the counts file or the BAM file you uploaded in the upload data section. In this example, we are using the counts-based version of the pipeline, so you can hook up the inputs by clicking on the input_counts slot and selecting the respective files. If you are using the realignment-based workflow, the process is similar with BAM input. Additionally, a parameter selecting the tissue type to compare against can be selected. The available options are \"Blood Cancer\", \"Brain Tumor\", and \"Solid Tumor\". Based on the selection, a reference collection of tumors of that type will be selected from St. Jude Cloud data and the input samples will be compared against this reference collection. If running the realignment workflow, the input file should be specified as a BAM to realign. HTSeq will run on the realigned BAM and the result will be passed into the t-SNE app for plotting against the reference data. The reference data should be specified in the reference_counts parameter as an array of HTSeq count files. The BAM will be specified to the RNA-Seq V2 stage as input_bam . The BAM should have properties set as described above. These will automatically be applied to the new HTSeq count file.","title":"Hooking up inputs"},{"location":"guides/genomics-platform/analyzing-data/rnaseq-expression-classification/#starting-the-workflow","text":"Once your input files are hooked up, you should be able to start the workflow by clicking the \"Run Analysis\" button in the top right hand corner of the workflow dialog.","title":"Starting the workflow"},{"location":"guides/genomics-platform/analyzing-data/rnaseq-expression-classification/#monitoring-run-progress","text":"Once you have started one or more RNA-Seq Expression Classification runs, you can safely close your browser and come back later to check the status of the jobs. To do this, navigate to the tool's landing page. Next, click \"View Results\" then select the \"View Running Jobs\" option. You will be redirected to the job monitoring page. Each job you kicked off gets one row in this table. You can click the \"+\" on any of the runs to check the status of individual steps of the RNA-Seq Expression Classification pipeline. Other information, such as time, cost of individual steps in the pipeline, and even viewing the job logs can accessed by clicking around the sub-items.","title":"Monitoring run progress"},{"location":"guides/genomics-platform/analyzing-data/rnaseq-expression-classification/#interpreting-results","text":"Once the resulting analysis job completes, an HTML plot of the results should be available. The plot is generated with the ProteinPaint library . The plot can be zoomed arbitrarily and group labels can be turned on/off for manual inspection. User input samples will be displayed in black marks with a label on the graph as well as an entry in the legend.","title":"Interpreting Results"},{"location":"guides/genomics-platform/analyzing-data/rnaseq-expression-classification/#batch-effect-corrections","text":"When comparing numerous samples such as those included in this analysis, it is important to consider the variation in data created by obtaining from various sources and across time. Therefore the t-SNE visualization incorporates some batch effect corrections for the reference data. Currently we correct for batch effect based on strandedness of the RNA-Seq sample, library type, read pairing, and read length. Batch Variable Values Library Type PolyA or Total Read Length integer, in bp, e.g. 101, 126 Strandedness Stranded-Forward, Stranded-Reverse, Unstranded Pairing Paired-end or Single-end","title":"Batch effect corrections"},{"location":"guides/genomics-platform/analyzing-data/rnaseq-expression-classification/#known-issues","text":"There are a few known cautions with the RNA-Seq Expression Classification workflow. Data must fit well defined values The RNA-Seq Expression Classification pipeline reference data is based on GRCh38 aligned, Gencode v31 annotated samples from fresh, frozen tissue samples. It has not been evaluated for samples that do not meet this criteria. The RNA-Seq Expression Classification pipeline reference data uses sequencing data from fresh, frozen tissue samples. It has not been evaluated for use with sequencing data generated from formalin-fixed paraffin-embedded (FFPE) specimens. If running the count-based RNA-Seq Expression Classification pipeline, alignment must be done against the GRCh38_no_alt reference . It should use parameters as specified in our RNA-seq workflow to minimize any discrepancies caused by differing alignment specification. If running the count-based RNA-Seq Expression Classification pipeline, feature counts should be generated with htseq-count as described in our RNA-seq workflow . This pipeline uses Gencode v31 annotations. Batch correction requires a minimum of two samples per batch to run properly. Introducing a single sample batch by adding an input sample with a unique protocol will cause unexpected results.","title":"Known issues"},{"location":"guides/genomics-platform/analyzing-data/rnaseq-expression-classification/#frequently-asked-questions","text":"If you have any questions not covered here, feel free to reach out on our contact form .","title":"Frequently asked questions"},{"location":"guides/genomics-platform/analyzing-data/rnaseq-expression-classification/#submit-batch-jobs-on-the-command-line","text":"See How can I run an analysis workflow on multiple sample files at the same time?","title":"Submit batch jobs on the command line"},{"location":"guides/genomics-platform/analyzing-data/running-sj-workflows/","text":"In this guide, we will explain generally how to run, from end-to-end, any of our in house analysis workflows from within the DNAnexus cloud ecosystem. The DNAnexus genomic ecosystem is the backbone for the computation and storage in St. Jude Cloud. If you'd like, you can read an introduction to the DNAnexus ecosystem here . If you haven't already, follow this guide to request access to St. Jude data in this secure cloud ecosystem. Note If you use the initial $50 credit from creating your account and are interested in additional funding, please reach out to support@stjude.cloud as additional collaboration funds may be available. Getting started \u00b6 To get started with any St. Jude Cloud workflow, first navigate to the appropriate workflow page. Below is a complete list of the workflows we offer along with links to their corresponding tool page and documentation page. ChIP-Seq Peak Calling [ tool page ] [ documentation ] Rapid RNA-Seq Fusion Detection [ tool page ] [ documentation ] WARDEN Differential Expression Analysis [ tool page ] [ documentation ] Mutational Signatures [ tool page ] [ documentation ] SequencErr [ tool page ] [ documentation ] RNA-Seq Expression Classification [ tool page ] [ documentation ] cis-X [ tool page ] [ documentation ] MethylationToActivity [ tool page ] [ documentation ] From the appropriate workflow page, click the \"Start\" button in the left hand pane. This creates a new DNAnexus cloud workspace (with the same name as the workflow) and imports the workflow. With subsequent runs, in place of the \"Start\" button will be two buttons \"Launch Tool\" and \"View Results\", meaning a cloud workspace with the workflow has already been created for you. In this case, you're good! You can move on to the next section. Note If you have not yet logged in, in place of the \"Start\" button will be a button the says \"Log In\". If you see this, simply login and try again. For a guide to creating an account go here . If you are still unable to start the workflow, contact us . Uploading Files \u00b6 Now that a DNAnexus cloud workspace has been created, you will be able to upload input files to that workspace. The specific documentation for each workflow will detail what input files you will need to upload. You can upload these files using the the command line . Running the Workflow \u00b6 Once you've uploaded data to your cloud workspace, click \"Launch Tool\" on the workflow's landing page. A dropdown will present any presets required for running the workflow. For example, some workflows ask that you select whether you wish to start with FastQ files or a BAM file. Launching the workflow will redirect you to you workspace in DNAnexus. The gif below shows an example with the Rapid RNA-Seq workflow Selecting Parameters \u00b6 Some workflows allow you to specify or customize one or more run parameters. Many parameters will be set to a default value. To see all parameter options available, click the gear cog next to the substep titled with the workflow name. For a full list of the parameters and their descriptions, see Inputs table on the documentation page for the workflow that you are running. Below is an example showing how to customize parameters for the Neoepitope Prediction workflow. Hooking up Inputs \u00b6 Next, you'll need to hook up the input files you uploaded in the upload files section . In the example below, we are running the Rapid RNA-Seq workflow using the FastQ version of the pipeline. The example gif shows that you hook up the inputs by clicking on the Fastq/R1 and Fastq/R2 slots and selecting the respective input files. This process is similar for all workflows. Starting the Workflow \u00b6 Once your input files are hooked up, you should be able to start the workflow by clicking the Run as Analysis... button in the top right hand corner of the workflow dialog. See the example below using the Rapid RNA-Seq workflow. Tip If you cannot click this button, please ensure that all of the inputs are correctly hooked up. If you're still have trouble, please contact us and include a screenshot of the workflow screen above. Monitoring Run Progress \u00b6 Once you have started one or more workflow runs, you can safely close your browser and come back later to check the status of the jobs. To do this, navigate to the landing page of the workflow that you want to check. Next, click \"View Results\" then select the \"View Running Jobs\" option. You will be redirected to the job monitoring page in your DNAnexus workspace. Each job you kicked off gets one row in this table. See the two examples below for the Rapid RNA-Seq workflow. You can click the \"+\" on any of the runs to check the status of individual steps of the workflow. Other information, such as time, cost of individual steps in the workflow, and even viewing the job logs can accessed by clicking around the sub-items. Tip Refer to the DNAnexus Monitoring Executions Documentation for advanced capabilities for monitoring jobs. Accessing Results \u00b6 Custom Visualizations \u00b6 Most workflows in St. Jude Cloud produce one or more visualizations that helps you to understand the raw results. To access the visualization(s), navigate to the landing page of the workflow that you want to check. Next, click \"View Results\" then select the \"Visualize Results\" option. You should now see a list of visualization files. Click on a visualization name to explore. Below is a brief description of two of our custom visualizations. ProteinPaint BigWig Viewer \u00b6 The ProteinPaint interactive coverage viewer is used to visualize any bigWig file. You can follow these steps to get an understanding of how it works. Open up the custom viewer file output by your pipeline. The name of this file will vary, so consult the specific pipeline guide to know where to find it. Click \"Launch\" in the bottom right corner to launch the custom viewer. Once the page has loaded, you will be able to see the bigWig viewer. You can navigate around the genome by gene or genomic location. Alongside the coverage track is the GENCODE gene reference. ProteinPaint Fusion Viewer \u00b6 The ProteinPaint interactive fusion viewer is used to visualize putative fusions called by Rapid RNA-Seq. You can follow these steps to get an understanding of how it works. Open up the custom viewer file output by your pipeline. The name of this file will vary, so consult the specific pipeline guide to know where to find it. Click \"Launch\" in the bottom right corner to launch the custom viewer. Once the page has finished loading, you will be presented with a summary of all of the fusions produced by the pipeline. Each bullet point is a separate category for the structural variants, with the more interesting fusions at the top. Click one of the categories to view the fusions in that category. You can see all of the fusions in that category are now listed on the screen. Hover over one of the fusions to see the detailed view. The popup contains a large amount of information that might be interesting to you based on your use case, such as the transcript and other metrics like read counts, quality metrics, and recurrence. Raw Results Files \u00b6 If additionally, you would like to view raw output files, you may do so by following the directions below. To access the raw output file, navigate to the landing page of the workflow that you want to check. Next, click \"View Results\" then select the \"View Results Files\" option. You should now be in the filesystem view of your workflow's workspace in DNAnexus with access to files that you uploaded as well as results files that are generated. See the example filesystem view below for the Rapid RNA-Seq workflow. This is similar to your the filesystem on your computer, and you can do many common operations such as deleting, renaming, and moving files. How/where the result files are generated are specific to each pipeline. Please refer to your individual workflow's documentation on where the output files are kept. If you have any unanswered questions about how to run one of our in-house workflows, please contact us . Similar Topics \u00b6 Command Line Interaction Working with our Data Overview Upload/Download Data (local) Technical FAQs","title":"Running our Workflows"},{"location":"guides/genomics-platform/analyzing-data/running-sj-workflows/#getting-started","text":"To get started with any St. Jude Cloud workflow, first navigate to the appropriate workflow page. Below is a complete list of the workflows we offer along with links to their corresponding tool page and documentation page. ChIP-Seq Peak Calling [ tool page ] [ documentation ] Rapid RNA-Seq Fusion Detection [ tool page ] [ documentation ] WARDEN Differential Expression Analysis [ tool page ] [ documentation ] Mutational Signatures [ tool page ] [ documentation ] SequencErr [ tool page ] [ documentation ] RNA-Seq Expression Classification [ tool page ] [ documentation ] cis-X [ tool page ] [ documentation ] MethylationToActivity [ tool page ] [ documentation ] From the appropriate workflow page, click the \"Start\" button in the left hand pane. This creates a new DNAnexus cloud workspace (with the same name as the workflow) and imports the workflow. With subsequent runs, in place of the \"Start\" button will be two buttons \"Launch Tool\" and \"View Results\", meaning a cloud workspace with the workflow has already been created for you. In this case, you're good! You can move on to the next section. Note If you have not yet logged in, in place of the \"Start\" button will be a button the says \"Log In\". If you see this, simply login and try again. For a guide to creating an account go here . If you are still unable to start the workflow, contact us .","title":"Getting started"},{"location":"guides/genomics-platform/analyzing-data/running-sj-workflows/#uploading-files","text":"Now that a DNAnexus cloud workspace has been created, you will be able to upload input files to that workspace. The specific documentation for each workflow will detail what input files you will need to upload. You can upload these files using the the command line .","title":"Uploading Files"},{"location":"guides/genomics-platform/analyzing-data/running-sj-workflows/#running-the-workflow","text":"Once you've uploaded data to your cloud workspace, click \"Launch Tool\" on the workflow's landing page. A dropdown will present any presets required for running the workflow. For example, some workflows ask that you select whether you wish to start with FastQ files or a BAM file. Launching the workflow will redirect you to you workspace in DNAnexus. The gif below shows an example with the Rapid RNA-Seq workflow","title":"Running the Workflow"},{"location":"guides/genomics-platform/analyzing-data/running-sj-workflows/#selecting-parameters","text":"Some workflows allow you to specify or customize one or more run parameters. Many parameters will be set to a default value. To see all parameter options available, click the gear cog next to the substep titled with the workflow name. For a full list of the parameters and their descriptions, see Inputs table on the documentation page for the workflow that you are running. Below is an example showing how to customize parameters for the Neoepitope Prediction workflow.","title":"Selecting Parameters"},{"location":"guides/genomics-platform/analyzing-data/running-sj-workflows/#hooking-up-inputs","text":"Next, you'll need to hook up the input files you uploaded in the upload files section . In the example below, we are running the Rapid RNA-Seq workflow using the FastQ version of the pipeline. The example gif shows that you hook up the inputs by clicking on the Fastq/R1 and Fastq/R2 slots and selecting the respective input files. This process is similar for all workflows.","title":"Hooking up Inputs"},{"location":"guides/genomics-platform/analyzing-data/running-sj-workflows/#starting-the-workflow","text":"Once your input files are hooked up, you should be able to start the workflow by clicking the Run as Analysis... button in the top right hand corner of the workflow dialog. See the example below using the Rapid RNA-Seq workflow. Tip If you cannot click this button, please ensure that all of the inputs are correctly hooked up. If you're still have trouble, please contact us and include a screenshot of the workflow screen above.","title":"Starting the Workflow"},{"location":"guides/genomics-platform/analyzing-data/running-sj-workflows/#monitoring-run-progress","text":"Once you have started one or more workflow runs, you can safely close your browser and come back later to check the status of the jobs. To do this, navigate to the landing page of the workflow that you want to check. Next, click \"View Results\" then select the \"View Running Jobs\" option. You will be redirected to the job monitoring page in your DNAnexus workspace. Each job you kicked off gets one row in this table. See the two examples below for the Rapid RNA-Seq workflow. You can click the \"+\" on any of the runs to check the status of individual steps of the workflow. Other information, such as time, cost of individual steps in the workflow, and even viewing the job logs can accessed by clicking around the sub-items. Tip Refer to the DNAnexus Monitoring Executions Documentation for advanced capabilities for monitoring jobs.","title":"Monitoring Run Progress"},{"location":"guides/genomics-platform/analyzing-data/running-sj-workflows/#accessing-results","text":"","title":"Accessing Results"},{"location":"guides/genomics-platform/analyzing-data/running-sj-workflows/#custom-visualizations","text":"Most workflows in St. Jude Cloud produce one or more visualizations that helps you to understand the raw results. To access the visualization(s), navigate to the landing page of the workflow that you want to check. Next, click \"View Results\" then select the \"Visualize Results\" option. You should now see a list of visualization files. Click on a visualization name to explore. Below is a brief description of two of our custom visualizations.","title":"Custom Visualizations"},{"location":"guides/genomics-platform/analyzing-data/running-sj-workflows/#proteinpaint-bigwig-viewer","text":"The ProteinPaint interactive coverage viewer is used to visualize any bigWig file. You can follow these steps to get an understanding of how it works. Open up the custom viewer file output by your pipeline. The name of this file will vary, so consult the specific pipeline guide to know where to find it. Click \"Launch\" in the bottom right corner to launch the custom viewer. Once the page has loaded, you will be able to see the bigWig viewer. You can navigate around the genome by gene or genomic location. Alongside the coverage track is the GENCODE gene reference.","title":"ProteinPaint BigWig Viewer"},{"location":"guides/genomics-platform/analyzing-data/running-sj-workflows/#proteinpaint-fusion-viewer","text":"The ProteinPaint interactive fusion viewer is used to visualize putative fusions called by Rapid RNA-Seq. You can follow these steps to get an understanding of how it works. Open up the custom viewer file output by your pipeline. The name of this file will vary, so consult the specific pipeline guide to know where to find it. Click \"Launch\" in the bottom right corner to launch the custom viewer. Once the page has finished loading, you will be presented with a summary of all of the fusions produced by the pipeline. Each bullet point is a separate category for the structural variants, with the more interesting fusions at the top. Click one of the categories to view the fusions in that category. You can see all of the fusions in that category are now listed on the screen. Hover over one of the fusions to see the detailed view. The popup contains a large amount of information that might be interesting to you based on your use case, such as the transcript and other metrics like read counts, quality metrics, and recurrence.","title":"ProteinPaint Fusion Viewer"},{"location":"guides/genomics-platform/analyzing-data/running-sj-workflows/#raw-results-files","text":"If additionally, you would like to view raw output files, you may do so by following the directions below. To access the raw output file, navigate to the landing page of the workflow that you want to check. Next, click \"View Results\" then select the \"View Results Files\" option. You should now be in the filesystem view of your workflow's workspace in DNAnexus with access to files that you uploaded as well as results files that are generated. See the example filesystem view below for the Rapid RNA-Seq workflow. This is similar to your the filesystem on your computer, and you can do many common operations such as deleting, renaming, and moving files. How/where the result files are generated are specific to each pipeline. Please refer to your individual workflow's documentation on where the output files are kept. If you have any unanswered questions about how to run one of our in-house workflows, please contact us .","title":"Raw Results Files"},{"location":"guides/genomics-platform/analyzing-data/running-sj-workflows/#similar-topics","text":"Command Line Interaction Working with our Data Overview Upload/Download Data (local) Technical FAQs","title":"Similar Topics"},{"location":"guides/genomics-platform/analyzing-data/sequencerr/","text":"Measuring and suppressing sequencer errors in next-generation sequencing data \u00b6 Authors Eric M Davis, Yu Sun, Yanling Liu, Pandurang Kolekar, Ying Shao, Karol Szlachta, Heather L Mulder, Dongren Ren, Stephen V Rice, Zhaoming Wang, Joy Nakitandwe, Alex Gout, Bridget Shaner, Salina Hall, Leslie L Robison, Stanley Pounds, Jefferey Klco, John Easton, Xiaotu Ma* Publication Davis, E.M. et al. SequencErr: measuring and suppressing sequencer errors in next-generation sequencing data. Genome Biol 22(1):37 (2021). doi: 10.1186/s13059-020-02254-2 Technical Support Contact Us Overview \u00b6 There is currently no method to precisely measure the errors that occur in the sequencing instrument, which is critical for next generation sequencing applications aimed at discovering the genetic makeup of heterogeneous cellular populations. We propose a novel computational method, SequencErr, to address this challenge by measuring base concordance in overlapping region between forward and reverse reads. Analysis of 3,777 public datasets from 75 research institutions in 18 countries revealed the sequencer error rate to be ~10 per million (pm) and 1.4% of sequencers and 2.7% of flow cells have error rates >100 pm. At the flow cell level, error rates are elevated in the bottom surfaces and >90% of HiSeq and NovaSeq flow cells have at least one outlier error-prone tiles. By sequencing a common DNA library on different sequencers, we demonstrate that sequencers with high error rates have reduced overall sequencing accuracy, and that removal of outlier error-prone tiles improves sequencing accuracy. Our study revealed novel insights into the nature DNA sequencing errors incurred in sequencers. Our method can be used to assess, calibrate, and monitor sequencer accuracy, and to computationally suppress sequencer errors in existing datasets Inputs \u00b6 Name Type Description Example BAM file Input file Binary version of the SAM file format ( *.bam ) Sample.bam BAM index file Input file Index file for the BAM file ( *.bai ) Sample.bam.bai Outputs \u00b6 Name Format Description PairError file .txt Base concordance/discordance counts Counts file .txt Base call frequencies for each genomic coordinate Details of SequencErr Input Files and Parameters \u00b6 BAM file name [Required] A BAM file to process. This app currently only supports DNA sequencing. The bam file should be generated by \u201cbwa aln\u201d. It works on \u201cbwa MEM\u201d but may take a lot more resources. Notes on preparing the BAM file Read names must have all the 7 fields as described below, [instrument]:[run number]:[flowcell ID]:[lane]:[tile]:[x-pos]:[y-pos] Example: A041:30:HHTYVDSXX:1:2242:28366:18897 BAM format details here See this page for details of the fields in readname BAM index file name [Required] The BAM index for your BAM file sample id [Required] A unique name or identifier for the sample trimming length [optional] Number of bases to trim off the 5' and 3' of the read. Default: 5 hard quality cutoff [optional] A hard threshold for discarding reads. If the fraction of bases with quality scores falling below this value exceeds fcut, the read will be filtered. Default: 20 don't report base counts [optional] Set this to prevent large count files from being generated Default: true Running the Analysis \u00b6 Note This tool is intended free-of-charge for non-profit usages. Please contact Dr. Xiaotu Ma for for-profit usages and modifications Please refer to the following steps to learn how to launch the workflow, hook up input files, adjust parameters, run analysis and inspect output files. Log in and Launch the SequencErr SequencErr application can be accessed from https://platform.stjude.cloud/workflows/sequencerr Please refer to the following instructions. Choose Input BAM and Index Files Users can upload and download data files with command line interactions as described here Follow the similar steps to choose and select the corresponding BAM index file Provide Input Parameters Run the Analysis Locate Output File(s) after Completion of the Analysis Interpreting results \u00b6 *.pairError.txt file: A text file containing Instrument, Flowcell, Lane and Tile level base concordance/discordance counts *.counts.txt file [optional] : A text file containing the base call frequencies and coverage for each genomic coordinate at specified base quality cut-off Similar Topics \u00b6 Running our Workflows Working with our Data Overview Upload/Download Data (local)","title":"SequencErr"},{"location":"guides/genomics-platform/analyzing-data/sequencerr/#measuring-and-suppressing-sequencer-errors-in-next-generation-sequencing-data","text":"Authors Eric M Davis, Yu Sun, Yanling Liu, Pandurang Kolekar, Ying Shao, Karol Szlachta, Heather L Mulder, Dongren Ren, Stephen V Rice, Zhaoming Wang, Joy Nakitandwe, Alex Gout, Bridget Shaner, Salina Hall, Leslie L Robison, Stanley Pounds, Jefferey Klco, John Easton, Xiaotu Ma* Publication Davis, E.M. et al. SequencErr: measuring and suppressing sequencer errors in next-generation sequencing data. Genome Biol 22(1):37 (2021). doi: 10.1186/s13059-020-02254-2 Technical Support Contact Us","title":"Measuring and suppressing sequencer errors in next-generation sequencing data"},{"location":"guides/genomics-platform/analyzing-data/sequencerr/#overview","text":"There is currently no method to precisely measure the errors that occur in the sequencing instrument, which is critical for next generation sequencing applications aimed at discovering the genetic makeup of heterogeneous cellular populations. We propose a novel computational method, SequencErr, to address this challenge by measuring base concordance in overlapping region between forward and reverse reads. Analysis of 3,777 public datasets from 75 research institutions in 18 countries revealed the sequencer error rate to be ~10 per million (pm) and 1.4% of sequencers and 2.7% of flow cells have error rates >100 pm. At the flow cell level, error rates are elevated in the bottom surfaces and >90% of HiSeq and NovaSeq flow cells have at least one outlier error-prone tiles. By sequencing a common DNA library on different sequencers, we demonstrate that sequencers with high error rates have reduced overall sequencing accuracy, and that removal of outlier error-prone tiles improves sequencing accuracy. Our study revealed novel insights into the nature DNA sequencing errors incurred in sequencers. Our method can be used to assess, calibrate, and monitor sequencer accuracy, and to computationally suppress sequencer errors in existing datasets","title":"Overview"},{"location":"guides/genomics-platform/analyzing-data/sequencerr/#inputs","text":"Name Type Description Example BAM file Input file Binary version of the SAM file format ( *.bam ) Sample.bam BAM index file Input file Index file for the BAM file ( *.bai ) Sample.bam.bai","title":"Inputs"},{"location":"guides/genomics-platform/analyzing-data/sequencerr/#outputs","text":"Name Format Description PairError file .txt Base concordance/discordance counts Counts file .txt Base call frequencies for each genomic coordinate","title":"Outputs"},{"location":"guides/genomics-platform/analyzing-data/sequencerr/#details-of-sequencerr-input-files-and-parameters","text":"BAM file name [Required] A BAM file to process. This app currently only supports DNA sequencing. The bam file should be generated by \u201cbwa aln\u201d. It works on \u201cbwa MEM\u201d but may take a lot more resources. Notes on preparing the BAM file Read names must have all the 7 fields as described below, [instrument]:[run number]:[flowcell ID]:[lane]:[tile]:[x-pos]:[y-pos] Example: A041:30:HHTYVDSXX:1:2242:28366:18897 BAM format details here See this page for details of the fields in readname BAM index file name [Required] The BAM index for your BAM file sample id [Required] A unique name or identifier for the sample trimming length [optional] Number of bases to trim off the 5' and 3' of the read. Default: 5 hard quality cutoff [optional] A hard threshold for discarding reads. If the fraction of bases with quality scores falling below this value exceeds fcut, the read will be filtered. Default: 20 don't report base counts [optional] Set this to prevent large count files from being generated Default: true","title":"Details of SequencErr Input Files and Parameters"},{"location":"guides/genomics-platform/analyzing-data/sequencerr/#running-the-analysis","text":"Note This tool is intended free-of-charge for non-profit usages. Please contact Dr. Xiaotu Ma for for-profit usages and modifications Please refer to the following steps to learn how to launch the workflow, hook up input files, adjust parameters, run analysis and inspect output files. Log in and Launch the SequencErr SequencErr application can be accessed from https://platform.stjude.cloud/workflows/sequencerr Please refer to the following instructions. Choose Input BAM and Index Files Users can upload and download data files with command line interactions as described here Follow the similar steps to choose and select the corresponding BAM index file Provide Input Parameters Run the Analysis Locate Output File(s) after Completion of the Analysis","title":"Running the Analysis"},{"location":"guides/genomics-platform/analyzing-data/sequencerr/#interpreting-results","text":"*.pairError.txt file: A text file containing Instrument, Flowcell, Lane and Tile level base concordance/discordance counts *.counts.txt file [optional] : A text file containing the base call frequencies and coverage for each genomic coordinate at specified base quality cut-off","title":"Interpreting results"},{"location":"guides/genomics-platform/analyzing-data/sequencerr/#similar-topics","text":"Running our Workflows Working with our Data Overview Upload/Download Data (local)","title":"Similar Topics"},{"location":"guides/genomics-platform/analyzing-data/visualizing-ngs-data/","text":"Visualizing NGS Data In the future, we will release an alpha version of the GenomePaint visualization tool on St. Jude Cloud. In the meantime, the best way to visualize NGS data on St. Jude Cloud is using IGV. You can use the desktop or web browser versions of IGV. Desktop IGV \u00b6 DNAnexus has an existing guide on viewing files in DNAnexus using the desktop version of IGV. You can view the guide here . Web Browser IGV \u00b6 Within any DNAnexus project, you can view the data in the IGV web browser by doing the following steps. Select \"Visualize\" Select IGV v2.0.0 Select the files you want to view","title":"Visualizing NGS data"},{"location":"guides/genomics-platform/analyzing-data/visualizing-ngs-data/#desktop-igv","text":"DNAnexus has an existing guide on viewing files in DNAnexus using the desktop version of IGV. You can view the guide here .","title":"Desktop IGV"},{"location":"guides/genomics-platform/analyzing-data/visualizing-ngs-data/#web-browser-igv","text":"Within any DNAnexus project, you can view the data in the IGV web browser by doing the following steps. Select \"Visualize\" Select IGV v2.0.0 Select the files you want to view","title":"Web Browser IGV"},{"location":"guides/genomics-platform/analyzing-data/warden/","text":"Authors Lance Palmer Publication N/A (not published) Technical Support Contact Us Overview \u00b6 The WARDEN ( W**orkflow for the **A**nalysis of **R**NA-Seq **D**ifferential **E**xpressio**N ) software uses RNA-Seq sequence files to perform alignment, coverage analysis, gene counts and differential expression analysis. Inputs \u00b6 The WARDEN workflow requires two types of input files and that two parameters be set manually. All other parameters are preset with reasonable defaults. Name Type Description Example FastQ files ( required ) Input file(s) Gzipped FastQ files generated by experiment Sample1.fastq.gz, Sample2.fastq.gz Sample sheet ( required ) Input file Sample sheet generated and uploaded by the user *.txt Input file configuration \u00b6 You'll need to create a sample sheet which describes the relationship between case and control samples, phenotype/condition information, and the comparisons you would like to perform. The sample sheet is a tab-delimited text document that can be created in Microsoft Excel (recommended) or a text editor. Note You will need to upload your sample sheet in a similar manner as your FastQ files, so you can follow the same uploading instructions to achieve this. Prepare using Microsoft Excel \u00b6 Tip Download the file_download sample excel spreadsheet as a starting point! The final product for the excel spreadsheet will look like the screenshot below. If you create the sample sheet from scratch, please ensure the the columns are exactly in this order. Sample rows Each row in the spreadsheet (except for the last row, which we will talk about in the next section) corresponds to a sample with one or more FastQ files. You should fill in these rows based on your data and the guidelines below: Guidelines The sample name should be unique and should only contain letters, numbers and underscores. The condition/phenotype column associates similar samples together. The values should contain only letters, numbers and underscores. ReadFile1 should contain forward reads (e.g. *.R1.fastq.gz or *_1.fastq.gz ). ReadFile2 will contain reads in reverse orientation to ReadFile2 (e.g. *.R2.fastq.gz or *_2.fastq.gz ). For single end reads a single dash ('-') should be entered in the ReadFile2 column. Comparison row The last line in the sample sheet is called the \"comparison row\". This line specifies the comparisons to be done between conditions/phenotypes. All pairwise combinations of the values in the \"Phenotype\" column can be analyzed. To specify the comparisons, on a separate line, include #comparisons= followed be a comma delimited list of two conditions separated by a dash. Example The following lines are all valid examples. #comparisons=KO-WT #comparisons=Condition1-Control,Condition2-Control #comparisons=Phenotype2-Phenotype1,Phenotype3-Phenotype2,Phenotype3-Phenotype1 Note If a comparison has at least 3 samples for each condition/phenotype, VOOM/LIMMA will be run. A simple differential comparison will be run on all samples. Finalizing the sample sheet To finalize the sample sheet, save the Microsoft Excel file with whatever name you like. Save the file as an Excel Workbook with the .xlsx extension. Prepare using a text editor \u00b6 Tip Download the file_download sample text file as a starting point! Creating a sample sheet with a text editor is an option for advanced users. The process of creating a sample sheet with a text editor is the same as creating one with Microsoft Excel, with the small difference that you must manually create your columns using the tab character. Save the file with a .txt extension. Outputs \u00b6 Name Description FastQC Report Quality control analysis by FastQC. Aligned BAM Aligned BAM files from STAR mapping. Splice junctions Splice junction information from STAR mapping. Coverage files bigWig ( .bw ) and BED ( .bed ) files detailing coverage. Gene counts Gene counts generated by HT-Seq count. VOOM/LIMMA results Pairwise comparisons of expression data. Requires at least 3 samples vs 3 samples. Simple DE analysis No statistical analysis, requires only a 1 samples vs 1 sample comparison. MA/Volcano plots Both of the above produce tabular outputs, MA plots and volcano plots. Workflow Steps \u00b6 FastQ files generated by RNA-Seq are mapped to a reference genome using the STAR. HT-Seq count is used to assign mapped reads to genes. Differential expression analysis is performed using VOOM normalization of counts and LIMMA analysis. Coverage plots of mapped reads are generated as interactive visualizations. Creating a workspace \u00b6 Before you can run one of our workflows, you must first create a workspace in DNAnexus for the run. Refer to the general workflow guide to learn how to create a DNAnexus workspace for each workflow run. You can navigate to the WARDEN Differential Expression Analysis workflow page here . Uploading Input Files \u00b6 The WARDEN Differential Expression analysis pipeline takes Gzipped FastQ files generated by an RNA-Seq experiment as input . Refer to the general workflow guide to learn how to upload input files to the workspace you just created. Running the Workflow \u00b6 Refer to the general workflow guide to learn how to launch the workflow, hook up input files, adjust parameters, start a run, and monitor run progress. Note The WARDEN tool operation is slightly different than the other pipelines because it accepts a variable number of samples. First , you will run a \"bootstrapping\" step that creates a custom executable for your analysis. Second , you will need to manually execute the generated workflow from the first step. This allows us to take advantage of many nice features, like check-pointing and cost reduction. Don't worry, we'll show you how to do this step by step below. Hooking up Inputs \u00b6 You'll need to hook up the FastQ files and sample sheet you uploaded in the upload data section . Click the FASTQ_FILES input field and select all FastQ files. Next, click the sampleList input field and select the corresponding samplesheet. Selecting Parameters \u00b6 We now need to configure the parameters for the pipeline, such as reference genome and sequencing method. You can access all of the available parameters by clicking on the WARDEN WORKFLOW GENERATOR substep. For the general workflow instructions refer here Parameter setup steps In the Output Folder field, select a folder to output to. You can structure your experiments however you like (e.g. /My_Outputs ) In the analysisName field, enter a prefix for all of the output files. This can be any value you want to use to remember this run. Be sure to use underscores instead of spaces here! Select the sequenceStandedness from the drop down menu. This information can be determined from the sequencing or source of the data. If you don't know what to put here, select \"no\". Select the Genome pulldown menu. Choose the appropriate box. The LIMMA parameters can be left alone for most analyses. If you are an advanced LIMMA user, you can change the various settings exposed below the required parameters. When all parameters have been set, press the save button. Starting the workflow \u00b6 Once your input files are hooked up and your parameters are set, you should be able to start the workflow by clicking the \"Run as Analysis...\" button in the top right hand corner of the workflow dialog. For the general workflow instructions refer here . The tool will begin running and will automatically take you to the Monitor page, where you should see that your workflow is \"In Progress\". When the custom workflow has finished generating, the word 'Done' will appear in green in the status column. This indicates that the bootstrapping step has completed successfully. Custom Workflow Process \u00b6 Wait for the workflow generator to finish. Click on the WARDEN name in the name column. You will now be on a page specific to the running of the workflow. On the left side, you will see the inputs you selected for the workflow generator. On the right side are the output files (including the generated workflow). Select the generated workflow as shown in the picture below. You will now be within the output folder you specified earlier. Select the file that begins with 'WARDEN WORKFLOW:' A workflow generated for your data will be presented to you. Select 'Run as analysis' in the upper right. The workflow will initiate, and you will be brought to the 'Monitor' page. (Note to get back to this page, you can select 'Monitor' on one of the menu bars near the top ) Expand the the workflow progress be selecting the '+' sign next to 'In Progress' As parts of the pipeline are run, you will see different tasks in different colors. Green means done, blue is running, orange is waiting, and red means error. When done the status will be shown as 'Done'. Select the Workflow name under Status. You will be brought to a page that show more information about the workflow analysis. Click on the output folder to go to the output. The output folders will now be shown. For a description of the output, please refer to Interpreting Results . Analysis of Results \u00b6 Each tool in St. Jude Cloud produces a visualization that makes understanding results more accessible than working with excel spreadsheet or tab delimited files. This is the primary way we recommend you work with your results. Refer to the general workflow guide to learn how to access these visualizations. We also include the raw output files for you to dig into if the visualization is not sufficient to answer your research question. Refer to the general workflow guide to learn how to access raw results files. Interpreting Primary Results \u00b6 Alignment statistics \u00b6 Several files should be examined initially to determine the quality of the results. alignmentStatistics.txt shows alignment statistics for all samples. This file is a plain text tab-delimited file that can be opened in Excel or a text editor such as Notepad++. This file contains information on the total reads per sample, the percentage of duplicate reads and the percentage of mapped reads. An example of this file is below. (Within the DNAnexus output directory structure, these files will be in the COMBINED_FLAGSTAT directory.) Multidimensional scaling (MDS) Plot \u00b6 The second set of files to look at are the Multidimensional scaling (MDS) plots using the plotMDS function within LIMMA. Similar to PCA, these graphs will show how similar samples are to each other. There are different sets of MDS plots. For comparisons where there are 3 or more samples per condition, an MDS plot using Voom (Limma) normalized values are generated. An example can be seen below. These files will be labeled mdsPlot.png . For all comparisons, regardless of sample size, and MDS plot will also be generated with Counts per million (CPM) normalized gene counts. These files will be labeled mdsPlot.normCPM.png . (Within the DNAnexus output directory structure, these files will be in the LIMMA directory.) MDS plot from just CPM normalized data. ProteinPaint Visualizations \u00b6 Several files on DNAnexus allow the data to be viewed in the Protein Paint viewer. (Note: We plan to have links downloaded in the future to allow the viewing of these files off of DNAnexus.) LIMMA differential expression viewer Within LIMMA/VIEWERS directory (note if no comparisons meet the 3 sample condition, the LIMMA folder will not exist), there will be a viewer file for each valid comparison ( * results. .txt.viewer**). Simply select the file and press 'Launch viewer' in the lower right. A viewer will pop up showing both the MA Plot and Volcano plot. By moving the mouse over a circle, the circle will highlight and the corresponding gene on the other graph will also highlight. Additional information about the gene and its expression values will also be shown. One can also type in multiple gene symbols in the provided text box. By pressing 'Show gene labels' all these genes will show up on the plots. Simple differential expression viewer There will also be a viewer for the simple differential expression analysis in SIMPLE_DIFEX/VIEWERS. The P-value for the results have all been set to 1, so the volcano plot will not be relevant. bigWig viewer In the BIGWIG_VIEWER directory there will be a bigwigViewer file. Select this file and then 'Launch viewer'. A graph of coverage for the genome should be visible. Interpreting Secondary Results \u00b6 Interactive MA/Volcano Plots \u00b6 In addition to viewing the MA and volcano plots through the visualization tool Differential expression results \u00b6 Other useful differential expression results will be downloaded by the desktop app. This included tabular output from the differential expression analysis. For each comparison with three or more samples per condition, results.*.txt will be produced. GSEA.input.txt and GSEA.tStat.txt \u00b6 Input files that can be used for GSEA analysis. The tStat file is preferred for a more accurate analysis, but will not give a heatmap diagram. - (Within the DNAnexus output directory structure, these files will be in the LIMMA directory.) For plain text results from the simple differential expression analysis, the files will be named simpleDE.*.txt . (Within the DNAnexus output directory structure, these files will be in the SIMPLE_DIFEX directory.) Prelabelled MA and volcano plots are provided for the analysis. These files are labeled maPlot.*.png and volcanoPlot.*.png where * is the comparison (e.g. ko_vs_wt) The MA plot shows the average expression of the gene on the X-axis, and Log2 fold change between condition/phenotype is on the Y-axis (if the name is for example maPlot.condition2-condition1.png then the fold change would represent condition1 minus condition2). Each gene is represented by a circle. The top 20 genes (by p-value) are identified on the plot. The genes are color coded by the chosen multiple testing correction method (False Discovery Rate (FDR) by default. An example MA plot can be seen below. (Within the DNAnexus output directory structure, these files will be in the LIMMA directory.) The volcano plot shows the Log2Fold change between the conditions on the X-axis, and the -Log10 of the multiple testing corrected P-value on the Y-axis. An MA plot is generated for all comparisons regardless of number of samples. This is the simpleDEPlot.*.png no statistics are shown and genes are not labeled. (Within the DNAnexus output directory structure, these files will be in the SIMPLE_DIFEX directory.) Differential analysis input \u00b6 Inputs and commands are provided for rerunning differential expression analysis on ones own computer. The R commands used for the analysis are found in voomLimma.R . An experienced R user can rerun the analysis with any desired changes. This analysis requires the input countFile.txt which contains counts per genes, the Rparameters.txt file containing input parameters, and a processed sample list file sampleList.txt (Within the DNAnexus output directory structure, these files will be in the LIMMA directory.) The input for the simple differential analysis expression will be Rparameters_simple.txt , simpleDE.R , countFile.txt and sampleList.txt . countFile.txt and sampleList.txt are the same files used by the LIMMA analysis. (Within the DNAnexus output directory structure, these files will be in the SIMPLE_DIFEX directory.) Coverage results \u00b6 bigWig files will be generated for use in genome browsers (such as IGV http://software.broadinstitute.org/software/igv/ ). For each sample, multiple bigWig files will be found. For all types of sequencing strandedness, there will be bigWig files labeled, *.sortedCoverageFile.bed.bw where ' ' is the sample name. For stranded data there will also be*.sortedPosCoverageFile.bed.bw * and *.sortedNegCoverageFile.bed.bw which contains coverage information for the positive and negative strand of the genome. (Within the DNAnexus output directory structure, these files will be in the BIGWIG directory.) Quality Control Results (FastQC) \u00b6 Within the FastQC directory, for each sample and read direction there will be an html file and a zip file ( *.FastQc.html *.FastQc.zip where '*' is the base FastQ name), containing results from FastQTC. For the average user the html file is sufficient. This file can give some basic statistics on the quality of the data. (Within the DNAnexus output directory structure, these files will be in the FastQC directory.) BAM alignment files \u00b6 There are two BAM files generated per sample that contain mapping information for all reads. The first is labeled *.Aligned.sortedByCoord.dup.bam where ' ' is the sample name. The BAM file is sorted by coordinates and has duplicates marked. The second file is*.Aligned.toTranscriptome.out.bam * and contains reads mapped to transcripts. (Within the DNAnexus output directory structure, these files will be in the ALIGN directory.) Chimeric reads and junction files \u00b6 Additional files created by STAR are provided. More information on these files can be found here . *.SJ.out.tab contain splice junction information. Fusion detection files are labeled *.Chimeric.out.bam and *.Chimeric.out.junction . (Within the DNAnexus output directory structure, these files will be in the ALIGN directory.) FPKM and count files (per sample) \u00b6 Per sample files containing FPKM and raw count values for each gene can be found in *.fpkm.txt and *.htseq_counts.txt where '*' is the sample name. Within the DNAnexus output directory structure, these files will be in the HTSEQ directory. Methods Files \u00b6 A more human readable explanation is found in methods.docx . Detailed documentation can be found in methods.txt (Within the DNAnexus output directory structure, these files will be in the METHODS directory.) Auxiliary Files \u00b6 This section describes the files that exist within the DNAnexus output folder. Most of these files will not be of interest to the average user. However, interactive viewers are describe in LIMMA differential expression viewer and Simple differential expression viewer . The output will be divided into multiple folders. The results being the most useful will be the differential expression analysis results in the LIMMA and SIMPLE_DIFEX folders. Bigwig files for viewing read coverage will be in the BIGWIG folder. Other folder contain different types of data and are explained in further detail below. The following description of files is sorted by their output directory. ALIGN \u00b6 This directory contains the BAM files described in BAM alignment files and the chimeric and junction files are described in Chimeric reads and junction files . In addition there are 2 log files. *Log.final.out has relevant statistics for the alignment. The *.Log.out file just contains a log of the analysis run, including input parameters. Per sample FLAGSTAT results are found in *.flagStatOut.txt . Finally the ALIGN directory has multiple .starAlign.methods.txt files. These files can be ignored as they are summarized in the finalmethods.docx * and methods.txt files described in Methods Files . BIGWIG \u00b6 All of the files here are described in section Coverage results . The bgToBw.methods.txt files can be ignored as they are summarized in the files described in Methods Files . BIGWIG_VIEWER \u00b6 See bigWig viewer COMBINED_FLAGSTAT \u00b6 This directory contains the alignmentStatistics.txt file, which contains the combined alignment statistics from all samples. It is generated from the flagstat files describe in the ALIGN directory. COMBINED_HTSEQ \u00b6 Used for input in differential expression analysis. The combineCountFile.txt is the same as countFile.txt described in Differential analysis input COVERAGE \u00b6 BED graph files used to generate bigWig files are here. FastQC \u00b6 See Quality Control Results (FastQC) HTSEQ \u00b6 Per-sample HTSEQ-count results ( *.htseq_counts.txt ) and FPKM results ( *.fpkm.txt ). Temporary methods files are found as *.htseq-count.methods.txt LIMMA \u00b6 mdsPlot.png , maPlot.png , volcanoPlot.png are described in Initial analysis of results results.txt , GSEA.input.txt and GSEA.tStat.txt are describe in Differential expression results voomLimma.R , countFile.txt , Rparameters.txt , and sampleList.txt are described in Differential analysis input See LIMMA differential expression viewer for a description of the VIEWERS directory. Other files in the LIMMA directory include contrastFiles.txt contrastsFile.txt, and limmaSampleList.txt which are used internally. limmaMethods.txt is an intermediate file describing methods. Out.tar.gz is used for testing purposes. The sessionInfo.txt file describe the R session working parameters and modules loaded. meanVariance.png is a plot for assessing quality of count data ( https://genomebiology.biomedcentral.com/articles/10.1186/gb-2014-15-2-r29 ) METHODS The files here are described in Methods Files . SAMPLELIST These files are used internally by the pipeline. SIMPLE_DIFEX mdsPlot.normCPM.png and simpleDEPlot.png are described in Initial analysis of results simpleDE.txt are describe in Differential expression results simpleDE.R , countFile.txt , Rparameters_simple.txt , and sampleList.txt are described in Differential analysis input See Simple differential expression viewer for a description of the VIEWERS directory. Other files in the SIMPLE_DIFEX directory include contrastFiles.txt contrastsFile.txt, and limmaSampleList.txt which are used internally. simpleDifEx.methods.txt is an intermediate file describing methods. Out.tar.gz is used for testing purposes. The sessionInfo.txt file describe the R session working parameters and modules loaded. Frequently Asked Questions \u00b6 None yet! If you have any questions not covered here, feel free to reach out on our contact form . Similar Topics \u00b6 Running our Workflows Working with our Data Overview Upload/Download Data (local)","title":"WARDEN Differential Expression Analysis"},{"location":"guides/genomics-platform/analyzing-data/warden/#overview","text":"The WARDEN ( W**orkflow for the **A**nalysis of **R**NA-Seq **D**ifferential **E**xpressio**N ) software uses RNA-Seq sequence files to perform alignment, coverage analysis, gene counts and differential expression analysis.","title":"Overview"},{"location":"guides/genomics-platform/analyzing-data/warden/#inputs","text":"The WARDEN workflow requires two types of input files and that two parameters be set manually. All other parameters are preset with reasonable defaults. Name Type Description Example FastQ files ( required ) Input file(s) Gzipped FastQ files generated by experiment Sample1.fastq.gz, Sample2.fastq.gz Sample sheet ( required ) Input file Sample sheet generated and uploaded by the user *.txt","title":"Inputs"},{"location":"guides/genomics-platform/analyzing-data/warden/#input-file-configuration","text":"You'll need to create a sample sheet which describes the relationship between case and control samples, phenotype/condition information, and the comparisons you would like to perform. The sample sheet is a tab-delimited text document that can be created in Microsoft Excel (recommended) or a text editor. Note You will need to upload your sample sheet in a similar manner as your FastQ files, so you can follow the same uploading instructions to achieve this.","title":"Input file configuration"},{"location":"guides/genomics-platform/analyzing-data/warden/#prepare-using-microsoft-excel","text":"Tip Download the file_download sample excel spreadsheet as a starting point! The final product for the excel spreadsheet will look like the screenshot below. If you create the sample sheet from scratch, please ensure the the columns are exactly in this order. Sample rows Each row in the spreadsheet (except for the last row, which we will talk about in the next section) corresponds to a sample with one or more FastQ files. You should fill in these rows based on your data and the guidelines below: Guidelines The sample name should be unique and should only contain letters, numbers and underscores. The condition/phenotype column associates similar samples together. The values should contain only letters, numbers and underscores. ReadFile1 should contain forward reads (e.g. *.R1.fastq.gz or *_1.fastq.gz ). ReadFile2 will contain reads in reverse orientation to ReadFile2 (e.g. *.R2.fastq.gz or *_2.fastq.gz ). For single end reads a single dash ('-') should be entered in the ReadFile2 column. Comparison row The last line in the sample sheet is called the \"comparison row\". This line specifies the comparisons to be done between conditions/phenotypes. All pairwise combinations of the values in the \"Phenotype\" column can be analyzed. To specify the comparisons, on a separate line, include #comparisons= followed be a comma delimited list of two conditions separated by a dash. Example The following lines are all valid examples. #comparisons=KO-WT #comparisons=Condition1-Control,Condition2-Control #comparisons=Phenotype2-Phenotype1,Phenotype3-Phenotype2,Phenotype3-Phenotype1 Note If a comparison has at least 3 samples for each condition/phenotype, VOOM/LIMMA will be run. A simple differential comparison will be run on all samples. Finalizing the sample sheet To finalize the sample sheet, save the Microsoft Excel file with whatever name you like. Save the file as an Excel Workbook with the .xlsx extension.","title":"Prepare using Microsoft Excel"},{"location":"guides/genomics-platform/analyzing-data/warden/#prepare-using-a-text-editor","text":"Tip Download the file_download sample text file as a starting point! Creating a sample sheet with a text editor is an option for advanced users. The process of creating a sample sheet with a text editor is the same as creating one with Microsoft Excel, with the small difference that you must manually create your columns using the tab character. Save the file with a .txt extension.","title":"Prepare using a text editor"},{"location":"guides/genomics-platform/analyzing-data/warden/#outputs","text":"Name Description FastQC Report Quality control analysis by FastQC. Aligned BAM Aligned BAM files from STAR mapping. Splice junctions Splice junction information from STAR mapping. Coverage files bigWig ( .bw ) and BED ( .bed ) files detailing coverage. Gene counts Gene counts generated by HT-Seq count. VOOM/LIMMA results Pairwise comparisons of expression data. Requires at least 3 samples vs 3 samples. Simple DE analysis No statistical analysis, requires only a 1 samples vs 1 sample comparison. MA/Volcano plots Both of the above produce tabular outputs, MA plots and volcano plots.","title":"Outputs"},{"location":"guides/genomics-platform/analyzing-data/warden/#workflow-steps","text":"FastQ files generated by RNA-Seq are mapped to a reference genome using the STAR. HT-Seq count is used to assign mapped reads to genes. Differential expression analysis is performed using VOOM normalization of counts and LIMMA analysis. Coverage plots of mapped reads are generated as interactive visualizations.","title":"Workflow Steps"},{"location":"guides/genomics-platform/analyzing-data/warden/#creating-a-workspace","text":"Before you can run one of our workflows, you must first create a workspace in DNAnexus for the run. Refer to the general workflow guide to learn how to create a DNAnexus workspace for each workflow run. You can navigate to the WARDEN Differential Expression Analysis workflow page here .","title":"Creating a workspace"},{"location":"guides/genomics-platform/analyzing-data/warden/#uploading-input-files","text":"The WARDEN Differential Expression analysis pipeline takes Gzipped FastQ files generated by an RNA-Seq experiment as input . Refer to the general workflow guide to learn how to upload input files to the workspace you just created.","title":"Uploading Input Files"},{"location":"guides/genomics-platform/analyzing-data/warden/#running-the-workflow","text":"Refer to the general workflow guide to learn how to launch the workflow, hook up input files, adjust parameters, start a run, and monitor run progress. Note The WARDEN tool operation is slightly different than the other pipelines because it accepts a variable number of samples. First , you will run a \"bootstrapping\" step that creates a custom executable for your analysis. Second , you will need to manually execute the generated workflow from the first step. This allows us to take advantage of many nice features, like check-pointing and cost reduction. Don't worry, we'll show you how to do this step by step below.","title":"Running the Workflow"},{"location":"guides/genomics-platform/analyzing-data/warden/#hooking-up-inputs","text":"You'll need to hook up the FastQ files and sample sheet you uploaded in the upload data section . Click the FASTQ_FILES input field and select all FastQ files. Next, click the sampleList input field and select the corresponding samplesheet.","title":"Hooking up Inputs"},{"location":"guides/genomics-platform/analyzing-data/warden/#selecting-parameters","text":"We now need to configure the parameters for the pipeline, such as reference genome and sequencing method. You can access all of the available parameters by clicking on the WARDEN WORKFLOW GENERATOR substep. For the general workflow instructions refer here Parameter setup steps In the Output Folder field, select a folder to output to. You can structure your experiments however you like (e.g. /My_Outputs ) In the analysisName field, enter a prefix for all of the output files. This can be any value you want to use to remember this run. Be sure to use underscores instead of spaces here! Select the sequenceStandedness from the drop down menu. This information can be determined from the sequencing or source of the data. If you don't know what to put here, select \"no\". Select the Genome pulldown menu. Choose the appropriate box. The LIMMA parameters can be left alone for most analyses. If you are an advanced LIMMA user, you can change the various settings exposed below the required parameters. When all parameters have been set, press the save button.","title":"Selecting Parameters"},{"location":"guides/genomics-platform/analyzing-data/warden/#starting-the-workflow","text":"Once your input files are hooked up and your parameters are set, you should be able to start the workflow by clicking the \"Run as Analysis...\" button in the top right hand corner of the workflow dialog. For the general workflow instructions refer here . The tool will begin running and will automatically take you to the Monitor page, where you should see that your workflow is \"In Progress\". When the custom workflow has finished generating, the word 'Done' will appear in green in the status column. This indicates that the bootstrapping step has completed successfully.","title":"Starting the workflow"},{"location":"guides/genomics-platform/analyzing-data/warden/#custom-workflow-process","text":"Wait for the workflow generator to finish. Click on the WARDEN name in the name column. You will now be on a page specific to the running of the workflow. On the left side, you will see the inputs you selected for the workflow generator. On the right side are the output files (including the generated workflow). Select the generated workflow as shown in the picture below. You will now be within the output folder you specified earlier. Select the file that begins with 'WARDEN WORKFLOW:' A workflow generated for your data will be presented to you. Select 'Run as analysis' in the upper right. The workflow will initiate, and you will be brought to the 'Monitor' page. (Note to get back to this page, you can select 'Monitor' on one of the menu bars near the top ) Expand the the workflow progress be selecting the '+' sign next to 'In Progress' As parts of the pipeline are run, you will see different tasks in different colors. Green means done, blue is running, orange is waiting, and red means error. When done the status will be shown as 'Done'. Select the Workflow name under Status. You will be brought to a page that show more information about the workflow analysis. Click on the output folder to go to the output. The output folders will now be shown. For a description of the output, please refer to Interpreting Results .","title":"Custom Workflow Process"},{"location":"guides/genomics-platform/analyzing-data/warden/#analysis-of-results","text":"Each tool in St. Jude Cloud produces a visualization that makes understanding results more accessible than working with excel spreadsheet or tab delimited files. This is the primary way we recommend you work with your results. Refer to the general workflow guide to learn how to access these visualizations. We also include the raw output files for you to dig into if the visualization is not sufficient to answer your research question. Refer to the general workflow guide to learn how to access raw results files.","title":"Analysis of Results"},{"location":"guides/genomics-platform/analyzing-data/warden/#interpreting-primary-results","text":"","title":"Interpreting Primary Results"},{"location":"guides/genomics-platform/analyzing-data/warden/#alignment-statistics","text":"Several files should be examined initially to determine the quality of the results. alignmentStatistics.txt shows alignment statistics for all samples. This file is a plain text tab-delimited file that can be opened in Excel or a text editor such as Notepad++. This file contains information on the total reads per sample, the percentage of duplicate reads and the percentage of mapped reads. An example of this file is below. (Within the DNAnexus output directory structure, these files will be in the COMBINED_FLAGSTAT directory.)","title":"Alignment statistics"},{"location":"guides/genomics-platform/analyzing-data/warden/#multidimensional-scaling-mds-plot","text":"The second set of files to look at are the Multidimensional scaling (MDS) plots using the plotMDS function within LIMMA. Similar to PCA, these graphs will show how similar samples are to each other. There are different sets of MDS plots. For comparisons where there are 3 or more samples per condition, an MDS plot using Voom (Limma) normalized values are generated. An example can be seen below. These files will be labeled mdsPlot.png . For all comparisons, regardless of sample size, and MDS plot will also be generated with Counts per million (CPM) normalized gene counts. These files will be labeled mdsPlot.normCPM.png . (Within the DNAnexus output directory structure, these files will be in the LIMMA directory.) MDS plot from just CPM normalized data.","title":"Multidimensional scaling (MDS) Plot"},{"location":"guides/genomics-platform/analyzing-data/warden/#proteinpaint-visualizations","text":"Several files on DNAnexus allow the data to be viewed in the Protein Paint viewer. (Note: We plan to have links downloaded in the future to allow the viewing of these files off of DNAnexus.) LIMMA differential expression viewer Within LIMMA/VIEWERS directory (note if no comparisons meet the 3 sample condition, the LIMMA folder will not exist), there will be a viewer file for each valid comparison ( * results. .txt.viewer**). Simply select the file and press 'Launch viewer' in the lower right. A viewer will pop up showing both the MA Plot and Volcano plot. By moving the mouse over a circle, the circle will highlight and the corresponding gene on the other graph will also highlight. Additional information about the gene and its expression values will also be shown. One can also type in multiple gene symbols in the provided text box. By pressing 'Show gene labels' all these genes will show up on the plots. Simple differential expression viewer There will also be a viewer for the simple differential expression analysis in SIMPLE_DIFEX/VIEWERS. The P-value for the results have all been set to 1, so the volcano plot will not be relevant. bigWig viewer In the BIGWIG_VIEWER directory there will be a bigwigViewer file. Select this file and then 'Launch viewer'. A graph of coverage for the genome should be visible.","title":"ProteinPaint Visualizations"},{"location":"guides/genomics-platform/analyzing-data/warden/#interpreting-secondary-results","text":"","title":"Interpreting Secondary Results"},{"location":"guides/genomics-platform/analyzing-data/warden/#interactive-mavolcano-plots","text":"In addition to viewing the MA and volcano plots through the visualization tool","title":"Interactive MA/Volcano Plots"},{"location":"guides/genomics-platform/analyzing-data/warden/#differential-expression-results","text":"Other useful differential expression results will be downloaded by the desktop app. This included tabular output from the differential expression analysis. For each comparison with three or more samples per condition, results.*.txt will be produced.","title":"Differential expression results"},{"location":"guides/genomics-platform/analyzing-data/warden/#gseainputtxt-and-gseatstattxt","text":"Input files that can be used for GSEA analysis. The tStat file is preferred for a more accurate analysis, but will not give a heatmap diagram. - (Within the DNAnexus output directory structure, these files will be in the LIMMA directory.) For plain text results from the simple differential expression analysis, the files will be named simpleDE.*.txt . (Within the DNAnexus output directory structure, these files will be in the SIMPLE_DIFEX directory.) Prelabelled MA and volcano plots are provided for the analysis. These files are labeled maPlot.*.png and volcanoPlot.*.png where * is the comparison (e.g. ko_vs_wt) The MA plot shows the average expression of the gene on the X-axis, and Log2 fold change between condition/phenotype is on the Y-axis (if the name is for example maPlot.condition2-condition1.png then the fold change would represent condition1 minus condition2). Each gene is represented by a circle. The top 20 genes (by p-value) are identified on the plot. The genes are color coded by the chosen multiple testing correction method (False Discovery Rate (FDR) by default. An example MA plot can be seen below. (Within the DNAnexus output directory structure, these files will be in the LIMMA directory.) The volcano plot shows the Log2Fold change between the conditions on the X-axis, and the -Log10 of the multiple testing corrected P-value on the Y-axis. An MA plot is generated for all comparisons regardless of number of samples. This is the simpleDEPlot.*.png no statistics are shown and genes are not labeled. (Within the DNAnexus output directory structure, these files will be in the SIMPLE_DIFEX directory.)","title":"GSEA.input.txt and GSEA.tStat.txt"},{"location":"guides/genomics-platform/analyzing-data/warden/#differential-analysis-input","text":"Inputs and commands are provided for rerunning differential expression analysis on ones own computer. The R commands used for the analysis are found in voomLimma.R . An experienced R user can rerun the analysis with any desired changes. This analysis requires the input countFile.txt which contains counts per genes, the Rparameters.txt file containing input parameters, and a processed sample list file sampleList.txt (Within the DNAnexus output directory structure, these files will be in the LIMMA directory.) The input for the simple differential analysis expression will be Rparameters_simple.txt , simpleDE.R , countFile.txt and sampleList.txt . countFile.txt and sampleList.txt are the same files used by the LIMMA analysis. (Within the DNAnexus output directory structure, these files will be in the SIMPLE_DIFEX directory.)","title":"Differential analysis input"},{"location":"guides/genomics-platform/analyzing-data/warden/#coverage-results","text":"bigWig files will be generated for use in genome browsers (such as IGV http://software.broadinstitute.org/software/igv/ ). For each sample, multiple bigWig files will be found. For all types of sequencing strandedness, there will be bigWig files labeled, *.sortedCoverageFile.bed.bw where ' ' is the sample name. For stranded data there will also be*.sortedPosCoverageFile.bed.bw * and *.sortedNegCoverageFile.bed.bw which contains coverage information for the positive and negative strand of the genome. (Within the DNAnexus output directory structure, these files will be in the BIGWIG directory.)","title":"Coverage results"},{"location":"guides/genomics-platform/analyzing-data/warden/#quality-control-results-fastqc","text":"Within the FastQC directory, for each sample and read direction there will be an html file and a zip file ( *.FastQc.html *.FastQc.zip where '*' is the base FastQ name), containing results from FastQTC. For the average user the html file is sufficient. This file can give some basic statistics on the quality of the data. (Within the DNAnexus output directory structure, these files will be in the FastQC directory.)","title":"Quality Control Results (FastQC)"},{"location":"guides/genomics-platform/analyzing-data/warden/#bam-alignment-files","text":"There are two BAM files generated per sample that contain mapping information for all reads. The first is labeled *.Aligned.sortedByCoord.dup.bam where ' ' is the sample name. The BAM file is sorted by coordinates and has duplicates marked. The second file is*.Aligned.toTranscriptome.out.bam * and contains reads mapped to transcripts. (Within the DNAnexus output directory structure, these files will be in the ALIGN directory.)","title":"BAM alignment files"},{"location":"guides/genomics-platform/analyzing-data/warden/#chimeric-reads-and-junction-files","text":"Additional files created by STAR are provided. More information on these files can be found here . *.SJ.out.tab contain splice junction information. Fusion detection files are labeled *.Chimeric.out.bam and *.Chimeric.out.junction . (Within the DNAnexus output directory structure, these files will be in the ALIGN directory.)","title":"Chimeric reads and junction files"},{"location":"guides/genomics-platform/analyzing-data/warden/#fpkm-and-count-files-per-sample","text":"Per sample files containing FPKM and raw count values for each gene can be found in *.fpkm.txt and *.htseq_counts.txt where '*' is the sample name. Within the DNAnexus output directory structure, these files will be in the HTSEQ directory.","title":"FPKM and count files (per sample)"},{"location":"guides/genomics-platform/analyzing-data/warden/#methods-files","text":"A more human readable explanation is found in methods.docx . Detailed documentation can be found in methods.txt (Within the DNAnexus output directory structure, these files will be in the METHODS directory.)","title":"Methods Files"},{"location":"guides/genomics-platform/analyzing-data/warden/#auxiliary-files","text":"This section describes the files that exist within the DNAnexus output folder. Most of these files will not be of interest to the average user. However, interactive viewers are describe in LIMMA differential expression viewer and Simple differential expression viewer . The output will be divided into multiple folders. The results being the most useful will be the differential expression analysis results in the LIMMA and SIMPLE_DIFEX folders. Bigwig files for viewing read coverage will be in the BIGWIG folder. Other folder contain different types of data and are explained in further detail below. The following description of files is sorted by their output directory.","title":"Auxiliary Files"},{"location":"guides/genomics-platform/analyzing-data/warden/#align","text":"This directory contains the BAM files described in BAM alignment files and the chimeric and junction files are described in Chimeric reads and junction files . In addition there are 2 log files. *Log.final.out has relevant statistics for the alignment. The *.Log.out file just contains a log of the analysis run, including input parameters. Per sample FLAGSTAT results are found in *.flagStatOut.txt . Finally the ALIGN directory has multiple .starAlign.methods.txt files. These files can be ignored as they are summarized in the finalmethods.docx * and methods.txt files described in Methods Files .","title":"ALIGN"},{"location":"guides/genomics-platform/analyzing-data/warden/#bigwig","text":"All of the files here are described in section Coverage results . The bgToBw.methods.txt files can be ignored as they are summarized in the files described in Methods Files .","title":"BIGWIG"},{"location":"guides/genomics-platform/analyzing-data/warden/#bigwig_viewer","text":"See bigWig viewer","title":"BIGWIG_VIEWER"},{"location":"guides/genomics-platform/analyzing-data/warden/#combined_flagstat","text":"This directory contains the alignmentStatistics.txt file, which contains the combined alignment statistics from all samples. It is generated from the flagstat files describe in the ALIGN directory.","title":"COMBINED_FLAGSTAT"},{"location":"guides/genomics-platform/analyzing-data/warden/#combined_htseq","text":"Used for input in differential expression analysis. The combineCountFile.txt is the same as countFile.txt described in Differential analysis input","title":"COMBINED_HTSEQ"},{"location":"guides/genomics-platform/analyzing-data/warden/#coverage","text":"BED graph files used to generate bigWig files are here.","title":"COVERAGE"},{"location":"guides/genomics-platform/analyzing-data/warden/#fastqc","text":"See Quality Control Results (FastQC)","title":"FastQC"},{"location":"guides/genomics-platform/analyzing-data/warden/#htseq","text":"Per-sample HTSEQ-count results ( *.htseq_counts.txt ) and FPKM results ( *.fpkm.txt ). Temporary methods files are found as *.htseq-count.methods.txt","title":"HTSEQ"},{"location":"guides/genomics-platform/analyzing-data/warden/#limma","text":"mdsPlot.png , maPlot.png , volcanoPlot.png are described in Initial analysis of results results.txt , GSEA.input.txt and GSEA.tStat.txt are describe in Differential expression results voomLimma.R , countFile.txt , Rparameters.txt , and sampleList.txt are described in Differential analysis input See LIMMA differential expression viewer for a description of the VIEWERS directory. Other files in the LIMMA directory include contrastFiles.txt contrastsFile.txt, and limmaSampleList.txt which are used internally. limmaMethods.txt is an intermediate file describing methods. Out.tar.gz is used for testing purposes. The sessionInfo.txt file describe the R session working parameters and modules loaded. meanVariance.png is a plot for assessing quality of count data ( https://genomebiology.biomedcentral.com/articles/10.1186/gb-2014-15-2-r29 ) METHODS The files here are described in Methods Files . SAMPLELIST These files are used internally by the pipeline. SIMPLE_DIFEX mdsPlot.normCPM.png and simpleDEPlot.png are described in Initial analysis of results simpleDE.txt are describe in Differential expression results simpleDE.R , countFile.txt , Rparameters_simple.txt , and sampleList.txt are described in Differential analysis input See Simple differential expression viewer for a description of the VIEWERS directory. Other files in the SIMPLE_DIFEX directory include contrastFiles.txt contrastsFile.txt, and limmaSampleList.txt which are used internally. simpleDifEx.methods.txt is an intermediate file describing methods. Out.tar.gz is used for testing purposes. The sessionInfo.txt file describe the R session working parameters and modules loaded.","title":"LIMMA"},{"location":"guides/genomics-platform/analyzing-data/warden/#frequently-asked-questions","text":"None yet! If you have any questions not covered here, feel free to reach out on our contact form .","title":"Frequently Asked Questions"},{"location":"guides/genomics-platform/analyzing-data/warden/#similar-topics","text":"Running our Workflows Working with our Data Overview Upload/Download Data (local)","title":"Similar Topics"},{"location":"guides/genomics-platform/analyzing-data/xeno-cp/","text":"XenoCP Authors John Doe Publication N/A (not published) Technical Support Contact Us Overview \u00b6 abstract-type description of tool Inputs \u00b6 table of inputs; example below Name Type Description Example FastQ files ( required if using FastQ inputs) Input file Gzipped FastQ files generated by experiment. Sample_R1.fastq.gz and Sample_R2.fastq.gz BAM files ( required if using BAM inputs) Input file BAM files aligned against HG19/Hg38 (WGS, WES or RNA-Seq). Sample.bam BAM indices ( required if using BAM inputs) Input file Corresponding BAM index of the BAM files above. Sample.bam.bai Mutation file ( required ) Input file File describing the mutations present in the sample (special format, see below). *.txt (tab-delimited) SNV or fusion Parameter Specify the mutation file contains SNV or gene fusion. SNV Peptide size Parameter Size of the peptide. 9 Affinity threshold Parameter Affinity cutoff for epitope prediction report. 500 Input file configuration \u00b6 if needed Outputs \u00b6 table of outputs; example below Name Description Epitope affinity prediction (html) Epitope affinity. The peptide with affinity < cutoff will be highlighted. Epitope affinity prediction (xlsx) Excel tables for the information of all epitopes Affinity (raw output) Epitope affinity Peptide sequence (raw output) Peptide sequences in Fasta format Workflow Steps \u00b6 description of algorithm(s) or workflow steps Additional Info \u00b6 description of any additional information that the user might need to know/do before running the workflow Creating a workspace \u00b6 Before you can run one of our workflows, you must first create a workspace in DNAnexus for the run. Refer to the general workflow guide to learn how to create a DNAnexus workspace for each workflow run. You can navigate to the workflow name workflow page here . Uploading Input files \u00b6 note any additional information the user should know about what input files are required Refer to the general workflow guide to learn how to upload input files to the workspace you just created. Running the Workflow \u00b6 Refer to the general workflow guide to learn how to launch the workflow, hook up input files, adjust parameters, start a run, and monitor run progress. !!! caution any cautionary notes specific to running this workflow Analysis of Results \u00b6 Each tool in St. Jude Cloud produces a visualization that makes understanding results more accessible than working with excel spreadsheet or tab delimited files. This is the primary way we recommend you work with your results. Refer to the general workflow guide to learn how to access these visualizations. We also include the raw output files for you to dig into if the visualization is not sufficient to answer your research question. Refer to the general workflow guide to learn how to access raw results files. Interpreting results \u00b6 detailed explanations with helpful screenshots or gifs Frequently asked questions \u00b6 faqs If you have any questions not covered here, feel free to reach out on our contact form . Similar Topics \u00b6 Running our Workflows Working with our Data Overview Upload/Download Data (local)","title":"XenoCP"},{"location":"guides/genomics-platform/analyzing-data/xeno-cp/#overview","text":"abstract-type description of tool","title":"Overview"},{"location":"guides/genomics-platform/analyzing-data/xeno-cp/#inputs","text":"table of inputs; example below Name Type Description Example FastQ files ( required if using FastQ inputs) Input file Gzipped FastQ files generated by experiment. Sample_R1.fastq.gz and Sample_R2.fastq.gz BAM files ( required if using BAM inputs) Input file BAM files aligned against HG19/Hg38 (WGS, WES or RNA-Seq). Sample.bam BAM indices ( required if using BAM inputs) Input file Corresponding BAM index of the BAM files above. Sample.bam.bai Mutation file ( required ) Input file File describing the mutations present in the sample (special format, see below). *.txt (tab-delimited) SNV or fusion Parameter Specify the mutation file contains SNV or gene fusion. SNV Peptide size Parameter Size of the peptide. 9 Affinity threshold Parameter Affinity cutoff for epitope prediction report. 500","title":"Inputs"},{"location":"guides/genomics-platform/analyzing-data/xeno-cp/#input-file-configuration","text":"if needed","title":"Input file configuration"},{"location":"guides/genomics-platform/analyzing-data/xeno-cp/#outputs","text":"table of outputs; example below Name Description Epitope affinity prediction (html) Epitope affinity. The peptide with affinity < cutoff will be highlighted. Epitope affinity prediction (xlsx) Excel tables for the information of all epitopes Affinity (raw output) Epitope affinity Peptide sequence (raw output) Peptide sequences in Fasta format","title":"Outputs"},{"location":"guides/genomics-platform/analyzing-data/xeno-cp/#workflow-steps","text":"description of algorithm(s) or workflow steps","title":"Workflow Steps"},{"location":"guides/genomics-platform/analyzing-data/xeno-cp/#additional-info","text":"description of any additional information that the user might need to know/do before running the workflow","title":"Additional Info"},{"location":"guides/genomics-platform/analyzing-data/xeno-cp/#creating-a-workspace","text":"Before you can run one of our workflows, you must first create a workspace in DNAnexus for the run. Refer to the general workflow guide to learn how to create a DNAnexus workspace for each workflow run. You can navigate to the workflow name workflow page here .","title":"Creating a workspace"},{"location":"guides/genomics-platform/analyzing-data/xeno-cp/#uploading-input-files","text":"note any additional information the user should know about what input files are required Refer to the general workflow guide to learn how to upload input files to the workspace you just created.","title":"Uploading Input files"},{"location":"guides/genomics-platform/analyzing-data/xeno-cp/#running-the-workflow","text":"Refer to the general workflow guide to learn how to launch the workflow, hook up input files, adjust parameters, start a run, and monitor run progress. !!! caution any cautionary notes specific to running this workflow","title":"Running the Workflow"},{"location":"guides/genomics-platform/analyzing-data/xeno-cp/#analysis-of-results","text":"Each tool in St. Jude Cloud produces a visualization that makes understanding results more accessible than working with excel spreadsheet or tab delimited files. This is the primary way we recommend you work with your results. Refer to the general workflow guide to learn how to access these visualizations. We also include the raw output files for you to dig into if the visualization is not sufficient to answer your research question. Refer to the general workflow guide to learn how to access raw results files.","title":"Analysis of Results"},{"location":"guides/genomics-platform/analyzing-data/xeno-cp/#interpreting-results","text":"detailed explanations with helpful screenshots or gifs","title":"Interpreting results"},{"location":"guides/genomics-platform/analyzing-data/xeno-cp/#frequently-asked-questions","text":"faqs If you have any questions not covered here, feel free to reach out on our contact form .","title":"Frequently asked questions"},{"location":"guides/genomics-platform/analyzing-data/xeno-cp/#similar-topics","text":"Running our Workflows Working with our Data Overview Upload/Download Data (local)","title":"Similar Topics"},{"location":"guides/genomics-platform/managing-data/how-to-fill-out-Extension/","text":"Filling Out The Extension Addendum The St. Jude Cloud Data Access Agreement (DAA) is only valid for one year after the date it was approved. When your DAA is about to expire, you will get an automated email from notifications@stjude.cloud with the name of the DAA that is expiring and a link to the St. Jude Cloud Extension Addendum. In order to extend your DAA, you must fill out an Extension Addendum. The Extension Addendum will extend the previous agreement for an additional year. Please note that if you do not fill out an Extension Addendum, you will be expected to delete all copies of the data subject to the expiring agreement. Follow the steps below to ensure that you have accurately filled out all sections of the Extension Addendum. Page 1 In the top section, enter the current date on which that the agreement is being filled out, your current institution, and the date on which you signed the expiring DAA or extension. In the bottom section, enter a date that is one year after the date on which you signed the expiring DAA or extension. This can be found on the page linked from the email notifying you of agreement expiration. Page 2 Check exactly the datasets that you were granted access to by the terms of the original DAA. The datasets checked on the original DAA and any extensions must match. If you would like to apply for access to additional datasets, please make a new data request for the additional dataset(s). The Principal Investigator (PI) or faculty level supervisor on the project must sign and date the extension. The PI who signed the original DAA must match the PI signing any extensions. All additional applicants (excluding the administrative authority and information security officer) that were included in the original DAA must sign and date the extension. Page 3 Enter the name of your current institution. This must match the institution entered on page 1. The Administrative Authority must sign and date the extension. This is usually the same administrative authority as the one on the original DAA. The Information Security Officer must sign and date the extension. The bottom section of page 3 is for St. Jude to sign and date. Do not fill out this section. Page 4 If your research question(s) or contemplated use has changed since the original DAA, use this space to provide your updated project description. You may also use this space to explain why you need to extend your agreement. Finally, if the Administrative Authority or Information Security Officer has changed from the original DAA to this extension, please use this space to explain why. Once you have finished filling out the Extension Addendum, you may upload the completed form on the extension addendum page linked in the notification of expiration email from notifications@stjude.cloud . Similar Topics \u00b6 About our Decision Process & Terminology Filling Out a Data Access Agreement","title":"Renewing your Data Access"},{"location":"guides/genomics-platform/managing-data/how-to-fill-out-Extension/#similar-topics","text":"About our Decision Process & Terminology Filling Out a Data Access Agreement","title":"Similar Topics"},{"location":"guides/genomics-platform/managing-data/upload-cluster/","text":"Uploading Data from St. Jude HPC to DNAnexus This guide describes how to upload data from St. Jude's research computing cluster to DNAnexus. It covers logging in to the HPC, creating an interactive session, loading the DNAnexus upload agent, and uploading files to DNAnexus. The research cluster is restricted to St. Jude employees, as it is only accessible on St. Jude's intranet. If you are reading this page and work at another institution, please work with your HPC staff on translating the steps to your architecture. Logging in to the HPC \u00b6 The SSH (Secure Shell) protocol is used to log in to hpc , the hostname of the entry point into St. Jude's research cluster. SSH provides a secure method to log in to a remote computer. Regardless of platform, logging in requires a St. Jude username and will prompt you for your password. They are the same username and password used to log in to all St. Jude services. Windows \u00b6 Windows does not have an SSH client preinstalled. As of Windows 10 1809, OpenSSH is included as a feature that can be installed. Open the Settings app (search \"Settings\" in the Start menu). Under Apps > Apps & features > Apps & features, click on Optional features . Under the OpenSSH Client entry, click Install . Open PowerShell and run ssh <username>@hpc Alternatively (or on older versions of Windows), install and use the terminal emulator PuTTY . macOS \u00b6 macOS includes OpenSSH by default. Open Terminal and run $ ssh <username>@hpc Linux \u00b6 Most Linux distributions have OpenSSH installed by default. Open a terminal and run $ ssh <username>@hpc Creating an interactive session \u00b6 When logging in to hpc , you are placed on a head node , a controlled gateway configured to allow external access to the cluster. This node is not meant for computation, which should be done on a cluster node instead. To move to a cluster node, start an interactive session. The cluster's workload is managed by IBM Spectrum LSF , and even though LSF commands can be used to create an interactive session, the High-Performance Computer Facility (HPCF) provides a convenience script named hpcf_interactive for a simpler invocation. $ hpcf_interactive This moves you from the head node to a node in the research cluster, and tasks that require CPU time, memory, high bandwidth network access, etc., can be executed. When an interactive session starts, the prompt will look similar to the following: Job <99871669> is submitted to queue <interactive>. <<Waiting for dispatch ...>> <<Starting on nodecn013>> [username@nodecn013 ~]$ DNAnexus Upload Agent \u00b6 DNAnexus provides multiple methods to upload files to their platform. In this section, Upload Agent (UA) is used. It is simple to use and supports resuming interrupted transfers. Setup \u00b6 You can load the DNAnexus upload agent command line tool, ua , by loading the dx-ua module. module load dx-ua/1.5.30 Next, you'll need to configure the ua command line tool with access to your St. Jude Cloud account. Rather than exposing your username and password, best practice is to generate an authentication token that lives for a short period of time instead. You can do so by following this guide on how to generate a DNAnexus authentication token . Replace <auth-token> with your own token in the example below. $ export DX_SECURITY_CONTEXT = '{\"auth_token_type\": \"bearer\", \"auth_token\": \"<auth-token>\"}' This must be set once for ever new interactive session started. Uploading files \u00b6 Basic usage \u00b6 With DNAnexus Upload Agent loaded, files can be uploaded by running ua . To get acquainted with the command, you can view the help message for ua . ua --help The simplest usage of ua is providing the DNAnexus project to upload to and a source file. $ ua --do-not-compress --project <project-name-or-id> <src> For example, with a DNAnexus project named flagstat and a file named sample.1.bam , the command would be $ ua --do-not-compress --project flagstat sample.1.bam Why is --do-not-compress always set? Upload Agent uses an unfortunate default where uncompressed files are automatically gzipped. For example, uploading the text file samplesheet.txt results in the file samplesheet.txt.gz on DNAnexus. This is confusing and unexpected, and file management is more straightforward with the option disabled. Batched jobs \u00b6 When working in an interactive session, if the session is closed (e.g., a network disconnection or you quit the terminal), all running commands are killed. To avoid this from happening, a job is submitted in its place, which continues to run even after the session is closed. To submit a job, use the LSF command bsub , where -P is an arbitrary project name for the job submission. When uploading a large batch of files, HPCF requests the /stjudecloud/uploads job group be used to rate limit upload jobs. This can be done using the -g option when submitting a job. $ bsub \\ -P dx-upload \\ -g /stjudecloud/uploads \\ -R \"rusage[mem=2882]\" \\ ua \\ --do-not-compress \\ --project <project-name-or-id> \\ <src> Where does the 2882 MiB resource requirement come from? There is a note in the source code of Upload Agent that gives an estimate of how much memory is used for a transfer: <read-threads> + 2 * (<compress-threads> + <upload-threads>) * <chunk-size> Thus, using the default values (see ua --help ) and adding 20% as a buffer: (2 + 2 * (8 + 8) * 75 MiB) * 1.2 = ~2882 MiB Further examples \u00b6 The following examples are common usages of Upload Agent. If you use any of these options, please be sure submit them to the HPC job group as shown in batched jobs to ensure the number of uploads is throttled. Upload multiple files \u00b6 ua takes multiple source arguments. $ ua --do-not-compress --project <project-name-or-id> <src...> For example, for two files sample.1.bam and sample.1.bam.bai , the command is $ ua --do-not-compress --project flagstat sample.1.bam sample.1.bam.bai Upload a folder in DNAnexus \u00b6 By default, all files uploaded via ua get placed at the root of the project, i.e., / . To upload to a particular directory, use the --folder option. $ ua --do-not-compress --project <project-name-or-id> --folder /data sample.1.bam The resulting uploaded file will be located at /data/sample.1.bam . The directory does not have a previously exist in the DNAnexus project and will be created automatically, along with its parents (similar to mkdir -p ). Upload a local directory \u00b6 When uploading a directory, ua will only use the files at the top level (similar to find data -type f -maxdepth 1 ). For example, take the following directory structure and ua command. $ tree data data \u251c\u2500\u2500 extra \u2502 \u251c\u2500\u2500 sample.2.bam \u2502 \u2514\u2500\u2500 sample.2.bam.bai \u251c\u2500\u2500 sample.1.bam \u2514\u2500\u2500 sample.1.bam.bai 1 directory, 4 files $ ua --do-not-compress --project <project-name-or-id> data The resulting files will be /sample.1.bam and /sample.1.bam.bai . Use the --folder option and name it the same as the local source directory to include the directory on DNAnexus. $ ua --do-not-compress --project <project-name-or-id> --folder /data data The resulting files will be /data/sample.1.bam and /data/sample1.bam.bai . To include the subdirectories, use the --recursive option. $ ua --do-not-compress --project <project-name-or-id> --folder /data --recursive data Thus, using both --folder and --recursive uploads an entire directory: /data/sample.1.bam , /data/sample.1.bam.bai , /data/extras/sample.2.bam , and /data/extras/sample.2.bam.bai .","title":"Upload Data (HPC)"},{"location":"guides/genomics-platform/managing-data/upload-cluster/#logging-in-to-the-hpc","text":"The SSH (Secure Shell) protocol is used to log in to hpc , the hostname of the entry point into St. Jude's research cluster. SSH provides a secure method to log in to a remote computer. Regardless of platform, logging in requires a St. Jude username and will prompt you for your password. They are the same username and password used to log in to all St. Jude services.","title":"Logging in to the HPC"},{"location":"guides/genomics-platform/managing-data/upload-cluster/#windows","text":"Windows does not have an SSH client preinstalled. As of Windows 10 1809, OpenSSH is included as a feature that can be installed. Open the Settings app (search \"Settings\" in the Start menu). Under Apps > Apps & features > Apps & features, click on Optional features . Under the OpenSSH Client entry, click Install . Open PowerShell and run ssh <username>@hpc Alternatively (or on older versions of Windows), install and use the terminal emulator PuTTY .","title":"Windows"},{"location":"guides/genomics-platform/managing-data/upload-cluster/#macos","text":"macOS includes OpenSSH by default. Open Terminal and run $ ssh <username>@hpc","title":"macOS"},{"location":"guides/genomics-platform/managing-data/upload-cluster/#linux","text":"Most Linux distributions have OpenSSH installed by default. Open a terminal and run $ ssh <username>@hpc","title":"Linux"},{"location":"guides/genomics-platform/managing-data/upload-cluster/#creating-an-interactive-session","text":"When logging in to hpc , you are placed on a head node , a controlled gateway configured to allow external access to the cluster. This node is not meant for computation, which should be done on a cluster node instead. To move to a cluster node, start an interactive session. The cluster's workload is managed by IBM Spectrum LSF , and even though LSF commands can be used to create an interactive session, the High-Performance Computer Facility (HPCF) provides a convenience script named hpcf_interactive for a simpler invocation. $ hpcf_interactive This moves you from the head node to a node in the research cluster, and tasks that require CPU time, memory, high bandwidth network access, etc., can be executed. When an interactive session starts, the prompt will look similar to the following: Job <99871669> is submitted to queue <interactive>. <<Waiting for dispatch ...>> <<Starting on nodecn013>> [username@nodecn013 ~]$","title":"Creating an interactive session"},{"location":"guides/genomics-platform/managing-data/upload-cluster/#dnanexus-upload-agent","text":"DNAnexus provides multiple methods to upload files to their platform. In this section, Upload Agent (UA) is used. It is simple to use and supports resuming interrupted transfers.","title":"DNAnexus Upload Agent"},{"location":"guides/genomics-platform/managing-data/upload-cluster/#setup","text":"You can load the DNAnexus upload agent command line tool, ua , by loading the dx-ua module. module load dx-ua/1.5.30 Next, you'll need to configure the ua command line tool with access to your St. Jude Cloud account. Rather than exposing your username and password, best practice is to generate an authentication token that lives for a short period of time instead. You can do so by following this guide on how to generate a DNAnexus authentication token . Replace <auth-token> with your own token in the example below. $ export DX_SECURITY_CONTEXT = '{\"auth_token_type\": \"bearer\", \"auth_token\": \"<auth-token>\"}' This must be set once for ever new interactive session started.","title":"Setup"},{"location":"guides/genomics-platform/managing-data/upload-cluster/#uploading-files","text":"","title":"Uploading files"},{"location":"guides/genomics-platform/managing-data/upload-cluster/#basic-usage","text":"With DNAnexus Upload Agent loaded, files can be uploaded by running ua . To get acquainted with the command, you can view the help message for ua . ua --help The simplest usage of ua is providing the DNAnexus project to upload to and a source file. $ ua --do-not-compress --project <project-name-or-id> <src> For example, with a DNAnexus project named flagstat and a file named sample.1.bam , the command would be $ ua --do-not-compress --project flagstat sample.1.bam Why is --do-not-compress always set? Upload Agent uses an unfortunate default where uncompressed files are automatically gzipped. For example, uploading the text file samplesheet.txt results in the file samplesheet.txt.gz on DNAnexus. This is confusing and unexpected, and file management is more straightforward with the option disabled.","title":"Basic usage"},{"location":"guides/genomics-platform/managing-data/upload-cluster/#batched-jobs","text":"When working in an interactive session, if the session is closed (e.g., a network disconnection or you quit the terminal), all running commands are killed. To avoid this from happening, a job is submitted in its place, which continues to run even after the session is closed. To submit a job, use the LSF command bsub , where -P is an arbitrary project name for the job submission. When uploading a large batch of files, HPCF requests the /stjudecloud/uploads job group be used to rate limit upload jobs. This can be done using the -g option when submitting a job. $ bsub \\ -P dx-upload \\ -g /stjudecloud/uploads \\ -R \"rusage[mem=2882]\" \\ ua \\ --do-not-compress \\ --project <project-name-or-id> \\ <src> Where does the 2882 MiB resource requirement come from? There is a note in the source code of Upload Agent that gives an estimate of how much memory is used for a transfer: <read-threads> + 2 * (<compress-threads> + <upload-threads>) * <chunk-size> Thus, using the default values (see ua --help ) and adding 20% as a buffer: (2 + 2 * (8 + 8) * 75 MiB) * 1.2 = ~2882 MiB","title":"Batched jobs"},{"location":"guides/genomics-platform/managing-data/upload-cluster/#further-examples","text":"The following examples are common usages of Upload Agent. If you use any of these options, please be sure submit them to the HPC job group as shown in batched jobs to ensure the number of uploads is throttled.","title":"Further examples"},{"location":"guides/genomics-platform/managing-data/upload-cluster/#upload-multiple-files","text":"ua takes multiple source arguments. $ ua --do-not-compress --project <project-name-or-id> <src...> For example, for two files sample.1.bam and sample.1.bam.bai , the command is $ ua --do-not-compress --project flagstat sample.1.bam sample.1.bam.bai","title":"Upload multiple files"},{"location":"guides/genomics-platform/managing-data/upload-cluster/#upload-a-folder-in-dnanexus","text":"By default, all files uploaded via ua get placed at the root of the project, i.e., / . To upload to a particular directory, use the --folder option. $ ua --do-not-compress --project <project-name-or-id> --folder /data sample.1.bam The resulting uploaded file will be located at /data/sample.1.bam . The directory does not have a previously exist in the DNAnexus project and will be created automatically, along with its parents (similar to mkdir -p ).","title":"Upload a folder in DNAnexus"},{"location":"guides/genomics-platform/managing-data/upload-cluster/#upload-a-local-directory","text":"When uploading a directory, ua will only use the files at the top level (similar to find data -type f -maxdepth 1 ). For example, take the following directory structure and ua command. $ tree data data \u251c\u2500\u2500 extra \u2502 \u251c\u2500\u2500 sample.2.bam \u2502 \u2514\u2500\u2500 sample.2.bam.bai \u251c\u2500\u2500 sample.1.bam \u2514\u2500\u2500 sample.1.bam.bai 1 directory, 4 files $ ua --do-not-compress --project <project-name-or-id> data The resulting files will be /sample.1.bam and /sample.1.bam.bai . Use the --folder option and name it the same as the local source directory to include the directory on DNAnexus. $ ua --do-not-compress --project <project-name-or-id> --folder /data data The resulting files will be /data/sample.1.bam and /data/sample1.bam.bai . To include the subdirectories, use the --recursive option. $ ua --do-not-compress --project <project-name-or-id> --folder /data --recursive data Thus, using both --folder and --recursive uploads an entire directory: /data/sample.1.bam , /data/sample.1.bam.bai , /data/extras/sample.2.bam , and /data/extras/sample.2.bam.bai .","title":"Upload a local directory"},{"location":"guides/genomics-platform/managing-data/upload-local/","text":"Uploading Data from your Local Computer Warning Uploading to DNAnexus from your laptop should not be done over the VPN \u2014 ensure you are disconnected before continuing with this guide! DNAnexus provides a command line utility, dx , to enable users to upload input data, download results, and run workflows in the cloud. Click here to learn about all of the commands included in dx . The dx command line tool is written in Python. It can be installed onto your computer using pip install dxpy . However, many computers ship with multiple versions of Python, and that can lead to many really strange errors (e.g. one version of Python trying to load libraries from a different version of Python). Thus, we highly recommend the use of conda environments to create an isolated Python environment and install dx there. Tip If you are interested in learning more about the features provided by conda, their getting started guide is quite good. This is not strictly necessary for continuing with this guide. Installing via conda \u00b6 To install conda and start creating isolated Python environments, you can visit the conda download documentation and complete the install instructions for your operating system. Be sure to select \"Python 3.X version\" when choosing which version to download. Once you complete installation, you should be able to use the conda command in your terminal. conda can be used to create multiple, independent Python environments. To leverage it to use dx , you'll need to do two things: a one-time creation of a Python 3 environment with dx installed. an environment activation step for every new terminal you open. Note that the environment we create will not be accessible without this explicit activation step. To create an isolated Python 3 environment with dxpy installed, use the following command (you can give your environment any name, here we name it dx-env ). # conda create -n [environment-name] python=3 dxpy -y conda create -n dx-env python = 3 dxpy -y Once you the environment is created, you can run this command each time you open a new terminal to ensure that environment is active. # conda activate [environment-name] conda activate dx-env You should now be able to use the dx command line tool in your terminal. dx --help Authenticating \u00b6 Next, you'll need to configure the dx command line tool with access to your St. Jude Cloud account. Rather than exposing your username and password, best practice is to generate an authentication token that lives for a short period of time instead. You can do so by following this guide on how to generate a DNAnexus authentication token . Replace <auth-token> with your own token in the example below. dx login --token <auth-token> --noprojects Upload and download files \u00b6 With DNAnexus toolkit installed and configured, files can be transferred between St. Jude Cloud and your local computer by running dx upload and dx download . To get acquainted with the command, you can view the relevant help messages. dx upload -h dx download -h To upload a file sample.1.bam to the /test/ folder in the project-alpha cloud project, you could use the following command: dx upload sample.1.bam --destination \"project-alpha:/test/\" To download all files in the /results/ folder in the project-alpha cloud project to the current working directory, you could use the following command: dx download -r \"project-alpha:/results/\" The dx command line utility and its upload / download subcommands have many options you can configure based on your use case. We recommend you view the help messages or reach out to us at support@stjude.cloud for more information.","title":"Upload/Download Data (local)"},{"location":"guides/genomics-platform/managing-data/upload-local/#installing-via-conda","text":"To install conda and start creating isolated Python environments, you can visit the conda download documentation and complete the install instructions for your operating system. Be sure to select \"Python 3.X version\" when choosing which version to download. Once you complete installation, you should be able to use the conda command in your terminal. conda can be used to create multiple, independent Python environments. To leverage it to use dx , you'll need to do two things: a one-time creation of a Python 3 environment with dx installed. an environment activation step for every new terminal you open. Note that the environment we create will not be accessible without this explicit activation step. To create an isolated Python 3 environment with dxpy installed, use the following command (you can give your environment any name, here we name it dx-env ). # conda create -n [environment-name] python=3 dxpy -y conda create -n dx-env python = 3 dxpy -y Once you the environment is created, you can run this command each time you open a new terminal to ensure that environment is active. # conda activate [environment-name] conda activate dx-env You should now be able to use the dx command line tool in your terminal. dx --help","title":"Installing via conda"},{"location":"guides/genomics-platform/managing-data/upload-local/#authenticating","text":"Next, you'll need to configure the dx command line tool with access to your St. Jude Cloud account. Rather than exposing your username and password, best practice is to generate an authentication token that lives for a short period of time instead. You can do so by following this guide on how to generate a DNAnexus authentication token . Replace <auth-token> with your own token in the example below. dx login --token <auth-token> --noprojects","title":"Authenticating"},{"location":"guides/genomics-platform/managing-data/upload-local/#upload-and-download-files","text":"With DNAnexus toolkit installed and configured, files can be transferred between St. Jude Cloud and your local computer by running dx upload and dx download . To get acquainted with the command, you can view the relevant help messages. dx upload -h dx download -h To upload a file sample.1.bam to the /test/ folder in the project-alpha cloud project, you could use the following command: dx upload sample.1.bam --destination \"project-alpha:/test/\" To download all files in the /results/ folder in the project-alpha cloud project to the current working directory, you could use the following command: dx download -r \"project-alpha:/results/\" The dx command line utility and its upload / download subcommands have many options you can configure based on your use case. We recommend you view the help messages or reach out to us at support@stjude.cloud for more information.","title":"Upload and download files"},{"location":"guides/genomics-platform/managing-data/working-with-our-data/","text":"In this overview, we will explain how to manage your data request(s) from St. Jude Cloud's genomics platform My Dashboard page and how to access and manage your data (once it has been vended to you) from within a DNAnexus project. The DNAnexus genomic ecosystem is the backbone for the computation and storage in St. Jude Cloud. This means that each data request in St. Jude Cloud corresponds to a project in DNAnexus. If you'd like, you can read an introduction to the DNAnexus ecosystem here . If you haven't already, follow this guide to request access to St. Jude data in this secure cloud ecosystem. Managing Your Data Requests \u00b6 Below is a snapshot of the My Dashboard on our Genomcis Platform. From this page you can check the status of your data request, complete an EDAA draft, upload a revised DAA or an Extension Addendum , or link to your DNAnexus project folder for a specific data request. Pending Request Types Request 1 is an Open Draft, meaning the requestor has not yet finished the setup wizard and the DocuSign envelope has not yet been sent to any of the signatories. Request 2, listed in the Projects section, has been sent to the signatories, but has not been completed by all of them. This status will look like the Request 3 when all of the signatories sign the document and it is ready to be sent to the Data Access Committee(s). Request 3 is pending approval from the Data Access Committee(s), and the status will change from Pending to either Approved or Rejected, based on their decision. All submitted manual-process Data Access Agreements will show up on your My Dashboard page like Request 3. If you have a question about the status of your data request which is not answered on the \"My Dashboard\" page, you can email us at support@stjude.cloud . Accessing Your Data \u00b6 Once your data access request is approved, the data you requested from St. Jude Cloud will automatically be distributed to a DNAnexus project with the same name that you entered through the data request setup wizard. From your My Dashboard page, click on a specific data request name to navigate directly to your corresponding project in DNAnexus. (You can also follow the link in the approval email from notifications@stjude.cloud .) When the data is vended, the directory structure of your DNAnexus project will look something like this: project_space/ \u251c\u2500\u2500 restricted/ \u2502 \u251c\u2500\u2500 bam/ \u2502 \u251c\u2500\u2500 gVCF/ \u2502 \u251c\u2500\u2500 Somatic_VCF/ \u2502 \u2514\u2500\u2500 CNV/ \u2514\u2500\u2500 SAMPLE_INFO.txt The SAMPLE_INFO.txt file provides all the metadata associated with the request, and the restricted folder contains all the data for which you were approved separated by file type. Using Your Data \u00b6 There are two primary ways you can interact with data vended to you in St. Jude Cloud: Cloud access . You can choose to work with the data in DNAnexus' genomics cloud ecosystem. This is our suggested method of interaction, as you can avoid downloading the data to your local servers (which both takes time and is error prone). If you choose to leverage this approach, you can either wrap your own analysis pipeline as a cloud app (see our guide ) or leverage any of DNAnexus' publicly available apps (see DNAnexus' guide . Download the data ( not suggested ). The second way to interact with data vended to you in St. Jude Cloud is by downloading the data to your local servers. If you wish to do this, you can download the data on the command line (see our guide ). Note that you must have indicated you wish to download the data in your data access agreement . Similar Topics \u00b6 About our Data Making a Data Request Upload/Download Data (local)","title":"Managing Data Overview"},{"location":"guides/genomics-platform/managing-data/working-with-our-data/#managing-your-data-requests","text":"Below is a snapshot of the My Dashboard on our Genomcis Platform. From this page you can check the status of your data request, complete an EDAA draft, upload a revised DAA or an Extension Addendum , or link to your DNAnexus project folder for a specific data request. Pending Request Types Request 1 is an Open Draft, meaning the requestor has not yet finished the setup wizard and the DocuSign envelope has not yet been sent to any of the signatories. Request 2, listed in the Projects section, has been sent to the signatories, but has not been completed by all of them. This status will look like the Request 3 when all of the signatories sign the document and it is ready to be sent to the Data Access Committee(s). Request 3 is pending approval from the Data Access Committee(s), and the status will change from Pending to either Approved or Rejected, based on their decision. All submitted manual-process Data Access Agreements will show up on your My Dashboard page like Request 3. If you have a question about the status of your data request which is not answered on the \"My Dashboard\" page, you can email us at support@stjude.cloud .","title":"Managing Your Data Requests"},{"location":"guides/genomics-platform/managing-data/working-with-our-data/#accessing-your-data","text":"Once your data access request is approved, the data you requested from St. Jude Cloud will automatically be distributed to a DNAnexus project with the same name that you entered through the data request setup wizard. From your My Dashboard page, click on a specific data request name to navigate directly to your corresponding project in DNAnexus. (You can also follow the link in the approval email from notifications@stjude.cloud .) When the data is vended, the directory structure of your DNAnexus project will look something like this: project_space/ \u251c\u2500\u2500 restricted/ \u2502 \u251c\u2500\u2500 bam/ \u2502 \u251c\u2500\u2500 gVCF/ \u2502 \u251c\u2500\u2500 Somatic_VCF/ \u2502 \u2514\u2500\u2500 CNV/ \u2514\u2500\u2500 SAMPLE_INFO.txt The SAMPLE_INFO.txt file provides all the metadata associated with the request, and the restricted folder contains all the data for which you were approved separated by file type.","title":"Accessing Your Data"},{"location":"guides/genomics-platform/managing-data/working-with-our-data/#using-your-data","text":"There are two primary ways you can interact with data vended to you in St. Jude Cloud: Cloud access . You can choose to work with the data in DNAnexus' genomics cloud ecosystem. This is our suggested method of interaction, as you can avoid downloading the data to your local servers (which both takes time and is error prone). If you choose to leverage this approach, you can either wrap your own analysis pipeline as a cloud app (see our guide ) or leverage any of DNAnexus' publicly available apps (see DNAnexus' guide . Download the data ( not suggested ). The second way to interact with data vended to you in St. Jude Cloud is by downloading the data to your local servers. If you wish to do this, you can download the data on the command line (see our guide ). Note that you must have indicated you wish to download the data in your data access agreement .","title":"Using Your Data"},{"location":"guides/genomics-platform/managing-data/working-with-our-data/#similar-topics","text":"About our Data Making a Data Request Upload/Download Data (local)","title":"Similar Topics"},{"location":"guides/genomics-platform/requesting-data/about-our-data/","text":"About Our Data File Formats \u00b6 St. Jude Cloud hosts both raw genomic data files and processed results files: File Type Short Description Details BAM HG38 aligned BAM files produced by Microsoft Genomics Service (DNA-Seq) or STAR 2-pass mapping (RNA-Seq). Click here gVCF Genomic VCF files produced by Microsoft Genomics Service . Click here Somatic VCF Curated list of somatic variants produced by the St. Jude somatic variant analysis pipeline. Click here CNV List of somatic copy number alterations produced by St. Jude CONSERTING pipeline. Click here Feature Counts Curated list of read counts mapped to each gene produced by HTSeq Click here BAM files \u00b6 In St. Jude Cloud, we store aligned sequence reads in BAM file format for whole genome sequencing, whole exome sequencing, and RNA-seq. For more information on SAM/BAM files, please refer to the SAM/BAM specification . For research samples, we require the standard 30X coverage for whole genome and 100X for whole exome sequencing. For clinical samples, we require higher coverage, 45X, for whole genome sequencing due to tumor purity issues found in clinical tumor specimens. For RNA-Seq, since only a subset of genes are expressed in a specific tissue, we require 30% of the exons to have 20X coverage in order to ensure that at least 30% of the expressed genes have sufficient coverage. gVCF files \u00b6 We provide gVCF files produced by the Microsoft Genomics Service . gVCF files are derived from the BAM files produced above as called by GATK's haplotype caller . Today, we defer to the official specification document from the Broad Institute, as well as this discussion on the difference between VCF and gVCF files. For more information about how Microsoft Genomics produces gVCF files or any other questions regarding data generation, please refer to the official Microsoft Genomics whitepaper . Somatic VCF files \u00b6 Somatic VCF files contain HG38 based SNV/Indel variant calls from the St. Jude somatic variant analysis pipeline as follows. Broadly speaking: Reads were aligned to HG19 using bwa backtrack ( bwa aln + bwa sampe ) using default parameters. Post processing of aligned reads was performed using Picard CleanSam and MarkDuplicates . Variants were called using the Bambino variant caller (you can download Bambino here or by navigating to the Zhang Lab page where the \"Bambino package\" is listed as a dependency under the CONSERTING section). Variants were post-processed using an in-house post-processing pipeline that cleans and annotates variants. This pipeline is not currently publicly available. Variants were manually reviewed by analysts and published with the relevant Pediatric Cancer Genome Project (PCGP) paper . Post-publication, variants were lifted over to HG38 (the original HG19 coordinates are stored in the HG19 INFO field.). Note Our Somatic VCF files were designed specifically for St. Jude Cloud visualization purposes. Variants in these files were manually curated from analyses across multiple sequencing types including WGS and WES. For more information on variants for each of the individuals, please refer to the relevant PCGP paper. For more information on the variant calling format (VCF), please see the latest specification for VCF document listed here . CNV files \u00b6 CNV files contain copy number alteration (CNA) analysis results for paired tumor-normal WGS samples. Files are produced by running paired tumor-normal BAM files through the CONSERTING pipeline which identifies CNA through iterative analysis of (i) local segmentation by read depth within boundaries identified by structural variation (SV) breakpoints followed by (ii) segment merging and local SV analysis. CREST was used to identify local SV breakpoints. CNV files contain the following information: Field Description chrom chromosome loc.start start of segment loc.end end of segment num.mark number of windows retained in the segment (gaps and windows with low mappability are excluded) length.ratio The ratio between the length of the used windows to the genomic length seg.mean The estimated GC corrected difference signal (2 copy gain will have a seg.mean of 1) GMean The mean coverage in the germline sample (a value of 1 represents diploid) DMean The mean coverage in the tumor sample LogRatio Log2 ratio between tumor and normal coverage Quality score A empirical score used in merging SV_Matching Whether the boundary of the segments were supported by SVs (3: both ends supported, 2: right end supported, 1: left end supported, 0: neither end supported) Feature Counts files \u00b6 Feature counts are text files that contain counts of reads aligned to genomic features. St. Jude Cloud feature files are generated using HTSeq. The detailed command is documented in our RNA-Seq V2 RFC . The files contain a count of the number of reads overlapping each genomic feature, in this case, genes as specified in GENCODE V31 . St. Jude Cloud uses the gene name as feature key. The files are tab-delimited text and contain the feature key and read count for that feature. Sequencing Information \u00b6 Whole Genome and Whole Exome \u00b6 Whole Genome Sequence (WGS) and Whole Exome Sequence (WES) BAM files were produced by the Microsoft Genomics Service aligned to HG38 (GRCh38 no alt analysis set). For more information about how Microsoft Genomics produces BAM files or any other questions regarding data generation, please refer to the official Microsoft Genomics whitepaper . RNA-Seq \u00b6 RNA-Seq BAM files are mapped to HG38. For alignment, STAR v2.7.1a 2-pass mapping is used. Below is the STAR command used during alignment. For more information about any of the parameters used, please refer to the STAR manual for v2.7.1a. The complete RNA-Seq WDL pipeline is available on GitHub . The STAR alignment parameters are also available on GitHub . STAR \\ --readFilesIn $( cat read_one_fastqs_sorted.txt ) $( cat read_two_fastqs_sorted.txt ) \\ --genomeDir ~ { stardb_dir } \\ --runThreadN $n_cores \\ --outSAMunmapped Within \\ --outSAMstrandField intronMotif \\ --outSAMtype BAM Unsorted \\ --outSAMattributes NH HI AS nM NM MD XS \\ --outFilterMultimapScoreRange 1 \\ --outFilterMultimapNmax 20 \\ --outFilterMismatchNmax 10 \\ --alignIntronMax 500000 \\ --alignMatesGapMax 1000000 \\ --sjdbScore 2 \\ --alignSJDBoverhangMin 1 \\ --outFilterMatchNminOverLread 0 .66 \\ --outFilterScoreMinOverLread 0 .66 \\ --outFileNamePrefix ~ { output_prefix + \".\" } \\ --twopassMode Basic \\ --limitBAMsortRAM ~ {( memory_gb - 2 ) + \"000000000\" } \\ --outSAMattrRGline $( cat read_groups_sorted.txt ) Data Access Units \u00b6 We currently have the five Data Access Units (DAU) listed below. Basic clinical data is available for relevant subjects in each DAU. Click on the DAU's abbreviation below to navigate directly to that DAU's Study page for more detailed information. Pediatric Cancer Genome Project (PCGP) \u00b6 PCGP is a paired-tumor normal dataset focused on discovering the genetic origins of pediatric cancer. The Pediatric Cancer Genome Project is a collaboration between St. Jude Children's Research Hospital and the McDonnell Genome Institute at Washington University School of Medicine that sequenced the genomes of over 600 pediatric cancer patients. St. Jude Lifetime (SJLIFE) \u00b6 SJLIFE is a germline-only dataset focused on studying the long-term adverse outcomes associated with cancer and cancer-related therapy. St. Jude Lifetime (SJLIFE) is a longevity study from St. Jude Children's Research Hospital that aims to identify all inherited genome sequence and structural variants influencing the development of childhood cancer and occurrence of long-term adverse outcomes associated with cancer and cancer-related therapy. This cohort contains unpaired germline samples and does not contain tumor samples. Clinical Genomics (Clinical Pilot, G4K, and RTCG) \u00b6 Clinical Genomics is a paired tumor-normal dataset focused on identifying variants that influence the development and behavior of childhood tumors. Clinical Genomics is a cohort from St. Jude Children's Research Hospital, comprised of three studies: Clinical Pilot, Genomes4Kids, and Real-time Clinical Genomics. Clinical Pilot is a smaller, pilot study generated to asses the validity and accuracy of moving forward with the G4K study. The RTCG study aims to release Clinical Genomics data in real time to the research community. The goal of these studies is to identify all inherited and tumor-acquired (somatic) genome sequence and structural variants influencing the development and behavior of childhood tumors. Sickle Cell Genome Project (SGP) \u00b6 SGP is a germline-only dataset of Sickle Cell Disease (SCD) patients from birth to young adulthood. The Sickle Cell Genome Project (SGP) is a collaboration between St. Jude Children\u2019s Research Hospital and Baylor College of Medicine focused on identifying genetic modifiers that contribute to various health complications in SCD patients. Additional objectives include, but are not limited to, developing accurate methods to characterize germline structural variants in highly homologous globin locus and blood typing. Childhood Cancer Survivor Study (CCSS) \u00b6 CCSS is a germline-only dataset consisting of whole genome sequencing of childhood cancer survivors. CCSS is a multi-institutional, multi-disciplinary, NCI-funded collaborative resource established to evaluate long-term outcomes among survivors of childhood cancer. It is a retrospective cohort consisting of >24,000 five-year survivors of childhood cancer who were diagnosed between 1970-1999 at one of 31 participating centers in the U.S. and Canada. The primary purpose of this sequencing of CCSS participants is to identify all inherited genome sequence and structural variants influencing the development of childhood cancer and occurrence of long-term adverse outcomes associated with cancer and cancer-related therapy. CCSS: Potential Bacterial Contamination Samples for the Childhood Cancer Survivorship Study were collected by sending out Buccal swab kits to enrolled participants and having them complete the kits at home. This mechanism of collecting saliva and buccal cells for sequencing is highly desirable because of its non-invasive nature and ease of execution. However, collection of samples in this manner also has higher probability of contamination from external sources (as compared to, say, samples collected using blood). We have observed some samples in this cohort which suffer from bacterial contamination. To address this issue, we have taken the following steps: We have estimated the bacterial contamination rate and annotated each of the samples in the CCSS cohort. For each sample, you will find the estimated contamination rate in the Description field of the SAMPLE_INFO.txt file that is vended with your data (and as a property on the DNAnexus file). For information on this field, see the Metadata specification . Using this estimated contamination rate, we have removed 82 samples which exhibited large rates of bacterial contamination. For the remaining samples, we have provided the BAM file as aligned with bwa mem with default parameters. We have observed that there are instances of reads originating from bacterial contamination that are erroneously mapped to the human genome and display a very low mapping quality. Please be advised that we have kept these reads as they were aligned and have not yet made any attempt to unmap these reads. Any analysis you perform on these samples will need to take this into account! Last, we will be working over the coming months to unmap the reads originating from bacterial contamination and release updated BAM files along with the associated gVCF files from Microsoft Genomics Service. With any questions on the nature or implications of this warning, please contact us at support@stjude.cloud . Pan-Acute Lymphoblastic Leukemia (PanALL) \u00b6 PanALL comprises cases of B-progenitor and T-lineage ALL encompassing the spectrum of ALL subtypes across the age continuum. Samples sequenced were obtained from multiple sites, centers and cooperative groups including St. Jude Children\u2019s Research Hospital, The Children\u2019s Oncology Group, The Alliance \u2013 Cancer and Leukemia Group B, the Eastern Cooperative Oncology Group, The Southwestern Oncology group, MD Anderson Cancer Center, City of Hope National Medical Center, Princess Margaret Cancer Center, Northern Italy Leukemia Group, and UKALL. Metadata \u00b6 Each data request includes a text file called SAMPLE_INFO.txt that provides a number of file level properties (sample identifiers, clinical attributes, etc). Standard Metadata \u00b6 Below are the set of tags which may exist for any given file in St. Jude Cloud. All optional metadata will have sj_ prepended to their tag name. Property Description file_path The path to the file in your St. Jude Cloud project. subject_name A unique subject identifier assigned internally at St. Jude. sample_name A unique sample identifier assigned internally at St. Jude. sample_type One of Autopsy, Cell line, Diagnosis, Germline, Metastasis, Relapse, or Xenograft. sequencing_type Whether the file was generated from Whole Genome (WGS), Whole Exome (WES), or RNA-Seq. file_type One of the file types available in St. Jude Cloud. description Optional field that may contain additional file information. sj_diseases If your data request was process after August 18, 2020, the field should be interpreted as the harmonized St. Jude Cloud diagnosis based on the best available information (data provided by the lab or PI and followup by scientists on the St. Jude Cloud team). If your data request was processed before August 18, 2020, this field should be interpreted as the disease identifier assigned at the time of genomic sequencing (keyly, the diagnosis known at the time of genomic testing may not be the best available information). If your data request was processed after August 18, 2020 and you'd like to use the most up to date, harmonized diagnosis , we recommend using sj_diseases when including diagnosis in your analysis. If your data request was made before this time or if you wish to use the values exactly as provided by the lab or PI, we recommend using the lab-provided value in attr_diagnosis . sj_datasets If present, the datasets in the data browser which this file is associated with. sj_pmid_accessions If the file was associated with a paper, the related Pubmed accession number. sj_ega_accessions If the file was associated with a paper, the related EGA accession number. sj_dataset_accession If present, the permanent accession number assigned in St. Jude Cloud. sj_embargo_date The embargo date , which specifies the first date which the files can be used in a publication. Clinical and Phenotypic Information \u00b6 Also included is a set of phenotypic information queried from the physician or research team's records at the time of sample submission to St. Jude Cloud. These are all considered to be optional , as the level of information gathered for each sample varies. If empty, the physician or research team did not indicate a value for the field. All basic clinical or phenotypic information will have attr_ prepended to their tag name. Property Description attr_age_at_diagnosis Age at first diagnosis. This field is normalized as a decimal value. If empty, the physician or research team did not indicate a value for this field. attr_diagnosis Unharmonized primary diagnosis as reported by the lab or PI upon submission of data to St. Jude Cloud. attr_ethnicity Self-reported ethnicity. Values are normalized according to the US Census Bureau classifications . attr_race Self-reported race. Values are normalized according to the US Census Bureau classifications . attr_sex Self-reported sex. attr_oncotree_disease_code The disease code (assigned at the time of genomic sequencing) as specified by Oncotree Version 2019-03-01 . Diagnosis Codes \u00b6 Note During the release of the St. Jude Cloud paper, we undertook a massive effort to curate and harmonize diagnosis values within St. Jude Cloud. We provide two values for diagnosis, and you should select carefully which value you use based on your use case: sj_diseases , which, since August 18, 2020, represents the harmonized diagnosis value curated by scientists on the St. Jude Cloud team (before that time it represented the diagnosis known at time of sequencing). attr_diagnosis , which contains the unharmonized diagnosis value directly as it was submitted to us from the lab or PI. If your data request was processed after August 18, 2020 and you'd like to use the most up to date, harmonized diagnosis , we recommend using sj_diseases field. If your data request was made before this time or if you wish to use the values exactly as provided by the lab or PI, we recommend using the value in attr_diagnosis . The SAMPLE_INFO.txt file that comes with your data request will contain the list of associated harmonized diagnosis codes ( sj_diseases ) for each sample. These codes represent the harmonized diagnosis values curated by the St. Jude Cloud team and reflect the most up to date information about the sample. Below, we include the full set of diagnosis values in St. Jude Cloud Genomics Platform, the category of the tumor, and the closest available OncoTree term. We regularly work with the OncoTree committee to update new subtypes, so any discrepancies between our diagnosis code and the OncoTree term can be interpreted as more granular classifications that OncoTree does not yet account for. Tumor Category Diagnosis Diagnosis Code Corresponding Oncotree Code Brain Tumor Astrocytoma, NOS ASTR ASTR Brain Tumor Atypical Meningioma ATM ATM Brain Tumor Atypical Teratoid/Rhabdoid Tumor ATRT ATRT Brain Tumor Central Neurocytoma CNC CNC Brain Tumor Choroid Plexus Carcinoma CPC CPC Brain Tumor Craniopharyngioma, Adamantinomatous Type ACPG ACPG Brain Tumor Craniopharyngioma, NOS CPG SELT Brain Tumor Desmoplastic/Nodular Medulloblastoma DMBL DMBL Brain Tumor Dysembryoplastic Neuroepithelial Tumor DNT DNT Brain Tumor Embryonal Tumor with Multilayered Rosettes, Brain ETMR EMBT Brain Tumor Embryonal Tumor, Brain EBMT EMBT Brain Tumor Ependymomal Tumor EPMT EPMT Brain Tumor Ependymomal Tumor, Posterior Fossa EPMTPF EPMT Brain Tumor Ependymomal Tumor, Spinal Tumor EPMTST EPMT Brain Tumor Ependymomal Tumor, Supratentorial EPMTSU EPMT Brain Tumor Fibrillary Astrocytoma FASTR DASTR Brain Tumor Gangliocytoma GNG GNG Brain Tumor Glioblastoma GB GB Brain Tumor Glioma, NOS GNOS GNOS Brain Tumor High-Grade Glioma, NOS HGGNOS HGGNOS Brain Tumor High-Grade Neuroepithelial Tumor HGNET HGNET Brain Tumor Low-Grade Glioma, NOS LGGNOS LGGNOS Brain Tumor Medulloblastoma MBL MBL Brain Tumor Medulloblastoma, Group 3 MBLG3 MBL Brain Tumor Medulloblastoma, Group 4 MBLG4 MBL Brain Tumor Medulloblastoma, SHH subtype MBLSHH MBL Brain Tumor Medulloblastoma, WNT subtype MBLWNT MBL Brain Tumor Medulloepithelioma MDEP MDEP Brain Tumor Meningioma MNG MNG Brain Tumor Miscellaneous Brain Tumor MBT MBT Brain Tumor Mixed Myxopapillary Anaplastic Ependymoma, Spinal Tumor MEPMST EPMT Brain Tumor Myxopapillary Ependymoma MPE MPE Brain Tumor Myxopapillary Ependymoma, Fourth Ventrice MPEFV MPE Brain Tumor Myxopapillary Ependymoma, Posterior Fossa MPEPF MPE Brain Tumor Neuroepithelioma NEP Brain Tumor Oligodendroglioma ODG ODG Brain Tumor Papillary Ependymoma, NOS PEPNOS EPMT Brain Tumor Peripheral Primitive Neuroectodermal Tumor PPNET PNET Brain Tumor Pilocytic Astrocytoma PAST PAST Brain Tumor Pineoblastoma PBL PBL Brain Tumor Pleomorphic Xanthoastrocytoma PXA PXA Brain Tumor Primitive Neuroectodermal Tumor PNET PNET Brain Tumor Subependymal Giant Cell Astrocytoma SEGA Germ Cell Tumor Choriocarcinoma CCA Germ Cell Tumor Dysgerminoma DYS Germ Cell Tumor Dysgerminoma, Ovarian ODYS ODYS Germ Cell Tumor Dysgerminoma, Pelvis PDYS Germ Cell Tumor Embryonal Carcinoma, NOS ECNOS Germ Cell Tumor Germ Cell Tumor, Brain BGCT BGCT Germ Cell Tumor Germ Cell Tumor, NOS GCT Germ Cell Tumor Germinoma GMN GMN Germ Cell Tumor Mixed Germ Cell Tumor, Brain BMGCT BMGCT Germ Cell Tumor Mixed Germ Cell Tumor, NOS MGCTNOS Germ Cell Tumor Mixed Germ Cell Tumor, Ovary and Lymph Node OMGCT OMGCT Germ Cell Tumor Mixed Germ Cell Tumor, Testis MGCT MGCT Germ Cell Tumor Teratocarcinoma TTC Germ Cell Tumor Teratoma, NOS TTNOS Germ Cell Tumor Yolk Sac Tumor, Brain BYST BYST Germ Cell Tumor Yolk Sac Tumor, NOS YSTNOS Hematologic Malignancy Acute Leukemias of Ambiguous Lineage ALAL ALAL Hematologic Malignancy Acute Lymphoblastic Leukemia, NOS ALL LNM Hematologic Malignancy Acute Megakaryoblastic Leukemia AMKL AMKL Hematologic Malignancy Acute Myeloid Leukemia AML AML Hematologic Malignancy Acute Myeloid Leukemia, Core Binding Factor CBF AMLRGA Hematologic Malignancy Acute Myeloid Leukemia, KMT2A rearrangement AML AMLRGA Hematologic Malignancy Acute Promyelocytic Leukemia APLPMLRARA APLPMLRARA Hematologic Malignancy Acute Undifferentiated Leukemia, KMT2A rearrangement AULKMT2A AUL Hematologic Malignancy Anaplastic Large Cell Lymphoma ALCL ALCL Hematologic Malignancy B-cell Acute Lymphoblastic Leukemia, BCR-ABL1 BALLBCRABL1 BLLBCRABL1 Hematologic Malignancy B-cell Acute Lymphoblastic Leukemia, BCR-ABL1 like BALLBCRABL1L BLLBCRABL1L Hematologic Malignancy B-cell Acute Lymphoblastic Leukemia, DUX4-IGH BALLDUX4IGH BLLRGA Hematologic Malignancy B-cell Acute Lymphoblastic Leukemia, DUX4-IGH like BALLDUX4IGHL BLLRGA Hematologic Malignancy B-cell Acute Lymphoblastic Leukemia, ETV6-RUNX1 BALLETV6RUNX1 BLLETV6RUNX1 Hematologic Malignancy B-cell Acute Lymphoblastic Leukemia, ETV6-RUNX1 like BALLETV6RUNX1L BLLRGA Hematologic Malignancy B-cell Acute Lymphoblastic Leukemia, HLF rearrangement BALLHLF BLLRGA Hematologic Malignancy B-cell Acute Lymphoblastic Leukemia, Hyperdiploidy BALLHYPER BLLHYPER Hematologic Malignancy B-cell Acute Lymphoblastic Leukemia, Hypodiploidy BALLHYPO BLLHYPO Hematologic Malignancy B-cell Acute Lymphoblastic Leukemia, iAMP21 BALLIAMP21 BLLIAMP21 Hematologic Malignancy B-cell Acute Lymphoblastic Leukemia, IGH-CEBPD BALLIGHCEBPD BLLRGA Hematologic Malignancy B-cell Acute Lymphoblastic Leukemia, KMT2A rearrangement BALLKMT2A BLLKMT2A Hematologic Malignancy B-cell Acute Lymphoblastic Leukemia, MEF2D rearrangement BALLMEF2D BLLRGA Hematologic Malignancy B-cell Acute Lymphoblastic Leukemia, MYC rearrangement BALLMYC BLLRGA Hematologic Malignancy B-cell Acute Lymphoblastic Leukemia, NOS BALLNOS BLLNOS Hematologic Malignancy B-cell Acute Lymphoblastic Leukemia, NUTM1 rearrangement BALLNUTM1 BLLRGA Hematologic Malignancy B-cell Acute Lymphoblastic Leukemia, PAX5 Alteration BALLPAX5 BLLRGA Hematologic Malignancy B-cell Acute Lymphoblastic Leukemia, PAX5 P80R BALLPAX5P80R BLLRGA Hematologic Malignancy B-cell Acute Lymphoblastic Leukemia, TCF3-PBX1 BALLTCF3PBX1 BLLTCF3PBX1 Hematologic Malignancy B-cell Acute Lymphoblastic Leukemia, ZNF384 rearrangement BALLZNF384 BLLRGA Hematologic Malignancy B-cell Acute Lymphoblastic Leukemia, ZNF384 rearrangement like BALLZNF384L BLLRGA Hematologic Malignancy Blood Cancer of Unknown Primary BCUP CUP Hematologic Malignancy Burkitt Lymphoma BL BL Hematologic Malignancy Chronic Myeloid Leukemia CML CML Hematologic Malignancy Diffuse Large B-cell Lymphoma, NOS DLBCLNOS DLBCLNOS Hematologic Malignancy General Leukemia SJGENLK Hematologic Malignancy Hodgkin Lymphoma HL HL Hematologic Malignancy Langerhans Cell Histiocytosis LCH LCH Hematologic Malignancy Lymphocyte-Depleted Classical Hodgkin Lymphoma LDCHL LDCHL Hematologic Malignancy Lymphocyte-Rich Classical Hodgkin Lymphoma LRCHL LRCHL Hematologic Malignancy Mixed Cellularity Classical Hodgkin Lymphoma MCCHL MCCHL Hematologic Malignancy Mycosis Fungoides MYCF MYCF Hematologic Malignancy Myelodysplastic Syndromes MDS MDS Hematologic Malignancy Myeloid Sarcoma MS MS Hematologic Malignancy Nodular Lymphocyte-Predominant Hodgkin Lymphoma NLPHL NLPHL Hematologic Malignancy Nodular Sclerosis Classical Hodgkin Lymphoma NSCHL NSCHL Hematologic Malignancy Non-Hodgkin Lymphoma NHL NHL Hematologic Malignancy T-cell Acute Lymphoblastic Leukemia TALL TLL Hematologic Malignancy T-cell Acute Lymphoblastic Leukemia, KMT2A rearrangement TALLKMT2A TLL Hematologic Malignancy T-cell Lymphoblastic Lymphoma TLL TLL Non-Malignancy Non-Malignancy SJNM Normal SJLIFE Normal Control SJNORM Sickle Cell Disease Sickle Cell Disease SJSCD Solid Tumor Acinar Cell Carcinoma ACN ACN Solid Tumor Adenocarcinoma, NOS ADNOS ADNOS Solid Tumor Adrenocortical Carcinoma ACC ACC Solid Tumor Alveolar Rhabdomyosarcoma ARMS ARMS Solid Tumor Alveolar Soft Part Sarcoma ASPS ASPS Solid Tumor Angiomatoid Fibrous Histiocytoma AFH AFH Solid Tumor Basal Cell Carcinoma BCC BCC Solid Tumor Botryoid Type Embryonal Rhabdomyosarcoma BERMS ERMS Solid Tumor Carcinoma, NOS CNOS CUP Solid Tumor Chondroblastic Osteosarcoma CHOS CHOS Solid Tumor Chondrosarcoma CHS CHS Solid Tumor Chordoma CHDM CHDM Solid Tumor Clear Cell Sarcoma of Kidney CCSK CCSK Solid Tumor Congenital Mesoblastic Nephroma CMN RCC Solid Tumor Dermatofibrosarcoma Protuberans DFSP DFSP Solid Tumor Desmoid/Aggressive Fibromatosis DES DES Solid Tumor Desmoplastic Small Round Cell Tumor DSRCT DSRCT Solid Tumor Embryonal Rhabdomyosarcoma ERMS ERMS Solid Tumor Endometrioid Adenocarcinoma, NOS EACNOS ADNOS Solid Tumor Epithelioid Hemangioendothelioma EHAE EHAE Solid Tumor Epithelioid Sarcoma EPIS EPIS Solid Tumor Ewing Sarcoma EWS ES Solid Tumor Fibroblastic Osteosarcoma FIOS FIOS Solid Tumor Fibromyxoid Sarcoma FMS Solid Tumor Fibrosarcoma, NOS FIBS FIBS Solid Tumor Follicular Thyroid Cancer THFO THFO Solid Tumor Ganglioneuroblastoma GNBL GNBL Solid Tumor Ganglioneuroma GN GN Solid Tumor Gastrointestinal Stromal Tumor GIST GIST Solid Tumor General Bone Tumor SJGENBN Solid Tumor Giant Cell Tumor, NOS GICT GCTB Solid Tumor Granulosa Cell Tumor GRCT GRCT Solid Tumor Hepatoblastoma HB LIHB Solid Tumor Hepatocellular Carcinoma HCC HCC Solid Tumor Infantile Fibrosarcoma IFS IFS Solid Tumor Leiomyosarcoma, NOS LMS LMS Solid Tumor Liposarcoma LIPO LIPO Solid Tumor Liver Malignancy, NOS LMNOS Solid Tumor Malignant Fibrous Histiocytoma MFH MFH Solid Tumor Malignant Mesenchymoma MME Solid Tumor Malignant Mesenchymoma of the Liver MMEL Solid Tumor Malignant Peripheral Nerve Sheath Tumor MPNST MPNST Solid Tumor Malignant Rhabdoid Tumor of the Liver MRTL MRTL Solid Tumor Melanoma MEL MEL Solid Tumor Mesenchymal Chondrosarcoma MCHS MCHS Solid Tumor Mixed Spindle Cell and Embryonal Rhabdomyosarcoma MSCERMS RMS Solid Tumor Mucinous Adenocarcinoma of the Colon and Rectum MACR MACR Solid Tumor Mucinous Adenocarcinoma, NOS MACNOS Solid Tumor Mucoepidermoid Carcinoma MUCC MUCC Solid Tumor Nasopharyngeal Carcinoma NPC NPC Solid Tumor Neuroblastoma NBL NBL Solid Tumor Neurofibroma NFIB NFIB Solid Tumor Osteosarcoma OS OS Solid Tumor Pancreatic Neuroendocrine Tumor PANET PANET Solid Tumor Papillary Renal Cell Carcinoma PRCC PRCC Solid Tumor Papillary Thyroid Cancer THPA THPA Solid Tumor Paraganglioma PGNG PGNG Solid Tumor Parosteal Osteosarcoma PAOS PAOS Solid Tumor Periosteal Osteosarcoma PEOS PEOS Solid Tumor Pleuropulmonary Blastoma PPB PPB Solid Tumor Renal Cell Carcinoma RCC RCC Solid Tumor Renal Clear Cell Carcinoma CCRCC CCRCC Solid Tumor Retinoblastoma RBL RBL Solid Tumor Rhabdoid Cancer, Kidney MRT MRT Solid Tumor Rhabdomyosarcoma RMS RMS Solid Tumor Round Cell Sarcoma, NOS RCSNOS RCSNOS Solid Tumor Serous Surface Papillary Carcinoma SSPC Solid Tumor Small Cell Osteosarcoma SCOS SCOS Solid Tumor Soft Tissue Sarcoma, NOS STSNOS CUP Solid Tumor Solid Cancer of Unknown Primary SCUP CUP Solid Tumor Solitary Fibrous Tumor/Hemangiopericytoma SFT SFT Solid Tumor Spindle Cell Rhabdomyosarcoma SCRMS SCRMS Solid Tumor Spindle Cell Sarcoma, NOS SCSNOS Solid Tumor Spindle Cell/Sclerosing Rhabdomyosarcoma SCSRMS SCSRMS Solid Tumor Spindle Epithelial Tumor with Thymus-Like Differentiation SETTLE Solid Tumor Squamous Cell Carcinoma, NOS SCCNOS SCCNOS Solid Tumor Stomach Inflammatory Pseudotumor SIPT Solid Tumor Synovial Sarcoma SYNS SYNS Solid Tumor Telangiectatic Osteosarcoma TEOS TEOS Solid Tumor Undifferentiated Embryonal Sarcoma of the Liver UESL UESL Solid Tumor Wilms WT WT Solid Tumor Wilms, Bilateral WTB WT Similar Topics \u00b6 About our Decision Process & Terminology Making a Data Request Managing Data Overview","title":"About our Data"},{"location":"guides/genomics-platform/requesting-data/about-our-data/#file-formats","text":"St. Jude Cloud hosts both raw genomic data files and processed results files: File Type Short Description Details BAM HG38 aligned BAM files produced by Microsoft Genomics Service (DNA-Seq) or STAR 2-pass mapping (RNA-Seq). Click here gVCF Genomic VCF files produced by Microsoft Genomics Service . Click here Somatic VCF Curated list of somatic variants produced by the St. Jude somatic variant analysis pipeline. Click here CNV List of somatic copy number alterations produced by St. Jude CONSERTING pipeline. Click here Feature Counts Curated list of read counts mapped to each gene produced by HTSeq Click here","title":"File Formats"},{"location":"guides/genomics-platform/requesting-data/about-our-data/#bam-files","text":"In St. Jude Cloud, we store aligned sequence reads in BAM file format for whole genome sequencing, whole exome sequencing, and RNA-seq. For more information on SAM/BAM files, please refer to the SAM/BAM specification . For research samples, we require the standard 30X coverage for whole genome and 100X for whole exome sequencing. For clinical samples, we require higher coverage, 45X, for whole genome sequencing due to tumor purity issues found in clinical tumor specimens. For RNA-Seq, since only a subset of genes are expressed in a specific tissue, we require 30% of the exons to have 20X coverage in order to ensure that at least 30% of the expressed genes have sufficient coverage.","title":"BAM files"},{"location":"guides/genomics-platform/requesting-data/about-our-data/#gvcf-files","text":"We provide gVCF files produced by the Microsoft Genomics Service . gVCF files are derived from the BAM files produced above as called by GATK's haplotype caller . Today, we defer to the official specification document from the Broad Institute, as well as this discussion on the difference between VCF and gVCF files. For more information about how Microsoft Genomics produces gVCF files or any other questions regarding data generation, please refer to the official Microsoft Genomics whitepaper .","title":"gVCF files"},{"location":"guides/genomics-platform/requesting-data/about-our-data/#somatic-vcf-files","text":"Somatic VCF files contain HG38 based SNV/Indel variant calls from the St. Jude somatic variant analysis pipeline as follows. Broadly speaking: Reads were aligned to HG19 using bwa backtrack ( bwa aln + bwa sampe ) using default parameters. Post processing of aligned reads was performed using Picard CleanSam and MarkDuplicates . Variants were called using the Bambino variant caller (you can download Bambino here or by navigating to the Zhang Lab page where the \"Bambino package\" is listed as a dependency under the CONSERTING section). Variants were post-processed using an in-house post-processing pipeline that cleans and annotates variants. This pipeline is not currently publicly available. Variants were manually reviewed by analysts and published with the relevant Pediatric Cancer Genome Project (PCGP) paper . Post-publication, variants were lifted over to HG38 (the original HG19 coordinates are stored in the HG19 INFO field.). Note Our Somatic VCF files were designed specifically for St. Jude Cloud visualization purposes. Variants in these files were manually curated from analyses across multiple sequencing types including WGS and WES. For more information on variants for each of the individuals, please refer to the relevant PCGP paper. For more information on the variant calling format (VCF), please see the latest specification for VCF document listed here .","title":"Somatic VCF files"},{"location":"guides/genomics-platform/requesting-data/about-our-data/#cnv-files","text":"CNV files contain copy number alteration (CNA) analysis results for paired tumor-normal WGS samples. Files are produced by running paired tumor-normal BAM files through the CONSERTING pipeline which identifies CNA through iterative analysis of (i) local segmentation by read depth within boundaries identified by structural variation (SV) breakpoints followed by (ii) segment merging and local SV analysis. CREST was used to identify local SV breakpoints. CNV files contain the following information: Field Description chrom chromosome loc.start start of segment loc.end end of segment num.mark number of windows retained in the segment (gaps and windows with low mappability are excluded) length.ratio The ratio between the length of the used windows to the genomic length seg.mean The estimated GC corrected difference signal (2 copy gain will have a seg.mean of 1) GMean The mean coverage in the germline sample (a value of 1 represents diploid) DMean The mean coverage in the tumor sample LogRatio Log2 ratio between tumor and normal coverage Quality score A empirical score used in merging SV_Matching Whether the boundary of the segments were supported by SVs (3: both ends supported, 2: right end supported, 1: left end supported, 0: neither end supported)","title":"CNV files"},{"location":"guides/genomics-platform/requesting-data/about-our-data/#feature-counts-files","text":"Feature counts are text files that contain counts of reads aligned to genomic features. St. Jude Cloud feature files are generated using HTSeq. The detailed command is documented in our RNA-Seq V2 RFC . The files contain a count of the number of reads overlapping each genomic feature, in this case, genes as specified in GENCODE V31 . St. Jude Cloud uses the gene name as feature key. The files are tab-delimited text and contain the feature key and read count for that feature.","title":"Feature Counts files"},{"location":"guides/genomics-platform/requesting-data/about-our-data/#sequencing-information","text":"","title":"Sequencing Information"},{"location":"guides/genomics-platform/requesting-data/about-our-data/#whole-genome-and-whole-exome","text":"Whole Genome Sequence (WGS) and Whole Exome Sequence (WES) BAM files were produced by the Microsoft Genomics Service aligned to HG38 (GRCh38 no alt analysis set). For more information about how Microsoft Genomics produces BAM files or any other questions regarding data generation, please refer to the official Microsoft Genomics whitepaper .","title":"Whole Genome and Whole Exome"},{"location":"guides/genomics-platform/requesting-data/about-our-data/#rna-seq","text":"RNA-Seq BAM files are mapped to HG38. For alignment, STAR v2.7.1a 2-pass mapping is used. Below is the STAR command used during alignment. For more information about any of the parameters used, please refer to the STAR manual for v2.7.1a. The complete RNA-Seq WDL pipeline is available on GitHub . The STAR alignment parameters are also available on GitHub . STAR \\ --readFilesIn $( cat read_one_fastqs_sorted.txt ) $( cat read_two_fastqs_sorted.txt ) \\ --genomeDir ~ { stardb_dir } \\ --runThreadN $n_cores \\ --outSAMunmapped Within \\ --outSAMstrandField intronMotif \\ --outSAMtype BAM Unsorted \\ --outSAMattributes NH HI AS nM NM MD XS \\ --outFilterMultimapScoreRange 1 \\ --outFilterMultimapNmax 20 \\ --outFilterMismatchNmax 10 \\ --alignIntronMax 500000 \\ --alignMatesGapMax 1000000 \\ --sjdbScore 2 \\ --alignSJDBoverhangMin 1 \\ --outFilterMatchNminOverLread 0 .66 \\ --outFilterScoreMinOverLread 0 .66 \\ --outFileNamePrefix ~ { output_prefix + \".\" } \\ --twopassMode Basic \\ --limitBAMsortRAM ~ {( memory_gb - 2 ) + \"000000000\" } \\ --outSAMattrRGline $( cat read_groups_sorted.txt )","title":"RNA-Seq"},{"location":"guides/genomics-platform/requesting-data/about-our-data/#data-access-units","text":"We currently have the five Data Access Units (DAU) listed below. Basic clinical data is available for relevant subjects in each DAU. Click on the DAU's abbreviation below to navigate directly to that DAU's Study page for more detailed information.","title":"Data Access Units"},{"location":"guides/genomics-platform/requesting-data/about-our-data/#pediatric-cancer-genome-project-pcgp","text":"PCGP is a paired-tumor normal dataset focused on discovering the genetic origins of pediatric cancer. The Pediatric Cancer Genome Project is a collaboration between St. Jude Children's Research Hospital and the McDonnell Genome Institute at Washington University School of Medicine that sequenced the genomes of over 600 pediatric cancer patients.","title":"Pediatric Cancer Genome Project (PCGP)"},{"location":"guides/genomics-platform/requesting-data/about-our-data/#st-jude-lifetime-sjlife","text":"SJLIFE is a germline-only dataset focused on studying the long-term adverse outcomes associated with cancer and cancer-related therapy. St. Jude Lifetime (SJLIFE) is a longevity study from St. Jude Children's Research Hospital that aims to identify all inherited genome sequence and structural variants influencing the development of childhood cancer and occurrence of long-term adverse outcomes associated with cancer and cancer-related therapy. This cohort contains unpaired germline samples and does not contain tumor samples.","title":"St. Jude Lifetime (SJLIFE)"},{"location":"guides/genomics-platform/requesting-data/about-our-data/#clinical-genomics-clinical-pilot-g4k-and-rtcg","text":"Clinical Genomics is a paired tumor-normal dataset focused on identifying variants that influence the development and behavior of childhood tumors. Clinical Genomics is a cohort from St. Jude Children's Research Hospital, comprised of three studies: Clinical Pilot, Genomes4Kids, and Real-time Clinical Genomics. Clinical Pilot is a smaller, pilot study generated to asses the validity and accuracy of moving forward with the G4K study. The RTCG study aims to release Clinical Genomics data in real time to the research community. The goal of these studies is to identify all inherited and tumor-acquired (somatic) genome sequence and structural variants influencing the development and behavior of childhood tumors.","title":"Clinical Genomics (Clinical Pilot, G4K, and RTCG)"},{"location":"guides/genomics-platform/requesting-data/about-our-data/#sickle-cell-genome-project-sgp","text":"SGP is a germline-only dataset of Sickle Cell Disease (SCD) patients from birth to young adulthood. The Sickle Cell Genome Project (SGP) is a collaboration between St. Jude Children\u2019s Research Hospital and Baylor College of Medicine focused on identifying genetic modifiers that contribute to various health complications in SCD patients. Additional objectives include, but are not limited to, developing accurate methods to characterize germline structural variants in highly homologous globin locus and blood typing.","title":"Sickle Cell Genome Project (SGP)"},{"location":"guides/genomics-platform/requesting-data/about-our-data/#childhood-cancer-survivor-study-ccss","text":"CCSS is a germline-only dataset consisting of whole genome sequencing of childhood cancer survivors. CCSS is a multi-institutional, multi-disciplinary, NCI-funded collaborative resource established to evaluate long-term outcomes among survivors of childhood cancer. It is a retrospective cohort consisting of >24,000 five-year survivors of childhood cancer who were diagnosed between 1970-1999 at one of 31 participating centers in the U.S. and Canada. The primary purpose of this sequencing of CCSS participants is to identify all inherited genome sequence and structural variants influencing the development of childhood cancer and occurrence of long-term adverse outcomes associated with cancer and cancer-related therapy. CCSS: Potential Bacterial Contamination Samples for the Childhood Cancer Survivorship Study were collected by sending out Buccal swab kits to enrolled participants and having them complete the kits at home. This mechanism of collecting saliva and buccal cells for sequencing is highly desirable because of its non-invasive nature and ease of execution. However, collection of samples in this manner also has higher probability of contamination from external sources (as compared to, say, samples collected using blood). We have observed some samples in this cohort which suffer from bacterial contamination. To address this issue, we have taken the following steps: We have estimated the bacterial contamination rate and annotated each of the samples in the CCSS cohort. For each sample, you will find the estimated contamination rate in the Description field of the SAMPLE_INFO.txt file that is vended with your data (and as a property on the DNAnexus file). For information on this field, see the Metadata specification . Using this estimated contamination rate, we have removed 82 samples which exhibited large rates of bacterial contamination. For the remaining samples, we have provided the BAM file as aligned with bwa mem with default parameters. We have observed that there are instances of reads originating from bacterial contamination that are erroneously mapped to the human genome and display a very low mapping quality. Please be advised that we have kept these reads as they were aligned and have not yet made any attempt to unmap these reads. Any analysis you perform on these samples will need to take this into account! Last, we will be working over the coming months to unmap the reads originating from bacterial contamination and release updated BAM files along with the associated gVCF files from Microsoft Genomics Service. With any questions on the nature or implications of this warning, please contact us at support@stjude.cloud .","title":"Childhood Cancer Survivor Study (CCSS)"},{"location":"guides/genomics-platform/requesting-data/about-our-data/#pan-acute-lymphoblastic-leukemia-panall","text":"PanALL comprises cases of B-progenitor and T-lineage ALL encompassing the spectrum of ALL subtypes across the age continuum. Samples sequenced were obtained from multiple sites, centers and cooperative groups including St. Jude Children\u2019s Research Hospital, The Children\u2019s Oncology Group, The Alliance \u2013 Cancer and Leukemia Group B, the Eastern Cooperative Oncology Group, The Southwestern Oncology group, MD Anderson Cancer Center, City of Hope National Medical Center, Princess Margaret Cancer Center, Northern Italy Leukemia Group, and UKALL.","title":"Pan-Acute Lymphoblastic Leukemia (PanALL)"},{"location":"guides/genomics-platform/requesting-data/about-our-data/#metadata","text":"Each data request includes a text file called SAMPLE_INFO.txt that provides a number of file level properties (sample identifiers, clinical attributes, etc).","title":"Metadata"},{"location":"guides/genomics-platform/requesting-data/about-our-data/#standard-metadata","text":"Below are the set of tags which may exist for any given file in St. Jude Cloud. All optional metadata will have sj_ prepended to their tag name. Property Description file_path The path to the file in your St. Jude Cloud project. subject_name A unique subject identifier assigned internally at St. Jude. sample_name A unique sample identifier assigned internally at St. Jude. sample_type One of Autopsy, Cell line, Diagnosis, Germline, Metastasis, Relapse, or Xenograft. sequencing_type Whether the file was generated from Whole Genome (WGS), Whole Exome (WES), or RNA-Seq. file_type One of the file types available in St. Jude Cloud. description Optional field that may contain additional file information. sj_diseases If your data request was process after August 18, 2020, the field should be interpreted as the harmonized St. Jude Cloud diagnosis based on the best available information (data provided by the lab or PI and followup by scientists on the St. Jude Cloud team). If your data request was processed before August 18, 2020, this field should be interpreted as the disease identifier assigned at the time of genomic sequencing (keyly, the diagnosis known at the time of genomic testing may not be the best available information). If your data request was processed after August 18, 2020 and you'd like to use the most up to date, harmonized diagnosis , we recommend using sj_diseases when including diagnosis in your analysis. If your data request was made before this time or if you wish to use the values exactly as provided by the lab or PI, we recommend using the lab-provided value in attr_diagnosis . sj_datasets If present, the datasets in the data browser which this file is associated with. sj_pmid_accessions If the file was associated with a paper, the related Pubmed accession number. sj_ega_accessions If the file was associated with a paper, the related EGA accession number. sj_dataset_accession If present, the permanent accession number assigned in St. Jude Cloud. sj_embargo_date The embargo date , which specifies the first date which the files can be used in a publication.","title":"Standard Metadata"},{"location":"guides/genomics-platform/requesting-data/about-our-data/#clinical-and-phenotypic-information","text":"Also included is a set of phenotypic information queried from the physician or research team's records at the time of sample submission to St. Jude Cloud. These are all considered to be optional , as the level of information gathered for each sample varies. If empty, the physician or research team did not indicate a value for the field. All basic clinical or phenotypic information will have attr_ prepended to their tag name. Property Description attr_age_at_diagnosis Age at first diagnosis. This field is normalized as a decimal value. If empty, the physician or research team did not indicate a value for this field. attr_diagnosis Unharmonized primary diagnosis as reported by the lab or PI upon submission of data to St. Jude Cloud. attr_ethnicity Self-reported ethnicity. Values are normalized according to the US Census Bureau classifications . attr_race Self-reported race. Values are normalized according to the US Census Bureau classifications . attr_sex Self-reported sex. attr_oncotree_disease_code The disease code (assigned at the time of genomic sequencing) as specified by Oncotree Version 2019-03-01 .","title":"Clinical and Phenotypic Information"},{"location":"guides/genomics-platform/requesting-data/about-our-data/#diagnosis-codes","text":"Note During the release of the St. Jude Cloud paper, we undertook a massive effort to curate and harmonize diagnosis values within St. Jude Cloud. We provide two values for diagnosis, and you should select carefully which value you use based on your use case: sj_diseases , which, since August 18, 2020, represents the harmonized diagnosis value curated by scientists on the St. Jude Cloud team (before that time it represented the diagnosis known at time of sequencing). attr_diagnosis , which contains the unharmonized diagnosis value directly as it was submitted to us from the lab or PI. If your data request was processed after August 18, 2020 and you'd like to use the most up to date, harmonized diagnosis , we recommend using sj_diseases field. If your data request was made before this time or if you wish to use the values exactly as provided by the lab or PI, we recommend using the value in attr_diagnosis . The SAMPLE_INFO.txt file that comes with your data request will contain the list of associated harmonized diagnosis codes ( sj_diseases ) for each sample. These codes represent the harmonized diagnosis values curated by the St. Jude Cloud team and reflect the most up to date information about the sample. Below, we include the full set of diagnosis values in St. Jude Cloud Genomics Platform, the category of the tumor, and the closest available OncoTree term. We regularly work with the OncoTree committee to update new subtypes, so any discrepancies between our diagnosis code and the OncoTree term can be interpreted as more granular classifications that OncoTree does not yet account for. Tumor Category Diagnosis Diagnosis Code Corresponding Oncotree Code Brain Tumor Astrocytoma, NOS ASTR ASTR Brain Tumor Atypical Meningioma ATM ATM Brain Tumor Atypical Teratoid/Rhabdoid Tumor ATRT ATRT Brain Tumor Central Neurocytoma CNC CNC Brain Tumor Choroid Plexus Carcinoma CPC CPC Brain Tumor Craniopharyngioma, Adamantinomatous Type ACPG ACPG Brain Tumor Craniopharyngioma, NOS CPG SELT Brain Tumor Desmoplastic/Nodular Medulloblastoma DMBL DMBL Brain Tumor Dysembryoplastic Neuroepithelial Tumor DNT DNT Brain Tumor Embryonal Tumor with Multilayered Rosettes, Brain ETMR EMBT Brain Tumor Embryonal Tumor, Brain EBMT EMBT Brain Tumor Ependymomal Tumor EPMT EPMT Brain Tumor Ependymomal Tumor, Posterior Fossa EPMTPF EPMT Brain Tumor Ependymomal Tumor, Spinal Tumor EPMTST EPMT Brain Tumor Ependymomal Tumor, Supratentorial EPMTSU EPMT Brain Tumor Fibrillary Astrocytoma FASTR DASTR Brain Tumor Gangliocytoma GNG GNG Brain Tumor Glioblastoma GB GB Brain Tumor Glioma, NOS GNOS GNOS Brain Tumor High-Grade Glioma, NOS HGGNOS HGGNOS Brain Tumor High-Grade Neuroepithelial Tumor HGNET HGNET Brain Tumor Low-Grade Glioma, NOS LGGNOS LGGNOS Brain Tumor Medulloblastoma MBL MBL Brain Tumor Medulloblastoma, Group 3 MBLG3 MBL Brain Tumor Medulloblastoma, Group 4 MBLG4 MBL Brain Tumor Medulloblastoma, SHH subtype MBLSHH MBL Brain Tumor Medulloblastoma, WNT subtype MBLWNT MBL Brain Tumor Medulloepithelioma MDEP MDEP Brain Tumor Meningioma MNG MNG Brain Tumor Miscellaneous Brain Tumor MBT MBT Brain Tumor Mixed Myxopapillary Anaplastic Ependymoma, Spinal Tumor MEPMST EPMT Brain Tumor Myxopapillary Ependymoma MPE MPE Brain Tumor Myxopapillary Ependymoma, Fourth Ventrice MPEFV MPE Brain Tumor Myxopapillary Ependymoma, Posterior Fossa MPEPF MPE Brain Tumor Neuroepithelioma NEP Brain Tumor Oligodendroglioma ODG ODG Brain Tumor Papillary Ependymoma, NOS PEPNOS EPMT Brain Tumor Peripheral Primitive Neuroectodermal Tumor PPNET PNET Brain Tumor Pilocytic Astrocytoma PAST PAST Brain Tumor Pineoblastoma PBL PBL Brain Tumor Pleomorphic Xanthoastrocytoma PXA PXA Brain Tumor Primitive Neuroectodermal Tumor PNET PNET Brain Tumor Subependymal Giant Cell Astrocytoma SEGA Germ Cell Tumor Choriocarcinoma CCA Germ Cell Tumor Dysgerminoma DYS Germ Cell Tumor Dysgerminoma, Ovarian ODYS ODYS Germ Cell Tumor Dysgerminoma, Pelvis PDYS Germ Cell Tumor Embryonal Carcinoma, NOS ECNOS Germ Cell Tumor Germ Cell Tumor, Brain BGCT BGCT Germ Cell Tumor Germ Cell Tumor, NOS GCT Germ Cell Tumor Germinoma GMN GMN Germ Cell Tumor Mixed Germ Cell Tumor, Brain BMGCT BMGCT Germ Cell Tumor Mixed Germ Cell Tumor, NOS MGCTNOS Germ Cell Tumor Mixed Germ Cell Tumor, Ovary and Lymph Node OMGCT OMGCT Germ Cell Tumor Mixed Germ Cell Tumor, Testis MGCT MGCT Germ Cell Tumor Teratocarcinoma TTC Germ Cell Tumor Teratoma, NOS TTNOS Germ Cell Tumor Yolk Sac Tumor, Brain BYST BYST Germ Cell Tumor Yolk Sac Tumor, NOS YSTNOS Hematologic Malignancy Acute Leukemias of Ambiguous Lineage ALAL ALAL Hematologic Malignancy Acute Lymphoblastic Leukemia, NOS ALL LNM Hematologic Malignancy Acute Megakaryoblastic Leukemia AMKL AMKL Hematologic Malignancy Acute Myeloid Leukemia AML AML Hematologic Malignancy Acute Myeloid Leukemia, Core Binding Factor CBF AMLRGA Hematologic Malignancy Acute Myeloid Leukemia, KMT2A rearrangement AML AMLRGA Hematologic Malignancy Acute Promyelocytic Leukemia APLPMLRARA APLPMLRARA Hematologic Malignancy Acute Undifferentiated Leukemia, KMT2A rearrangement AULKMT2A AUL Hematologic Malignancy Anaplastic Large Cell Lymphoma ALCL ALCL Hematologic Malignancy B-cell Acute Lymphoblastic Leukemia, BCR-ABL1 BALLBCRABL1 BLLBCRABL1 Hematologic Malignancy B-cell Acute Lymphoblastic Leukemia, BCR-ABL1 like BALLBCRABL1L BLLBCRABL1L Hematologic Malignancy B-cell Acute Lymphoblastic Leukemia, DUX4-IGH BALLDUX4IGH BLLRGA Hematologic Malignancy B-cell Acute Lymphoblastic Leukemia, DUX4-IGH like BALLDUX4IGHL BLLRGA Hematologic Malignancy B-cell Acute Lymphoblastic Leukemia, ETV6-RUNX1 BALLETV6RUNX1 BLLETV6RUNX1 Hematologic Malignancy B-cell Acute Lymphoblastic Leukemia, ETV6-RUNX1 like BALLETV6RUNX1L BLLRGA Hematologic Malignancy B-cell Acute Lymphoblastic Leukemia, HLF rearrangement BALLHLF BLLRGA Hematologic Malignancy B-cell Acute Lymphoblastic Leukemia, Hyperdiploidy BALLHYPER BLLHYPER Hematologic Malignancy B-cell Acute Lymphoblastic Leukemia, Hypodiploidy BALLHYPO BLLHYPO Hematologic Malignancy B-cell Acute Lymphoblastic Leukemia, iAMP21 BALLIAMP21 BLLIAMP21 Hematologic Malignancy B-cell Acute Lymphoblastic Leukemia, IGH-CEBPD BALLIGHCEBPD BLLRGA Hematologic Malignancy B-cell Acute Lymphoblastic Leukemia, KMT2A rearrangement BALLKMT2A BLLKMT2A Hematologic Malignancy B-cell Acute Lymphoblastic Leukemia, MEF2D rearrangement BALLMEF2D BLLRGA Hematologic Malignancy B-cell Acute Lymphoblastic Leukemia, MYC rearrangement BALLMYC BLLRGA Hematologic Malignancy B-cell Acute Lymphoblastic Leukemia, NOS BALLNOS BLLNOS Hematologic Malignancy B-cell Acute Lymphoblastic Leukemia, NUTM1 rearrangement BALLNUTM1 BLLRGA Hematologic Malignancy B-cell Acute Lymphoblastic Leukemia, PAX5 Alteration BALLPAX5 BLLRGA Hematologic Malignancy B-cell Acute Lymphoblastic Leukemia, PAX5 P80R BALLPAX5P80R BLLRGA Hematologic Malignancy B-cell Acute Lymphoblastic Leukemia, TCF3-PBX1 BALLTCF3PBX1 BLLTCF3PBX1 Hematologic Malignancy B-cell Acute Lymphoblastic Leukemia, ZNF384 rearrangement BALLZNF384 BLLRGA Hematologic Malignancy B-cell Acute Lymphoblastic Leukemia, ZNF384 rearrangement like BALLZNF384L BLLRGA Hematologic Malignancy Blood Cancer of Unknown Primary BCUP CUP Hematologic Malignancy Burkitt Lymphoma BL BL Hematologic Malignancy Chronic Myeloid Leukemia CML CML Hematologic Malignancy Diffuse Large B-cell Lymphoma, NOS DLBCLNOS DLBCLNOS Hematologic Malignancy General Leukemia SJGENLK Hematologic Malignancy Hodgkin Lymphoma HL HL Hematologic Malignancy Langerhans Cell Histiocytosis LCH LCH Hematologic Malignancy Lymphocyte-Depleted Classical Hodgkin Lymphoma LDCHL LDCHL Hematologic Malignancy Lymphocyte-Rich Classical Hodgkin Lymphoma LRCHL LRCHL Hematologic Malignancy Mixed Cellularity Classical Hodgkin Lymphoma MCCHL MCCHL Hematologic Malignancy Mycosis Fungoides MYCF MYCF Hematologic Malignancy Myelodysplastic Syndromes MDS MDS Hematologic Malignancy Myeloid Sarcoma MS MS Hematologic Malignancy Nodular Lymphocyte-Predominant Hodgkin Lymphoma NLPHL NLPHL Hematologic Malignancy Nodular Sclerosis Classical Hodgkin Lymphoma NSCHL NSCHL Hematologic Malignancy Non-Hodgkin Lymphoma NHL NHL Hematologic Malignancy T-cell Acute Lymphoblastic Leukemia TALL TLL Hematologic Malignancy T-cell Acute Lymphoblastic Leukemia, KMT2A rearrangement TALLKMT2A TLL Hematologic Malignancy T-cell Lymphoblastic Lymphoma TLL TLL Non-Malignancy Non-Malignancy SJNM Normal SJLIFE Normal Control SJNORM Sickle Cell Disease Sickle Cell Disease SJSCD Solid Tumor Acinar Cell Carcinoma ACN ACN Solid Tumor Adenocarcinoma, NOS ADNOS ADNOS Solid Tumor Adrenocortical Carcinoma ACC ACC Solid Tumor Alveolar Rhabdomyosarcoma ARMS ARMS Solid Tumor Alveolar Soft Part Sarcoma ASPS ASPS Solid Tumor Angiomatoid Fibrous Histiocytoma AFH AFH Solid Tumor Basal Cell Carcinoma BCC BCC Solid Tumor Botryoid Type Embryonal Rhabdomyosarcoma BERMS ERMS Solid Tumor Carcinoma, NOS CNOS CUP Solid Tumor Chondroblastic Osteosarcoma CHOS CHOS Solid Tumor Chondrosarcoma CHS CHS Solid Tumor Chordoma CHDM CHDM Solid Tumor Clear Cell Sarcoma of Kidney CCSK CCSK Solid Tumor Congenital Mesoblastic Nephroma CMN RCC Solid Tumor Dermatofibrosarcoma Protuberans DFSP DFSP Solid Tumor Desmoid/Aggressive Fibromatosis DES DES Solid Tumor Desmoplastic Small Round Cell Tumor DSRCT DSRCT Solid Tumor Embryonal Rhabdomyosarcoma ERMS ERMS Solid Tumor Endometrioid Adenocarcinoma, NOS EACNOS ADNOS Solid Tumor Epithelioid Hemangioendothelioma EHAE EHAE Solid Tumor Epithelioid Sarcoma EPIS EPIS Solid Tumor Ewing Sarcoma EWS ES Solid Tumor Fibroblastic Osteosarcoma FIOS FIOS Solid Tumor Fibromyxoid Sarcoma FMS Solid Tumor Fibrosarcoma, NOS FIBS FIBS Solid Tumor Follicular Thyroid Cancer THFO THFO Solid Tumor Ganglioneuroblastoma GNBL GNBL Solid Tumor Ganglioneuroma GN GN Solid Tumor Gastrointestinal Stromal Tumor GIST GIST Solid Tumor General Bone Tumor SJGENBN Solid Tumor Giant Cell Tumor, NOS GICT GCTB Solid Tumor Granulosa Cell Tumor GRCT GRCT Solid Tumor Hepatoblastoma HB LIHB Solid Tumor Hepatocellular Carcinoma HCC HCC Solid Tumor Infantile Fibrosarcoma IFS IFS Solid Tumor Leiomyosarcoma, NOS LMS LMS Solid Tumor Liposarcoma LIPO LIPO Solid Tumor Liver Malignancy, NOS LMNOS Solid Tumor Malignant Fibrous Histiocytoma MFH MFH Solid Tumor Malignant Mesenchymoma MME Solid Tumor Malignant Mesenchymoma of the Liver MMEL Solid Tumor Malignant Peripheral Nerve Sheath Tumor MPNST MPNST Solid Tumor Malignant Rhabdoid Tumor of the Liver MRTL MRTL Solid Tumor Melanoma MEL MEL Solid Tumor Mesenchymal Chondrosarcoma MCHS MCHS Solid Tumor Mixed Spindle Cell and Embryonal Rhabdomyosarcoma MSCERMS RMS Solid Tumor Mucinous Adenocarcinoma of the Colon and Rectum MACR MACR Solid Tumor Mucinous Adenocarcinoma, NOS MACNOS Solid Tumor Mucoepidermoid Carcinoma MUCC MUCC Solid Tumor Nasopharyngeal Carcinoma NPC NPC Solid Tumor Neuroblastoma NBL NBL Solid Tumor Neurofibroma NFIB NFIB Solid Tumor Osteosarcoma OS OS Solid Tumor Pancreatic Neuroendocrine Tumor PANET PANET Solid Tumor Papillary Renal Cell Carcinoma PRCC PRCC Solid Tumor Papillary Thyroid Cancer THPA THPA Solid Tumor Paraganglioma PGNG PGNG Solid Tumor Parosteal Osteosarcoma PAOS PAOS Solid Tumor Periosteal Osteosarcoma PEOS PEOS Solid Tumor Pleuropulmonary Blastoma PPB PPB Solid Tumor Renal Cell Carcinoma RCC RCC Solid Tumor Renal Clear Cell Carcinoma CCRCC CCRCC Solid Tumor Retinoblastoma RBL RBL Solid Tumor Rhabdoid Cancer, Kidney MRT MRT Solid Tumor Rhabdomyosarcoma RMS RMS Solid Tumor Round Cell Sarcoma, NOS RCSNOS RCSNOS Solid Tumor Serous Surface Papillary Carcinoma SSPC Solid Tumor Small Cell Osteosarcoma SCOS SCOS Solid Tumor Soft Tissue Sarcoma, NOS STSNOS CUP Solid Tumor Solid Cancer of Unknown Primary SCUP CUP Solid Tumor Solitary Fibrous Tumor/Hemangiopericytoma SFT SFT Solid Tumor Spindle Cell Rhabdomyosarcoma SCRMS SCRMS Solid Tumor Spindle Cell Sarcoma, NOS SCSNOS Solid Tumor Spindle Cell/Sclerosing Rhabdomyosarcoma SCSRMS SCSRMS Solid Tumor Spindle Epithelial Tumor with Thymus-Like Differentiation SETTLE Solid Tumor Squamous Cell Carcinoma, NOS SCCNOS SCCNOS Solid Tumor Stomach Inflammatory Pseudotumor SIPT Solid Tumor Synovial Sarcoma SYNS SYNS Solid Tumor Telangiectatic Osteosarcoma TEOS TEOS Solid Tumor Undifferentiated Embryonal Sarcoma of the Liver UESL UESL Solid Tumor Wilms WT WT Solid Tumor Wilms, Bilateral WTB WT","title":"Diagnosis Codes"},{"location":"guides/genomics-platform/requesting-data/about-our-data/#similar-topics","text":"About our Decision Process & Terminology Making a Data Request Managing Data Overview","title":"Similar Topics"},{"location":"guides/genomics-platform/requesting-data/data-request/","text":"For-Profit Companies St. Jude Cloud does not allow for-profit companies to access any restricted access genomics data. We are actively working with our institution to assess the feasibility of providing data to for-profit entities. If you work for a for-profit company and would like to be notified if this restriction changes, feel free to email us at support@stjude.cloud . Request Process Overview \u00b6 Creating a data request is the premier way to access raw St. Jude next generation sequencing data in the cloud. You can get a free copy of the data in a secure cloud environment powered by Microsoft Azure and DNAnexus , or you can elect to download the data to your local computing environment. Helpful Things to Remember: \u00b6 Data in St. Jude Cloud is grouped into Data Access Units (DAUs) , which usually correspond to large-scale sequencing initiatives at St. Jude. Individuals can apply for access to DAUs on a case-by-case basis for a specific amount of time (usually 1 year). Access to data in a given DAU is assessed by the corresponding Data Access Committee who reviews a variety of factors to grant access. There are a number of terms of use and restrictions outlined in the Data Access Agreement . Everyone who will be working with the data must understand and agree to these terms. Selecting Data \u00b6 The primary way to make your data selection is through our Genomics Platform Data Browser . You can search our raw genomic data by diagnosis, publication, or study by selecting a tab along the top. You may further refine your search by applying filters from four categories: Sequencing Type, Sample Type, File Type, and Tissue Type. Please note that applying multiple filters within the same category filters using 'OR' logic while applying multiple filters across different categories filters using 'AND' logic. For example in the overview image above, we have filtered the browser to only show data that is (either WGS OR WES) AND (Diagnosis OR Relapse) AND BAM AND Paired Tumor-Normal. As you filter and make selections, the data summary panel in the upper left hand corner will update dynamically to give you important descriptive information about the set of data you have selected. Click on an empty box to make a selection; when selected, the box will turn blue with a white check mark. Once you have completed your data selection, click on Request Data to submit your request and proceed. Note You must have created an account and be logged in to submit a data request. If you have not yet created an account or you are not logged in, the submit button will say Log In rather than Request Data . Alternatively, you may be directed to the Genomics Platform Data Browser through another App to request specific samples. The PeCan homepage is one such app that allows you to select data through an interactive visualization. After clicking on Request Data , we ask that you review your selection and make sure that the DAUs corresponding to the set of data you have selected is indeed the data you want to request. Making the Request \u00b6 Now that you have selected your data, you will need to fill in some information to complete the request. From here, necessary information will be collected through a setup wizard. All of your progress will be automatically saved, and you can follow along with your progress on the left sidebar. This information will be collected whether you are requesting open-access or controlled-access data. It helps us structure your project folder correctly when we vend the data to you. Signing the Data Access Agreement \u00b6 Info If you already have access to the data or are requesting open-access data, you will not be prompted to go through this section. Every person who requests access to our controlled-access data must sign the Data Access Agreememnt (DAA) . If you are located in the United States of America, you can opt in to completing the DAA through an electronic setup wizard. If you are not located in the USA, or would like to complete the form manually, you can follow our instructions on Filling Out The Data Access Agreement . If you opt to do the process through the setup wizard, the necessary information will be collected and added automatically to your agreement. Once you have completed the setup wizard, the form will be sent to you and necessary signatories through email via DocuSign . You can learn more about our electronic data access agreement process here . Request approval typically takes a week or two if your data access agreement is correctly and completely filled out. You will receive automated emails from notifications@stjude.cloud at the time that your request is approved. Tip If you receive an email from us that your DAA is incomplete, you may edit your DAA and upload the revised copy using the 'Add a Form' button the on My Dashboard page. Managing your Data Request \u00b6 Go to our Managing Data Overview documentation page to learn how to check the status of your data request, complete an EDAA draft, upload a revised DAA, and ultimately access your data from your My Dashboard page. Info If you would like to download the data to local storage, there are extra steps you'll need to follow such as getting additional signatures on your data access agreement. We recommend that you work with the data in the cloud if it's feasible; the data provided by St. Jude is free, the compute charges are reasonable, and working in the cloud helps to eliminate the long, error-prone downloading process. Porting your tools to be run in the cloud is easy, as well. We recommend you follow this guide to get started. Similar Topics \u00b6 About our Data About our Decision Process & Terminology Creating an Account Managing Data Overview Renewing your Data Access","title":"Making a Data Request"},{"location":"guides/genomics-platform/requesting-data/data-request/#request-process-overview","text":"Creating a data request is the premier way to access raw St. Jude next generation sequencing data in the cloud. You can get a free copy of the data in a secure cloud environment powered by Microsoft Azure and DNAnexus , or you can elect to download the data to your local computing environment.","title":"Request Process Overview"},{"location":"guides/genomics-platform/requesting-data/data-request/#helpful-things-to-remember","text":"Data in St. Jude Cloud is grouped into Data Access Units (DAUs) , which usually correspond to large-scale sequencing initiatives at St. Jude. Individuals can apply for access to DAUs on a case-by-case basis for a specific amount of time (usually 1 year). Access to data in a given DAU is assessed by the corresponding Data Access Committee who reviews a variety of factors to grant access. There are a number of terms of use and restrictions outlined in the Data Access Agreement . Everyone who will be working with the data must understand and agree to these terms.","title":"Helpful Things to Remember:"},{"location":"guides/genomics-platform/requesting-data/data-request/#selecting-data","text":"The primary way to make your data selection is through our Genomics Platform Data Browser . You can search our raw genomic data by diagnosis, publication, or study by selecting a tab along the top. You may further refine your search by applying filters from four categories: Sequencing Type, Sample Type, File Type, and Tissue Type. Please note that applying multiple filters within the same category filters using 'OR' logic while applying multiple filters across different categories filters using 'AND' logic. For example in the overview image above, we have filtered the browser to only show data that is (either WGS OR WES) AND (Diagnosis OR Relapse) AND BAM AND Paired Tumor-Normal. As you filter and make selections, the data summary panel in the upper left hand corner will update dynamically to give you important descriptive information about the set of data you have selected. Click on an empty box to make a selection; when selected, the box will turn blue with a white check mark. Once you have completed your data selection, click on Request Data to submit your request and proceed. Note You must have created an account and be logged in to submit a data request. If you have not yet created an account or you are not logged in, the submit button will say Log In rather than Request Data . Alternatively, you may be directed to the Genomics Platform Data Browser through another App to request specific samples. The PeCan homepage is one such app that allows you to select data through an interactive visualization. After clicking on Request Data , we ask that you review your selection and make sure that the DAUs corresponding to the set of data you have selected is indeed the data you want to request.","title":"Selecting Data"},{"location":"guides/genomics-platform/requesting-data/data-request/#making-the-request","text":"Now that you have selected your data, you will need to fill in some information to complete the request. From here, necessary information will be collected through a setup wizard. All of your progress will be automatically saved, and you can follow along with your progress on the left sidebar. This information will be collected whether you are requesting open-access or controlled-access data. It helps us structure your project folder correctly when we vend the data to you.","title":"Making the Request"},{"location":"guides/genomics-platform/requesting-data/data-request/#signing-the-data-access-agreement","text":"Info If you already have access to the data or are requesting open-access data, you will not be prompted to go through this section. Every person who requests access to our controlled-access data must sign the Data Access Agreememnt (DAA) . If you are located in the United States of America, you can opt in to completing the DAA through an electronic setup wizard. If you are not located in the USA, or would like to complete the form manually, you can follow our instructions on Filling Out The Data Access Agreement . If you opt to do the process through the setup wizard, the necessary information will be collected and added automatically to your agreement. Once you have completed the setup wizard, the form will be sent to you and necessary signatories through email via DocuSign . You can learn more about our electronic data access agreement process here . Request approval typically takes a week or two if your data access agreement is correctly and completely filled out. You will receive automated emails from notifications@stjude.cloud at the time that your request is approved. Tip If you receive an email from us that your DAA is incomplete, you may edit your DAA and upload the revised copy using the 'Add a Form' button the on My Dashboard page.","title":"Signing the Data Access Agreement"},{"location":"guides/genomics-platform/requesting-data/data-request/#managing-your-data-request","text":"Go to our Managing Data Overview documentation page to learn how to check the status of your data request, complete an EDAA draft, upload a revised DAA, and ultimately access your data from your My Dashboard page. Info If you would like to download the data to local storage, there are extra steps you'll need to follow such as getting additional signatures on your data access agreement. We recommend that you work with the data in the cloud if it's feasible; the data provided by St. Jude is free, the compute charges are reasonable, and working in the cloud helps to eliminate the long, error-prone downloading process. Porting your tools to be run in the cloud is easy, as well. We recommend you follow this guide to get started.","title":"Managing your Data Request"},{"location":"guides/genomics-platform/requesting-data/data-request/#similar-topics","text":"About our Data About our Decision Process & Terminology Creating an Account Managing Data Overview Renewing your Data Access","title":"Similar Topics"},{"location":"guides/genomics-platform/requesting-data/glossary/","text":"Data Access Unit \u00b6 A St. Jude Cloud Data Access Unit (DAU) is a grouping of data that typically corresponds to a project, study, or dataset generated at the same time at the same institution. Each DAU has its own governing body of researchers, the Data Access Committee , who preside over the data and who may grant or deny access. Each Data Access Committee has its own protocols for approving access to their DAU. Please contact us if you have questions about committee approval protocols. We currently have 5 DAUs: Pediatric Cancer Genome Project (PCGP), St. Jude Lifetime Cohort Study (SJLIFE), Genomes for Kids (G4K) and Clinical Genomics, Sickle Cell Genome Project (SGP), and Childhood Cancer Survivor Study (CCSS). For a brief description of each DAU see the Studies page . For a more detailed description please see the respective Schedule 1(s) . Data Access Agreement \u00b6 A St. Jude Cloud Data Access Agreement (DAA) is a legally binding document outlining a number of terms and conditions to which anyone working with St. Jude Cloud data must agree. We do not negotiate the terms of this document unless terms are found to be in conflict with the institution's state law. Filling out the Data Access Agreement carefully and completely is crucial to having your request approved promptly. Click Here to download a copy of the DAA. Click Here for a step by step guide on how to fill out the DAA. If you have incompletely or incorrectly filled out your DAA and would like to upload a revised form, Click Here for instructions. Once you have submitted a correctly filled out DAA and have been granted access to one or more Data Access Units (DAUs) , you can continue checking out files from those DAUs until your access expires. Access is generally granted for 1 year, at which point you must submit an Extension Addendum to continue using the data. Click Here for a step-by-step guide on how to fill out the Extension Addendum. Data Access Committee \u00b6 A St. Jude Cloud Data Access Committee (DAC) is group of St. Jude researchers who oversee access to a particular Data Access Unit (DAU) and evaluate incoming data requests. The first time you request access to files in a DAU, it is required that you fill out a Data Access Agreement (DAA) . Access is granted at the DAU level based on the decision of each DAC upon reviewing the DAA. Example For example, if you make a request asking for all of St. Jude's Acute Lymphoblastic Leukemia sequencing data, you might be asking for data from multiple different projects (DAUs) here at St. Jude. For the sake of the example, let's say the data you want is spread across three different DAUs. Once you place a request, your application will be routed to the corresponding three data access committees for approval. Since each DAC is made up of different individuals using different criteria for evaluation, you may or may not be approved for access to all of the files. Embargo Date \u00b6 The Embargo Date specifies the date that a publishing embargo on the file in question has been lifted. Publishing using any of the files before the embargo date has passed is strictly prohibited as outlined in the Data Access Agreement (DAA) . Typically, samples from the same Data Access Unit (DAU) all have the same embargo date, as they would have been released on St. Jude Cloud at the same time. Current Embargo Dates Data Access Unit Embargo Date Pediatric Cancer Genome Project July 23, 2018 St. Jude LIFE January 15, 2019 Clinical Genomics Rolling based on release date Sickle Cell Genome Project September 1, 2019 Childhood Cancer Survivor Study November 1, 2019 Pan-Acute Lymphoblastic Leukemia January 14, 2019 Similar Topics \u00b6 About our Data","title":"About our Decision Process & Terminology"},{"location":"guides/genomics-platform/requesting-data/glossary/#data-access-unit","text":"A St. Jude Cloud Data Access Unit (DAU) is a grouping of data that typically corresponds to a project, study, or dataset generated at the same time at the same institution. Each DAU has its own governing body of researchers, the Data Access Committee , who preside over the data and who may grant or deny access. Each Data Access Committee has its own protocols for approving access to their DAU. Please contact us if you have questions about committee approval protocols. We currently have 5 DAUs: Pediatric Cancer Genome Project (PCGP), St. Jude Lifetime Cohort Study (SJLIFE), Genomes for Kids (G4K) and Clinical Genomics, Sickle Cell Genome Project (SGP), and Childhood Cancer Survivor Study (CCSS). For a brief description of each DAU see the Studies page . For a more detailed description please see the respective Schedule 1(s) .","title":"Data Access Unit"},{"location":"guides/genomics-platform/requesting-data/glossary/#data-access-agreement","text":"A St. Jude Cloud Data Access Agreement (DAA) is a legally binding document outlining a number of terms and conditions to which anyone working with St. Jude Cloud data must agree. We do not negotiate the terms of this document unless terms are found to be in conflict with the institution's state law. Filling out the Data Access Agreement carefully and completely is crucial to having your request approved promptly. Click Here to download a copy of the DAA. Click Here for a step by step guide on how to fill out the DAA. If you have incompletely or incorrectly filled out your DAA and would like to upload a revised form, Click Here for instructions. Once you have submitted a correctly filled out DAA and have been granted access to one or more Data Access Units (DAUs) , you can continue checking out files from those DAUs until your access expires. Access is generally granted for 1 year, at which point you must submit an Extension Addendum to continue using the data. Click Here for a step-by-step guide on how to fill out the Extension Addendum.","title":"Data Access Agreement"},{"location":"guides/genomics-platform/requesting-data/glossary/#data-access-committee","text":"A St. Jude Cloud Data Access Committee (DAC) is group of St. Jude researchers who oversee access to a particular Data Access Unit (DAU) and evaluate incoming data requests. The first time you request access to files in a DAU, it is required that you fill out a Data Access Agreement (DAA) . Access is granted at the DAU level based on the decision of each DAC upon reviewing the DAA. Example For example, if you make a request asking for all of St. Jude's Acute Lymphoblastic Leukemia sequencing data, you might be asking for data from multiple different projects (DAUs) here at St. Jude. For the sake of the example, let's say the data you want is spread across three different DAUs. Once you place a request, your application will be routed to the corresponding three data access committees for approval. Since each DAC is made up of different individuals using different criteria for evaluation, you may or may not be approved for access to all of the files.","title":"Data Access Committee"},{"location":"guides/genomics-platform/requesting-data/glossary/#embargo-date","text":"The Embargo Date specifies the date that a publishing embargo on the file in question has been lifted. Publishing using any of the files before the embargo date has passed is strictly prohibited as outlined in the Data Access Agreement (DAA) . Typically, samples from the same Data Access Unit (DAU) all have the same embargo date, as they would have been released on St. Jude Cloud at the same time. Current Embargo Dates Data Access Unit Embargo Date Pediatric Cancer Genome Project July 23, 2018 St. Jude LIFE January 15, 2019 Clinical Genomics Rolling based on release date Sickle Cell Genome Project September 1, 2019 Childhood Cancer Survivor Study November 1, 2019 Pan-Acute Lymphoblastic Leukemia January 14, 2019","title":"Embargo Date"},{"location":"guides/genomics-platform/requesting-data/glossary/#similar-topics","text":"About our Data","title":"Similar Topics"},{"location":"guides/genomics-platform/requesting-data/how-to-fill-out-DAA/","text":"Filling Out The Data Access Agreement The Data Access Agreement (DAA) is a legal document used by St. Jude Cloud to verify the identity and intent of those requesting to access St. Jude Children\u2019s Research Hospital\u2019s genomics data. The document binds you and your institution in agreement to protect, use and share the data appropriately. Upon selection of your desired data, you will be prompted to complete a Data Access Agreement if you have not already been approved for access to the selected datasets. In order to simplify the data access request process, an electronic data access agreement is available for US residents only. If you reside outside of the US, you must fill out the Data Access Agreement manually. You may click here to download the latest version of the DAA. Please read the first 6 pages carefully, which consist of terms and conditions that you and your institution must agree to in order to access any data on St. Jude Cloud. Then, follow the directions starting at Data Access Units to ensure that you have correctly filled out the DAA. Please note that there are two additional required sections if you intend to download data to your local infrastructure. The Data Access Agreement \u00b6 Downloading Data \u00b6 If and only if you wish to download the genomic data locally, you must have the Principal Investigator initial on page 7 and have the Information Security Officer sign on page 13. If filling out the Data Access Agreement electronically, you must select the option to download within the setup wizard and input the contact information of your institution\u2019s Information Security Officer. Data Access Units \u00b6 A St. Jude Cloud Data Access Unit (DAU) is a grouping of data that typically corresponds to a project, study, or dataset generated at the same time at the same institution. To learn more, see our section on Data Access Units . On page 7 of the DAA, you must mark all Data Access Units for which you are applying. The DAU(s) associated to the data you requested are listed in the Controlled Access Data section, directly above the Download Data Access Agreement button. This can be found on the Request Data webpage which immediately follows your selection of data from the data browser. If you mark the incorrect datasets, you will be required to resubmit your agreement with the correct datasets marked. When completing the DAA electronically using the setup wizard, the DAU options will be automatically preselected for you. Contemplated Use \u00b6 On page 8 of the DAA, you must submit a description of your research project. Please specifically describe the intended role of St. Jude\u2019s data in your research project. Your contemplated use can be anywhere from a paragraph to a few pages long, although a typical contemplated use is 1-2 paragraphs. Each Data Access Committee will evaluate your contemplated use case and decide whether to approve or deny your application for data access based on their own set of protocols. Please contact us if you have any questions regarding the protocols of the approval process. Contemplated Use Example \u00b6 The below is a simulated example of a contemplated use. \"We propose to apply our own variant calling method to detect structural variants in both pediatric tumor and germline samples. The detected variants will then be compared to our own genomic data and to publicly available data sources of normal and disease samples to assess the novelty of those variants and their association with disease. Variants will be categorized by their expected effect on genes known to be relevant to cancer, DNA repair, or epigenetics. One goal of the research is to compare our mutation detection software to existing methods on samples with known mutations and structural variants such as those in the PCGP data set. Another goal is the identification of novel variants with potential clinical relevance. Promising tractable variants will be introduced into cell lines to observe their effect on cell growth and tumor progression. Lastly, we propose to use the results of our analyses to further develop and refine our variant detection methods.\" Principal Investigator \u00b6 On page 9 of the DAA, the Principal Investigator of the research project must input their information and sign the agreement. Typically the PI signee is the faculty-level supervisor on the project, but it is not a requirement. Who may qualify as a Principal Investigator (PI)? The PI is designated by the grantee organization to direct the project or activity being supported by the grant. The PI is responsible and accountable to the grantee for the proper conduct of the project or activity. The role of the PI within the eRA Commons is to complete the grant process, either by completing the required forms via the eRA Commons or by delegating this responsibility to another individual. A PI can access information for any grant for which they are designated the PI. See eRA Commons Roles & Privileges Matrix. Additional Applicants \u00b6 Pages 10 and 11 of the DAA must be signed by any additional person(s) who will have access to the data. Additional applicants may include those working on your project, those working in your lab, or those who have access to where the data will be stored. These individuals will be legally bound to protecting and handling the data properly. Pages 10 and 11 may be duplicated and added to the agreement to accommodate for more than 8 additional applicants. When filling out the DAA electronically, you may only include up to 8 additional applicants on your agreement. Institutional Authority \u00b6 Page 12 of the agreement must be filled out and signed by your Institutional or Administrative Authority. The institutional authority is an individual who has the authority to sign for a grant application. This individual cannot be the same as the Principal Investigator that signed on page 9, as this additional signature provides a second-party authority of the institution to ensure that the institution will uphold the terms of this agreement. Information Security Officer \u00b6 On page 13 of the DAA, your institution\u2019s Information Security Officer's signature is required if and only if you intend to download a local copy of the data (note: you must also initial in the line below the DAU selection). This individual may go by varying job titles, such as Information Director or Chief Information Security Officer, but is the individual responsible for information security at your institution. This signature verifies that the data, once downloaded, will remain protected by your institution's data security protocols. Uploading A Revised DAA \u00b6 If your DAA is incomplete (for example you missed a required signature or neglected to check the box next to a dataset for which you requested data), you will be contacted by a member of the St. Jude Cloud team. Once you have made the required edits, you can reupload a revised DAA through the Manage Data page by clicking on the Add a Form button. The Electronic Data Access Agreement Process \u00b6 Users who live in the United States will be given the option to complete the Data Access Agreement electronically or manually. If you elect to complete it electronically, the setup wizard will request information about you, your institution and your associates. You will also be asked to provide a detailed description of the research project in which the data you have requested will be used. After submitting the required information, the Data Access Agreement will be sent via email to each individual entered through the setup wizard. Each individual must follow the link in their email to sign the appropriate page of the agreement via DocuSign. If any individual rejects or declines to sign the agreement, you will need to start a new data request from the data browser. Once you start the Electronic Data Access Agreement process, you will have a draft autosaved for you on your My Dashboard page, accessible at any time. Learn how to check your Request Status Once all signatures have been collected, your data access request will be submitted to St. Jude Cloud. A St. Jude Cloud administrator will forward your Data Access Agreement and intended use to the appropriate Data Access Committee(s) for approval. Upon approval from the DAC(s), you will receive an email with a link to the approved data, which will be hosted through DNAnexus. Similar Topics \u00b6 Studies Making a Data Request Renewing your Data Access Managing Data Overview","title":"Filling Out a Data Access Agreement"},{"location":"guides/genomics-platform/requesting-data/how-to-fill-out-DAA/#the-data-access-agreement","text":"","title":"The Data Access Agreement"},{"location":"guides/genomics-platform/requesting-data/how-to-fill-out-DAA/#downloading-data","text":"If and only if you wish to download the genomic data locally, you must have the Principal Investigator initial on page 7 and have the Information Security Officer sign on page 13. If filling out the Data Access Agreement electronically, you must select the option to download within the setup wizard and input the contact information of your institution\u2019s Information Security Officer.","title":"Downloading Data"},{"location":"guides/genomics-platform/requesting-data/how-to-fill-out-DAA/#data-access-units","text":"A St. Jude Cloud Data Access Unit (DAU) is a grouping of data that typically corresponds to a project, study, or dataset generated at the same time at the same institution. To learn more, see our section on Data Access Units . On page 7 of the DAA, you must mark all Data Access Units for which you are applying. The DAU(s) associated to the data you requested are listed in the Controlled Access Data section, directly above the Download Data Access Agreement button. This can be found on the Request Data webpage which immediately follows your selection of data from the data browser. If you mark the incorrect datasets, you will be required to resubmit your agreement with the correct datasets marked. When completing the DAA electronically using the setup wizard, the DAU options will be automatically preselected for you.","title":"Data Access Units"},{"location":"guides/genomics-platform/requesting-data/how-to-fill-out-DAA/#contemplated-use","text":"On page 8 of the DAA, you must submit a description of your research project. Please specifically describe the intended role of St. Jude\u2019s data in your research project. Your contemplated use can be anywhere from a paragraph to a few pages long, although a typical contemplated use is 1-2 paragraphs. Each Data Access Committee will evaluate your contemplated use case and decide whether to approve or deny your application for data access based on their own set of protocols. Please contact us if you have any questions regarding the protocols of the approval process.","title":"Contemplated Use"},{"location":"guides/genomics-platform/requesting-data/how-to-fill-out-DAA/#contemplated-use-example","text":"The below is a simulated example of a contemplated use. \"We propose to apply our own variant calling method to detect structural variants in both pediatric tumor and germline samples. The detected variants will then be compared to our own genomic data and to publicly available data sources of normal and disease samples to assess the novelty of those variants and their association with disease. Variants will be categorized by their expected effect on genes known to be relevant to cancer, DNA repair, or epigenetics. One goal of the research is to compare our mutation detection software to existing methods on samples with known mutations and structural variants such as those in the PCGP data set. Another goal is the identification of novel variants with potential clinical relevance. Promising tractable variants will be introduced into cell lines to observe their effect on cell growth and tumor progression. Lastly, we propose to use the results of our analyses to further develop and refine our variant detection methods.\"","title":"Contemplated Use Example"},{"location":"guides/genomics-platform/requesting-data/how-to-fill-out-DAA/#principal-investigator","text":"On page 9 of the DAA, the Principal Investigator of the research project must input their information and sign the agreement. Typically the PI signee is the faculty-level supervisor on the project, but it is not a requirement. Who may qualify as a Principal Investigator (PI)? The PI is designated by the grantee organization to direct the project or activity being supported by the grant. The PI is responsible and accountable to the grantee for the proper conduct of the project or activity. The role of the PI within the eRA Commons is to complete the grant process, either by completing the required forms via the eRA Commons or by delegating this responsibility to another individual. A PI can access information for any grant for which they are designated the PI. See eRA Commons Roles & Privileges Matrix.","title":"Principal Investigator"},{"location":"guides/genomics-platform/requesting-data/how-to-fill-out-DAA/#additional-applicants","text":"Pages 10 and 11 of the DAA must be signed by any additional person(s) who will have access to the data. Additional applicants may include those working on your project, those working in your lab, or those who have access to where the data will be stored. These individuals will be legally bound to protecting and handling the data properly. Pages 10 and 11 may be duplicated and added to the agreement to accommodate for more than 8 additional applicants. When filling out the DAA electronically, you may only include up to 8 additional applicants on your agreement.","title":"Additional Applicants"},{"location":"guides/genomics-platform/requesting-data/how-to-fill-out-DAA/#institutional-authority","text":"Page 12 of the agreement must be filled out and signed by your Institutional or Administrative Authority. The institutional authority is an individual who has the authority to sign for a grant application. This individual cannot be the same as the Principal Investigator that signed on page 9, as this additional signature provides a second-party authority of the institution to ensure that the institution will uphold the terms of this agreement.","title":"Institutional Authority"},{"location":"guides/genomics-platform/requesting-data/how-to-fill-out-DAA/#information-security-officer","text":"On page 13 of the DAA, your institution\u2019s Information Security Officer's signature is required if and only if you intend to download a local copy of the data (note: you must also initial in the line below the DAU selection). This individual may go by varying job titles, such as Information Director or Chief Information Security Officer, but is the individual responsible for information security at your institution. This signature verifies that the data, once downloaded, will remain protected by your institution's data security protocols.","title":"Information Security Officer"},{"location":"guides/genomics-platform/requesting-data/how-to-fill-out-DAA/#uploading-a-revised-daa","text":"If your DAA is incomplete (for example you missed a required signature or neglected to check the box next to a dataset for which you requested data), you will be contacted by a member of the St. Jude Cloud team. Once you have made the required edits, you can reupload a revised DAA through the Manage Data page by clicking on the Add a Form button.","title":"Uploading A Revised DAA"},{"location":"guides/genomics-platform/requesting-data/how-to-fill-out-DAA/#the-electronic-data-access-agreement-process","text":"Users who live in the United States will be given the option to complete the Data Access Agreement electronically or manually. If you elect to complete it electronically, the setup wizard will request information about you, your institution and your associates. You will also be asked to provide a detailed description of the research project in which the data you have requested will be used. After submitting the required information, the Data Access Agreement will be sent via email to each individual entered through the setup wizard. Each individual must follow the link in their email to sign the appropriate page of the agreement via DocuSign. If any individual rejects or declines to sign the agreement, you will need to start a new data request from the data browser. Once you start the Electronic Data Access Agreement process, you will have a draft autosaved for you on your My Dashboard page, accessible at any time. Learn how to check your Request Status Once all signatures have been collected, your data access request will be submitted to St. Jude Cloud. A St. Jude Cloud administrator will forward your Data Access Agreement and intended use to the appropriate Data Access Committee(s) for approval. Upon approval from the DAC(s), you will receive an email with a link to the approved data, which will be hosted through DNAnexus.","title":"The Electronic Data Access Agreement Process"},{"location":"guides/genomics-platform/requesting-data/how-to-fill-out-DAA/#similar-topics","text":"Studies Making a Data Request Renewing your Data Access Managing Data Overview","title":"Similar Topics"},{"location":"guides/pecan/","text":"PeCan PeCan provides interactive visualizations of pediatric cancer mutations across various projects at St. Jude Children's Research Hospital and its collaborating institutions. Homepage \u00b6 The PeCan homepage contains two main visualizations that work with each other to give a high level overview of the data being presented (SJ Cloud's PCGP dataset along with curated datasets from other institutions such as TARGET , dkfz , and others). Donut Chart \u00b6 The donut chart (shown below) gives an at-a-glance disease distribution and disease hierarchy. You can hover over the various donut slices to glance at the number (and %) of samples being represented by that disease. The diseases are categorized in two three main root categories: 1) HM -Hematopoietic Malignancies, 2) BT -Brain Tumor, 3) ST -Solid Tumor. Click here for a full mapping of disease codes. Bubble Chart \u00b6 Any slice (at any level) of the donut chart can be clicked on to select it, and reveal a bubble chart of related genes. Note that the dataset bar (shown below) on top of the bubble chart visualizes the distribution of selected data across the datasets used in this visualization. It will update dynamically as you interact with the donut chart and make different selections. An example of the bubble chart is shown below. You can see the selected disease shown at the top (1). The bubbles represent the most prevalent genes in the selected disease sample set. The size of the bubble corresponds to the number of mutations in the set with that gene. For some disease sets (like the one shown above), we have identified the most important disease pathway for the gene and have categorized them as such. This information is represented here via the use of colors. The legend at the bottom allows you to view the pathway information being shown (including the number of genes that are attached to each pathway). Hovering over a pathway in the legend will highlight all matching genes. Clicking a gene will open it's ProteinPaint view. To learn more about the software behind ProteinPaint, visit the ProteinPaint documentation . Requesting Raw Genomics through PeCan \u00b6 Add samples to your cart by diagnosis. Add samples to your cart by gene mutation. Add samples to your cart by gene expression. Clicking Submit to SJCloud from the PeCan checkout window will land you back in the Data Browser with your checked out data selected.","title":"Getting Started"},{"location":"guides/pecan/#homepage","text":"The PeCan homepage contains two main visualizations that work with each other to give a high level overview of the data being presented (SJ Cloud's PCGP dataset along with curated datasets from other institutions such as TARGET , dkfz , and others).","title":"Homepage"},{"location":"guides/pecan/#donut-chart","text":"The donut chart (shown below) gives an at-a-glance disease distribution and disease hierarchy. You can hover over the various donut slices to glance at the number (and %) of samples being represented by that disease. The diseases are categorized in two three main root categories: 1) HM -Hematopoietic Malignancies, 2) BT -Brain Tumor, 3) ST -Solid Tumor. Click here for a full mapping of disease codes.","title":"Donut Chart"},{"location":"guides/pecan/#bubble-chart","text":"Any slice (at any level) of the donut chart can be clicked on to select it, and reveal a bubble chart of related genes. Note that the dataset bar (shown below) on top of the bubble chart visualizes the distribution of selected data across the datasets used in this visualization. It will update dynamically as you interact with the donut chart and make different selections. An example of the bubble chart is shown below. You can see the selected disease shown at the top (1). The bubbles represent the most prevalent genes in the selected disease sample set. The size of the bubble corresponds to the number of mutations in the set with that gene. For some disease sets (like the one shown above), we have identified the most important disease pathway for the gene and have categorized them as such. This information is represented here via the use of colors. The legend at the bottom allows you to view the pathway information being shown (including the number of genes that are attached to each pathway). Hovering over a pathway in the legend will highlight all matching genes. Clicking a gene will open it's ProteinPaint view. To learn more about the software behind ProteinPaint, visit the ProteinPaint documentation .","title":"Bubble Chart"},{"location":"guides/pecan/#requesting-raw-genomics-through-pecan","text":"Add samples to your cart by diagnosis. Add samples to your cart by gene mutation. Add samples to your cart by gene expression. Clicking Submit to SJCloud from the PeCan checkout window will land you back in the Data Browser with your checked out data selected.","title":"Requesting Raw Genomics through PeCan"},{"location":"guides/pecan/faq/","text":"Frequently Asked Questions Will I be charged for using St. Jude Cloud PeCan? Will St. Jude Cloud host my institution's data in the data browser or on PeCan? Will I be charged for using St. Jude Cloud PeCan? \u00b6 You will not incur any costs for using PeCan. Will St. Jude Cloud host my institution's data in the data browser or on PeCan? \u00b6 If you are interested in submitting data to St. Jude Cloud, please contact us at support@stjude.cloud","title":"Frequently Asked Questions"},{"location":"guides/pecan/faq/#will-i-be-charged-for-using-st-jude-cloud-pecan","text":"You will not incur any costs for using PeCan.","title":"Will I be charged for using St. Jude Cloud PeCan?"},{"location":"guides/pecan/faq/#will-st-jude-cloud-host-my-institutions-data-in-the-data-browser-or-on-pecan","text":"If you are interested in submitting data to St. Jude Cloud, please contact us at support@stjude.cloud","title":"Will St. Jude Cloud host my institution's data in the data browser or on PeCan?"},{"location":"guides/pecan/pecan-pie/","text":"Pecan PIE Authors Michael Edmonson, Aman Patel Publication Edmonson et al., Genome Research 2019 Technical Support Contact Us Pecan PIE (the **Pe**diatric **Can**cer Variant **P**athogenicity **I**nformation **E**xchange) is a cloud-based variant classification and interpretation service. It annotates and ranks variants by putative pathogenicity, then displays them in an interactive web interface for formal review and classification following ACMG guidelines . The portal also contains a repository of expert-reviewed germline mutations that may predispose individuals to cancer. It is free for non-commercial use. Pecan PIE utilizes St. Jude Medal Ceremony, the same pipeline that powers our clinical and research genomics projects. Medal Ceremony provides a 3-level ranking of putative pathogenicity - Gold, Silver or Bronze - for mutations within disease-related genes. Medal assignment is based on matches to 22 mutation databases, mutation type, population frequency, tumor suppressor status and predicted functional impact. The evidence used for medal assignment is imported into an interactive variant review page where an analyst can enter additional curated information such as primary diagnosis, presence of subsequent neoplasm, family history and related literature. Classification tags can be assigned to curated data enabling automated calculation of pathogenicity rating based on ACMG/AMP 2015 guidelines. See file_download PowerPoint slides presented at the ASHG 2017 annual meeting (note that some of this information is out of date, various improvements have been made since then). Go to https://pecan.stjude.cloud/pie to get started! Overview \u00b6 An overview of the Pecan PIE workflow: Log in and upload a VCF of SNVs and indels. The portal will process your variants, notifying you upon completion. Variants are annotated with VEP+ (VEP with postprocessing for enhanced splice variant calling) then classified with Medal Ceremony. Browse results, which include a detailed page for each variation. Variants may be formally classified with an interface based on ACMG guidelines. Getting started \u00b6 Start by logging into the portal with a DNAnexus account, creating an account if you need one. PIE uses DNAnexus as a secure cloud backend. Logging in is required for private storage of your data and so that we can send you e-mail notifications when your analysis jobs are complete. PIE is free for non-commercial use. St. Jude pays the (small) cloud computing costs, your DNAnexus account will not be billed. Uploading data \u00b6 Pecan PIE takes standard VCF files as input, which may be either uncompressed or compressed with bgzip . Click the \"Securely upload a VCF file\" button. Choose the genome your variants were mapped to, which may be either GRCh37-lite or GRCh38. Advanced options \u00b6 The \"Advanced option\" panel lets you customize the behavior of the pipeline: Gene list: Pick a gene list from the pulldown. This filters your variants to genes in the specified list. This option is required and turned on automatically if your uploaded file is 2 megabytes or larger. See the frequently asked questions for more information. This option reduces the variant processing burden on PIE by removing variants that will not be assigned a medal in any case because they are not on the cancer predisposition gene list. You can review the genes by clicking on the link that will appear just below the pull down titled \"See gene list\". Custom gene list: Choosing \"custom\" as your gene list will open a window that will let you paste in a list of genes. Any invalid genes will be dropped from your list automatically. You can separate your genes by spaces or new lines. Max Population frequency: PIE by default will not call medals for variants present in the ExAC (ex-TCGA) database at an allele frequency greater than 0.001. This option lets you override the filtering threshold to whatever frequency you prefer. To disable filtering altogether, specify a value of 1. Progress page \u00b6 After uploading is complete you will be taken to a status screen showing the progress of your job through the system. Analysis typically takes 10-15 minutes depending on file size and system availability. It isn't necessary to keep your browser open on this page until your results are ready: the system will e-mail you with a link to return to your results. Optional browser notifications are also available. Analysis of Results \u00b6 Results browser \u00b6 When your job is complete you will be taken to an overview page where you can browse your results and examine a detailed results page for each variant. The variants in the results can be filtered by: Filter Meaning Class Predicted effect of variant on protein coding, e.g. missense, nonsense, etc. Somatic medal Medal assigned to the variant by the somatic classifier. Germline medal Medal assigned to the variant by the germline classifier. Committee Classification If the variant has been reviewed by the St. Jude germline variant review committee, the result will appear in this column, otherwise it will be blank. The \"search\" box lets you filter the results by gene and/or amino acid change. The view is dynamically filtered to matching variants as you type. Medal meaning \u00b6 Medals are only assigned for coding and splice-related variants in disease predisposition genes. Germline medals are only assigned for novel variants or those present in the ExAC (ex-TCGA) database with a MAF no greater than 0.1% (0.001 expressed fractionally). Gold medals are assigned to truncations in tumor suppressor genes, hotspots derived from the COSMIC database, as well as perfect matches to variants in the IARC TP53, PCGP, ASU TERT, ARUP RET, and BIC databases. Silver medals are assigned to in-frame indels, truncations in non-tumor suppressor genes, variants predicted deleterious by damage-prediction algorithms, variants receiving a gold medal from the somatic classifier, and perfect matches to variants in the following databases: ClinVar (predicted pathogenic or likely pathogenic), RB1, LOVD, and UMD. Bronze medals are assigned to variants predicted tolerated by damage-prediction algorithms. Variants having an imperfect match to a database (i.e. different variants at the same genomic position or codon) typically receive a lesser medal. A summary graphic can be found in slide 4 of the ASHG 2017 presentation ( download here ). For additional details see Zhang et al., NEJM 2015 (supplementary appendix pp. 7-10). Variant page \u00b6 Each variant links to a detailed variant page, which integrates data from a variety of sources. If either you or the St. Jude germline variant review committee have annotated a variant, that information will be pre-populated. Summary information The top of the page shows a summary of the variant, including its genomic and HGVS annotations, predicted effect on the protein, and somatic and germline medals. A description of the gene from Entrez follows, and a custom description or selection rationale may also be entered. Medal call information Clicking on one of the medal icons (gold, silver, bronze, unknown) or on the top of the page will show a summary of information related to the medal call. ProteinPaint An embedded version of ProteinPaint ( Zhou et al., Nat. Genet. 2016 ) appears next, showing the variant in the context of a number of pediatric datasets including PCGP. A link is provided to the main ProteinPaint application which provides visualizations for additional datasets, including COSMIC and ClinVar. ASHG pathogenicity classification Formal variant pathogenicity classification is supported by an interface implementing ACMG guidelines ( Richards et al., Genet Med. 2015 ). The analyst reviews a series of curated category tags, assigning applicable tags to the variant and optionally supplying additional information for each such as PubMed IDs and supporting evidence. The system will then compute an appropriate pathogenicity score based on the user-flagged categories. Additional free-form custom evidence can also be entered. This structured approach both helps eliminate arbitrary decision-making from the pathogenicity classification process and also constructs a concise summary of the logic and evidence supporting the final call. ClinVar and allele frequency Matches of the variant in ClinVar are also provided, along with predicted clinical significance and review status. Allele frequencies for the variant in the PCGP (somatic and germline), NHLBI ESP 6500, and ExAC databases are presented both as fractional values and on a log10 plot. Detailed allele population breakdowns are provided for ExAC. Damage prediction algorithms Precomputed damage-prediction algorithm calls for nonsynonymous coding SNVs are presented from the dbNSFP database. Available algorithms are PolyPhen2 (HVAR), SIFT, CADD, REVEL, FATHMM, MutationAssessor, and LRT. The calls are presented in a circular diagram with entries color-coded based on the predicted severity of the result. Medal ceremony and linkouts Additional output from medal ceremony classification can also be reviewed. This is only loosely structured, additional fields here may eventually be integrated into Pecan PIE. Links are provided to relevant dbSNP entries and other information sources. Final classification The final 5-tier ACMG classification can be selected after which the decision will be marked as reviewed. A checkbox is also available to indicate this variant is a potential candidate for functional review. Standalone usage \u00b6 This section is intended only for users who want to invoke Pecan PIE's underlying analysis pipelines independently on the DNAnexus platform. If you just want to use the Pecan PIE website you can safely ignore this section of the documentation. We assume familiarity with the DNAnexus platform. If you aren't familiar with this, DNAnexus' quickstart guide is a great place to start. Warning This section of the guide is only relevant to power users! Two DNAnexus cloud application pipelines were created during the development of Pecan PIE: Name Corresponding DNAnexus App Description VEP+ app-stjude_vep_plus A cloud installation of VEP with improved logic for splice variant calls. Converts an input VCF of variants to annotated, tab-delimited format. Medal Ceremony app-stjude_medal_ceremony Additional annotation and automated variant classification. Requires a special input format which is produced by VEP+. Permissions \u00b6 In order to run the cloud pipelines independently, your DNAnexus account needs to be granted permissions to access them. After your initial login to St. Jude Cloud and/or Pecan PIE, these permissions will be granted automatically. A single login is required even if you just want to use the standalone pipelines rather than the Pecan PIE portal ( contact us if you encounter problems accessing the pipelines). There are two methods of running pipelines on DNAnexus: DNAnexus GUI. DNAnexus provides a standardized graphical user interface for configurating, launching, and monitoring jobs on the cloud. Our pipelines can be run like any other DNAnexus pipeline. Command line. Jobs may also be invoked via the dx command line client. Command-line use allows submitting cloud jobs without interacting with a GUI, and so supports scripting and easier integration with local workflows. See this section for information on how to get set up with the dx-toolkit . Note The following examples demonstrate command-line usage. Uploading files \u00b6 All input files must be uploaded onto the DNAnexus platform. When specifying files for input you can use either the DNAnexus fie IDs (e.g. file-FBgvp680gz1bGQ5p8yZKz69g ), or the filenames if they are unique. For an idea of how to upload files to DNAnexus, see this guide . Step 1: Running VEP+ \u00b6 To run the VEP+ DNAnexus app, you can use the following dx command with your own inputs in place of the example's: dx run app-stjude_vep_plus -iinput_file = my_vcf.vcf -igenome_string = GRCh37-lite -igermline_reviewable_only = true Tip genome_string must be either GRCh37-lite or GRCh38 . If GRCh38 is specified, variants will be lifted over to GRCh37-lite in output, i.e. the output will always be GRCh37-lite (Medal Ceremony currently only supports GRCh37-lite ). The input VCF specified by input_file may be either uncompressed, or compressed with bgzip only (htslib/tabix packages). The germline_reviewable_only parameter is optional, but strongly recommended. If specified, only variants in disease-gene related intervals will be annotated, which is appropriate for Medal Ceremony. If this option is not specified all variants will be annotated, which depending on the size of your VCF might take a lot longer, and many of the resulting variants won't be usable by Medal Ceremony. If you want to do this anyway and have a large number of variants, consider submitting your job to an instance with more CPU cores (e.g. mem1_ssd1_x16 or mem1_ssd1_x32 ) as the code will take advantage of the additional cores. If you are using a custom gene list (below) that takes precedence and this parameter is not needed. The optional parameter custom_genes_file specifies a plain text file of HUGO gene symbols to analyze (whitespace separated, or one per line). If specified, analysis will be restricted to these genes only. This pipeline produces two output files, output_file contains annotations for all variants, while medal_prep_output_file is the specially-filtered and formatted file required as input to Medal Ceremony below. Step 2: Running Medal Ceremony \u00b6 To run the medal ceremony DNAnexus app, you can use the following dx command with your own inputs in place of the example's: dx run app-stjude_medal_ceremony -iinfile = medal_prep_output_file Tip The optional parameter custom_genes_file operates in the same way as in the VEP+ pipeline above. For custom gene lists to work properly this parameter must be specified when running both the VEP+ and Medal Ceremony pipelines. The optional parameter max_population_frequency may be specified, a fractional value representing the maximum population frequency allowed for a variant in the ExAC (ex-TCGA) database to receive a medal. The default is 0.001, a.k.a. \".1%\". Frequently asked questions \u00b6 If you have any questions not covered here, feel free to reach out on our contact form . Q: Which files are supported? PIE works with variants in VCF format: Uploaded files must be compliant with the VCF specification . VCF files may be either uncompressed, or compressed with bgzip only . bgzip is part of the htslib/tabix packages (see below). Improperly formatted VCF files will not work with PIE. Some common problems include: Missing header line Missing required columns Files were compressed by gzip, zip, or any method other than the required bgzip To verify compatibility of your VCF you can try one of these methods: Compressing your VCF with bgzip and indexing it with tabix , both programs from the HTSlib package (some systems also use the earlier, pre-HTSlib \"tabix\" package). This process will only succeed for compliant VCF files, and can help diagnose failures. Running \"vcf-validator\" program from the vcftools package. While the VCF specification also requires that variants be sorted by chromosome name and position, PIE is now often able to automatically correct sorting issues in uploaded files. PIE requires sorted data in order to query data for targeted genes. Q: Are there limits on the size of VCF files? Uploaded files must not exceed 4 gigabytes. If an uploaded file is larger than 2 megabytes, the cancer predisposition gene list filter will be automatically enabled unless you are using a custom gene list. This reduces the processing burden on the system by removing variants outside of targeted genes. Q: Is there an example/demo VCF I can try with PIE? A. You can use this VCF from the Genome in a Bottle project. This ~133 megabyte bgzip-compressed VCF was used during testing of Pecan PIE and is known to work. These variants are mapped to GRCh37. Q. What genome versions are supported? A. Pecan PIE will accept variants mapped to either GRCh37-lite/hg19 or GRCh38. GRCh38 variants are automatically lifted over to 37, as the system uses 37 internally. The liftover process is able to compensate for strand and reference/variant allele swaps which can occur. A native hg38 version is in development, but is not yet available. Pecan PIE only works for human data. Q. What genes are on the curated gene list? A. The list consists of disease-related genes, both cancer and non-cancer, see the file_download Excel spreadsheet for details. Filtering the source variants to a target list of genes reduces the processing burden on the system. When browsing the results the view may be filtered to disease sub-categories of interest. You can also specify your own custom list of genes to process when submitting your VCF file (see the advanced options panel). Q. Why is the classification column blank in my results? Q. This column displays the classification assigned by the St. Jude Germline Committee reviewers. If a variant was not classified by this committee before, this field will be blank. Pecan PIE provides classifications from the Medal Ceremony pipeline, which may assign variants gold, silver, or bronze medals. An \"Unknown\" medal may be assigned for non-disease-predisposition genes, variants present in the ExAC (ex-TCGA) database at an allele frequency > 0.1%, or variants without functional annotations (which includes most silent variants). Q. What do the medals mean? A. The medal column is a rough indicator of the likelihood of the variant being clinically significant as predicted by the medal ceremony software. Variants with gold medals are most likely to be significant, and those with no medal are least likely. More details can be found in the Analysis of Results <results> section. Q. Why are some of my variants missing? A. Currently only coding and splice-related variants in disease-related genes make it to the medaling process. Intergenic, intronic, and UTR variants are excluded, as are those in non-coding transcripts. Q. Why does the ExAC allele frequency shown differ from the ExAC portal? A. The reported ExAC frequency may differ for several reasons: PIE uses the TCGA-subtracted distribution of ExAC rather than the main distribution. PIE reports the primary allele frequencies in the ExAC database, specifically the AC, AN, and AF fields from the VCF distribution. The ExAC portal appears to use the \"adjusted\" frequencies which may be different. Q. Is Pecan PIE free? A. Pecan PIE is free for non-commercial use. St. Jude covers the cost of running the pipeline and hosting. DNANexus accounts are required to keep track of your jobs in the cloud so that you can retrieve and manage from multiple locations. Accounts also make it possible to alert you of job completion via email.","title":"Pecan PIE"},{"location":"guides/pecan/pecan-pie/#overview","text":"An overview of the Pecan PIE workflow: Log in and upload a VCF of SNVs and indels. The portal will process your variants, notifying you upon completion. Variants are annotated with VEP+ (VEP with postprocessing for enhanced splice variant calling) then classified with Medal Ceremony. Browse results, which include a detailed page for each variation. Variants may be formally classified with an interface based on ACMG guidelines.","title":"Overview"},{"location":"guides/pecan/pecan-pie/#getting-started","text":"Start by logging into the portal with a DNAnexus account, creating an account if you need one. PIE uses DNAnexus as a secure cloud backend. Logging in is required for private storage of your data and so that we can send you e-mail notifications when your analysis jobs are complete. PIE is free for non-commercial use. St. Jude pays the (small) cloud computing costs, your DNAnexus account will not be billed.","title":"Getting started"},{"location":"guides/pecan/pecan-pie/#uploading-data","text":"Pecan PIE takes standard VCF files as input, which may be either uncompressed or compressed with bgzip . Click the \"Securely upload a VCF file\" button. Choose the genome your variants were mapped to, which may be either GRCh37-lite or GRCh38.","title":"Uploading data"},{"location":"guides/pecan/pecan-pie/#advanced-options","text":"The \"Advanced option\" panel lets you customize the behavior of the pipeline: Gene list: Pick a gene list from the pulldown. This filters your variants to genes in the specified list. This option is required and turned on automatically if your uploaded file is 2 megabytes or larger. See the frequently asked questions for more information. This option reduces the variant processing burden on PIE by removing variants that will not be assigned a medal in any case because they are not on the cancer predisposition gene list. You can review the genes by clicking on the link that will appear just below the pull down titled \"See gene list\". Custom gene list: Choosing \"custom\" as your gene list will open a window that will let you paste in a list of genes. Any invalid genes will be dropped from your list automatically. You can separate your genes by spaces or new lines. Max Population frequency: PIE by default will not call medals for variants present in the ExAC (ex-TCGA) database at an allele frequency greater than 0.001. This option lets you override the filtering threshold to whatever frequency you prefer. To disable filtering altogether, specify a value of 1.","title":"Advanced options"},{"location":"guides/pecan/pecan-pie/#progress-page","text":"After uploading is complete you will be taken to a status screen showing the progress of your job through the system. Analysis typically takes 10-15 minutes depending on file size and system availability. It isn't necessary to keep your browser open on this page until your results are ready: the system will e-mail you with a link to return to your results. Optional browser notifications are also available.","title":"Progress page"},{"location":"guides/pecan/pecan-pie/#analysis-of-results","text":"","title":"Analysis of Results"},{"location":"guides/pecan/pecan-pie/#results-browser","text":"When your job is complete you will be taken to an overview page where you can browse your results and examine a detailed results page for each variant. The variants in the results can be filtered by: Filter Meaning Class Predicted effect of variant on protein coding, e.g. missense, nonsense, etc. Somatic medal Medal assigned to the variant by the somatic classifier. Germline medal Medal assigned to the variant by the germline classifier. Committee Classification If the variant has been reviewed by the St. Jude germline variant review committee, the result will appear in this column, otherwise it will be blank. The \"search\" box lets you filter the results by gene and/or amino acid change. The view is dynamically filtered to matching variants as you type.","title":"Results browser"},{"location":"guides/pecan/pecan-pie/#medal-meaning","text":"Medals are only assigned for coding and splice-related variants in disease predisposition genes. Germline medals are only assigned for novel variants or those present in the ExAC (ex-TCGA) database with a MAF no greater than 0.1% (0.001 expressed fractionally). Gold medals are assigned to truncations in tumor suppressor genes, hotspots derived from the COSMIC database, as well as perfect matches to variants in the IARC TP53, PCGP, ASU TERT, ARUP RET, and BIC databases. Silver medals are assigned to in-frame indels, truncations in non-tumor suppressor genes, variants predicted deleterious by damage-prediction algorithms, variants receiving a gold medal from the somatic classifier, and perfect matches to variants in the following databases: ClinVar (predicted pathogenic or likely pathogenic), RB1, LOVD, and UMD. Bronze medals are assigned to variants predicted tolerated by damage-prediction algorithms. Variants having an imperfect match to a database (i.e. different variants at the same genomic position or codon) typically receive a lesser medal. A summary graphic can be found in slide 4 of the ASHG 2017 presentation ( download here ). For additional details see Zhang et al., NEJM 2015 (supplementary appendix pp. 7-10).","title":"Medal meaning"},{"location":"guides/pecan/pecan-pie/#variant-page","text":"Each variant links to a detailed variant page, which integrates data from a variety of sources. If either you or the St. Jude germline variant review committee have annotated a variant, that information will be pre-populated. Summary information The top of the page shows a summary of the variant, including its genomic and HGVS annotations, predicted effect on the protein, and somatic and germline medals. A description of the gene from Entrez follows, and a custom description or selection rationale may also be entered. Medal call information Clicking on one of the medal icons (gold, silver, bronze, unknown) or on the top of the page will show a summary of information related to the medal call. ProteinPaint An embedded version of ProteinPaint ( Zhou et al., Nat. Genet. 2016 ) appears next, showing the variant in the context of a number of pediatric datasets including PCGP. A link is provided to the main ProteinPaint application which provides visualizations for additional datasets, including COSMIC and ClinVar. ASHG pathogenicity classification Formal variant pathogenicity classification is supported by an interface implementing ACMG guidelines ( Richards et al., Genet Med. 2015 ). The analyst reviews a series of curated category tags, assigning applicable tags to the variant and optionally supplying additional information for each such as PubMed IDs and supporting evidence. The system will then compute an appropriate pathogenicity score based on the user-flagged categories. Additional free-form custom evidence can also be entered. This structured approach both helps eliminate arbitrary decision-making from the pathogenicity classification process and also constructs a concise summary of the logic and evidence supporting the final call. ClinVar and allele frequency Matches of the variant in ClinVar are also provided, along with predicted clinical significance and review status. Allele frequencies for the variant in the PCGP (somatic and germline), NHLBI ESP 6500, and ExAC databases are presented both as fractional values and on a log10 plot. Detailed allele population breakdowns are provided for ExAC. Damage prediction algorithms Precomputed damage-prediction algorithm calls for nonsynonymous coding SNVs are presented from the dbNSFP database. Available algorithms are PolyPhen2 (HVAR), SIFT, CADD, REVEL, FATHMM, MutationAssessor, and LRT. The calls are presented in a circular diagram with entries color-coded based on the predicted severity of the result. Medal ceremony and linkouts Additional output from medal ceremony classification can also be reviewed. This is only loosely structured, additional fields here may eventually be integrated into Pecan PIE. Links are provided to relevant dbSNP entries and other information sources. Final classification The final 5-tier ACMG classification can be selected after which the decision will be marked as reviewed. A checkbox is also available to indicate this variant is a potential candidate for functional review.","title":"Variant page"},{"location":"guides/pecan/pecan-pie/#standalone-usage","text":"This section is intended only for users who want to invoke Pecan PIE's underlying analysis pipelines independently on the DNAnexus platform. If you just want to use the Pecan PIE website you can safely ignore this section of the documentation. We assume familiarity with the DNAnexus platform. If you aren't familiar with this, DNAnexus' quickstart guide is a great place to start. Warning This section of the guide is only relevant to power users! Two DNAnexus cloud application pipelines were created during the development of Pecan PIE: Name Corresponding DNAnexus App Description VEP+ app-stjude_vep_plus A cloud installation of VEP with improved logic for splice variant calls. Converts an input VCF of variants to annotated, tab-delimited format. Medal Ceremony app-stjude_medal_ceremony Additional annotation and automated variant classification. Requires a special input format which is produced by VEP+.","title":"Standalone usage"},{"location":"guides/pecan/pecan-pie/#permissions","text":"In order to run the cloud pipelines independently, your DNAnexus account needs to be granted permissions to access them. After your initial login to St. Jude Cloud and/or Pecan PIE, these permissions will be granted automatically. A single login is required even if you just want to use the standalone pipelines rather than the Pecan PIE portal ( contact us if you encounter problems accessing the pipelines). There are two methods of running pipelines on DNAnexus: DNAnexus GUI. DNAnexus provides a standardized graphical user interface for configurating, launching, and monitoring jobs on the cloud. Our pipelines can be run like any other DNAnexus pipeline. Command line. Jobs may also be invoked via the dx command line client. Command-line use allows submitting cloud jobs without interacting with a GUI, and so supports scripting and easier integration with local workflows. See this section for information on how to get set up with the dx-toolkit . Note The following examples demonstrate command-line usage.","title":"Permissions"},{"location":"guides/pecan/pecan-pie/#uploading-files","text":"All input files must be uploaded onto the DNAnexus platform. When specifying files for input you can use either the DNAnexus fie IDs (e.g. file-FBgvp680gz1bGQ5p8yZKz69g ), or the filenames if they are unique. For an idea of how to upload files to DNAnexus, see this guide .","title":"Uploading files"},{"location":"guides/pecan/pecan-pie/#step-1-running-vep","text":"To run the VEP+ DNAnexus app, you can use the following dx command with your own inputs in place of the example's: dx run app-stjude_vep_plus -iinput_file = my_vcf.vcf -igenome_string = GRCh37-lite -igermline_reviewable_only = true Tip genome_string must be either GRCh37-lite or GRCh38 . If GRCh38 is specified, variants will be lifted over to GRCh37-lite in output, i.e. the output will always be GRCh37-lite (Medal Ceremony currently only supports GRCh37-lite ). The input VCF specified by input_file may be either uncompressed, or compressed with bgzip only (htslib/tabix packages). The germline_reviewable_only parameter is optional, but strongly recommended. If specified, only variants in disease-gene related intervals will be annotated, which is appropriate for Medal Ceremony. If this option is not specified all variants will be annotated, which depending on the size of your VCF might take a lot longer, and many of the resulting variants won't be usable by Medal Ceremony. If you want to do this anyway and have a large number of variants, consider submitting your job to an instance with more CPU cores (e.g. mem1_ssd1_x16 or mem1_ssd1_x32 ) as the code will take advantage of the additional cores. If you are using a custom gene list (below) that takes precedence and this parameter is not needed. The optional parameter custom_genes_file specifies a plain text file of HUGO gene symbols to analyze (whitespace separated, or one per line). If specified, analysis will be restricted to these genes only. This pipeline produces two output files, output_file contains annotations for all variants, while medal_prep_output_file is the specially-filtered and formatted file required as input to Medal Ceremony below.","title":"Step 1: Running VEP+"},{"location":"guides/pecan/pecan-pie/#step-2-running-medal-ceremony","text":"To run the medal ceremony DNAnexus app, you can use the following dx command with your own inputs in place of the example's: dx run app-stjude_medal_ceremony -iinfile = medal_prep_output_file Tip The optional parameter custom_genes_file operates in the same way as in the VEP+ pipeline above. For custom gene lists to work properly this parameter must be specified when running both the VEP+ and Medal Ceremony pipelines. The optional parameter max_population_frequency may be specified, a fractional value representing the maximum population frequency allowed for a variant in the ExAC (ex-TCGA) database to receive a medal. The default is 0.001, a.k.a. \".1%\".","title":"Step 2: Running Medal Ceremony"},{"location":"guides/pecan/pecan-pie/#frequently-asked-questions","text":"If you have any questions not covered here, feel free to reach out on our contact form . Q: Which files are supported? PIE works with variants in VCF format: Uploaded files must be compliant with the VCF specification . VCF files may be either uncompressed, or compressed with bgzip only . bgzip is part of the htslib/tabix packages (see below). Improperly formatted VCF files will not work with PIE. Some common problems include: Missing header line Missing required columns Files were compressed by gzip, zip, or any method other than the required bgzip To verify compatibility of your VCF you can try one of these methods: Compressing your VCF with bgzip and indexing it with tabix , both programs from the HTSlib package (some systems also use the earlier, pre-HTSlib \"tabix\" package). This process will only succeed for compliant VCF files, and can help diagnose failures. Running \"vcf-validator\" program from the vcftools package. While the VCF specification also requires that variants be sorted by chromosome name and position, PIE is now often able to automatically correct sorting issues in uploaded files. PIE requires sorted data in order to query data for targeted genes. Q: Are there limits on the size of VCF files? Uploaded files must not exceed 4 gigabytes. If an uploaded file is larger than 2 megabytes, the cancer predisposition gene list filter will be automatically enabled unless you are using a custom gene list. This reduces the processing burden on the system by removing variants outside of targeted genes. Q: Is there an example/demo VCF I can try with PIE? A. You can use this VCF from the Genome in a Bottle project. This ~133 megabyte bgzip-compressed VCF was used during testing of Pecan PIE and is known to work. These variants are mapped to GRCh37. Q. What genome versions are supported? A. Pecan PIE will accept variants mapped to either GRCh37-lite/hg19 or GRCh38. GRCh38 variants are automatically lifted over to 37, as the system uses 37 internally. The liftover process is able to compensate for strand and reference/variant allele swaps which can occur. A native hg38 version is in development, but is not yet available. Pecan PIE only works for human data. Q. What genes are on the curated gene list? A. The list consists of disease-related genes, both cancer and non-cancer, see the file_download Excel spreadsheet for details. Filtering the source variants to a target list of genes reduces the processing burden on the system. When browsing the results the view may be filtered to disease sub-categories of interest. You can also specify your own custom list of genes to process when submitting your VCF file (see the advanced options panel). Q. Why is the classification column blank in my results? Q. This column displays the classification assigned by the St. Jude Germline Committee reviewers. If a variant was not classified by this committee before, this field will be blank. Pecan PIE provides classifications from the Medal Ceremony pipeline, which may assign variants gold, silver, or bronze medals. An \"Unknown\" medal may be assigned for non-disease-predisposition genes, variants present in the ExAC (ex-TCGA) database at an allele frequency > 0.1%, or variants without functional annotations (which includes most silent variants). Q. What do the medals mean? A. The medal column is a rough indicator of the likelihood of the variant being clinically significant as predicted by the medal ceremony software. Variants with gold medals are most likely to be significant, and those with no medal are least likely. More details can be found in the Analysis of Results <results> section. Q. Why are some of my variants missing? A. Currently only coding and splice-related variants in disease-related genes make it to the medaling process. Intergenic, intronic, and UTR variants are excluded, as are those in non-coding transcripts. Q. Why does the ExAC allele frequency shown differ from the ExAC portal? A. The reported ExAC frequency may differ for several reasons: PIE uses the TCGA-subtracted distribution of ExAC rather than the main distribution. PIE reports the primary allele frequencies in the ExAC database, specifically the AC, AN, and AF fields from the VCF distribution. The ExAC portal appears to use the \"adjusted\" frequencies which may be different. Q. Is Pecan PIE free? A. Pecan PIE is free for non-commercial use. St. Jude covers the cost of running the pipeline and hosting. DNANexus accounts are required to keep track of your jobs in the cloud so that you can retrieve and manage from multiple locations. Accounts also make it possible to alert you of job completion via email.","title":"Frequently asked questions"},{"location":"guides/proteinpaint/","text":"ProteinPaint is the flagship protein-based visualization tool created at St. Jude Children's Research Hospital. You can use it to examine the domains of genes, known isoforms of a given gene, hotspot mutations for single nucleotide variations (SNVs), insertions and deletions (Indels), and structural variations (SVs) in both pediatric and adult cancers, and RNA-seq expression of a given protein in different tumour types. There are two primary ways you can use ProteinPaint. You can use ProteinPaint to explore mutations our curated pediatric and adult cohorts using PeCan (ex: TP53 ). If you'd like to create and publish to the community your own visualizations with ProteinPaint, you can do so with the Visualization Community ( still in development, available soon! ). Human, hg19 \u2014 Human, hg38 \u2014 Mouse, mm9 \u2014 Mouse, mm10 Fruit fly, dm3 \u2014 Fruit fly, dm6 \u2014 Zebra fish, danRer10 Features \u00b6 Explore SNV and Indel mutations from the Pediatric, COSMIC, and ClinVar datasets ( learn more ). Load custom protein domains and annotations ( learn more ). Inspect details for a given mutation ( learn more ) Filtering of mutations based on class and origin ( learn more ). Stratifying mutations based on cancer subtype ( learn more ). Visualize your own SNV and Indel mutations ( learn more ). Saving figures and exporting data ( learn more ). Explore gene fusions ( learn more ). Explore gene expression data including \"rope graph\", boxplots, and sunburst charts ( learn more ). Embed ProteinPaint on your website ( learn more ). Make a study view ( learn more ). Loading tab-delimited text files of mutations ( learn more ). Supported Data Formats \u00b6 SNV and Indel (supports both MAF and customized format) ( learn more ). Example: Loading TCGA MAF file SV and fusion transcript transcript ( learn more ) CNV ( learn more ) Internal tandem duplications (ITD) ( learn more ) Intragenic deletion ( learn more ) Trunction: N-loss or C-loss ( learn more ) JSON-BED ( learn more ) Splice Junction ( learn more ) Profile-Gene-Value ( learn more ) Bampile ( learn more )","title":"Introduction"},{"location":"guides/proteinpaint/#features","text":"Explore SNV and Indel mutations from the Pediatric, COSMIC, and ClinVar datasets ( learn more ). Load custom protein domains and annotations ( learn more ). Inspect details for a given mutation ( learn more ) Filtering of mutations based on class and origin ( learn more ). Stratifying mutations based on cancer subtype ( learn more ). Visualize your own SNV and Indel mutations ( learn more ). Saving figures and exporting data ( learn more ). Explore gene fusions ( learn more ). Explore gene expression data including \"rope graph\", boxplots, and sunburst charts ( learn more ). Embed ProteinPaint on your website ( learn more ). Make a study view ( learn more ). Loading tab-delimited text files of mutations ( learn more ).","title":"Features"},{"location":"guides/proteinpaint/#supported-data-formats","text":"SNV and Indel (supports both MAF and customized format) ( learn more ). Example: Loading TCGA MAF file SV and fusion transcript transcript ( learn more ) CNV ( learn more ) Internal tandem duplications (ITD) ( learn more ) Intragenic deletion ( learn more ) Trunction: N-loss or C-loss ( learn more ) JSON-BED ( learn more ) Splice Junction ( learn more ) Profile-Gene-Value ( learn more ) Bampile ( learn more )","title":"Supported Data Formats"},{"location":"guides/proteinpaint/exploring-gene-expression/","text":"Gene expression data by RNA-Seq is available for close to 1000 pediatric cancer samples. This data set is made available on ProteinPaint in the form of gene-level FPKM values, so that while browsing the Pediatric mutations in genes of interest, the user may view gene expression levels in the same cohort. Rope graph \u00b6 When showing Pediatric data for TP53 on ProteinPaint, the gene expression data will be shown as a \"rope graph\" on right: The \"rope\" consists of circles representing Pediatric samples that have been profiled by RNA-Seq. Each circle's distance to left represents its TP53 FPKM value, also indicated by the axis on top. The circles are arranged from top to bottom in descending order of TP53 FPKM values. Mouse over a circle to see the details about the expression in one sample: Since the expression panel shows data about the same cohort as the mutation panel, the corresponding samples can be highlighted on the right when the user hovers the cursor over the discs representing mutations. The following shows 3 samples which are highlighted with the MAF label by hovering cursor over R248Q. The highlight effect disappears upon moving cursor out of the R248Q disc: By showing the mutation table for R248Q cases, a button is available as an additional way to highlight samples in the expression panel. In this way, the highlight effect will persist until the user clicks the button again. This can be convenient when making screenshots retaining such highlighting: The rope graph can be adjusted by dragging vertically on the circles. The circles are divided into two halves for this adjustment: the top half with high expression is for adjusting vertical span; the bottom half with low expression is for adjusting vertical position: In this way, the rope plot can be compressed to avoid overlap with boxplots, or reverse the ranking order: To reset the rope plot to its default look, choose the \"Reset circle positions\" option from the options menu: Expression value distribution of selected samples \u00b6 A boxplot is created by default to show expression value distribution for all samples. In the following screenshot, the boxplot is labeled by a number \"928\" indicating it represents all 928 samples: Additional boxplots can be added for subsets of the sample from each individual cancer types. To select cancer types and create boxplots, mouse over the \"Options \u21e3\" for a menu: Select \"Boxplots\" to show the cancer type listing in a new panel. This listing shows highest groups by default: Clicking on the labels in each group to reveal more detailed groupings: A box labeled with a number in each row indicates the cohort size for each cancer type. Click on the box to show a boxplot representing the gene expression distribution in the selected cohort: In above screenshot, separate boxplots are shown for the BALL, AML, and MLL cohorts, in comparison with the big boxplot at the bottom representing all pediatric cancer samples. At the cancer type listing, the number buttons show no border as an indication. The boxplots are labeled with the cancer name and cohort size, with box heights reflecting the relative cohort sizes. The rope graph can also change to highlight samples from a cohort represented by a boxplot: Click on the boxplot label to highlight its samples in the rope graph, or click again to cancel the highlight. The boxplots can be moved to a different vertical position by dragging on the labels. To remove a boxplot, either click the boxplot graph directly, or go to the cancer type listing and click the corresponding number button. Cancer type distribution at selected expression range \u00b6 The user can drag on the axis of the rope graph to select a range of FPKM values, and in turn select a set of samples with FPKM values within the range. The cancer composition of selected samples will be indicated by a sunburst chart: The center of the sunburst chart shows the range of FPKM values and the number of samples within that range. The chart shows up to four layers to represent the cancer type stratification, with inner to outer layers representing: cancer group, cancer, subtype, and subgroup. This is in unison to the hierarchical list shown above. The surrounding text labels represent the name of each smallest group in selected samples. Mouse over an arc from any of the four layers to see the full name and sample count at the center: An orange-colored box behind the sunburst chart marks out the FPKM value range. User can slide this bar left or right and see the change to the sunburst chart to conveniently explore the cancer type composition of samples stratified by an gene expression level gradient. User can also drag on the thick bars on top of the orange box to widen or narrow the box and change the span of FPKM value range. To dismiss the FPKM range selection, click on the center of the sunburst chart. Finally, the screenshot and data of the sample expressions can be exported through the menu options, in the same fashion with the mutation data. The screenshot will retain all items currently shown in the expression panel, including rope graph, boxplots, and the sunburst chart.","title":"Viewing Expression Data"},{"location":"guides/proteinpaint/exploring-gene-expression/#rope-graph","text":"When showing Pediatric data for TP53 on ProteinPaint, the gene expression data will be shown as a \"rope graph\" on right: The \"rope\" consists of circles representing Pediatric samples that have been profiled by RNA-Seq. Each circle's distance to left represents its TP53 FPKM value, also indicated by the axis on top. The circles are arranged from top to bottom in descending order of TP53 FPKM values. Mouse over a circle to see the details about the expression in one sample: Since the expression panel shows data about the same cohort as the mutation panel, the corresponding samples can be highlighted on the right when the user hovers the cursor over the discs representing mutations. The following shows 3 samples which are highlighted with the MAF label by hovering cursor over R248Q. The highlight effect disappears upon moving cursor out of the R248Q disc: By showing the mutation table for R248Q cases, a button is available as an additional way to highlight samples in the expression panel. In this way, the highlight effect will persist until the user clicks the button again. This can be convenient when making screenshots retaining such highlighting: The rope graph can be adjusted by dragging vertically on the circles. The circles are divided into two halves for this adjustment: the top half with high expression is for adjusting vertical span; the bottom half with low expression is for adjusting vertical position: In this way, the rope plot can be compressed to avoid overlap with boxplots, or reverse the ranking order: To reset the rope plot to its default look, choose the \"Reset circle positions\" option from the options menu:","title":"Rope graph"},{"location":"guides/proteinpaint/exploring-gene-expression/#expression-value-distribution-of-selected-samples","text":"A boxplot is created by default to show expression value distribution for all samples. In the following screenshot, the boxplot is labeled by a number \"928\" indicating it represents all 928 samples: Additional boxplots can be added for subsets of the sample from each individual cancer types. To select cancer types and create boxplots, mouse over the \"Options \u21e3\" for a menu: Select \"Boxplots\" to show the cancer type listing in a new panel. This listing shows highest groups by default: Clicking on the labels in each group to reveal more detailed groupings: A box labeled with a number in each row indicates the cohort size for each cancer type. Click on the box to show a boxplot representing the gene expression distribution in the selected cohort: In above screenshot, separate boxplots are shown for the BALL, AML, and MLL cohorts, in comparison with the big boxplot at the bottom representing all pediatric cancer samples. At the cancer type listing, the number buttons show no border as an indication. The boxplots are labeled with the cancer name and cohort size, with box heights reflecting the relative cohort sizes. The rope graph can also change to highlight samples from a cohort represented by a boxplot: Click on the boxplot label to highlight its samples in the rope graph, or click again to cancel the highlight. The boxplots can be moved to a different vertical position by dragging on the labels. To remove a boxplot, either click the boxplot graph directly, or go to the cancer type listing and click the corresponding number button.","title":"Expression value distribution of selected samples"},{"location":"guides/proteinpaint/exploring-gene-expression/#cancer-type-distribution-at-selected-expression-range","text":"The user can drag on the axis of the rope graph to select a range of FPKM values, and in turn select a set of samples with FPKM values within the range. The cancer composition of selected samples will be indicated by a sunburst chart: The center of the sunburst chart shows the range of FPKM values and the number of samples within that range. The chart shows up to four layers to represent the cancer type stratification, with inner to outer layers representing: cancer group, cancer, subtype, and subgroup. This is in unison to the hierarchical list shown above. The surrounding text labels represent the name of each smallest group in selected samples. Mouse over an arc from any of the four layers to see the full name and sample count at the center: An orange-colored box behind the sunburst chart marks out the FPKM value range. User can slide this bar left or right and see the change to the sunburst chart to conveniently explore the cancer type composition of samples stratified by an gene expression level gradient. User can also drag on the thick bars on top of the orange box to widen or narrow the box and change the span of FPKM value range. To dismiss the FPKM range selection, click on the center of the sunburst chart. Finally, the screenshot and data of the sample expressions can be exported through the menu options, in the same fashion with the mutation data. The screenshot will retain all items currently shown in the expression panel, including rope graph, boxplots, and the sunburst chart.","title":"Cancer type distribution at selected expression range"},{"location":"guides/proteinpaint/exploring-gene-fusions/","text":"Fusion gene data are available for a subset of Pediatric cancer samples (Ph-like B-cell acute lymphoblastic leukemia, Fig. 1b ), detected from RNA-Seq data using the software CICERO (Li, Y. and Zhang, J. in preparation). The comprehensive set of fusion gene information from all Pediatric samples is being produced at the time of writing and will be made available on ProteinPaint. As an example, viewing Pediatric mutations for PAX5 shows a number of fusion gene events amongst SNVs and indels: In this graph, there are 7 cases of fusion with JAK2 . The disc is half-filled on left indicating the N-terminus part of PAX5 protein is fused with JAK2 . Conversely, in JAK2 ProteinPaint shows the same set of 7 fusion events with PAX5 : Click on the half-filled disc labeled \"PAX5\" to view a graphical representation of this fusion event: In this view, the protein schema is displayed for both PAX5 and JAK2 . The two proteins are positioned in this way that the N-terminus segment (PAX5) is on top, and the C-terminus (JAK2) is on bottom. A thick horizontal line marks out the part of each protein that is retained in the fusion event, and a thin dashed line joins the segments. The amino acid positions from which the dashed line starts and ends are marked on both proteins. Click the button \"Show chimeric\" to transform the view into a \"chimeric\" protein, in which only the N-terminus of PAX5 and C-terminus of JAK2 are visible: Mouse over either of the proteins to examine details about protein domains through the tooltip: Click the button \"7 samples\" to view the list of samples from which the PAX5-JAK2 fusion has been discovered: In this table, \"Fusion over total RNA\" shows color-bars to show the fraction value of fusion transcripts in the total transcripts of each gene (PAX5 and JAK2). This fraction value is calculated by the software CICERO.","title":"Viewing Gene Fusions"},{"location":"guides/proteinpaint/exporting-figures-and-data/","text":"User can export figure or data for the current view on ProteinPaint. Mouse over the \"More\" link following the data set handles for a menu, then click \"Export SVG\" to download an SVG file as the screenshot of current view, like the example below: The exported figure will contain following contents, many will reflect user's customization: Datasets that are currently displayed, including custom data Expand/fold states of all mutations Sequences in the protein if at zoom-in level Show/hide state of exon boundaries Sunburst charts Protein domains without the hidden ones All mutations without the hidden classes or origins Legend for protein domain, mutation class and origin Following is another screenshot showing a customized graph, leaving out exon boundaries, three types of domains, and missense mutations: The exported figure is an SVG file, which can be viewed on a web browser, printed to a PDF file, or edited using a text editor. Note that the exported SVG file can be properly displayed in Adobe Illustrator CS2 but not CS6. To export SNV/indel data, use either one of the two buttons labeled \"html\" and \"text\". This will export the entire sets of mutation data from all figures shown in ProteinPaint, without filtering.","title":"Exporting Figures and Data"},{"location":"guides/proteinpaint/filtering-mutations/","text":"Filtering mutations based on class and origin \u00b6 ProteinPaint uses the color of the discs to represent the mutation classes, as indicated in the legend: The numbers in the legend indicate the total number of mutations currently shown for each class. Clicking on a class shows a menu: Use the options in the menu to show/hide mutations from a selected class. The following screenshot shows the view after hiding all missense mutations, making nonsense mutations (orange) the most abundant class. There is also a strikethrough to the MISSENSE class label in legend, indicating it is hidden As another example, the following shows only splice site mutations, with strikethroughs in all the other class labels in the legend: To restore mutations for of all classes, click on any mutation class button then select \"Show all classes\": In the Pediatric data set, germline and relapse mutations are also denoted in the \"Origin\" section of the legend: Click on an origin type to see a menu similar to the mutation class menu: Using these options, only germline mutations are shown as below:","title":"Filtering Mutations"},{"location":"guides/proteinpaint/filtering-mutations/#filtering-mutations-based-on-class-and-origin","text":"ProteinPaint uses the color of the discs to represent the mutation classes, as indicated in the legend: The numbers in the legend indicate the total number of mutations currently shown for each class. Clicking on a class shows a menu: Use the options in the menu to show/hide mutations from a selected class. The following screenshot shows the view after hiding all missense mutations, making nonsense mutations (orange) the most abundant class. There is also a strikethrough to the MISSENSE class label in legend, indicating it is hidden As another example, the following shows only splice site mutations, with strikethroughs in all the other class labels in the legend: To restore mutations for of all classes, click on any mutation class button then select \"Show all classes\": In the Pediatric data set, germline and relapse mutations are also denoted in the \"Origin\" section of the legend: Click on an origin type to see a menu similar to the mutation class menu: Using these options, only germline mutations are shown as below:","title":"Filtering mutations based on class and origin"},{"location":"guides/proteinpaint/loading-datasets/","text":"Pediatric and COSMIC are the two data sets formally supported by ProteinPaint. These are indicated by two buttons on the top, referred to as handles . Click the handle labeled \"Pediatric\" to load Pediatric mutations: Once loaded, the Pediatric mutations will be shown as discs extending from the protein, and the handle will turn gray, indicating the data has been loaded. The top of the graph shows a header with a set of buttons starting with \"Pediatric\": Click the handle for \"COSMIC\" to load adult cancer mutations. This can take a few moments to load since the amount of COSMIC mutations may be much larger than Pediatric, depending on specific protein. In the following example, COSMIC data is shown on the other side of the protein from the Pediatric data set, allowing for convenient comparison. On the COSMIC side of the graph, discs extend downward from the protein, and the header is at the bottom: At this stage, you may click either \"Pediatric\" or \"COSMIC\" handle to hide the graph from ProteinPaint display, after which the handle turns dark gray again: Click on the handle to toggle the the data set on again. Dragging the first button in the graph header moves the graph vertically. It can be moved to the top or bottom of the protein ruler, or change its order of appearance when there are multiple data set graphs. The following shows both COSMIC and Pediatric data sets on top of the protein: ProteinPaint shows the full view of the protein by default, and groups mutations by amino acid positions, so that discs representing mutations at the same amino acid position will be aligned to the same horizontal position. At each amino acid position, discs are vertically stacked by the number of mutations in each group, with largest group closest to the protein, as illustrated by an example from COSMIC: The text labels to the right of the discs show amino acid changes. Together the disc radii and label font sizes reflect the number of affected samples by each mutation. Clicking on any text label will fold the discs and their labels. Clicking on a disc will expand its folded mutation. These interactive features allow the user to configure and customize the fold/expand states of any mutation as desired. For added convenience, an option is provided allowing the user to toggle the fold/expand of all mutations in a dataset by clicking on the second button of the graph header. The following shows all TP53 mutations folded using this method: When folded, the discs will be slightly raised away from the protein by a distance relative to the number of mutations at that amino acid position. To get a quick view of the data contained in any folded disc, mouse over the disc and a tooltip will appear, for example: ProteinPaint highlights mutations of germline and relapse origin using arcs surrounding the discs. In the example below, the 11 mutations for R248Q show two types of arcs, the solid arc indicates two of these mutations are from germline samples, and hollow arc indicates one is from a relapsed sample. The remaining portion of the disc not covered by an arc indicates the final 8 mutations are from diagnostic (somatic) samples: At the present time, only the Pediatric dataset contains germline and relapse mutations. All COSMIC mutations are somatic.","title":"Loading Datasets"},{"location":"guides/proteinpaint/navigating-the-protein-diagram/","text":"Use the search box on the top to find a protein by HUGO gene symbol, for example \"TP53\". The TP53 protein is rendered as a color-banded ruler, with the numerical axis the representing number of amino acid residues from N-terminus to C-terminus. This example shows the protein translated from the preferred isoform of TP53 gene (NM_000546), shown on the top left. Click the gene symbol to view all isoforms for TP53: To view a different protein isoform, either click on the diagram of the isoform in above panel, or search by the isoform's RefSeq accession number instead of gene symbol. Protein domain \u00b6 The source of protein domain annotation is primarily the NCBI CDD database, which has been supplemented by in-house curation efforts. In ProteinPaint, domains are represented by color bands, with varying colors indicating different types of domains. The list of domain types is shown in the legend according to their order of appearance on the protein. For manually curated domains, a PubMed link may be available to reference the source publication. Hovering the cursor over the protein will display a tooltip showing any domains under the cursor (in some cases there can be more than one): As a convenience, ProteinPaint offers an option to hide selected domains. To hide a domain type, click on one of the colored boxes in the legend to hide all occurrences of the selected type of domain from display. An \"x\" sign will appear inside the box to indicate a domain has been hidden. Following example shows TP53 protein with three types of domain hidden: Hidden domains will be excluded from screenshots. Click the box marked by \"X\" to toggle the domain visible again. Exon junction \u00b6 When hovering the cursor over the protein, the tooltip indicates the amino acid residue under the cursor, and the associated exon number: Dashed lines represent exon junctions. The following example shows an exon junction is overlaps with Alanine 307, which is marked by exon numbers 8 and 9: To show additional details about A307, click on this position and ProteinPaint will zoom in to show that the exon junction falls inside codon A307, between the first and second nucleotides. The codon nucleotides are shown in the top row, and amino acid residues are shown in the middle. Alternating background shades help distinguish adjacent codons. During zoom-in, the genomic coordinates of nucleotides will also be shown in tooltip: The exon junctions are aligned to nucleotide positions by default. This alignment can be configured or turned to hidden using a drop-down menu in the legend: For example, by choosing the option \"align to amino acid\", the exon junction inside A307 will be aligned to the center of the A307 residue: After zooming-in, clicking on either side of the protein will scroll left or right. To zoom out and view entire protein again, click the \"Show all\" button on the top: Summary \u00b6","title":"Getting Started"},{"location":"guides/proteinpaint/navigating-the-protein-diagram/#protein-domain","text":"The source of protein domain annotation is primarily the NCBI CDD database, which has been supplemented by in-house curation efforts. In ProteinPaint, domains are represented by color bands, with varying colors indicating different types of domains. The list of domain types is shown in the legend according to their order of appearance on the protein. For manually curated domains, a PubMed link may be available to reference the source publication. Hovering the cursor over the protein will display a tooltip showing any domains under the cursor (in some cases there can be more than one): As a convenience, ProteinPaint offers an option to hide selected domains. To hide a domain type, click on one of the colored boxes in the legend to hide all occurrences of the selected type of domain from display. An \"x\" sign will appear inside the box to indicate a domain has been hidden. Following example shows TP53 protein with three types of domain hidden: Hidden domains will be excluded from screenshots. Click the box marked by \"X\" to toggle the domain visible again.","title":"Protein domain"},{"location":"guides/proteinpaint/navigating-the-protein-diagram/#exon-junction","text":"When hovering the cursor over the protein, the tooltip indicates the amino acid residue under the cursor, and the associated exon number: Dashed lines represent exon junctions. The following example shows an exon junction is overlaps with Alanine 307, which is marked by exon numbers 8 and 9: To show additional details about A307, click on this position and ProteinPaint will zoom in to show that the exon junction falls inside codon A307, between the first and second nucleotides. The codon nucleotides are shown in the top row, and amino acid residues are shown in the middle. Alternating background shades help distinguish adjacent codons. During zoom-in, the genomic coordinates of nucleotides will also be shown in tooltip: The exon junctions are aligned to nucleotide positions by default. This alignment can be configured or turned to hidden using a drop-down menu in the legend: For example, by choosing the option \"align to amino acid\", the exon junction inside A307 will be aligned to the center of the A307 residue: After zooming-in, clicking on either side of the protein will scroll left or right. To zoom out and view entire protein again, click the \"Show all\" button on the top:","title":"Exon junction"},{"location":"guides/proteinpaint/navigating-the-protein-diagram/#summary","text":"","title":"Summary"},{"location":"guides/proteinpaint/view-mutation-details/","text":"In the Pediatric data set, clicking on a disc will bring up a sunburst chart showing the cancer type and subtype information for the set of samples affected by this mutation. The sunburst chart is labeled by amino acid change in the center and can be moved by clicking and dragging on this label: In a sunburst chart, the inner layer represents cancer types. The outmost layer represents each individual sample. When there is cancer subtype information available for the sample, an intermediate layer will appear. Hovering cursor on any layer will display the name: Mousing over the bottom of the R248Q disc will show a box with number 16, representing all 16 mutations at the position R248 (11 from R248Q, 5 from R248W). Clicking this box will bring up a new chart representing these 16 mutations. Notice the label at the center now reads \"R248\", indicating it now represents all amino acid changes at R248: This feature is handy for exploring cases like the KRAS mutations at G12, a hotspot with multiple mutated alleles. A single click will show the cancer type composition for all different types of G12 mutations: For COSMIC, clicking on a disc will also generate a sunburst chart but consisting of only two layers: the inner layer representing the source tissue type of the cancer, and the outer layer representing samples: As an optimization to improve performance, when the number of mutations is greater than 400, the sunburst chart will not show individual samples at the outmost ring: To dismiss the chart, click on the center of the ring around the mutation name. Click the \"List\" button inside the chart to show a mutation table, as described below. Using the mutation table \u00b6 The mutation table is a powerful and versatile tool for examining details about samples and mutations. The following table shows details for the pediatric cases of TP53 p.R248Q: Additional columns that are not shown by default may be added by clicking the button \"Table columns\", which shows a list of all available columns. Toggle the checkboxes to add/remove columns to the mutation table. The following shows the column listing for the Pediatric dataset: Clicking on the header of any column in the table will sort the table based on the values in that column. Sorted columns will show a black up/down arrow in their header. Clicking the header again will reverse the sorting order: In the Pediatric mutation table, the cancer types are shown in abbreviated forms. Hover the cursor over the abbreviations to display their full names: In Pediatric data set, mutant allele fraction (MAF) information is available for the DNA of tumor and normal genomes, and for tumor RNA-seq of selected samples. This information is displayed in graphical forms of \"percentage bars\". Hover over a bar to see the fraction value and read counts: If the total read count is below the cutoff of 30, the bar will appear darkened: MAF value graphical display is also explained in the table legend, brought up by clicking the \"Legend\" button: Loss of heterozygosity (LOH) information will be shown in the mutation table for part of the Pediatric samples, which is also explained in the legend above. dbSNPs that are overlapping with mutations will be identified and shown along with the mutation table. Click the second button \"dbSNP\" in the bottom to show any such hits. Click on the displayed SNP to view its record in the dbSNP database: The button labeled \"highlight in RNA-seq panel\" is explained in section [put link here]. Zooming in to browse mutations at nucleotide level \u00b6 Todo We are still working on importing this content to the official St. Jude Cloud guide. Please be patient with us! If you have any questions, please contact us . Original Link: https://plus.google.com/u/0/+XinZhou_s/posts/5Ji9ZkecaDD","title":"Viewing SNV/Indel Mutations"},{"location":"guides/proteinpaint/view-mutation-details/#using-the-mutation-table","text":"The mutation table is a powerful and versatile tool for examining details about samples and mutations. The following table shows details for the pediatric cases of TP53 p.R248Q: Additional columns that are not shown by default may be added by clicking the button \"Table columns\", which shows a list of all available columns. Toggle the checkboxes to add/remove columns to the mutation table. The following shows the column listing for the Pediatric dataset: Clicking on the header of any column in the table will sort the table based on the values in that column. Sorted columns will show a black up/down arrow in their header. Clicking the header again will reverse the sorting order: In the Pediatric mutation table, the cancer types are shown in abbreviated forms. Hover the cursor over the abbreviations to display their full names: In Pediatric data set, mutant allele fraction (MAF) information is available for the DNA of tumor and normal genomes, and for tumor RNA-seq of selected samples. This information is displayed in graphical forms of \"percentage bars\". Hover over a bar to see the fraction value and read counts: If the total read count is below the cutoff of 30, the bar will appear darkened: MAF value graphical display is also explained in the table legend, brought up by clicking the \"Legend\" button: Loss of heterozygosity (LOH) information will be shown in the mutation table for part of the Pediatric samples, which is also explained in the legend above. dbSNPs that are overlapping with mutations will be identified and shown along with the mutation table. Click the second button \"dbSNP\" in the bottom to show any such hits. Click on the displayed SNP to view its record in the dbSNP database: The button labeled \"highlight in RNA-seq panel\" is explained in section [put link here].","title":"Using the mutation table"},{"location":"guides/proteinpaint/view-mutation-details/#zooming-in-to-browse-mutations-at-nucleotide-level","text":"Todo We are still working on importing this content to the official St. Jude Cloud guide. Please be patient with us! If you have any questions, please contact us . Original Link: https://plus.google.com/u/0/+XinZhou_s/posts/5Ji9ZkecaDD","title":"Zooming in to browse mutations at nucleotide level"},{"location":"guides/proteinpaint/advanced-guides/custom-protein-domains/","text":"Todo We are still working on importing this content to the official St. Jude Cloud guide. Please be patient with us! If you have any questions, please contact us . Original Link: https://plus.google.com/+XinZhou_s/posts/fmZqiqQsPdo","title":"Add Custom Protein Domains"},{"location":"guides/proteinpaint/advanced-guides/loading-snv-indel-mutations-from-a-file/","text":"Loading SNV/indel mutations from text file \u00b6 This function allows user to upload a mutation data set that are detected in many samples over many genes. SV/fusion and CNV data are supported in addition to SNV/indel. ProteinPaint generates an informative global view for the uploaded data, and these data can be compared to pediatric/COSMIC datasets, or explored in depth using the single gene-based mutation visualization described above. To use the file uploading feature, click the \"+\" button following the data set buttons and select \"Upload text files\": Alternatively, go to https://proteinpaint.stjude.org/ , click the \"Apps\" button at the top and select the option \"Load mutation from text file\". In both case, a new panel will be displayed prompting you to upload mutation data from text files: Use the drop-down menu to select the mutation type, then click the \"Choose File\" button to upload file. The panel lists supported mutation data types and format descriptions.","title":"Loading SNV/Indel Mutations from a File"},{"location":"guides/proteinpaint/advanced-guides/loading-snv-indel-mutations-from-a-file/#loading-snvindel-mutations-from-text-file","text":"This function allows user to upload a mutation data set that are detected in many samples over many genes. SV/fusion and CNV data are supported in addition to SNV/indel. ProteinPaint generates an informative global view for the uploaded data, and these data can be compared to pediatric/COSMIC datasets, or explored in depth using the single gene-based mutation visualization described above. To use the file uploading feature, click the \"+\" button following the data set buttons and select \"Upload text files\": Alternatively, go to https://proteinpaint.stjude.org/ , click the \"Apps\" button at the top and select the option \"Load mutation from text file\". In both case, a new panel will be displayed prompting you to upload mutation data from text files: Use the drop-down menu to select the mutation type, then click the \"Choose File\" button to upload file. The panel lists supported mutation data types and format descriptions.","title":"Loading SNV/indel mutations from text file"},{"location":"guides/proteinpaint/advanced-guides/loading-tcga-maf-file/","text":"Loading TCGA MAF file \u00b6 The MAF format is extensively used by TCGA and others to present cancer genomic mutations. The MAF format is specified here: https://wiki.nci.nih.gov/display/TCGA/Mutation+Annotation+Format+(MAF)+Specification . Here we describe steps to download MAF files from the TCGA Data Portal and display on ProteinPaint. Visit the TCGA data portal at https://tcga-data.nci.nih.gov/tcga/ and go to the \"Open-Access HTTP Directory\" from the menu: In the HTTP directory, click on any of the disease folder to look for mutations stored in MAF files: You may need to go down several folders to find the MAF files. For skin cancer, the path of folders to find MAF files is: skcm/ > gsc/ > broad.mit.edu/ > illuminaga_dnaseq/ > mutations/ > broad.mit.edu_SKCM.IlluminaGA_DNASeq.Level_2.0.1.0/ As an example, from this folder we download a MAF file named \"PR_TCGA_SKCM_PAIR_Capture_All_Pairs_QCPASS.aggregated.capture.tcga.uuid.somatic.maf\". This MAF file can be submitted to ProteinPaint. Due to the relatively large size of this MAF file, it can be helpful to keep only essential columns so as to reduce file size and speed up uploading and subsequent browsing. This can be done either using a shell command, or a spreadsheet software. Using shell command: cut -f1,5,6,9,16,40,42,44 PR_TCGA_SKCM_PAIR_Capture_All_Pairs_QCPASS.aggregated.capture.tcga.uuid.somatic.maf > TCGA_SKCM.slim.maf Using a spreadsheet software (e.g. Microsoft Excel, OpenOffice): Import the MAF file into the software by choosing \"tab\" as delimiter. Select columns with following header names: Hugo_Symbol, Chromosome, Start_position, Variant_Classification, Tumor_Sample_Barcode, cDNA_Change, Protein_Change, Refseq_mRNA_Id. Copy the contents of selected columns. Create a new sheet and paste these columns into the new sheet. Choose \"Save as...\" and select \"tab-delimited text\" format to save this sheet to a text file. Both methods will generate a new file which is 10% the size of the original MAF file. This new file contains following columns. Note that ProteinPaint does not require any specific order on the columns: Hugo_Symbol Chromosome Start_position Variant_Classification Tumor_Sample_Barcode cDNA_Change Protein_Change Refseq_mRNA_Id At the time of writing, ProteinPaint does not support disease subtype and subgroup information, as well as fusion gene data from the uploaded text file. Please check with the latest instructions on ProteinPaint to find out all supported data types and attributes. Uploading MAF file to ProteinPaint \u00b6 Load the trimmed-down version of the MAF file to ProteinPaint using the file upload panel previously shown: After loading this file, two new panels appear. The first panel shows the 5 reasons that some lines from the uploaded file are rejected by ProteinPaint. The reasons are ranked by the number of lines in which they occur: Click the first entry to inspect a rejected line for the reason \"wrong mutation class: RNA\". This is because that \"RNA\" describes a mutation in a noncoding gene, which ProteinPaint currently does not support: Please refer to other tutorials on exploring the data content from an uploaded MAF file.","title":"Loading a TCGA MAF File"},{"location":"guides/proteinpaint/advanced-guides/loading-tcga-maf-file/#loading-tcga-maf-file","text":"The MAF format is extensively used by TCGA and others to present cancer genomic mutations. The MAF format is specified here: https://wiki.nci.nih.gov/display/TCGA/Mutation+Annotation+Format+(MAF)+Specification . Here we describe steps to download MAF files from the TCGA Data Portal and display on ProteinPaint. Visit the TCGA data portal at https://tcga-data.nci.nih.gov/tcga/ and go to the \"Open-Access HTTP Directory\" from the menu: In the HTTP directory, click on any of the disease folder to look for mutations stored in MAF files: You may need to go down several folders to find the MAF files. For skin cancer, the path of folders to find MAF files is: skcm/ > gsc/ > broad.mit.edu/ > illuminaga_dnaseq/ > mutations/ > broad.mit.edu_SKCM.IlluminaGA_DNASeq.Level_2.0.1.0/ As an example, from this folder we download a MAF file named \"PR_TCGA_SKCM_PAIR_Capture_All_Pairs_QCPASS.aggregated.capture.tcga.uuid.somatic.maf\". This MAF file can be submitted to ProteinPaint. Due to the relatively large size of this MAF file, it can be helpful to keep only essential columns so as to reduce file size and speed up uploading and subsequent browsing. This can be done either using a shell command, or a spreadsheet software. Using shell command: cut -f1,5,6,9,16,40,42,44 PR_TCGA_SKCM_PAIR_Capture_All_Pairs_QCPASS.aggregated.capture.tcga.uuid.somatic.maf > TCGA_SKCM.slim.maf Using a spreadsheet software (e.g. Microsoft Excel, OpenOffice): Import the MAF file into the software by choosing \"tab\" as delimiter. Select columns with following header names: Hugo_Symbol, Chromosome, Start_position, Variant_Classification, Tumor_Sample_Barcode, cDNA_Change, Protein_Change, Refseq_mRNA_Id. Copy the contents of selected columns. Create a new sheet and paste these columns into the new sheet. Choose \"Save as...\" and select \"tab-delimited text\" format to save this sheet to a text file. Both methods will generate a new file which is 10% the size of the original MAF file. This new file contains following columns. Note that ProteinPaint does not require any specific order on the columns: Hugo_Symbol Chromosome Start_position Variant_Classification Tumor_Sample_Barcode cDNA_Change Protein_Change Refseq_mRNA_Id At the time of writing, ProteinPaint does not support disease subtype and subgroup information, as well as fusion gene data from the uploaded text file. Please check with the latest instructions on ProteinPaint to find out all supported data types and attributes.","title":"Loading TCGA MAF file"},{"location":"guides/proteinpaint/advanced-guides/loading-tcga-maf-file/#uploading-maf-file-to-proteinpaint","text":"Load the trimmed-down version of the MAF file to ProteinPaint using the file upload panel previously shown: After loading this file, two new panels appear. The first panel shows the 5 reasons that some lines from the uploaded file are rejected by ProteinPaint. The reasons are ranked by the number of lines in which they occur: Click the first entry to inspect a rejected line for the reason \"wrong mutation class: RNA\". This is because that \"RNA\" describes a mutation in a noncoding gene, which ProteinPaint currently does not support: Please refer to other tutorials on exploring the data content from an uploaded MAF file.","title":"Uploading MAF file to ProteinPaint"},{"location":"guides/proteinpaint/advanced-guides/stratify-mutation-by-cancer-subtype/","text":"In the header of the Pediatric data set graph, click on the third button labeled \"Cancer subtype\" to show a menu listing number of mutations in each cancer type and subtype: In above example, \"HGG\" is a type of cancer, with two subtypes named \"DIPG\" and \"Non-BS-HGG\" shown as indented rows. The right-side numbers are the number of TP53 mutations in each category. Following the total number is a breakdown by mutation classes, beginning with the largest class. Note that this list of options is generated based on the data for specific protein, and will have different content for another protein. Choose the option \"HGG\" from above example to show high-grade glioma mutations in a separate graph below the protein: On the top, a new handle is created for \"Pediatric, HGG\", which can be used to toggle or delete this subset of data: Click \"X\" on the right of this handle to remove this subset. A button on the top of cancer subtype list allows creating a sunburst chart for all mutations from the current data set: COSMIC data can also be stratified in a similar way, but according to tissue types. On the header of COSMIC graph, click the button labeled \"Tissue\" to get a list of tissue types. Choose a tissue type and a new graph will be created showing COSMIC mutations for only this tissue type: Note the new button \"15 not in list\" on the top, as a way to indicate some mutations are not identified by tissue type. Click this button to show these mutations: Note that the \"Primary site\" fields are blank for all these mutations, the reason why they are excluded from the stratification menu.","title":"Stratifying Mutations by Cancer Subtype"},{"location":"guides/proteinpaint/advanced-guides/uploaded-mutation-data-user-interface/","text":"Uploaded mutation data user interface After loading a mutation data file through \"\\bulk\", a panel similar to below will be generated: On the right is an active panel. By default it displays the gene table. On the left is a set of tabs displaying various stats about the uploaded data set. They can be clicked to show/hide corresponding panel. While a panel is displayed, the tab has a black border as indication. The first tab \"mutations\" is the most simple one. Click it to show a list of mutation classes found in the data set, ranked by the number of cases in each class: The gene, sample, and heatmap panels are described in separate tutorials. The header of the panel (gray box with the file name) is a drag-bar and can be used to move the panel around in the web browser window. By clicking the button on the left of the header, the panel will be folded to show only the header. Click again to show full panel.","title":"Uploaded Mutation Data User Interface"},{"location":"guides/proteinpaint/advanced-guides/using-a-vcf-file/","text":"Using VCF file on ProteinPaint Current implementation works for SNV/indel data only. Preparing a VCF file \u00b6 Input file: file.vcf bgzip file.vcf tabix -p vcf file.vcf.gz If successful, this will produce two files \"file.vcf.gz\" and \"file.vcf.gz.tbi\". The latter is the TBI index file. CSI index also works. Hosting a VCF file \u00b6 Host it on the ProteinPaint server: Put both the .gz file and the index file at the same directory > inside the directory of the ProteinPaint server. a. The directory is specified in the file \"serverconfig.json\". Obtain the relative path to the .gz file from but not include the directory. a. E.g. for /path/to/file.vcf.gz, the path would be \"path/to/file.vcf.gz\" Host it on a web server: Put the .gz and index files on the web server. Obtain the URL of the .gz file for submission. For most cases ProteinPaint expects to find the index file at the same location of the .gz file If the index file does not share URL with the .gz file, provide its URL via the .indexURL attribute in the JSON definition Showing a VCF file on ProteinPaint \u00b6 Via URL parameters \u00b6 Examples: http://server?block=on&genome=[genome]&vcffile=[name],[file path] http://server?block=on&genome=[genome]&vcfurl=[name],[file URL] The \"vcfurl\" cannot accept a separate URL for the index file, for such case, use embedding API instead This will launch a genome browser view showing the VCF track. Via embedding API \u00b6 If the index file is using a separate URL with the .gz file, the embedding API must be used, in which the attribute \"indexURL\" can be used to provide an additional URL for the index file. General introduction of embedding API. General introduction on JSON definition for tracks. See section Summary of VCF track object for an overview of the VCF track object. Variant annotation formats \u00b6 This section describes supported formats for functional annotation of variants. The annotation is optional and mostly for coding variants. The annotation will color-code variants using ProteinPaint's built-in protein mutation classes. Shortcoming is the built-in classes are hardcoded and cannot be customized. ProteinPaint fully supports custom defined classes through an alternative method. See the section on highlighting and filtering with INFO fields. VEP format \u00b6 The VCF output from the VEP is accepted by ProteinPaint. Find details at http://useast.ensembl.org/info/docs/tools/vep/vep_formats.html at the \"VCF output\" section. The annotation is encoded in an INFO field called CSQ. It supports functional annotation of multiple isoforms on a given allele. Description of the CSQ sub-fields must be in a required format for the purpose of identifying the name and order of the sub-fields. Following is one example: ##INFO=<ID=CSQ,Number=.,Type=String,Description=\"Consequence type as predicted by VEP. Format: Allele|Gene|Feature|Feature_type|Consequence|cDNA_position|CDS_position|Protein_position|Amino_acids|Codons|Existing_variation|ALLELE_NUM|DISTANCE|STRAND|SYMBOL|SYMBOL_SOURCE|HGNC_ID|BIOTYPE|CANONICAL|CCDS|ENSP|SWISSPROT|TREMBL|UNIPARC|SIFT|PolyPhen|EXON|INTRON|DOMAINS|HGVSc|HGVSp|GMAF|AFR_MAF|AMR_MAF|ASN_MAF|EUR_MAF|AA_MAF|EA_MAF|CLIN_SIG|SOMATIC|PUBMED|MOTIF_NAME|MOTIF_POS|HIGH_INF_POS|MOTIF_SCORE_CHANGE|LoF_info|LoF_flags|LoF_filter|LoF\"> Required CSQ sub-fields: Feature_type When the value of Feature_type is \"Transcript\" for a variant, the value of \"Feature\" should be isoform name, e.g. RefSeq or ENSEMBL isoform. If multiple isoform names joined by comma, the first will be used Consequence The VEP consequence notation http://useast.ensembl.org/info/genome/variation/predicted_data.html is converted to internal notation used by ProteinPaint. A match table is shown below HGVSp Protein_position Amino_acids HGVSc Existing_variation If any above fields are available, will use the value as the label of the variant VEP notation ProteinPaint notation Note transcript_ablation deletion, intragenic Not yet supported. splice_acceptor_variant splice splice_donor_variant splice stop_gained nonsense frameshift_variant frameshift stop_lost nonsense start_lost nonsense transcript_amplification nonstandard Not yet supported. inframe_insertion proteinins inframe_deletion proteindel missense_variant missense protein_altering_variant nonsense Not explicitly supported splice_region_variant splice_region incomplete_terminal_codon_variant nonsense stop_retained_variant silent Not explicitly supported. synonymous_variant silent coding_sequence_variant nonstandard Not explicitly supported. mature_miRNA_variant exon Not yet supported. 5_prime_UTR_variant utr_5 3_prime_UTR_variant utr_3 non_coding_transcript_exon_variant exon intron_variant intron NMD_transcript_variant silent Not equivalent. non_coding_transcript_variant exon upstream_gene_variant noncoding Not explicitly supported. downstream_gene_variant noncoding Not explicitly supported. TFBS_ablation noncoding Not yet supported. TFBS_amplification noncoding Not yet supported. TF_binding_site_variant noncoding Not yet supported. regulatory_region_ablation noncoding Not yet supported. regulatory_region_amplification noncoding Not yet supported. feature_elongation noncoding Not yet supported. regulatory_region_variant noncoding Not yet supported. feature_truncation noncoding Not yet supported. intergenic_variant noncoding Not yet supported. ANN format \u00b6 As generated by SnpEff: http://snpeff.sourceforge.net/VCFannotationformat_v1.0.pdf This format uses the \"ANN\" INFO field. The meta line: ##INFO=<ID=ANN,Number=.,Type=String,Description=\"Functional annotations: 'Allele | Annotation | Annotation_Impact | Gene_Name | Gene_ID | Feature_Type | Feature_ID | Transcript_BioType | Rank | HGVS.c | HGVS.p | cDNA.pos / cDNA.length | CDS.pos / CDS.length | AA.pos / AA.length | Distance | ERRORS / WARNINGS / INFO' \"> Example annotation data: ANN=T|5_prime_UTR_variant|MODIFIER|TUBB8|TUBB8|transcript|XM_011519459.2|protein_coding|1/4|c.-177G>A|||||750|,T|upstream_gene_variant|MODIFIER|TUBB8|TUBB8|transcript|NM_177987.2|protein_coding||c.-187G>A|||||187|,T|upstream_gene_variant|MODIFIER|TUBB8|TUBB8|transcript|XM_011519460.2|protein_coding||c.-1248G>A|||||961|,T|upstream_gene_variant|MODIFIER|TUBB8|TUBB8|transcript|XM_017016193.1|protein_coding||c.-1370G>A|||||967|,T|upstream_gene_variant|MODIFIER|TUBB8|TUBB8|transcript|XM_017016192.1|protein_coding||c.-1370G>A|||||955| The \"Annotation\" notations are converted to the built-in mutation class using the same set of VEP rules. In-house format \u00b6 This format uses multiple INFO fields to provide per-alt allele values: ##INFO=<ID=AV_POS,Number=A,Type=Integer,Description=\"Annovar+: adjusted allele position in order of ALT column\"> ##INFO=<ID=AV_REF,Number=A,Type=String,Description=\"Annovar+: adjusted reference allele in order of ALT column\"> ##INFO=<ID=AV_ALT,Number=A,Type=String,Description=\"Annovar+: adjusted variant allele in order of ALT column\"> ##INFO=<ID=AV_ACC,Number=A,Type=String,Description=\"Annovar+: isoform accession in order of ALT column\"> ##INFO=<ID=AV_AA,Number=A,Type=String,Description=\"Annovar+: amino acid change in order of ALT column\"> ##INFO=<ID=AV_CLASS,Number=A,Type=String,Description=\"Annovar+: variant class in order of ALT column\"> Example annotation: AV_POS=69655;AV_REF=G;AV_ALT=C;AV_ACC=NM_001005484;AV_AA=D189H;AV_CLASS=missense Combining multiple VCF files in one track \u00b6 This is only achievable by declaring the tracks in JSON and calling ProteinPaint's embedding API . Following example shows the JSON part of a VCF track which combines multiple VCF files. { \"type\" : \"vcf\" , \"name\" : \"track name\" , \"tracks\" : [ { \"file\" : \"path/to/sample1.gz\" }, { \"file\" : \"path/to/sample2.gz\" }, ... more files ... ] } In above example, the \"tracks\" attribute provides a list of member tracks. Each member track can have 0 or multiple samples. Highlighting and filtering variants with INFO fields \u00b6 Variants from a VCF track can be highlighted by other types of annotation, in addition to the default mutation class. To recreate this display, save following text into an HTML file, and display it in a web browser. <!DOCTYPE html> < html > < head >< meta charset = \"utf-8\" ></ head > < body > < script src = \"https://proteinpaint.stjude.org/bin/proteinpaint.js\" charset = \"utf-8\" ></ script > < div id = aaa style = \"margin:10px\" ></ div > < script > runproteinpaint ({ host : 'https://proteinpaint.stjude.org' , holder : document . getElementById ( 'aaa' ), parseurl : true , block : true , genome : 'hg38' , position : 'chr12:25245155-25246060' , nativetracks : 'RefGene' , tracks : [ { type : 'vcf' , name : 'Clinvar' , file : 'hg38/clinvar.hg38.vcf.gz' , vcfinfofilter : { lst : [ { name : 'Clinical significance' , locusinfo : { key : 'CLNSIG' , }, categories : { 'Uncertain_significance' : { color : '#aaa' , label : 'Uncertain significance' , textcolor : 'white' }, 'not_provided' : { color : '#ccc' , label : 'Not provided' }, '_not_provided' : { color : '#ccc' , label : 'Not provided' }, 'Benign' : { color : '#43ac6a' , label : 'Benign' , textcolor : 'white' }, 'Benign/Likely_benign' : { color : '#43ac6a' , label : 'Benign/Likely benign' , textcolor : 'white' }, 'Likely_benign' : { color : '#5bc0de' , label : 'Likely benign' , textcolor : 'white' }, 'Likely_pathogenic' : { color : '#e99002' , label : 'Likely pathogenic' , textcolor : 'white' }, 'Pathogenic' : { color : '#f04124' , label : 'Pathogenic' , textcolor : 'white' }, 'Pathogenic/Likely_pathogenic' : { color : '#f04124' , label : 'Pathogenic/Likely pathogenic' , textcolor : 'white' }, 'drug_response' : { color : 'gold' , label : 'Drug response' , textcolor : 'white' }, '_drug_response' : { color : 'gold' , label : 'Drug response' , textcolor : 'white' }, 'Conflicting_interpretations_of_pathogenicity' : { color : '#90C3D4' , label : 'Conflicting interpretations of pathogenicity' }, 'other' : { color : '#ccc' , label : 'Other' }, '_other' : { color : '#ccc' , label : 'Other' }, 'not_provided' : { color : '#ccc' , label : 'Not provided' }, '_not_provided' : { color : '#ccc' , label : 'Not provided' }, 'risk_factor' : { color : '#ccc' , label : 'Risk factor' }, '_risk_factor' : { color : '#ccc' , label : 'Risk factor' }, 'association' : { color : '#ccc' , label : 'Association' }, '_association' : { color : '#ccc' , label : 'Association' }, 'Affects' : { color : '#ccc' , label : 'Affects' }, '_Affects' : { color : '#ccc' , label : 'Affects' }, 'protective' : { color : '#ccc' , label : 'Protective' }, '_protective' : { color : '#ccc' , label : 'Protective' }, } }, { name : 'ExAC frequency' , locusinfo : { key : 'AF_EXAC' }, numericfilter : [ { side : '<' , value : 0.0001 }, { side : '<' , value : 0.001 }, { side : '<' , value : .01 } ], }, { name : 'GO-ESP frequency' , locusinfo : { key : 'AF_ESP' }, numericfilter : [ { side : '<' , value : 0.0001 }, { side : '<' , value : 0.001 }, { side : '<' , value : .01 } ], }, { name : '1000 Genomes frequency' , locusinfo : { key : 'AF_TGP' }, numericfilter : [ { side : '<' , value : 0.0001 }, { side : '<' , value : 0.001 }, { side : '<' , value : .01 } ], }, ], setidx4mclass : 0 , setidx4numeric : 3 , } } ] }) </ script > </ body > </ html > The example declares the VCF track as a JavaScript object (with the attribute \"vcfinfofilter\" explained below), and submit it to the public ProteinPaint server through the embedding API . The attribute \" vcfinfofilter \" provides instructions about what INFO fields can be used to highlight variants. It must contain the \" lst \" attribute which is an array, and each element is an object describing an INFO field. In each object describing an INFO field, use \" locusinfo \" to indicate that this field provides a value for each locus, and \" altalleleinfo \" to indicate that this field provides one value for each alternative allele, for a given locus. In a VCF file, an INFO field may describes categorical information about variants. In this case, the attribute \" categories \" is used to list a set of keys from such categorical information. And for each key, it provides the color and text label. Keys found in the VCF file but not listed here will be shown in black color. Variants not annotated by this INFO field will be aggregated under the category \"Not annotated\" and shown in black. Numerical INFO field can be used to provide cutoff values and filter variants, through \" numericfilter \". The attribute \"categories\" should not be used for numerical INFO. Categorical INFO field, locus-level \u00b6 { name : 'Variant origin' , locusinfo : { key : 'SAO' }, categories : { '0' : { color : '#aaa' , label : 'unspecified' }, '1' : { color : 'orange' , label : 'Germline' }, '2' : { color : 'blue' , label : 'Somatic' }, '3' : { color : 'magenta' , label : 'Both' } } }, Its META line: ##INFO=<ID=SAO,Number=1,Type=Integer,Description=\"Variant Allele Origin: 0 - unspecified, 1 - Germline, 2 - Somatic, 3 - Both\"> Annotation to a variant: #CHROM POS ID REF ALT QUAL FILTER INFO 1 1014143 . C T . . ...;SAO=1;... Categorical INFO field, alt-allele-level \u00b6 { name : 'Review status' , altalleleinfo : { key : 'CLNREVSTAT' , separator : '|' , }, categories : { 'no_assertion' : { color : '#545454' , label : 'no assertion' }, 'no_criteria' : { color : '#858585' , label : 'no criteria' }, 'mult' : { color : 'blue' , label : 'multiple submitters no conflicts' }, 'conf' : { color : 'red' , label : 'conflicting' }, 'exp' : { color : 'orange' , label : 'expert' }, 'guide' : { color : 'green' , label : 'Practice guideline' } } } Its META line: ##INFO=<ID=CLNREVSTAT,Number=.,Type=String,Description=\"no_assertion - No assertion provided, no_criteria - No assertion criteria provided, single - Criteria provided single submitter, mult - Criteria provided multiple submitters no conflicts, conf - Criteria provided conflicting interpretations, exp - Reviewed by expert panel, guideline - Practice guideline\"> Annotation to a variant: 1 1051336 rs141463750 C G,T . . ...;CLNREVSTAT=single;... (this may not be a good example of alt-allele-level INFO given the particular way that ClinVar selects an allele to describe, see the CLNALLE field) Categorical field without predefined categories and automatic color assignment \u00b6 This can apply to both locus-level and alt-allele level INFO fields. { name : '...' , altalleleinfo : { key : 'CLNREVSTAT' }, autocategory : true } When \"autocategory\" is set to true, it no longer requires the \"categories{}\" to predefine the list of types and colors. Such will be dynamically assigned each time the mutation data is loaded. A fixed color list will be used for assigning color to the list of showing categories by the order of abundance. May allow adding a color list. Numerical INFO field \u00b6 For numerical INFO field, its value can be used for filtering variants in the style of population frequency. Same as categorical INFO, it can be either alt-allele-level or locus-level. { vcfinfofilter : { lst : [ { name : 'Population frequency filter' , altalleleinfo : { key : 'AF' }, numericfilter : [ .000001 , 0.00001 , 0.0001 , 0.001 ], numericCutoff : 0.0001 , numericCutoffSide : '>' } ]} } The META line: ##INFO=<ID=AF,Number=A,Type=Float,Description=\"Allele Frequency, for each ALT allele, in the same order as listed\"> Annotation to a variant: 1 13528 . C G,T 1771.54 . ...;AF=5.438e-04,3.738e-04;... By default the filter will retain variants with values lower than the cutoff. To change the side of comparison, use the optional \"side\" attribute: numericfilter:[ {side:\">\",value:1}, {side:\">\", value:10} ... ] To set the default cutoff values from a numeric filter, use the \" numericCutoff \" and \" numericCutoffSide \" attributes as shown in above example. Missing value : if the numeric INFO field is missing for a variant, [its value will default to 0]{.underline}. This may work for the case of population frequency (AF), but may not make sense for other types of data. Possible solutions: Specify a value that a missing variant will default to. Underneath the Y scale, show a new row labeled \"missing\" to bin all the missing variants. Additional features \u00b6 These features will draw certain charts based on numeric attributes of the underlying samples. Population frequency filter \u00b6 The population frequency filter can be applied to any multi-sample VCF track, and requires appropriate configuration. As above, this requires declaring the track as JSON object and working with the embedding API. following is one example: { type : 'vcf' , name : 'SCD 143 samples' , file : 'path/to/vcf.gz' , populationfrequencyfilter : { name : \"Population frequency filter\" , lst : [ 0.01 , 0.05 , 0.1 ] } }, The attribute \"populationfrequencyfilter\" defines a set of fraction values between 0 and 1. Each value will search as a cutoff, e.g. value 0.01 allows to select variants with less than 1% frequency in the population (dividend is the total # of samples in the VCF track). In ProteinPaint, it's displayed as below: The cutoff values (1%, 5%, 10%) are listed in the legend section at the bottom. Click '<5%' to enable filtering, and resulted in 28 out of 35 variants visible in the track display. Click on the same cutoff value again to disable filtering. Coverage-VAF plot \u00b6 The coverage-VAF plot is available for any multi-sample tracks with allele read count information. The plot can be generated upon clicking on a mutation that is present in 2 or more samples. This graph Requires the AD FORMAT field ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=\"Allelic depths for the ref and alt alleles in the order listed\"> Declare the track as the following JSON object with the \"vaf2coverageplot\" attribute. { type : 'vcf' , name : 'SCD 143 samples' , file : 'path/to/vcf.gz' , vaf2coverageplot : {} }, Optionally, specify following attributes in vaf2coverageplot to distinguish samples by color in the plot. Todo Sample line plots \u00b6 Track Shows numerical Y axis, for each variant, all samples are shown as strokes One numerical value for each sample, as provided by a metadata attribute. \"samplebynumericvalue\" : { \"attrkey\" : \"HbFlevel\" , \"axislabel\" : \"HbF level\" }, Genotype by numeric value \u00b6 Track shows numerical Y axis. For each variant, one circle is shown for each genotype. Each circle represent a group of samples carrying that genotype. Circle vertical position is determined by a consensus value (mean) across the samples. This value should be provided as INFO fields. Circle sizes are scaled by number of samples in that group. The following configuration will require a multi-sample VCF file for getting the total number of samples for each genotype. \"genotypebynumericvalue\" : { \"axislabel\" : \"Genotype HbF\" , \"refref\" : { \"infokey\" : \"Hom_Ref_HbF\" , \"color\" : \"gray\" }, \"refalt\" : { \"infokey\" : \"Het_HbF\" , \"color\" : \"blue\" }, \"altalt\" : { \"infokey\" : \"Hom_Alt_HbF\" , \"color\" : \"red\" } }, Following configuration will als provide sample count in each genotype group as a INFO field. This requires two INFO fields for each genotype, one to provide Y-axis value, the other to provide number of samples for sizing the circle. \"genotypebynumericvalue\" : { \"axislabel\" : \"Genotype HbF\" , \"refref\" : { \"infokey\" : \"Hom_Ref_HbF\" , \"genotyepCountInfokey\" : STR , \"color\" : \"gray\" }, \"refalt\" : { \"infokey\" : \"Het_HbF\" , \"genotyepCountInfokey\" : STR , \"color\" : \"blue\" }, \"altalt\" : { \"infokey\" : \"Hom_Alt_HbF\" , \"genotyepCountInfokey\" : STR , \"color\" : \"red\" } }, Boxplots by genotype \u00b6 Upon clicking a variant, this will show a set of boxplots, one for each group of samples carrying one genotype from this variant. The boxplot reflects distribution of samples with respect to a specified numeric attribute. { \"genotype2boxplot\" : { \"axislabel\" : STR , \"sampleannotationkey\" : STR , \"boxplotvaluekey\" : STR // alternative to sampleannotationkey }, } If \" sampleannoationkey \" is set, will require sampleannotation to be provided. See the section on \"sample metadata annotation\". If \" boxplotvaluekey \" is provided, its value should be the name of an INFO field that provides the box-and-whisker values for creating boxplots for each genotype. The INFO field should be defined as: ##INFO=<ID=boxplotbygenotype,Number=1,Type=String,Description=\"For each possible genotype, define a boxplot with 5 numbers: low whisker, 1st quartile, median, 3rd quartile, high whisker. Genotypes are represented as refref, refalt, altalt. Separate genotypes by |, separate values by /\"> Example value to this INFO field: boxplotbygenotype=refref/0.1/1/4/6/8|refalt/1/2/3/4/5|altalt/2/3/4/5/6 Sample metadata annotation \u00b6 Sample annotation is an optional feature. If provided, it can be used to improve coverage-VAF plot, and divide samples to groups by the \"sampletype\" attribute to make separate coverage-VAF plots for each. To provide sample annotation, add a nested attribute \" sampleannotation.annotation \" to the VCF track object: { ... VCF definitions ... \"sampleannotation\" : { \"annotation\" : { \"sample1_D\" : { \"diagnosis\" : \"SCD\" , \"sampletype\" : \"Tumor\" , \"color\" : \"blue\" }, \"sample1_G\" : { \"diagnosis\" : \"SCD\" , \"sampletype\" : \"Normal\" , \"color\" : \"blue\" }, ... more samples ... }, \"key4annotation\" : \"sample\" } } \"annotation\" provides a hash, where are keys and values are annotations for this sample. \"Key4annotation\" defines the attribute name for . It enables user to specify if the annotation is at sample-level or patient-level. Todo further clarify Additional enhancements/description can be added to \" sampleannotation \": sampleannotation : { levels : [ { k : 'diagnosis' , label : 'Diagnosis' , full : 'diagnosis_full_name' }, { k : 'subtype' , label : 'Subtype' , full : 'subtype_full_name' } ], variantsunburst : true , key2color : { \"root...SCD\" : \"green\" } }, \"Levels\" provides a hierarchy of attributes for stratifying samples. Levels are arranged from high to low hierarchy. In each level, the string value of \" k \" and \" full \" should be found as attributes in \"sampleannotation.annotation\" of any sample. \"Variantsunburst\" allows showing a sunburst chart of samples when clicking on a variant. \"Key2color\" is a temp fix to define color for an annotation value from any level. In the example, \"SCD\" is the actual value of first level, and it must have prefix \"root...\". This defines the display color in sunburst chart. Live example: https://proteinpaint.stjude.org/pcgp.html in which the track \"PCGP somatic mutation\" is a multi-sample VCF track and is equipped with metadata annotation to its samples. Its track legend shows the annotation which can be used to filter samples: All the metadata annotation and track JSON declaration can be found in the source of the HTML page, around following lines: Speeding up multi-sample VCF track loading \u00b6 Given a multi-sample VCF track (cohort_VCF), prepare a variant-only version of this track (variant_VCF), and combine them in the track definition like below: { type : 'vcf' , name : 'lots of samples' , file : 'path/to/variant_VCF' , vcfcohorttrack : { file : 'path/to/cohort_VCF' , }, } When displaying this track in ProteinPaint, the variant_VCF will be loaded for showing all variants in the view range. Upon clicking a variant, the cohort_VCF will be queried to retrieve sample information on this variant, for rendering coverage-VAF plot or other uses. This design cuts down data transfer and can greatly improve performance for loading large-cohort VCF track. The \"samplenamemap()\" function can be applied in such track setup. Add this function in the \"vcfcohortrack\" object. Linking an image to each variant \u00b6 { type : 'vcf' , name : 'lots of samples' , file : 'path/to/variant_VCF' , variant2img : { path : 'path/to/imagefolder/' , ext : 'png' }, } By setting \"variant2img\", it allows to link an image to each variant. A \"Image\" button will appear at the details panel of the variant; clicking the button will display the image associated with this variant below. For each variant, the image will be located in the following way; note that the position is 1-based, and path is relative to the TP directory. variant2img.path + chromosome.position.REFallele.ALTallele + . + variant2img.ext Table display of multi-column INFO Field \u00b6 For a complex INFO field such as: ##INFO=<ID=INFOKEY,Number=.,Type=String,Description=\"Consequence annotations. Format: Allele|Consequence|SYMBOL|Entrez Gene ID|Feature_type|Feature|HGVSc|HGVSp|CIViC Variant Name|CIViC Variant ID|CIViC Variant Aliases|CIViC HGVS|Allele Registry ID|ClinVar IDs|CIViC Variant Evidence Score|CIViC Entity Type|CIViC Entity ID|CIViC Entity URL|CIViC Entity Source|CIViC Entity Variant Origin|CIViC Entity Status\"> Through configuration, contents of such INFO field for a variant can be displayed as a table: CIViC Entity Type CIViC Entity ID CIViC Entity URL CIViC Entity Source CIViC Entity Variant Origin CIViC Entity Status evidence 3766 [ https://civicdb.org/links/evidence/3766]{.underline}](https://civicdb.org/links/evidence/3766 ) PUBMED [ 22621641 Somatic submitted evidence 7485 [ https://civicdb.org/links/evidence/7485]{.underline}](https://civicdb.org/links/evidence/7485 ) PUBMED [ 31151904 Somatic submitted evidence 7077 [ https://civicdb.org/links/evidence/7077]{.underline}](https://civicdb.org/links/evidence/7077 ) PUBMED [ 25527633 Somatic submitted evidence 3768 [ https://civicdb.org/links/evidence/3768]{.underline}](https://civicdb.org/links/evidence/3768 ) PUBMED [ 23278307 Somatic submitted evidence 3781 [ https://civicdb.org/links/evidence/3781]{.underline}](https://civicdb.org/links/evidence/3781 ) PUBMED [ 23733758 Somatic submitted info2table:{} \u00b6 Key: name of the CSQ-like INFO field. Value: {} with keys of \"col_separator\" and \"fields\" array. \"Fields\" array should contain all the sub-fields in the INFO field, even for those hidden ones. Each element describes configurations with display/formatting instructions for each sub-field. info2table : { INFOKEY : { col_separator : '|' , separate_tables : [ ... ], // optional fields : [ { name : 'Allele' }, { name : 'Consequence' }, { name : 'SYMBOL' }, { name : 'Entrez Gene ID' }, { name : 'Feature_type' }, { name : 'Feature' }, { name : 'HGVSc' }, { name : 'HGVSp' }, ... more fields ... ] } } info2singletable:{} \u00b6 Same setting as the \"info2table\". Will only parse the first item of the CSQ field. This is useful in such cases when the given sub-fields are duplicated across all items. A \"vertical\" two-column table will be displayed, with a row for each sub-field. > Allele > T > Consequence > missense_variant > SYMBOL > BRAF > Entrez Gene ID > 673 > Feature_type > transcript > Feature > ENST00000288602.6 > HGVSc > ENST00000288602.6:c.1799T>A .hide:true \u00b6 If set, the field will be hidden from the table. .name:STR \u00b6 Required. A display name of the field. .ampersand2br:true \u00b6 Will convert all '&' to HTML line break . .isurl:true \u00b6 The column value is a full URL and will be shown as a tag. .appendUrl: STR \u00b6 To append the value to the end of the given partial URL and display the composed URL. .urlMatchLst:{} \u00b6 Example config: urlMatchLst : { separator : '_' , idIndex : 0 , types : [ { type : 'pubmed' , appendUrl : 'https://www.ncbi.nlm.nih.gov/pubmed/' }, { type : 'asco' , appendUrl : 'https://meetinglibrary.asco.org/record/' } ] } Which allows to parse following values into respective URL links. 31566309_(PubMed) 168986_(ASCO) separate_tables:\\[\\] \u00b6 Optional, and only applies to \"info2table\" but not \"info2singletable\". When multiple \"rows\" could be contained in one INFO field, the rows are to be divided into groups based on criteria of the \"groupers\" array, and shown in separate tables. Each table has the same set of columns, as defined in the \"fields[]\" array. separate_tables : [ { headhtml : 'Accepted evidence' , groupers : [ { field : 'CIViC Entity Type' , value : 'evidence' }, { field : 'CIViC Entity Status' , value : 'accepted' } ] }, { ... another table ... } ] URL links for variants \u00b6 A URL can be made for SNV/indel variants from a VCF track, so that when user clicks on the variant and shows the details, the URL link will be shown, to link to the variant in another website. To enable this, add the \" url4variant \" attribute in the track definition: { type : 'vcf' , name : 'Clinvar' , file : 'hg38/clinvar.hg38.201612.vcf.gz' , url4variant : [ { label : 'PeCAN-PIE' , makeurl : ( m )=>{ return 'https://pecan.stjude.org/#/variant/view/' + m . chr . replace ( 'chr' , '' ) + '/' + ( m . pos + 1 ) + '/' + m . ref + '/' + m . alt } } ], } Each element in \"url4variant\" describes a method to produce a URL for the variant. This allows multiple URL links to be produced on the same variant. Each element has the \" makeurl \" attribute, a JavaScript function that takes in the variant object as input, and returns the fully-formed URL string, parameterized by the attributes of the variant. The method may not work for mutation types other than SNV/indel. Summary of VCF track object \u00b6 A schematic overview of all available options that you can use to customize a VCF track.","title":"Loading a VCF File"},{"location":"guides/proteinpaint/advanced-guides/using-a-vcf-file/#preparing-a-vcf-file","text":"Input file: file.vcf bgzip file.vcf tabix -p vcf file.vcf.gz If successful, this will produce two files \"file.vcf.gz\" and \"file.vcf.gz.tbi\". The latter is the TBI index file. CSI index also works.","title":"Preparing a VCF file"},{"location":"guides/proteinpaint/advanced-guides/using-a-vcf-file/#hosting-a-vcf-file","text":"Host it on the ProteinPaint server: Put both the .gz file and the index file at the same directory > inside the directory of the ProteinPaint server. a. The directory is specified in the file \"serverconfig.json\". Obtain the relative path to the .gz file from but not include the directory. a. E.g. for /path/to/file.vcf.gz, the path would be \"path/to/file.vcf.gz\" Host it on a web server: Put the .gz and index files on the web server. Obtain the URL of the .gz file for submission. For most cases ProteinPaint expects to find the index file at the same location of the .gz file If the index file does not share URL with the .gz file, provide its URL via the .indexURL attribute in the JSON definition","title":"Hosting a VCF file"},{"location":"guides/proteinpaint/advanced-guides/using-a-vcf-file/#showing-a-vcf-file-on-proteinpaint","text":"","title":"Showing a VCF file on ProteinPaint"},{"location":"guides/proteinpaint/advanced-guides/using-a-vcf-file/#via-url-parameters","text":"Examples: http://server?block=on&genome=[genome]&vcffile=[name],[file path] http://server?block=on&genome=[genome]&vcfurl=[name],[file URL] The \"vcfurl\" cannot accept a separate URL for the index file, for such case, use embedding API instead This will launch a genome browser view showing the VCF track.","title":"Via URL parameters"},{"location":"guides/proteinpaint/advanced-guides/using-a-vcf-file/#via-embedding-api","text":"If the index file is using a separate URL with the .gz file, the embedding API must be used, in which the attribute \"indexURL\" can be used to provide an additional URL for the index file. General introduction of embedding API. General introduction on JSON definition for tracks. See section Summary of VCF track object for an overview of the VCF track object.","title":"Via embedding API"},{"location":"guides/proteinpaint/advanced-guides/using-a-vcf-file/#variant-annotation-formats","text":"This section describes supported formats for functional annotation of variants. The annotation is optional and mostly for coding variants. The annotation will color-code variants using ProteinPaint's built-in protein mutation classes. Shortcoming is the built-in classes are hardcoded and cannot be customized. ProteinPaint fully supports custom defined classes through an alternative method. See the section on highlighting and filtering with INFO fields.","title":"Variant annotation formats"},{"location":"guides/proteinpaint/advanced-guides/using-a-vcf-file/#vep-format","text":"The VCF output from the VEP is accepted by ProteinPaint. Find details at http://useast.ensembl.org/info/docs/tools/vep/vep_formats.html at the \"VCF output\" section. The annotation is encoded in an INFO field called CSQ. It supports functional annotation of multiple isoforms on a given allele. Description of the CSQ sub-fields must be in a required format for the purpose of identifying the name and order of the sub-fields. Following is one example: ##INFO=<ID=CSQ,Number=.,Type=String,Description=\"Consequence type as predicted by VEP. Format: Allele|Gene|Feature|Feature_type|Consequence|cDNA_position|CDS_position|Protein_position|Amino_acids|Codons|Existing_variation|ALLELE_NUM|DISTANCE|STRAND|SYMBOL|SYMBOL_SOURCE|HGNC_ID|BIOTYPE|CANONICAL|CCDS|ENSP|SWISSPROT|TREMBL|UNIPARC|SIFT|PolyPhen|EXON|INTRON|DOMAINS|HGVSc|HGVSp|GMAF|AFR_MAF|AMR_MAF|ASN_MAF|EUR_MAF|AA_MAF|EA_MAF|CLIN_SIG|SOMATIC|PUBMED|MOTIF_NAME|MOTIF_POS|HIGH_INF_POS|MOTIF_SCORE_CHANGE|LoF_info|LoF_flags|LoF_filter|LoF\"> Required CSQ sub-fields: Feature_type When the value of Feature_type is \"Transcript\" for a variant, the value of \"Feature\" should be isoform name, e.g. RefSeq or ENSEMBL isoform. If multiple isoform names joined by comma, the first will be used Consequence The VEP consequence notation http://useast.ensembl.org/info/genome/variation/predicted_data.html is converted to internal notation used by ProteinPaint. A match table is shown below HGVSp Protein_position Amino_acids HGVSc Existing_variation If any above fields are available, will use the value as the label of the variant VEP notation ProteinPaint notation Note transcript_ablation deletion, intragenic Not yet supported. splice_acceptor_variant splice splice_donor_variant splice stop_gained nonsense frameshift_variant frameshift stop_lost nonsense start_lost nonsense transcript_amplification nonstandard Not yet supported. inframe_insertion proteinins inframe_deletion proteindel missense_variant missense protein_altering_variant nonsense Not explicitly supported splice_region_variant splice_region incomplete_terminal_codon_variant nonsense stop_retained_variant silent Not explicitly supported. synonymous_variant silent coding_sequence_variant nonstandard Not explicitly supported. mature_miRNA_variant exon Not yet supported. 5_prime_UTR_variant utr_5 3_prime_UTR_variant utr_3 non_coding_transcript_exon_variant exon intron_variant intron NMD_transcript_variant silent Not equivalent. non_coding_transcript_variant exon upstream_gene_variant noncoding Not explicitly supported. downstream_gene_variant noncoding Not explicitly supported. TFBS_ablation noncoding Not yet supported. TFBS_amplification noncoding Not yet supported. TF_binding_site_variant noncoding Not yet supported. regulatory_region_ablation noncoding Not yet supported. regulatory_region_amplification noncoding Not yet supported. feature_elongation noncoding Not yet supported. regulatory_region_variant noncoding Not yet supported. feature_truncation noncoding Not yet supported. intergenic_variant noncoding Not yet supported.","title":"VEP format"},{"location":"guides/proteinpaint/advanced-guides/using-a-vcf-file/#ann-format","text":"As generated by SnpEff: http://snpeff.sourceforge.net/VCFannotationformat_v1.0.pdf This format uses the \"ANN\" INFO field. The meta line: ##INFO=<ID=ANN,Number=.,Type=String,Description=\"Functional annotations: 'Allele | Annotation | Annotation_Impact | Gene_Name | Gene_ID | Feature_Type | Feature_ID | Transcript_BioType | Rank | HGVS.c | HGVS.p | cDNA.pos / cDNA.length | CDS.pos / CDS.length | AA.pos / AA.length | Distance | ERRORS / WARNINGS / INFO' \"> Example annotation data: ANN=T|5_prime_UTR_variant|MODIFIER|TUBB8|TUBB8|transcript|XM_011519459.2|protein_coding|1/4|c.-177G>A|||||750|,T|upstream_gene_variant|MODIFIER|TUBB8|TUBB8|transcript|NM_177987.2|protein_coding||c.-187G>A|||||187|,T|upstream_gene_variant|MODIFIER|TUBB8|TUBB8|transcript|XM_011519460.2|protein_coding||c.-1248G>A|||||961|,T|upstream_gene_variant|MODIFIER|TUBB8|TUBB8|transcript|XM_017016193.1|protein_coding||c.-1370G>A|||||967|,T|upstream_gene_variant|MODIFIER|TUBB8|TUBB8|transcript|XM_017016192.1|protein_coding||c.-1370G>A|||||955| The \"Annotation\" notations are converted to the built-in mutation class using the same set of VEP rules.","title":"ANN format"},{"location":"guides/proteinpaint/advanced-guides/using-a-vcf-file/#in-house-format","text":"This format uses multiple INFO fields to provide per-alt allele values: ##INFO=<ID=AV_POS,Number=A,Type=Integer,Description=\"Annovar+: adjusted allele position in order of ALT column\"> ##INFO=<ID=AV_REF,Number=A,Type=String,Description=\"Annovar+: adjusted reference allele in order of ALT column\"> ##INFO=<ID=AV_ALT,Number=A,Type=String,Description=\"Annovar+: adjusted variant allele in order of ALT column\"> ##INFO=<ID=AV_ACC,Number=A,Type=String,Description=\"Annovar+: isoform accession in order of ALT column\"> ##INFO=<ID=AV_AA,Number=A,Type=String,Description=\"Annovar+: amino acid change in order of ALT column\"> ##INFO=<ID=AV_CLASS,Number=A,Type=String,Description=\"Annovar+: variant class in order of ALT column\"> Example annotation: AV_POS=69655;AV_REF=G;AV_ALT=C;AV_ACC=NM_001005484;AV_AA=D189H;AV_CLASS=missense","title":"In-house format"},{"location":"guides/proteinpaint/advanced-guides/using-a-vcf-file/#combining-multiple-vcf-files-in-one-track","text":"This is only achievable by declaring the tracks in JSON and calling ProteinPaint's embedding API . Following example shows the JSON part of a VCF track which combines multiple VCF files. { \"type\" : \"vcf\" , \"name\" : \"track name\" , \"tracks\" : [ { \"file\" : \"path/to/sample1.gz\" }, { \"file\" : \"path/to/sample2.gz\" }, ... more files ... ] } In above example, the \"tracks\" attribute provides a list of member tracks. Each member track can have 0 or multiple samples.","title":"Combining multiple VCF files in one track"},{"location":"guides/proteinpaint/advanced-guides/using-a-vcf-file/#highlighting-and-filtering-variants-with-info-fields","text":"Variants from a VCF track can be highlighted by other types of annotation, in addition to the default mutation class. To recreate this display, save following text into an HTML file, and display it in a web browser. <!DOCTYPE html> < html > < head >< meta charset = \"utf-8\" ></ head > < body > < script src = \"https://proteinpaint.stjude.org/bin/proteinpaint.js\" charset = \"utf-8\" ></ script > < div id = aaa style = \"margin:10px\" ></ div > < script > runproteinpaint ({ host : 'https://proteinpaint.stjude.org' , holder : document . getElementById ( 'aaa' ), parseurl : true , block : true , genome : 'hg38' , position : 'chr12:25245155-25246060' , nativetracks : 'RefGene' , tracks : [ { type : 'vcf' , name : 'Clinvar' , file : 'hg38/clinvar.hg38.vcf.gz' , vcfinfofilter : { lst : [ { name : 'Clinical significance' , locusinfo : { key : 'CLNSIG' , }, categories : { 'Uncertain_significance' : { color : '#aaa' , label : 'Uncertain significance' , textcolor : 'white' }, 'not_provided' : { color : '#ccc' , label : 'Not provided' }, '_not_provided' : { color : '#ccc' , label : 'Not provided' }, 'Benign' : { color : '#43ac6a' , label : 'Benign' , textcolor : 'white' }, 'Benign/Likely_benign' : { color : '#43ac6a' , label : 'Benign/Likely benign' , textcolor : 'white' }, 'Likely_benign' : { color : '#5bc0de' , label : 'Likely benign' , textcolor : 'white' }, 'Likely_pathogenic' : { color : '#e99002' , label : 'Likely pathogenic' , textcolor : 'white' }, 'Pathogenic' : { color : '#f04124' , label : 'Pathogenic' , textcolor : 'white' }, 'Pathogenic/Likely_pathogenic' : { color : '#f04124' , label : 'Pathogenic/Likely pathogenic' , textcolor : 'white' }, 'drug_response' : { color : 'gold' , label : 'Drug response' , textcolor : 'white' }, '_drug_response' : { color : 'gold' , label : 'Drug response' , textcolor : 'white' }, 'Conflicting_interpretations_of_pathogenicity' : { color : '#90C3D4' , label : 'Conflicting interpretations of pathogenicity' }, 'other' : { color : '#ccc' , label : 'Other' }, '_other' : { color : '#ccc' , label : 'Other' }, 'not_provided' : { color : '#ccc' , label : 'Not provided' }, '_not_provided' : { color : '#ccc' , label : 'Not provided' }, 'risk_factor' : { color : '#ccc' , label : 'Risk factor' }, '_risk_factor' : { color : '#ccc' , label : 'Risk factor' }, 'association' : { color : '#ccc' , label : 'Association' }, '_association' : { color : '#ccc' , label : 'Association' }, 'Affects' : { color : '#ccc' , label : 'Affects' }, '_Affects' : { color : '#ccc' , label : 'Affects' }, 'protective' : { color : '#ccc' , label : 'Protective' }, '_protective' : { color : '#ccc' , label : 'Protective' }, } }, { name : 'ExAC frequency' , locusinfo : { key : 'AF_EXAC' }, numericfilter : [ { side : '<' , value : 0.0001 }, { side : '<' , value : 0.001 }, { side : '<' , value : .01 } ], }, { name : 'GO-ESP frequency' , locusinfo : { key : 'AF_ESP' }, numericfilter : [ { side : '<' , value : 0.0001 }, { side : '<' , value : 0.001 }, { side : '<' , value : .01 } ], }, { name : '1000 Genomes frequency' , locusinfo : { key : 'AF_TGP' }, numericfilter : [ { side : '<' , value : 0.0001 }, { side : '<' , value : 0.001 }, { side : '<' , value : .01 } ], }, ], setidx4mclass : 0 , setidx4numeric : 3 , } } ] }) </ script > </ body > </ html > The example declares the VCF track as a JavaScript object (with the attribute \"vcfinfofilter\" explained below), and submit it to the public ProteinPaint server through the embedding API . The attribute \" vcfinfofilter \" provides instructions about what INFO fields can be used to highlight variants. It must contain the \" lst \" attribute which is an array, and each element is an object describing an INFO field. In each object describing an INFO field, use \" locusinfo \" to indicate that this field provides a value for each locus, and \" altalleleinfo \" to indicate that this field provides one value for each alternative allele, for a given locus. In a VCF file, an INFO field may describes categorical information about variants. In this case, the attribute \" categories \" is used to list a set of keys from such categorical information. And for each key, it provides the color and text label. Keys found in the VCF file but not listed here will be shown in black color. Variants not annotated by this INFO field will be aggregated under the category \"Not annotated\" and shown in black. Numerical INFO field can be used to provide cutoff values and filter variants, through \" numericfilter \". The attribute \"categories\" should not be used for numerical INFO.","title":"Highlighting and filtering variants with INFO fields"},{"location":"guides/proteinpaint/advanced-guides/using-a-vcf-file/#categorical-info-field-locus-level","text":"{ name : 'Variant origin' , locusinfo : { key : 'SAO' }, categories : { '0' : { color : '#aaa' , label : 'unspecified' }, '1' : { color : 'orange' , label : 'Germline' }, '2' : { color : 'blue' , label : 'Somatic' }, '3' : { color : 'magenta' , label : 'Both' } } }, Its META line: ##INFO=<ID=SAO,Number=1,Type=Integer,Description=\"Variant Allele Origin: 0 - unspecified, 1 - Germline, 2 - Somatic, 3 - Both\"> Annotation to a variant: #CHROM POS ID REF ALT QUAL FILTER INFO 1 1014143 . C T . . ...;SAO=1;...","title":"Categorical INFO field, locus-level"},{"location":"guides/proteinpaint/advanced-guides/using-a-vcf-file/#categorical-info-field-alt-allele-level","text":"{ name : 'Review status' , altalleleinfo : { key : 'CLNREVSTAT' , separator : '|' , }, categories : { 'no_assertion' : { color : '#545454' , label : 'no assertion' }, 'no_criteria' : { color : '#858585' , label : 'no criteria' }, 'mult' : { color : 'blue' , label : 'multiple submitters no conflicts' }, 'conf' : { color : 'red' , label : 'conflicting' }, 'exp' : { color : 'orange' , label : 'expert' }, 'guide' : { color : 'green' , label : 'Practice guideline' } } } Its META line: ##INFO=<ID=CLNREVSTAT,Number=.,Type=String,Description=\"no_assertion - No assertion provided, no_criteria - No assertion criteria provided, single - Criteria provided single submitter, mult - Criteria provided multiple submitters no conflicts, conf - Criteria provided conflicting interpretations, exp - Reviewed by expert panel, guideline - Practice guideline\"> Annotation to a variant: 1 1051336 rs141463750 C G,T . . ...;CLNREVSTAT=single;... (this may not be a good example of alt-allele-level INFO given the particular way that ClinVar selects an allele to describe, see the CLNALLE field)","title":"Categorical INFO field, alt-allele-level"},{"location":"guides/proteinpaint/advanced-guides/using-a-vcf-file/#categorical-field-without-predefined-categories-and-automatic-color-assignment","text":"This can apply to both locus-level and alt-allele level INFO fields. { name : '...' , altalleleinfo : { key : 'CLNREVSTAT' }, autocategory : true } When \"autocategory\" is set to true, it no longer requires the \"categories{}\" to predefine the list of types and colors. Such will be dynamically assigned each time the mutation data is loaded. A fixed color list will be used for assigning color to the list of showing categories by the order of abundance. May allow adding a color list.","title":"Categorical field without predefined categories and automatic color assignment"},{"location":"guides/proteinpaint/advanced-guides/using-a-vcf-file/#numerical-info-field","text":"For numerical INFO field, its value can be used for filtering variants in the style of population frequency. Same as categorical INFO, it can be either alt-allele-level or locus-level. { vcfinfofilter : { lst : [ { name : 'Population frequency filter' , altalleleinfo : { key : 'AF' }, numericfilter : [ .000001 , 0.00001 , 0.0001 , 0.001 ], numericCutoff : 0.0001 , numericCutoffSide : '>' } ]} } The META line: ##INFO=<ID=AF,Number=A,Type=Float,Description=\"Allele Frequency, for each ALT allele, in the same order as listed\"> Annotation to a variant: 1 13528 . C G,T 1771.54 . ...;AF=5.438e-04,3.738e-04;... By default the filter will retain variants with values lower than the cutoff. To change the side of comparison, use the optional \"side\" attribute: numericfilter:[ {side:\">\",value:1}, {side:\">\", value:10} ... ] To set the default cutoff values from a numeric filter, use the \" numericCutoff \" and \" numericCutoffSide \" attributes as shown in above example. Missing value : if the numeric INFO field is missing for a variant, [its value will default to 0]{.underline}. This may work for the case of population frequency (AF), but may not make sense for other types of data. Possible solutions: Specify a value that a missing variant will default to. Underneath the Y scale, show a new row labeled \"missing\" to bin all the missing variants.","title":"Numerical INFO field"},{"location":"guides/proteinpaint/advanced-guides/using-a-vcf-file/#additional-features","text":"These features will draw certain charts based on numeric attributes of the underlying samples.","title":"Additional features"},{"location":"guides/proteinpaint/advanced-guides/using-a-vcf-file/#population-frequency-filter","text":"The population frequency filter can be applied to any multi-sample VCF track, and requires appropriate configuration. As above, this requires declaring the track as JSON object and working with the embedding API. following is one example: { type : 'vcf' , name : 'SCD 143 samples' , file : 'path/to/vcf.gz' , populationfrequencyfilter : { name : \"Population frequency filter\" , lst : [ 0.01 , 0.05 , 0.1 ] } }, The attribute \"populationfrequencyfilter\" defines a set of fraction values between 0 and 1. Each value will search as a cutoff, e.g. value 0.01 allows to select variants with less than 1% frequency in the population (dividend is the total # of samples in the VCF track). In ProteinPaint, it's displayed as below: The cutoff values (1%, 5%, 10%) are listed in the legend section at the bottom. Click '<5%' to enable filtering, and resulted in 28 out of 35 variants visible in the track display. Click on the same cutoff value again to disable filtering.","title":"Population frequency filter"},{"location":"guides/proteinpaint/advanced-guides/using-a-vcf-file/#coverage-vaf-plot","text":"The coverage-VAF plot is available for any multi-sample tracks with allele read count information. The plot can be generated upon clicking on a mutation that is present in 2 or more samples. This graph Requires the AD FORMAT field ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=\"Allelic depths for the ref and alt alleles in the order listed\"> Declare the track as the following JSON object with the \"vaf2coverageplot\" attribute. { type : 'vcf' , name : 'SCD 143 samples' , file : 'path/to/vcf.gz' , vaf2coverageplot : {} }, Optionally, specify following attributes in vaf2coverageplot to distinguish samples by color in the plot. Todo","title":"Coverage-VAF plot"},{"location":"guides/proteinpaint/advanced-guides/using-a-vcf-file/#sample-line-plots","text":"Track Shows numerical Y axis, for each variant, all samples are shown as strokes One numerical value for each sample, as provided by a metadata attribute. \"samplebynumericvalue\" : { \"attrkey\" : \"HbFlevel\" , \"axislabel\" : \"HbF level\" },","title":"Sample line plots"},{"location":"guides/proteinpaint/advanced-guides/using-a-vcf-file/#genotype-by-numeric-value","text":"Track shows numerical Y axis. For each variant, one circle is shown for each genotype. Each circle represent a group of samples carrying that genotype. Circle vertical position is determined by a consensus value (mean) across the samples. This value should be provided as INFO fields. Circle sizes are scaled by number of samples in that group. The following configuration will require a multi-sample VCF file for getting the total number of samples for each genotype. \"genotypebynumericvalue\" : { \"axislabel\" : \"Genotype HbF\" , \"refref\" : { \"infokey\" : \"Hom_Ref_HbF\" , \"color\" : \"gray\" }, \"refalt\" : { \"infokey\" : \"Het_HbF\" , \"color\" : \"blue\" }, \"altalt\" : { \"infokey\" : \"Hom_Alt_HbF\" , \"color\" : \"red\" } }, Following configuration will als provide sample count in each genotype group as a INFO field. This requires two INFO fields for each genotype, one to provide Y-axis value, the other to provide number of samples for sizing the circle. \"genotypebynumericvalue\" : { \"axislabel\" : \"Genotype HbF\" , \"refref\" : { \"infokey\" : \"Hom_Ref_HbF\" , \"genotyepCountInfokey\" : STR , \"color\" : \"gray\" }, \"refalt\" : { \"infokey\" : \"Het_HbF\" , \"genotyepCountInfokey\" : STR , \"color\" : \"blue\" }, \"altalt\" : { \"infokey\" : \"Hom_Alt_HbF\" , \"genotyepCountInfokey\" : STR , \"color\" : \"red\" } },","title":"Genotype by numeric value"},{"location":"guides/proteinpaint/advanced-guides/using-a-vcf-file/#boxplots-by-genotype","text":"Upon clicking a variant, this will show a set of boxplots, one for each group of samples carrying one genotype from this variant. The boxplot reflects distribution of samples with respect to a specified numeric attribute. { \"genotype2boxplot\" : { \"axislabel\" : STR , \"sampleannotationkey\" : STR , \"boxplotvaluekey\" : STR // alternative to sampleannotationkey }, } If \" sampleannoationkey \" is set, will require sampleannotation to be provided. See the section on \"sample metadata annotation\". If \" boxplotvaluekey \" is provided, its value should be the name of an INFO field that provides the box-and-whisker values for creating boxplots for each genotype. The INFO field should be defined as: ##INFO=<ID=boxplotbygenotype,Number=1,Type=String,Description=\"For each possible genotype, define a boxplot with 5 numbers: low whisker, 1st quartile, median, 3rd quartile, high whisker. Genotypes are represented as refref, refalt, altalt. Separate genotypes by |, separate values by /\"> Example value to this INFO field: boxplotbygenotype=refref/0.1/1/4/6/8|refalt/1/2/3/4/5|altalt/2/3/4/5/6","title":"Boxplots by genotype"},{"location":"guides/proteinpaint/advanced-guides/using-a-vcf-file/#sample-metadata-annotation","text":"Sample annotation is an optional feature. If provided, it can be used to improve coverage-VAF plot, and divide samples to groups by the \"sampletype\" attribute to make separate coverage-VAF plots for each. To provide sample annotation, add a nested attribute \" sampleannotation.annotation \" to the VCF track object: { ... VCF definitions ... \"sampleannotation\" : { \"annotation\" : { \"sample1_D\" : { \"diagnosis\" : \"SCD\" , \"sampletype\" : \"Tumor\" , \"color\" : \"blue\" }, \"sample1_G\" : { \"diagnosis\" : \"SCD\" , \"sampletype\" : \"Normal\" , \"color\" : \"blue\" }, ... more samples ... }, \"key4annotation\" : \"sample\" } } \"annotation\" provides a hash, where are keys and values are annotations for this sample. \"Key4annotation\" defines the attribute name for . It enables user to specify if the annotation is at sample-level or patient-level. Todo further clarify Additional enhancements/description can be added to \" sampleannotation \": sampleannotation : { levels : [ { k : 'diagnosis' , label : 'Diagnosis' , full : 'diagnosis_full_name' }, { k : 'subtype' , label : 'Subtype' , full : 'subtype_full_name' } ], variantsunburst : true , key2color : { \"root...SCD\" : \"green\" } }, \"Levels\" provides a hierarchy of attributes for stratifying samples. Levels are arranged from high to low hierarchy. In each level, the string value of \" k \" and \" full \" should be found as attributes in \"sampleannotation.annotation\" of any sample. \"Variantsunburst\" allows showing a sunburst chart of samples when clicking on a variant. \"Key2color\" is a temp fix to define color for an annotation value from any level. In the example, \"SCD\" is the actual value of first level, and it must have prefix \"root...\". This defines the display color in sunburst chart. Live example: https://proteinpaint.stjude.org/pcgp.html in which the track \"PCGP somatic mutation\" is a multi-sample VCF track and is equipped with metadata annotation to its samples. Its track legend shows the annotation which can be used to filter samples: All the metadata annotation and track JSON declaration can be found in the source of the HTML page, around following lines:","title":"Sample metadata annotation"},{"location":"guides/proteinpaint/advanced-guides/using-a-vcf-file/#speeding-up-multi-sample-vcf-track-loading","text":"Given a multi-sample VCF track (cohort_VCF), prepare a variant-only version of this track (variant_VCF), and combine them in the track definition like below: { type : 'vcf' , name : 'lots of samples' , file : 'path/to/variant_VCF' , vcfcohorttrack : { file : 'path/to/cohort_VCF' , }, } When displaying this track in ProteinPaint, the variant_VCF will be loaded for showing all variants in the view range. Upon clicking a variant, the cohort_VCF will be queried to retrieve sample information on this variant, for rendering coverage-VAF plot or other uses. This design cuts down data transfer and can greatly improve performance for loading large-cohort VCF track. The \"samplenamemap()\" function can be applied in such track setup. Add this function in the \"vcfcohortrack\" object.","title":"Speeding up multi-sample VCF track loading"},{"location":"guides/proteinpaint/advanced-guides/using-a-vcf-file/#linking-an-image-to-each-variant","text":"{ type : 'vcf' , name : 'lots of samples' , file : 'path/to/variant_VCF' , variant2img : { path : 'path/to/imagefolder/' , ext : 'png' }, } By setting \"variant2img\", it allows to link an image to each variant. A \"Image\" button will appear at the details panel of the variant; clicking the button will display the image associated with this variant below. For each variant, the image will be located in the following way; note that the position is 1-based, and path is relative to the TP directory. variant2img.path + chromosome.position.REFallele.ALTallele + . + variant2img.ext","title":"Linking an image to each variant"},{"location":"guides/proteinpaint/advanced-guides/using-a-vcf-file/#table-display-of-multi-column-info-field","text":"For a complex INFO field such as: ##INFO=<ID=INFOKEY,Number=.,Type=String,Description=\"Consequence annotations. Format: Allele|Consequence|SYMBOL|Entrez Gene ID|Feature_type|Feature|HGVSc|HGVSp|CIViC Variant Name|CIViC Variant ID|CIViC Variant Aliases|CIViC HGVS|Allele Registry ID|ClinVar IDs|CIViC Variant Evidence Score|CIViC Entity Type|CIViC Entity ID|CIViC Entity URL|CIViC Entity Source|CIViC Entity Variant Origin|CIViC Entity Status\"> Through configuration, contents of such INFO field for a variant can be displayed as a table: CIViC Entity Type CIViC Entity ID CIViC Entity URL CIViC Entity Source CIViC Entity Variant Origin CIViC Entity Status evidence 3766 [ https://civicdb.org/links/evidence/3766]{.underline}](https://civicdb.org/links/evidence/3766 ) PUBMED [ 22621641 Somatic submitted evidence 7485 [ https://civicdb.org/links/evidence/7485]{.underline}](https://civicdb.org/links/evidence/7485 ) PUBMED [ 31151904 Somatic submitted evidence 7077 [ https://civicdb.org/links/evidence/7077]{.underline}](https://civicdb.org/links/evidence/7077 ) PUBMED [ 25527633 Somatic submitted evidence 3768 [ https://civicdb.org/links/evidence/3768]{.underline}](https://civicdb.org/links/evidence/3768 ) PUBMED [ 23278307 Somatic submitted evidence 3781 [ https://civicdb.org/links/evidence/3781]{.underline}](https://civicdb.org/links/evidence/3781 ) PUBMED [ 23733758 Somatic submitted","title":"Table display of multi-column INFO Field"},{"location":"guides/proteinpaint/advanced-guides/using-a-vcf-file/#info2table","text":"Key: name of the CSQ-like INFO field. Value: {} with keys of \"col_separator\" and \"fields\" array. \"Fields\" array should contain all the sub-fields in the INFO field, even for those hidden ones. Each element describes configurations with display/formatting instructions for each sub-field. info2table : { INFOKEY : { col_separator : '|' , separate_tables : [ ... ], // optional fields : [ { name : 'Allele' }, { name : 'Consequence' }, { name : 'SYMBOL' }, { name : 'Entrez Gene ID' }, { name : 'Feature_type' }, { name : 'Feature' }, { name : 'HGVSc' }, { name : 'HGVSp' }, ... more fields ... ] } }","title":"info2table:{}"},{"location":"guides/proteinpaint/advanced-guides/using-a-vcf-file/#info2singletable","text":"Same setting as the \"info2table\". Will only parse the first item of the CSQ field. This is useful in such cases when the given sub-fields are duplicated across all items. A \"vertical\" two-column table will be displayed, with a row for each sub-field. > Allele > T > Consequence > missense_variant > SYMBOL > BRAF > Entrez Gene ID > 673 > Feature_type > transcript > Feature > ENST00000288602.6 > HGVSc > ENST00000288602.6:c.1799T>A","title":"info2singletable:{}"},{"location":"guides/proteinpaint/advanced-guides/using-a-vcf-file/#hidetrue","text":"If set, the field will be hidden from the table.","title":".hide:true"},{"location":"guides/proteinpaint/advanced-guides/using-a-vcf-file/#namestr","text":"Required. A display name of the field.","title":".name:STR"},{"location":"guides/proteinpaint/advanced-guides/using-a-vcf-file/#ampersand2brtrue","text":"Will convert all '&' to HTML line break .","title":".ampersand2br:true"},{"location":"guides/proteinpaint/advanced-guides/using-a-vcf-file/#isurltrue","text":"The column value is a full URL and will be shown as a tag.","title":".isurl:true"},{"location":"guides/proteinpaint/advanced-guides/using-a-vcf-file/#appendurl-str","text":"To append the value to the end of the given partial URL and display the composed URL.","title":".appendUrl: STR"},{"location":"guides/proteinpaint/advanced-guides/using-a-vcf-file/#urlmatchlst","text":"Example config: urlMatchLst : { separator : '_' , idIndex : 0 , types : [ { type : 'pubmed' , appendUrl : 'https://www.ncbi.nlm.nih.gov/pubmed/' }, { type : 'asco' , appendUrl : 'https://meetinglibrary.asco.org/record/' } ] } Which allows to parse following values into respective URL links. 31566309_(PubMed) 168986_(ASCO)","title":".urlMatchLst:{}"},{"location":"guides/proteinpaint/advanced-guides/using-a-vcf-file/#separate_tables","text":"Optional, and only applies to \"info2table\" but not \"info2singletable\". When multiple \"rows\" could be contained in one INFO field, the rows are to be divided into groups based on criteria of the \"groupers\" array, and shown in separate tables. Each table has the same set of columns, as defined in the \"fields[]\" array. separate_tables : [ { headhtml : 'Accepted evidence' , groupers : [ { field : 'CIViC Entity Type' , value : 'evidence' }, { field : 'CIViC Entity Status' , value : 'accepted' } ] }, { ... another table ... } ]","title":"separate_tables:\\[\\]"},{"location":"guides/proteinpaint/advanced-guides/using-a-vcf-file/#url-links-for-variants","text":"A URL can be made for SNV/indel variants from a VCF track, so that when user clicks on the variant and shows the details, the URL link will be shown, to link to the variant in another website. To enable this, add the \" url4variant \" attribute in the track definition: { type : 'vcf' , name : 'Clinvar' , file : 'hg38/clinvar.hg38.201612.vcf.gz' , url4variant : [ { label : 'PeCAN-PIE' , makeurl : ( m )=>{ return 'https://pecan.stjude.org/#/variant/view/' + m . chr . replace ( 'chr' , '' ) + '/' + ( m . pos + 1 ) + '/' + m . ref + '/' + m . alt } } ], } Each element in \"url4variant\" describes a method to produce a URL for the variant. This allows multiple URL links to be produced on the same variant. Each element has the \" makeurl \" attribute, a JavaScript function that takes in the variant object as input, and returns the fully-formed URL string, parameterized by the attributes of the variant. The method may not work for mutation types other than SNV/indel.","title":"URL links for variants"},{"location":"guides/proteinpaint/advanced-guides/using-a-vcf-file/#summary-of-vcf-track-object","text":"A schematic overview of all available options that you can use to customize a VCF track.","title":"Summary of VCF track object"},{"location":"guides/proteinpaint/advanced-guides/using-custom-tracks/","text":"Using custom tracks in ProteinPaint Tracks are defined as JSON objects. Submit tracks by launching a genome browser, see below: All text values are case-sensitive . Use these color names \u00b6 Common names such as red, green: https://en.wikipedia.org/wiki/Web_colors FF0000 rgb(255,0,0) rgba(255,0,0,.5) Example \u00b6 Go to https://proteinpaint.stjude.org , launch hg19 genome browser and paste in following JSON text to add two tracks: [ { \"type\" : \"bigwig\" , \"file\" : \"hg19/hg19.100way.phastCons.bw\" , \"name\" : \"UCSC phastCons 100ways\" , \"dotplotfactor\" : 20 , \"height\" : 100 }, { \"type\" : \"bedj\" , \"file\" : \"anno/refGene.hg19.gz\" , \"name\" : \"RefSeq genes\" , \"translatecoding\" : 1 , \"color\" : \"#417D4C\" , \"stackheight\" : 20 } ] View or debug JSON with https://jsonlint.com/ The JSON track objects can be used with embedding API . Gallery \u00b6 https://proteinpaint.stjude.org/examples/ Attributes applicable to all track types \u00b6 Example: { \"name\" : \"name of the track\" , \"type\" :< typecode > , \"url\" : \"http://domain/file.gz\" , \"indexURL\" : \"http://domain/path/file.gz.tbi\" , \"file\" : \"path/to/file.gz\" , // use this when not using URL \"toppad\" : 5 , \"bottompad\" : 5 } \" name \": STR A string as track name \" type \": Typecode of the track. Allowed values are: bigwig bigwigstranded bedj profilegenevalue junction vcf bampile \" file \": STR \" url \": STR \" indexURL \": STR Either \"file\" or \"url\" should be provided, but not both. When using \"file\", provide the relative path to the track file starting from directory as is configured on the ProteinPaint server. When using URL for tabix-indexed files, by default it requires the index file to share URL with the .gz file. When it's not sharing the URL, the attribute \"indexURL\" must be used to provide the URL of the index file. \" toppad \": INT Number of pixels as the padding space on the top, default: 5 \" bottompad \": INT Number of pixels as the padding space at the bottom, default: 5 \" hidden \": 1 If set, the track will be hidden by default and can be found in the track menu (by clicking the \"Tracks\" button) Track: bigWig for numerical data \u00b6 Example: { \"name\" : \"track name\" , \"type\" : \"bigwig\" , \"file\" : \"targetRNAcoverage/SJNBL017066_D1.bw\" , \"scale\" : { \"min\" : 0 , \"max\" : 100 }, \"height\" : 100 } Live example: https://proteinpaint.stjude.org/examples/bigwig.html bigWig track attributes: scale : { } min max Set a fixed scale range of the Y axis percentile Value is integer from 1 to 99, representing a percentile of all the data in the view range Overrides min/max auto Value is simply \"1\" for \"on\". Set automatic scale, will override all other settings in \"scale\" height Bar plot height in number of pixels. If height is below 10, the track will be rendered as heatmap. pcolor Bar color of the positive values pcolor2 Rendering color for data points above Y axis maximum value. ncolor Bar color of negative values ncolor2 Rendering color for data points below Y axis minimum value dotplotfactor Value is positive integer e.g. 5 or 10. When applied, will request 5 or 10 times more data points from a bigWig track and plot each point as a dot, rather than bars. A use case is checking (large-scale) CNV from DNA sequencing coverage track Track: a pair of bigWig for data from forward and reverse strands \u00b6 Example: https://proteinpaint.stjude.org/examples/bigwig.stranded.html For showing stranded RNA-seq coverage data as a pair of bigWig tracks, with forward strand on top and reverse strand on bottom. { \"name\" : \"stranded RNA-seq coverage\" , \"type\" : \"bigwigstranded\" , \"strand1\" : { \"file\" : \"path/to/sample.forwardstrand.bw\" , \"scale\" : { \"min\" : 0 , \"max\" : 100 }, \"height\" : 50 }, \"strand2\" : { \"file\" : \"path/to/sample.reversestrand.bw\" , \"scale\" : { \"max\" : 0 , \"min\" : - 100 }, \"height\" : 50 , \"normalize\" : { \"dividefactor\" : - 1 } } } strand1 : {} The bigWig track of the data from forward strand For read-coverage data, the values in the forward-strand bigWig file should be positive strand2 : {} The bigWig track of the data from reverse strand Both strands follow the bigWig track definition. Note: for stranded bigwig files using all positive values for both strands (e.g. sequencing read coverage), a \"normalization value\" of -1 should be applied to the reverse strand, so the bars will point down. If the reverse strand bigwig track has been prepared to have negative values, then no need to apply the -1 normalizing factor. Track: JSON-BED \u00b6 Example: https://proteinpaint.stjude.org/examples/bedj.html The JSON-BED track for annotating genomic features, e.g. genes. Full specification of the JSON-BED track format . Track: genomic profile combined with gene expression value (PGV) \u00b6 Example: https://proteinpaint.stjude.org/examples/pgv.html Read more about the PGV track Track: splice junction \u00b6 Example: https://proteinpaint.stjude.org/examples/junction.html { \"type\" : \"junction\" , \"name\" : \"sample junction\" , \"file\" : \"junction/targetALL/10-PANYGB-diagnosis-SJCOGALL010859_D2.gz\" , \"categories\" : { \"known\" : { \"label\" : \"Known\" , \"color\" : \"#9c9c9c\" }, \"novel\" : { \"label\" : \"Novel\" , \"color\" : \"#cc0000\" } } } \"categories\" specifies the rendering color for types of junctions. Read the splice junction file format. Multiple junction tracks can be aggregated to show in one track, via the .tracks[ ] attribute: { \"type\" : \"junction\" , \"name\" : \"sample junction\" , \"tracks\" : [ { \"sample\" : \"sample1\" , \"file\" : \"path/to/sample1.gz\" }, { \"sample\" : \"sample2\" , \"file\" : \"path/to/sample2.gz\" }, ... more samples ... ], \"categories\" : { ... } } In the .tracks[ ], add one object for each member track. When combining multiple junction tracks, each track can contain one or multiple samples. Track: VCF \u00b6 Example: https://proteinpaint.stjude.org/clinvar.html { \"name\" : \"track name\" , \"type\" : \"vcf\" , \"file\" : \"path/to/vcffile.gz\" , \"url\" : \"use url if the vcf file is hosted on a web server\" } SNV and indel variants only, other types are not yet supported, e.g. CNV and SV. A VCF file can contain one or multiple samples. ProteinPaint requires VCF format specification version 4.2 Please refer to this document on following topics about the VCF track Preparing and hosting a VCF file Encoding functional annotation for coding-region mutations Combining multiple VCF files into one track Highlighting and filtering variants by values of an INFO field Features available for multi-sample VCF track a. Population frequency filter b. Sample annotation c. VAF-coverage plot Track: bampile \u00b6 Bampile track can be used to examine the very rare alleles from a high-depth (capture-based) DNA sequencing experiment. Example of bampile track: { \"name\" : \"track name\" , \"type\" : \"vcf\" , \"file\" : \"path/to/vcffile.gz\" , \"url\" : \"use url if the vcf file is hosted on a web server\" } Read the bampile file format. fineheight Height of the bar plot at bottom showing low-frequency alleles, the Y scale uses a cutoff value as defined by \"fineymax\" allheight Height of the bar plot at top showing frequency of all alleles with automatic scale for coverage midpad Padding distance between top and bottom bar plots fineymax Y scale used by the bottom bar plot usegrade Name of the grade to use Track: aicheck \u00b6 Example: https://proteinpaint.stjude.org/examples/aicheck.html Read the aicheck track tutorial. Track: GenomePaint \u00b6 Example: https://proteinpaint.stjude.org/examples/svcnv.html This launches custom MDS track (aka GenomePaint). To access official tracks, see embedding API . { \"name\" : \"track name\" , \"type\" : \"mdssvcnv\" , \"file\" : \"path/to/svcnv.gz\" , \"checkexpressionrank\" : { \"file\" : \"hg38/tcga-gdc/SKCM/TCGA_SKCM.fpkm.gz\" } \"checkvcf\" : { \"file\" : \"hg38/tcga-gdc/SKCM/TCGA_SKCM.vcf.gz\" } } Read the GenomePaint tutorial . You can replace \"file\" with \"url\" in above 3 places. Following attributes can be applied in the track object as detailed in the Embedding API . singlesample:{} isfull:true / isdense:true sampleAttribute:{} vcf:{} hide_cnvgain:true hide_cnvloss:true cnv:{} sampleset:[] A derivative of the \"mdssvcnv\" track is the multi-sample ASE track. Example: https://proteinpaint.stjude.org/examples/ase.html { type : 'mdssvcnv' , name : 'Multi-sample ASE analysis' , checkvcf : { file : 'hg19/TARGET/DNA/test/oct3/sorted.vcf.gz' , }, checkrnabam : { samples : { SJALL015260_D1 : { file : 'hg19/TARGET/RNAbam/SJALL015260_D1.bam' , totalreads : 83388794 , }, SJALL015643_D1 : { file : 'hg19/TARGET/RNAbam/SJALL015643_D1.bam' , totalreads : 103477133 , }, ... more BAM files ... }, } Track: ASE, single-sample \u00b6 Example: https://proteinpaint.stjude.org/examples/ase.single.html This carries on-the-fly ASE analysis for a single sample. This track can be built standalone, or spawned from a multi-sample track (a special mode of mdssvcnv track) { type : 'ase' , name : 'My sample ASE' , samplename : 'my_sample_name' , rnabamfile : 'path/to/sample.rnaseq.bam' , rnabamtotalreads : 103477133 , vcffile : 'path/to/SJALL015643_D1.gz' , },","title":"Using Custom Tracks"},{"location":"guides/proteinpaint/advanced-guides/using-custom-tracks/#use-these-color-names","text":"Common names such as red, green: https://en.wikipedia.org/wiki/Web_colors","title":"Use these color names"},{"location":"guides/proteinpaint/advanced-guides/using-custom-tracks/#example","text":"Go to https://proteinpaint.stjude.org , launch hg19 genome browser and paste in following JSON text to add two tracks: [ { \"type\" : \"bigwig\" , \"file\" : \"hg19/hg19.100way.phastCons.bw\" , \"name\" : \"UCSC phastCons 100ways\" , \"dotplotfactor\" : 20 , \"height\" : 100 }, { \"type\" : \"bedj\" , \"file\" : \"anno/refGene.hg19.gz\" , \"name\" : \"RefSeq genes\" , \"translatecoding\" : 1 , \"color\" : \"#417D4C\" , \"stackheight\" : 20 } ] View or debug JSON with https://jsonlint.com/ The JSON track objects can be used with embedding API .","title":"Example"},{"location":"guides/proteinpaint/advanced-guides/using-custom-tracks/#gallery","text":"https://proteinpaint.stjude.org/examples/","title":"Gallery"},{"location":"guides/proteinpaint/advanced-guides/using-custom-tracks/#attributes-applicable-to-all-track-types","text":"Example: { \"name\" : \"name of the track\" , \"type\" :< typecode > , \"url\" : \"http://domain/file.gz\" , \"indexURL\" : \"http://domain/path/file.gz.tbi\" , \"file\" : \"path/to/file.gz\" , // use this when not using URL \"toppad\" : 5 , \"bottompad\" : 5 } \" name \": STR A string as track name \" type \": Typecode of the track. Allowed values are: bigwig bigwigstranded bedj profilegenevalue junction vcf bampile \" file \": STR \" url \": STR \" indexURL \": STR Either \"file\" or \"url\" should be provided, but not both. When using \"file\", provide the relative path to the track file starting from directory as is configured on the ProteinPaint server. When using URL for tabix-indexed files, by default it requires the index file to share URL with the .gz file. When it's not sharing the URL, the attribute \"indexURL\" must be used to provide the URL of the index file. \" toppad \": INT Number of pixels as the padding space on the top, default: 5 \" bottompad \": INT Number of pixels as the padding space at the bottom, default: 5 \" hidden \": 1 If set, the track will be hidden by default and can be found in the track menu (by clicking the \"Tracks\" button)","title":"Attributes applicable to all track types"},{"location":"guides/proteinpaint/advanced-guides/using-custom-tracks/#track-bigwig-for-numerical-data","text":"Example: { \"name\" : \"track name\" , \"type\" : \"bigwig\" , \"file\" : \"targetRNAcoverage/SJNBL017066_D1.bw\" , \"scale\" : { \"min\" : 0 , \"max\" : 100 }, \"height\" : 100 } Live example: https://proteinpaint.stjude.org/examples/bigwig.html bigWig track attributes: scale : { } min max Set a fixed scale range of the Y axis percentile Value is integer from 1 to 99, representing a percentile of all the data in the view range Overrides min/max auto Value is simply \"1\" for \"on\". Set automatic scale, will override all other settings in \"scale\" height Bar plot height in number of pixels. If height is below 10, the track will be rendered as heatmap. pcolor Bar color of the positive values pcolor2 Rendering color for data points above Y axis maximum value. ncolor Bar color of negative values ncolor2 Rendering color for data points below Y axis minimum value dotplotfactor Value is positive integer e.g. 5 or 10. When applied, will request 5 or 10 times more data points from a bigWig track and plot each point as a dot, rather than bars. A use case is checking (large-scale) CNV from DNA sequencing coverage track","title":"Track: bigWig for numerical data"},{"location":"guides/proteinpaint/advanced-guides/using-custom-tracks/#track-a-pair-of-bigwig-for-data-from-forward-and-reverse-strands","text":"Example: https://proteinpaint.stjude.org/examples/bigwig.stranded.html For showing stranded RNA-seq coverage data as a pair of bigWig tracks, with forward strand on top and reverse strand on bottom. { \"name\" : \"stranded RNA-seq coverage\" , \"type\" : \"bigwigstranded\" , \"strand1\" : { \"file\" : \"path/to/sample.forwardstrand.bw\" , \"scale\" : { \"min\" : 0 , \"max\" : 100 }, \"height\" : 50 }, \"strand2\" : { \"file\" : \"path/to/sample.reversestrand.bw\" , \"scale\" : { \"max\" : 0 , \"min\" : - 100 }, \"height\" : 50 , \"normalize\" : { \"dividefactor\" : - 1 } } } strand1 : {} The bigWig track of the data from forward strand For read-coverage data, the values in the forward-strand bigWig file should be positive strand2 : {} The bigWig track of the data from reverse strand Both strands follow the bigWig track definition. Note: for stranded bigwig files using all positive values for both strands (e.g. sequencing read coverage), a \"normalization value\" of -1 should be applied to the reverse strand, so the bars will point down. If the reverse strand bigwig track has been prepared to have negative values, then no need to apply the -1 normalizing factor.","title":"Track: a pair of bigWig for data from forward and reverse strands"},{"location":"guides/proteinpaint/advanced-guides/using-custom-tracks/#track-json-bed","text":"Example: https://proteinpaint.stjude.org/examples/bedj.html The JSON-BED track for annotating genomic features, e.g. genes. Full specification of the JSON-BED track format .","title":"Track: JSON-BED"},{"location":"guides/proteinpaint/advanced-guides/using-custom-tracks/#track-genomic-profile-combined-with-gene-expression-value-pgv","text":"Example: https://proteinpaint.stjude.org/examples/pgv.html Read more about the PGV track","title":"Track: genomic profile combined with gene expression value (PGV)"},{"location":"guides/proteinpaint/advanced-guides/using-custom-tracks/#track-splice-junction","text":"Example: https://proteinpaint.stjude.org/examples/junction.html { \"type\" : \"junction\" , \"name\" : \"sample junction\" , \"file\" : \"junction/targetALL/10-PANYGB-diagnosis-SJCOGALL010859_D2.gz\" , \"categories\" : { \"known\" : { \"label\" : \"Known\" , \"color\" : \"#9c9c9c\" }, \"novel\" : { \"label\" : \"Novel\" , \"color\" : \"#cc0000\" } } } \"categories\" specifies the rendering color for types of junctions. Read the splice junction file format. Multiple junction tracks can be aggregated to show in one track, via the .tracks[ ] attribute: { \"type\" : \"junction\" , \"name\" : \"sample junction\" , \"tracks\" : [ { \"sample\" : \"sample1\" , \"file\" : \"path/to/sample1.gz\" }, { \"sample\" : \"sample2\" , \"file\" : \"path/to/sample2.gz\" }, ... more samples ... ], \"categories\" : { ... } } In the .tracks[ ], add one object for each member track. When combining multiple junction tracks, each track can contain one or multiple samples.","title":"Track: splice junction"},{"location":"guides/proteinpaint/advanced-guides/using-custom-tracks/#track-vcf","text":"Example: https://proteinpaint.stjude.org/clinvar.html { \"name\" : \"track name\" , \"type\" : \"vcf\" , \"file\" : \"path/to/vcffile.gz\" , \"url\" : \"use url if the vcf file is hosted on a web server\" } SNV and indel variants only, other types are not yet supported, e.g. CNV and SV. A VCF file can contain one or multiple samples. ProteinPaint requires VCF format specification version 4.2 Please refer to this document on following topics about the VCF track Preparing and hosting a VCF file Encoding functional annotation for coding-region mutations Combining multiple VCF files into one track Highlighting and filtering variants by values of an INFO field Features available for multi-sample VCF track a. Population frequency filter b. Sample annotation c. VAF-coverage plot","title":"Track: VCF"},{"location":"guides/proteinpaint/advanced-guides/using-custom-tracks/#track-bampile","text":"Bampile track can be used to examine the very rare alleles from a high-depth (capture-based) DNA sequencing experiment. Example of bampile track: { \"name\" : \"track name\" , \"type\" : \"vcf\" , \"file\" : \"path/to/vcffile.gz\" , \"url\" : \"use url if the vcf file is hosted on a web server\" } Read the bampile file format. fineheight Height of the bar plot at bottom showing low-frequency alleles, the Y scale uses a cutoff value as defined by \"fineymax\" allheight Height of the bar plot at top showing frequency of all alleles with automatic scale for coverage midpad Padding distance between top and bottom bar plots fineymax Y scale used by the bottom bar plot usegrade Name of the grade to use","title":"Track: bampile"},{"location":"guides/proteinpaint/advanced-guides/using-custom-tracks/#track-aicheck","text":"Example: https://proteinpaint.stjude.org/examples/aicheck.html Read the aicheck track tutorial.","title":"Track: aicheck"},{"location":"guides/proteinpaint/advanced-guides/using-custom-tracks/#track-genomepaint","text":"Example: https://proteinpaint.stjude.org/examples/svcnv.html This launches custom MDS track (aka GenomePaint). To access official tracks, see embedding API . { \"name\" : \"track name\" , \"type\" : \"mdssvcnv\" , \"file\" : \"path/to/svcnv.gz\" , \"checkexpressionrank\" : { \"file\" : \"hg38/tcga-gdc/SKCM/TCGA_SKCM.fpkm.gz\" } \"checkvcf\" : { \"file\" : \"hg38/tcga-gdc/SKCM/TCGA_SKCM.vcf.gz\" } } Read the GenomePaint tutorial . You can replace \"file\" with \"url\" in above 3 places. Following attributes can be applied in the track object as detailed in the Embedding API . singlesample:{} isfull:true / isdense:true sampleAttribute:{} vcf:{} hide_cnvgain:true hide_cnvloss:true cnv:{} sampleset:[] A derivative of the \"mdssvcnv\" track is the multi-sample ASE track. Example: https://proteinpaint.stjude.org/examples/ase.html { type : 'mdssvcnv' , name : 'Multi-sample ASE analysis' , checkvcf : { file : 'hg19/TARGET/DNA/test/oct3/sorted.vcf.gz' , }, checkrnabam : { samples : { SJALL015260_D1 : { file : 'hg19/TARGET/RNAbam/SJALL015260_D1.bam' , totalreads : 83388794 , }, SJALL015643_D1 : { file : 'hg19/TARGET/RNAbam/SJALL015643_D1.bam' , totalreads : 103477133 , }, ... more BAM files ... }, }","title":"Track: GenomePaint"},{"location":"guides/proteinpaint/advanced-guides/using-custom-tracks/#track-ase-single-sample","text":"Example: https://proteinpaint.stjude.org/examples/ase.single.html This carries on-the-fly ASE analysis for a single sample. This track can be built standalone, or spawned from a multi-sample track (a special mode of mdssvcnv track) { type : 'ase' , name : 'My sample ASE' , samplename : 'my_sample_name' , rnabamfile : 'path/to/sample.rnaseq.bam' , rnabamtotalreads : 103477133 , vcffile : 'path/to/SJALL015643_D1.gz' , },","title":"Track: ASE, single-sample"},{"location":"guides/proteinpaint/advanced-guides/using-disease-pie-charts/","text":"Using disease pie charts When the uploaded data set stratify samples based on disease categories, pie charts can be made to visualize mutation to a gene or gene set in each disease category. to be finished ...","title":"Using Disease Pie Charts"},{"location":"guides/proteinpaint/advanced-guides/using-the-gene-table/","text":"Using the gene table \u00b6 Updated: Dec 11, 2015 Above example shows the gene table after loading a public data set (TCGA skin cancer SNV/indel). See this tutorial for procedures to obtain and upload this data set. By default, the gene table shows top-100 recurrently mutated genes from the data set, ranked by the total number of mutations in each gene, as illustrated above. It also shows the breakdown of mutation classes using multiple columns. Click the gene names in yellow boxes to show this gene in ProteinPaint along with its mutations from this data set. To find a gene, type gene name in the search box on top. Scope of search is limited to this data set: Click the button \"Configure\" on top to show options (and the button turns red, click again to hide): Number of genes shown There are tens of thousands of genes in this data set. The viewer shows top 100 genes to avoid draining user's computer memory. To show more or less genes, click the button \"more\" or \"less\". Each click will add/remove ten genes from the rank. Showing a set of given genes By providing a list of gene names, gene table will show only provided genes. Click \"cancel\" to go back to full list view: Noncoding mutation visibility If there are noncoding mutations, user can determine whether to show them in the table. Use the show/hide switch to toggle the noncoding mutation visibility. The noncoding mutation includes classes of silent, splice_region, exon, UTR, and intron. Importing pediatric and COSMIC data sets for comparison User can import pediatric or COSMIC data set and show them alongside the uploaded data for easy comparison across data sets. Click on the \"Pediatric\" or \"COSMIC\" button to import: The sample size for pediatric and COSMIC is also indicated in the top header, as a reference for comparing mutated sample counts across different data sets. Here's how ProteinPaint decides whether to import silent mutation: Do not import silent mutation when there is no silent mutation in uploaded data set. Otherwise, silent mutation will only be imported if the missense-to-silent ratio is less than 5 in the uploaded data set. Total number of missense and silent mutations across all genes in the uploaded data set is used. If the missense-to-silent ratio is greater than 5, the silent mutation is considered insignificant. Note that the importing function is limited to 10 genes at a time since a larger request may delay the response and cause timeout error. To show the gene counts for additional genes, simply click the button once again to query the next 10 genes in the list. The server will remember the genes that have been imported before (by all users) in order to speed up the importing. To remove the imported data sets, click the \"X\" mark on the right of the pediatric or COSMIC header.","title":"Using the Gene Table"},{"location":"guides/proteinpaint/advanced-guides/using-the-gene-table/#using-the-gene-table","text":"Updated: Dec 11, 2015 Above example shows the gene table after loading a public data set (TCGA skin cancer SNV/indel). See this tutorial for procedures to obtain and upload this data set. By default, the gene table shows top-100 recurrently mutated genes from the data set, ranked by the total number of mutations in each gene, as illustrated above. It also shows the breakdown of mutation classes using multiple columns. Click the gene names in yellow boxes to show this gene in ProteinPaint along with its mutations from this data set. To find a gene, type gene name in the search box on top. Scope of search is limited to this data set: Click the button \"Configure\" on top to show options (and the button turns red, click again to hide): Number of genes shown There are tens of thousands of genes in this data set. The viewer shows top 100 genes to avoid draining user's computer memory. To show more or less genes, click the button \"more\" or \"less\". Each click will add/remove ten genes from the rank. Showing a set of given genes By providing a list of gene names, gene table will show only provided genes. Click \"cancel\" to go back to full list view: Noncoding mutation visibility If there are noncoding mutations, user can determine whether to show them in the table. Use the show/hide switch to toggle the noncoding mutation visibility. The noncoding mutation includes classes of silent, splice_region, exon, UTR, and intron. Importing pediatric and COSMIC data sets for comparison User can import pediatric or COSMIC data set and show them alongside the uploaded data for easy comparison across data sets. Click on the \"Pediatric\" or \"COSMIC\" button to import: The sample size for pediatric and COSMIC is also indicated in the top header, as a reference for comparing mutated sample counts across different data sets. Here's how ProteinPaint decides whether to import silent mutation: Do not import silent mutation when there is no silent mutation in uploaded data set. Otherwise, silent mutation will only be imported if the missense-to-silent ratio is less than 5 in the uploaded data set. Total number of missense and silent mutations across all genes in the uploaded data set is used. If the missense-to-silent ratio is greater than 5, the silent mutation is considered insignificant. Note that the importing function is limited to 10 genes at a time since a larger request may delay the response and cause timeout error. To show the gene counts for additional genes, simply click the button once again to query the next 10 genes in the list. The server will remember the genes that have been imported before (by all users) in order to speed up the importing. To remove the imported data sets, click the \"X\" mark on the right of the pediatric or COSMIC header.","title":"Using the gene table"},{"location":"guides/proteinpaint/advanced-guides/using-the-heatmap/","text":"Using heatmap Heatmap is a gene-by-sample grid representing mutations from a data set, looking like below: The heatmap can be customized to great extent. Click the button \"advanced\" on top: A box opens on the left showing texts that can be edited. The content is an JSON object describing the heatmap. Make modification to the JSON content, click \"update\" button to render a new heatmap to reflect your changes. Save your map before leaving... ProteinPaint will not save the JSON when you leave, because the heatmap is based on user-provided data. If you have made edits, copy and save the JSON text before leaving ProteinPaint. Next time you explore the same dataset, launch the heatmap, and paste your saved JSON in the text box to re-create the heatmap. Show a preconfigured map A preconfigured map can be stored in the schematics of a study view. Refer to the \" heatmapJSON \" attribute of the study schematics Also in study view, try the \" hard-coded map \" in which you have complete control of what is showing in one or more maps. To embed a map in your website, use the \"studyview\" as instructed here . Genes \u00b6 Sort samples by number of mutation in selected genes \u00b6 { \"name\" : \"JAK3\" , \"sortorder\" : 1 } By applying the \"sortorder\" attribute to a gene, samples will be sorted by the descending order of number of mutations in this gene. Samples with more mutation in this gene will be moved to left (or top). Value is any number. Multiple genes can be used for sorting. In such case, the numerical value determines the precedence of which genes are taken into sorting (smaller the value, earlier the gene is used). Samples are sorted within each sample group. Default applied to all genes. To disable such sorting, remove the attribute from a gene. Gene order \u00b6 The order of genes is determined by the order of appearance of genes in each gene group in the heatmap JSON. [ { \"name\" : \"JAK2\" }, { \"name\" : \"PAX5\" } ] In this example, JAK2 appears earlier than PAX5. By default, genes are arranged in descending order of total number of mutations from all samples. Samples \u00b6 Sample order \u00b6 By default, the order of samples are automatically adjusted using the \"sort-by-gene\" (described above). To manually adjust sample order, the sorting-by-gene must be disabled first. Then edit the order of samples in the sample group section of the heatmap JSON to take effect. Sample group \u00b6 Samples can be arranged into groups. Space can be applied between groups and borders can be drawn around each group, so that they appear distinct visually. { \"samplegroup\" : [ { \"name\" : \"sample group 1\" , \"lst\" : [ { \"name\" : \"sample_1\" }, { \"name\" : \"sample_2\" } ] }, { \"name\" : \"sample group 2\" , \"lst\" : [ { \"name\" : \"sample_3\" }, { \"name\" : \"sample_4\" } ] } ] } This code defines two sample groups, each with two samples. The \"samplegroup\" attribute is root-level. Refresh sample \u00b6 You can do this by clicking the \"refresh sample\" button located on top, rather than editing the JSON. This is because by default the heatmap chooses samples by requiring the sample to have at least 1 mutation in the initial set of genes. Afterwards the set of samples stay unchanged unless you alter the \"samplegroup\" contents in JSON. Sometime when user started using a new gene set different from the initial set, he/she would like the samples to update accordingly. This is when the \"refresh sample\" button comes in handy. Be careful that refreshing samples and your previous edits on samples will be lost. Will be available in the next release. Border \u00b6 Sample/gene group border \u00b6 { \"border\" : \"black\" , \"borderwidth\" : 1 } Add border attribute to either a sample or gene group, and a solid border in specified color will be drawn enclosing this group. Optionally provide \"borderwidth\" attribute to specify the width using integer value. Default 1. Default applied to gene group. Color \u00b6 Heatmap cell background color \u00b6 { \"cellbg\" : \"#f1f1f1\" } The background fill color for a heatmap cell if there is no data. Applicable for both data cells and metadata cells. Root-level attribute. Default provided. Sample group background color \u00b6 { \"background\" : \"black\" } Add background attribute to a sample group. The entire group will show this background color. Default not applied. This can be used to generate the look of \"borders\" around heatmap cells. The border width will be controlled by row/column spacing. Cell background color by sample \u00b6 { \"name\" : \"20-PANLJN\" , \"cellbg\" : \"#CCCCCC\" } Add the cellbg attribute to a sample. All cells belonging to this sample will use the specified background color instead of the global background color. Default not provided. Will be available soon. \"metadata\":[] \u00b6 Metadata is used for annotating samples. This is deprecated. Try to use \" metadatabymatrix \" instead. Example \"metadata\" : [ { \"key\" : \"a\" , \"label\" : \"Sex\" , \"type\" : \"fill\" , \"values\" : { \"male\" : \"red\" , \"female\" : \"blue\" } }, { \"key\" : \"b\" , \"label\" : \"WGS/WES\" , \"type\" : \"fill\" , \"values\" : { \"WGS\" : \"black\" , \"WES\" : \"#858585\" } } ], \"patientannotation\" : { \"PARDCK\" : { \"a\" : \"male\" , \"b\" : \"WGS\" }, \"PASRFS\" : { \"a\" : \"female\" , \"b\" : \"WGS\" }, \"PASTKC\" : { \"a\" : \"male\" , \"b\" : \"WES\" }, \"PASSRS\" : { \"a\" : \"female\" , \"b\" : \"WES\" }, \"PASGUT\" : { \"a\" : \"male\" , \"b\" : \"WGS\" }, \"PASKJX\" : { \"a\" : \"female\" , \"b\" : \"WGS\" }, \"PATHVK\" : { \"a\" : \"male\" , \"b\" : \"WES\" }, \"PAPKXS\" : { \"a\" : \"female\" , \"b\" : \"WGS\" }, \"PAMNLH\" : { \"a\" : \"male\" , \"b\" : \"WES\" } }, \"metadataborder\" : \"black\" , Rendered Metadata terms \u00b6 \"metadata\" : [ ... ] Root-level attribute. Value is a list, with each metadata term as one element. A term is defined as an object like below: { \"key\" : \"term1key\" , \"label\" : \"Term name\" , \"type\" : \"fill\" , \"values\" : { \"term1attribute1\" : \"red\" , \"term1attribute2\" : \"blue\" } }, key: key identifier of this term label: name to be displayed type: \"fill\" only, reserved for future expansion values: attribute values for this term. Key is attribute name, value is rendering color. Metadata box border and color \u00b6 \"metadataborder\" : \"color\" , Root-level attribute. If present, draw border around metadata section with given color. Width of metadata box border \u00b6 \"metadataborderwidth\" : 2 , Root-level attribute. If present, draw border with line of given thickness. \"patientannotation\":{ } \u00b6 Root-level attribute. For annotating patients or individuals. To be used along with the \"metadata\" attribute Value is a hash, with patient names as keys, and annotations as values. { \"sample1\" : { \"term1key\" : \"term1attribute1\" , \"term2key\" : \"term2attribute1\" , }, \"sample2\" : { ... }, ... }, When there is no sample type in the dataset, must use this attribute but not \"sampleannotation\". When there IS sampletype, using this attribute will annotate patients, but not the separate samples. To annotate samples instead (e.g. diagnosis/relapse), use \"sampleannotation\" described below. \"sampleannotation\":{ } \u00b6 Root-level attribute. For annotating individual samples rather than patients. To be used along with the \"metadata\" attribute. Value is a nested hash, with patient/individual name as level-1 keys, sample type as level-2 keys, and sample annotations as values. { \"patient1name\" : { \"sampletype1\" : { \"term1key\" : \"term1attribute1\" , \"term2key\" : \"term2attribute1\" }, \"Sampletype2\" : { ... annotation to this sample in this patient } }, \"patient2name\" : { ... }, ... }, \"metadatabymatrix\":{} \u00b6 Work in progress!! Prepare metadata annotation in a spreadsheet and declare it using \" metadatabymatrix \". Example: \"metadatabymatrix\" : { \"annotations\" : [ { \"text\" : \"matrix data lines\" } ], \"terms\" : { \"Cytogenetics\" : { \"Deletion\" : { \"label\" : \"Deletion\" , \"color\" : \"#3954a4\" }, \"Balanced\" : { \"label\" : \"Balanced\" , \"color\" : \"white\" }, \"Amplified\" : { \"label\" : \"Amplified\" , \"color\" : \"#ee2123\" }, \"NA\" : { \"label\" : \"NA\" , \"color\" : \"#ededed\" }, \"LOH\" : { \"label\" : \"LOH\" , \"color\" : \"#6abd45\" } }, \"Age\" : { \"infant\" : { \"label\" : \"Infant\" , \"color\" : \"#3954a4\" }, \"child\" : { \"label\" : \"Child\" , \"color\" : \"#0d8240\" }, \"adult\" : { \"label\" : \"Adult\" , \"color\" : \"#ee2123\" }, \"NA\" : { \"label\" : \"NA\" , \"color\" : \"#ededed\" } }, \"Ploidy\" : { \"diploid\" : { \"label\" : \"Diploid\" , \"color\" : \"#609fa0\" }, \"hyperploid\" : { \"label\" : \"Hyperploid\" , \"color\" : \"#a32525\" }, \"NA\" : { \"label\" : \"NA\" , \"color\" : \"#ededed\" } }, \"Gender\" : { \"M\" : { \"label\" : \"M\" , \"color\" : \"#41bcec\" }, \"F\" : { \"label\" : \"F\" , \"color\" : \"#f9bfcc\" }, \"K\" : { \"label\" : \"K\" , \"color\" : \"#f4ec17\" }, \"T\" : { \"label\" : \"T\" , \"color\" : \"#faa419\" }, \"NA\" : { \"label\" : \"NA\" , \"color\" : \"#ccc\" } } } } Metadata rows \"1q\" to \"Y\" belongs to the group \"Cytogenetics\", as defined in metadatabymatrix.terms:{}. In the legend, it will show \"Cytogenetics\" but rather each chromosome arm like 1q, 5p and such. Example of a matrix viewed in spreadsheet: Content of this file will be represented as a single string, where columns are joined by \"\\t\" and lines joined by \"\\n\". Others \u00b6 Gene recurrence \u00b6 \"samplecount4gene\" : true Root-level attribute. If set to \"true\", gene recurrence will be indicated by the number of samples:","title":"Using the Heatmap"},{"location":"guides/proteinpaint/advanced-guides/using-the-heatmap/#genes","text":"","title":"Genes"},{"location":"guides/proteinpaint/advanced-guides/using-the-heatmap/#sort-samples-by-number-of-mutation-in-selected-genes","text":"{ \"name\" : \"JAK3\" , \"sortorder\" : 1 } By applying the \"sortorder\" attribute to a gene, samples will be sorted by the descending order of number of mutations in this gene. Samples with more mutation in this gene will be moved to left (or top). Value is any number. Multiple genes can be used for sorting. In such case, the numerical value determines the precedence of which genes are taken into sorting (smaller the value, earlier the gene is used). Samples are sorted within each sample group. Default applied to all genes. To disable such sorting, remove the attribute from a gene.","title":"Sort samples by number of mutation in selected genes"},{"location":"guides/proteinpaint/advanced-guides/using-the-heatmap/#gene-order","text":"The order of genes is determined by the order of appearance of genes in each gene group in the heatmap JSON. [ { \"name\" : \"JAK2\" }, { \"name\" : \"PAX5\" } ] In this example, JAK2 appears earlier than PAX5. By default, genes are arranged in descending order of total number of mutations from all samples.","title":"Gene order"},{"location":"guides/proteinpaint/advanced-guides/using-the-heatmap/#samples","text":"","title":"Samples"},{"location":"guides/proteinpaint/advanced-guides/using-the-heatmap/#sample-order","text":"By default, the order of samples are automatically adjusted using the \"sort-by-gene\" (described above). To manually adjust sample order, the sorting-by-gene must be disabled first. Then edit the order of samples in the sample group section of the heatmap JSON to take effect.","title":"Sample order"},{"location":"guides/proteinpaint/advanced-guides/using-the-heatmap/#sample-group","text":"Samples can be arranged into groups. Space can be applied between groups and borders can be drawn around each group, so that they appear distinct visually. { \"samplegroup\" : [ { \"name\" : \"sample group 1\" , \"lst\" : [ { \"name\" : \"sample_1\" }, { \"name\" : \"sample_2\" } ] }, { \"name\" : \"sample group 2\" , \"lst\" : [ { \"name\" : \"sample_3\" }, { \"name\" : \"sample_4\" } ] } ] } This code defines two sample groups, each with two samples. The \"samplegroup\" attribute is root-level.","title":"Sample group"},{"location":"guides/proteinpaint/advanced-guides/using-the-heatmap/#refresh-sample","text":"You can do this by clicking the \"refresh sample\" button located on top, rather than editing the JSON. This is because by default the heatmap chooses samples by requiring the sample to have at least 1 mutation in the initial set of genes. Afterwards the set of samples stay unchanged unless you alter the \"samplegroup\" contents in JSON. Sometime when user started using a new gene set different from the initial set, he/she would like the samples to update accordingly. This is when the \"refresh sample\" button comes in handy. Be careful that refreshing samples and your previous edits on samples will be lost. Will be available in the next release.","title":"Refresh sample"},{"location":"guides/proteinpaint/advanced-guides/using-the-heatmap/#border","text":"","title":"Border"},{"location":"guides/proteinpaint/advanced-guides/using-the-heatmap/#samplegene-group-border","text":"{ \"border\" : \"black\" , \"borderwidth\" : 1 } Add border attribute to either a sample or gene group, and a solid border in specified color will be drawn enclosing this group. Optionally provide \"borderwidth\" attribute to specify the width using integer value. Default 1. Default applied to gene group.","title":"Sample/gene group border"},{"location":"guides/proteinpaint/advanced-guides/using-the-heatmap/#color","text":"","title":"Color"},{"location":"guides/proteinpaint/advanced-guides/using-the-heatmap/#heatmap-cell-background-color","text":"{ \"cellbg\" : \"#f1f1f1\" } The background fill color for a heatmap cell if there is no data. Applicable for both data cells and metadata cells. Root-level attribute. Default provided.","title":"Heatmap cell background color"},{"location":"guides/proteinpaint/advanced-guides/using-the-heatmap/#sample-group-background-color","text":"{ \"background\" : \"black\" } Add background attribute to a sample group. The entire group will show this background color. Default not applied. This can be used to generate the look of \"borders\" around heatmap cells. The border width will be controlled by row/column spacing.","title":"Sample group background color"},{"location":"guides/proteinpaint/advanced-guides/using-the-heatmap/#cell-background-color-by-sample","text":"{ \"name\" : \"20-PANLJN\" , \"cellbg\" : \"#CCCCCC\" } Add the cellbg attribute to a sample. All cells belonging to this sample will use the specified background color instead of the global background color. Default not provided. Will be available soon.","title":"Cell background color by sample"},{"location":"guides/proteinpaint/advanced-guides/using-the-heatmap/#metadata","text":"Metadata is used for annotating samples. This is deprecated. Try to use \" metadatabymatrix \" instead. Example \"metadata\" : [ { \"key\" : \"a\" , \"label\" : \"Sex\" , \"type\" : \"fill\" , \"values\" : { \"male\" : \"red\" , \"female\" : \"blue\" } }, { \"key\" : \"b\" , \"label\" : \"WGS/WES\" , \"type\" : \"fill\" , \"values\" : { \"WGS\" : \"black\" , \"WES\" : \"#858585\" } } ], \"patientannotation\" : { \"PARDCK\" : { \"a\" : \"male\" , \"b\" : \"WGS\" }, \"PASRFS\" : { \"a\" : \"female\" , \"b\" : \"WGS\" }, \"PASTKC\" : { \"a\" : \"male\" , \"b\" : \"WES\" }, \"PASSRS\" : { \"a\" : \"female\" , \"b\" : \"WES\" }, \"PASGUT\" : { \"a\" : \"male\" , \"b\" : \"WGS\" }, \"PASKJX\" : { \"a\" : \"female\" , \"b\" : \"WGS\" }, \"PATHVK\" : { \"a\" : \"male\" , \"b\" : \"WES\" }, \"PAPKXS\" : { \"a\" : \"female\" , \"b\" : \"WGS\" }, \"PAMNLH\" : { \"a\" : \"male\" , \"b\" : \"WES\" } }, \"metadataborder\" : \"black\" , Rendered","title":"\"metadata\":[]"},{"location":"guides/proteinpaint/advanced-guides/using-the-heatmap/#metadata-terms","text":"\"metadata\" : [ ... ] Root-level attribute. Value is a list, with each metadata term as one element. A term is defined as an object like below: { \"key\" : \"term1key\" , \"label\" : \"Term name\" , \"type\" : \"fill\" , \"values\" : { \"term1attribute1\" : \"red\" , \"term1attribute2\" : \"blue\" } }, key: key identifier of this term label: name to be displayed type: \"fill\" only, reserved for future expansion values: attribute values for this term. Key is attribute name, value is rendering color.","title":"Metadata terms"},{"location":"guides/proteinpaint/advanced-guides/using-the-heatmap/#metadata-box-border-and-color","text":"\"metadataborder\" : \"color\" , Root-level attribute. If present, draw border around metadata section with given color.","title":"Metadata box border and color"},{"location":"guides/proteinpaint/advanced-guides/using-the-heatmap/#width-of-metadata-box-border","text":"\"metadataborderwidth\" : 2 , Root-level attribute. If present, draw border with line of given thickness.","title":"Width of metadata box border"},{"location":"guides/proteinpaint/advanced-guides/using-the-heatmap/#patientannotation","text":"Root-level attribute. For annotating patients or individuals. To be used along with the \"metadata\" attribute Value is a hash, with patient names as keys, and annotations as values. { \"sample1\" : { \"term1key\" : \"term1attribute1\" , \"term2key\" : \"term2attribute1\" , }, \"sample2\" : { ... }, ... }, When there is no sample type in the dataset, must use this attribute but not \"sampleannotation\". When there IS sampletype, using this attribute will annotate patients, but not the separate samples. To annotate samples instead (e.g. diagnosis/relapse), use \"sampleannotation\" described below.","title":"\"patientannotation\":{ }"},{"location":"guides/proteinpaint/advanced-guides/using-the-heatmap/#sampleannotation","text":"Root-level attribute. For annotating individual samples rather than patients. To be used along with the \"metadata\" attribute. Value is a nested hash, with patient/individual name as level-1 keys, sample type as level-2 keys, and sample annotations as values. { \"patient1name\" : { \"sampletype1\" : { \"term1key\" : \"term1attribute1\" , \"term2key\" : \"term2attribute1\" }, \"Sampletype2\" : { ... annotation to this sample in this patient } }, \"patient2name\" : { ... }, ... },","title":"\"sampleannotation\":{ }"},{"location":"guides/proteinpaint/advanced-guides/using-the-heatmap/#metadatabymatrix","text":"Work in progress!! Prepare metadata annotation in a spreadsheet and declare it using \" metadatabymatrix \". Example: \"metadatabymatrix\" : { \"annotations\" : [ { \"text\" : \"matrix data lines\" } ], \"terms\" : { \"Cytogenetics\" : { \"Deletion\" : { \"label\" : \"Deletion\" , \"color\" : \"#3954a4\" }, \"Balanced\" : { \"label\" : \"Balanced\" , \"color\" : \"white\" }, \"Amplified\" : { \"label\" : \"Amplified\" , \"color\" : \"#ee2123\" }, \"NA\" : { \"label\" : \"NA\" , \"color\" : \"#ededed\" }, \"LOH\" : { \"label\" : \"LOH\" , \"color\" : \"#6abd45\" } }, \"Age\" : { \"infant\" : { \"label\" : \"Infant\" , \"color\" : \"#3954a4\" }, \"child\" : { \"label\" : \"Child\" , \"color\" : \"#0d8240\" }, \"adult\" : { \"label\" : \"Adult\" , \"color\" : \"#ee2123\" }, \"NA\" : { \"label\" : \"NA\" , \"color\" : \"#ededed\" } }, \"Ploidy\" : { \"diploid\" : { \"label\" : \"Diploid\" , \"color\" : \"#609fa0\" }, \"hyperploid\" : { \"label\" : \"Hyperploid\" , \"color\" : \"#a32525\" }, \"NA\" : { \"label\" : \"NA\" , \"color\" : \"#ededed\" } }, \"Gender\" : { \"M\" : { \"label\" : \"M\" , \"color\" : \"#41bcec\" }, \"F\" : { \"label\" : \"F\" , \"color\" : \"#f9bfcc\" }, \"K\" : { \"label\" : \"K\" , \"color\" : \"#f4ec17\" }, \"T\" : { \"label\" : \"T\" , \"color\" : \"#faa419\" }, \"NA\" : { \"label\" : \"NA\" , \"color\" : \"#ccc\" } } } } Metadata rows \"1q\" to \"Y\" belongs to the group \"Cytogenetics\", as defined in metadatabymatrix.terms:{}. In the legend, it will show \"Cytogenetics\" but rather each chromosome arm like 1q, 5p and such. Example of a matrix viewed in spreadsheet: Content of this file will be represented as a single string, where columns are joined by \"\\t\" and lines joined by \"\\n\".","title":"\"metadatabymatrix\":{}"},{"location":"guides/proteinpaint/advanced-guides/using-the-heatmap/#others","text":"","title":"Others"},{"location":"guides/proteinpaint/advanced-guides/using-the-heatmap/#gene-recurrence","text":"\"samplecount4gene\" : true Root-level attribute. If set to \"true\", gene recurrence will be indicated by the number of samples:","title":"Gene recurrence"},{"location":"guides/proteinpaint/advanced-guides/using-the-sample-table/","text":"Using the sample table \u00b6 The sample table shows overview of data from every patient and sample: In above example, the NAME column shows patient name, and the samples are identified for each patient. Some patients have only one sample (diagnosis), while others have a pair (diagnosis/relapse). Following each sample, the presence and abundance of various mutation data types are indicated (SNV/indel, SV, CNV). Notes: The table only shows names of patients, rather than the name of specific sample. ProteinPaint does not assume \"diagnosis/relapse\" are the only valid sample type. User is free to use any word to describe sample type. Click on the \"diagnosis/relapse\" button representing sample types to generate a whole-genome view of data from this sample: to be finished...","title":"Using the Sample Table"},{"location":"guides/proteinpaint/advanced-guides/using-the-sample-table/#using-the-sample-table","text":"The sample table shows overview of data from every patient and sample: In above example, the NAME column shows patient name, and the samples are identified for each patient. Some patients have only one sample (diagnosis), while others have a pair (diagnosis/relapse). Following each sample, the presence and abundance of various mutation data types are indicated (SNV/indel, SV, CNV). Notes: The table only shows names of patients, rather than the name of specific sample. ProteinPaint does not assume \"diagnosis/relapse\" are the only valid sample type. User is free to use any word to describe sample type. Click on the \"diagnosis/relapse\" button representing sample types to generate a whole-genome view of data from this sample: to be finished...","title":"Using the sample table"},{"location":"guides/proteinpaint/advanced-guides/visualize-custom-mutations/","text":"Todo We are still working on importing this content to the official St. Jude Cloud guide. Please be patient with us! If you have any questions, please contact us . Original Link: https://plus.google.com/+XinZhou_s/posts/B9iVVGAL2u9","title":"Visualize Your Mutation Data"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/","text":"Quickstart \u00b6 Gallery: https://proteinpaint.stjude.org/examples/ Create an HTML file and display it in the web browser to see embedding in action: < html > < body > < script src = \"https://proteinpaint.stjude.org/bin/proteinpaint.js\" charset = \"utf-8\" ></ script > < div id = a style = \"margin:10px\" ></ div > < script > runproteinpaint ({ host : 'https://proteinpaint.stjude.org' , holder : document . getElementById ( 'a' ), parseurl : true , block : true , nobox : 1 , noheader : 1 , genome : 'hg19' , position : 'chr12:25334648-25426944' , nativetracks : 'RefGene' , tracks : [{ type : \"bigwig\" , url : \"http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phyloP100way/hg19.100way.phyloP100way.bw\" , \"name\" : \"UCSC phyloP 100ways\" , \"height\" : 100 }] }) </ script > </ body > </ html > View this example live at https://proteinpaint.stjude.org/examples/bigwig.html . This is all driven by a JavaScript function runproteinpaint() . This function accepts an object as input, which contain key-value pairs to do many things such as launching components and customizing looks. Parameter names are case-sensitive. If you want to use the \"heatmap\", you need to also include the \"sjcharts\": < html > < body > < script src = \"https://pecan.stjude.cloud/sjcharts/bin/sjcharts.js\" charset = \"utf-8\" ></ script > < script src = \"https://proteinpaint.stjude.org/bin/proteinpaint.js\" charset = \"utf-8\" ></ script > ... rest omitted ... Required Parameters \u00b6 holder:<dom> \u00b6 A DOM object. Via jQuery, use as: holder:yourvariable[0], Via D3.js, use as: holder:yourvariable.node(), parseurl:true \u00b6 Value is boolean, if true, will attempt to parse parameter from URL from the parent web page. noheader:true \u00b6 Value is boolean, if true, will hide the default page header. genome:'hg19' \u00b6 Name of the reference genome Genome Browser View \u00b6 <!DOCTYPE html> < html > < head >< meta charset = \"utf-8\" ></ head > < body > < script src = \"https://proteinpaint.stjude.org/bin/proteinpaint.js\" charset = \"utf-8\" ></ script > < div id = a style = \"margin:20px\" ></ div > < script > runproteinpaint ({ host : 'https://proteinpaint.stjude.org' , holder : document . getElementById ( 'a' ), parseurl : true , block : true , nobox : 1 , noheader : 1 , genome : 'hg19' , position : 'chr12:25334648-25426944' , nativetracks : 'RefGene' , tracks : [{ \"type\" : \"bigwig\" , \"file\" : \"hg19/hg19.100way.phastCons.bw\" , \"name\" : \"UCSC phastCons 100ways\" , \"height\" : 100 }] }) </ script > </ body > </ html > View this example live at https://proteinpaint.stjude.org/examples/bigwig.html . block:true \u00b6 Value is \"true\". By setting this attribute it will require genome to be set. nativetracks:'RefGene' \u00b6 Show one or more native tracks. The tracks must be available from this genome on this ProteinPaint server. Value can be following: Track names joined by comma, e.g. \"refgene\", or \"refgene,repeatmasker\" Array of track names, [\"refgene\", \"repeatmasker\"] Array of track objects, with custom settings, each track must have the \"name\" attribute {\"name\":\"refgene\", \"stackheight\":15} {\"name\":\"refgene\", \"stackheight\":15} All track names are case-insensitive, e.g. \"refgene\" and \"RefGene\" refers to the same track tracks:[] \u00b6 Provide one or more custom tracks. Tracks must be declared as JSON objects, as defined in this tutorial . Defining view range \u00b6 position:'chr1:22222-33333' \u00b6 Specify the genomic region to display by default. If not provided, will show the default region of this genome (pre-configured in ProteinPaint). Note that the genome browser will force a minimum 400 bp range centered on the input position. If this is undesired (e.g. to zoom in to finest level), use \"chr/start\" keys as below. positionbygene:'crebbp' \u00b6 A gene name or RefSeq accession may be given instead of \"position\" (genomic coordinate). Gene name is case insensitive. chr:'chr?',start:12345, \u00b6 Provide both \"chr\" and \"start\" keys to zoom into a nucleotide, at the finest possible resolution. Optionally, define \"stop\". URL parameters \u00b6 Example: http://host/yourpage.html?position=chr1:111-222&hlregion=.. In which \"yourpage.html\" the HTML file calls the embedding API from this section to launch a genome browser (block). The URL parameters will customize the ways the block is shown, without having to update anything inside the HTML file. The URL parameters are listed below. position=chr:start-stop \u00b6 Will change the default position. hlregion=region1,region2,... \u00b6 To highlight the given regions. Requirements defined here . Genome browser API \u00b6 By executing runproteinpaint() in your embedding code, it will return a promise and resolve to an object with the attribute \"block\". The block attribute is the genome browser object which provides the following methods so you can manipulate the genome browser through your code. Changing view range \u00b6 runproteinpaint ({ block : true , ... }) . then ( _ =>{ _ . block . jump_1basedcoordinate ( 'chr1:222-333' ) // above will enforce a minimum 400bp range // alternatively, use {chr,start} to zoom in to finest level _ . block . jump_1basedcoordinate ({ chr : 'chr1' , start : 222 }) }) Highlight a region \u00b6 runproteinpaint ({ block : true , ... }) . then ( _ =>{ _ . block . highlight_1basedcoordinate ( 'chr1:222-333' ) }) Only show specific tracks for a track type \u00b6 All the other tracks of the same type will be turned hidden. runproteinpaint ({ block : true , ... }) . then ( _ =>{ _ . block . showTrackByFile ([ { type : 'bam' , file : 'path/to/file1.bam' }, {... another file } ]} }) Show given tracks \u00b6 runproteinpaint ({ block : true , ... }) . then ( _ =>{ _ . block . turnOnTrack ([ { type : 'bam' , file : 'path/to/file1.bam' }, {... another file } ]} }) Hide given tracks \u00b6 runproteinpaint ({ block : true , ... }) . then ( _ =>{ _ . block . turnOffTrack ([ { type : 'bam' , file : 'path/to/file1.bam' }, {... another file } ]} }) GenomePaint \u00b6 datasetqueries:[ {dataset, querykey, ... } ] \u00b6 \"block:true\" is required for this parameter to work. This launches one or multiple official GenomePaint tracks, available for this genome. See this tutorial for launching custom track . The track is a combination of mutation, CNV, LOH, SV/fusion, FPKM etc. Works with gene view and genome browser view. Each JSON object defines a track backed by a GenomePaint dataset, along with customization options. dataset : STR querykey : STR Points to the official dataset available from this genome. Customization parameters \u00b6 Following parameters will change the default behavior of the track. singlesample : {} singlesample : { name : STR , waterfall : { inuse : true } } Optional. If provided, will launch the single sample view instead of the multi-sample view. \"name\" is the sample name, required. \"waterfall\" is optional. If provided, will apply the settings to the waterfall plot. Following attributes also works for defining custom track : isfull : BOOL isdense : BOOL Defines if to show in \"dense\" or \"expanded\" mode, works for multi-sample. This overrides the default setting on the dataset. sampleAttribute :{} sampleAttribute : { \"cancer_type\" : { hiddenvalues : [ \"NBL\" , \"RB\" ] } } Optional. If provided, will filter out samples if they match with given sample attribute key and values. vcf :{} hiddenclass: [ 'M', 'N', ... ] See hlaachange for list of SNV/indel classes .hide_cnvgain:true .hide_cnvloss:true Setting to true to hide either gain or loss cnv :{} hidden:1 upperlengthlimit: 0 loh :{} hidden:1 upperlengthlimit: 0 Set to 0 to show all LOH segments sv :{} hidden:1 fusion :{} hidden:1 itd :{} hidden:1 sampleset :[] sampleset : [ { name : 'Group1' , samples : [ 'sample1' , 'sample2' , ... ] }, { name : 'Group2' , samples : [ 'sampleA' , 'sampleB' , ... ] } } Optional. Provides one or more groups of samples to limit the view only to these samples. mdssamplescatterplot:{ dataset:'xxx' } \u00b6 Launches the sample scatterplot view from a GenomePaint dataset. Only available for official datasets. See example . mdssurvivalplot:{} \u00b6 Launches a set of Kaplan-Meier plots from a GenomePaint dataset, with customizations for each plot. Only available for official datasets. View instructions . display_termdb:{} \u00b6 Launch termdb. Refer to termdb document . samplematrix:{} \u00b6 Using an official dataset ( example ): samplematrix : { genome : 'hg19' , dslabel : 'Pediatric2' , ismutation_allsymbolic : true , limitsamplebyeitherannotation : [ { key : 'diagnosis_short' , value : 'NBL' } ], features : [ { label : 'MYCN' , ismutation : 1 , querykeylst : [ 'svcnv' , 'snvindel' ], width : 50 , position : 'chr2:16079110-16087476' , snvindel : { excludeclasses : { snv : 1 , Intron : 1 , E : 1 , mnv : 1 , Utr3 : 1 , Utr5 : 1 } } }, { ... another feature ... } ] } Using a custom dataset (to add example): samplematrix : { genome : 'hg38' , iscustom : true , querykey2tracks : { svcnv : { type : 'mdssvcnv' , url : 'https://pecan.stjude.cloud/static/hg38/tcga-gdc/DLBC/TCGA_DLBC.CNV.gz' , }, vcf : { type : 'mdsvcf' , url : 'https://pecan.stjude.cloud/static/hg38/tcga-gdc/DLBC/TCGA_DLBC.vcf.gz' } }, features : [ { label : 'CDKN2A/B' , ismutation : 1 , querykeylst : [ 'svcnv' , 'vcf' ], width : 50 , position : 'chr9:21843776-22119276' , snvindel : { excludeclasses : { Intron : 1 }} }, { ... another feature ... } ] } Gene View \u00b6 gene:'ikzf1' \u00b6 To launch a gene-view with the given gene. Value can be gene symbol (TP53) or isoform name (NM_000546), case-insensitive. dataset:'clinvar' \u00b6 Show built-in datasets, join multiple by comma, case-insensitive hlaachange:'V617F' \u00b6 Highlight given mutations (mostly AA change names but could be label of any other type), for the first dataset specified by the \"dataset\" parameter. Groups of mutations with any label matching this input will be shown as expanded, while the rest folded. Mutation label must be exact match, case-sensitive. This will only be effective for the first dataset to be rendered. Provide the variants as string, join multiple mutation names by comma. Unmatched ones won't be displayed: hlaachange: \"V617F,V392M\", Alternatively, provide an array of mutations. Each mutation is described using a few attributes, of which \"name\" is used for matching. In case no match can be found, the unmatched ones will be shown as a new track, thus the purpose of \"codon\" and \"class\". hlaachange: [ { name:'V617F',codon:617,class:'missense'}, { name:'new datapoint',codon:500,class:'nonsense'} ] Value of \"class\" can be either class code or label. See below for supported classes. Class code Class label M MISSENSE E EXON F FRAMESHIFT N NONSENSE S SILENT D PROTEINDEL I PROTEININS P SPLICE_REGION L SPLICE Intron INTRON Utr3 UTR_3 Utr5 UTR_5 X NONSTANDARD noncoding NONCODING snv SNV mnv MNV insertion insertion deletion Small deletion mset:[] \u00b6 For adding one or multiple sets of predefined variants. mset : [ { name : 'Set 1' , mlst : [ { gene : 'BRAF' , isoform : 'NM_004333' , mname : 'V617F' , class : 'M' , chr : 'chr7' , pos : 140482900 , dt : 1 }, ... more variants ] }, ... more sets ] The value for \"class\" must be one of the class code from previous table. \"dt\":1 is a hardcoded attribute. hidedatasetexpression:true \u00b6 Value is \"true\". Only apply when \"dataset\" is provided. If set, will not display the gene expression panel accompanying the dataset, and will only show mutation data over the gene/protein. hidegenecontrol:true \u00b6 Value is \"true\". If set, will hide the control buttons atop the coordinate ruler when showing a gene. hidegenelegend:true \u00b6 Value is \"true\". If set, will hide all legends when showing a gene (mutation class, mutation origin, protein domains) Prediction of motif change caused by mutation \u00b6 Given a sequence mutation, PP will run fimo to predict motifs using the reference sequence at the mutation site with a bit of flanking; then will mutate the sequence, and run fimo again on the mutated sequence. Predicted motif change will be rendered. At the embedding API, add the \"fimo\" attribute to the argument of runproteinpaint() function. fimo : { genome : 'hg19' , m : { chr : 'chr1' , pos : 47704967 , ref : 'A' , alt : 'AAAC' }, fimo_thresh : 1 e - 3 , factor_profiles : [ { profile1 }, { profile2 }, ... ] } .m:{} \u00b6 Defines the variant, with 1-based position. Ref and alt allele sequences could be on the reverse strand. But is not allowed for one allele to be on forward, and the other allele on reverse. PP will carry out motif prediction on both strands. .factor_profiles:[] \u00b6 Transcription factor profiles to be shown alongside predicted motifs. Profile: isgenevalue \u00b6 { isgenevalue : 1 , name : 'TALL FPKM' , mdslabel : 'Pediatric2' , querykey : 'genefpkm' , samplegroup_attrlst : [ { k : 'diagnosis_group_short' , kvalue : 'HM' }, { k : 'diagnosis_short' , kvalue : 'TALL' } ] }, Profile: isgenevalueonesample \u00b6 { isgenevalueonesample : 1 , name : 'SJALL015645_D1-PASYAJ FPKM' , mdslabel : 'Pediatric2' , querykey : 'genefpkm' , samplename : 'SJALL015645_D1-PASYAJ' , width : 200 , }, Differential Gene Expression viewer \u00b6 mavolcanoplot:{} \u00b6 Will launch the differential gene expression viewer that renders the data in MA-plot and Volcano-plot. Keys: input:\"... ...\" A long string of differential gene expression data. url:\"...\" The URL of a single text file of the differential gene expression data, based on format specification . dataname:\"whatever\" Name of the dataset tracks:[] Optional. Provides a set of tracks to be displayed over the selected gene when clicking a gene in the MA/Volcano plot. Supported tracks: bigWig Stranded bigWig Refer to this tutorial for declaring tracks This requires the values in the \"gene\" column of the differential expression file to be valid gene names, so that the genomic position can be derived based on the gene name for launching the genome browser. Note for browsing stranded bigWig tracks on DNANexus: The bigWig format file must be named as following to be recognized: *.posStrand.bw *.negStrand.bw Fusion Editor \u00b6 fusioneditor:{} \u00b6 Will launch the Fusion Editor , value is an object, keys: input:\"... ...\" A long string of fusion gene data (from CICERO output). \\n as line break, tab separates columns, first line is header, refer to Format specification urls:[ URL1, URL2, ... ] List of URLs of text files as input, format of each file should match specification: Format specification \"urls\" will be ignored if \"input\" is set. dataname Name of this dataset Example: https://proteinpaint.stjude.org/examples/fusioneditor.html Study View \u00b6 studyview:{} \u00b6 (this part is being updated) Loads a study view by accepting various types of data. For mutation data including SNV/indel, ITD, sv/fusion, truncation, intragenic deletion, CNV, data should be submitted as a string variable that contain the entire content of a text file. studyview : { snvindel : \"a string, \\n as line breaks, first line is header\" , svjson : \"sv/fusion/itd/trunctation/deletion data in json format ... \" , cnv : \"cnv data in tabular format, \\n as line breaks, first line is header \" , name : \"name of this dataset\" , genome : \"hg19\" , } The \"studyview\" object is very similar to the JSON definition of study , with most attributes applicable here, except these: mutationset : [] dbexpression : {} study:\"path/to/studyconfigfile\" \u00b6 Loads a study view from a server-side JSON file. Value is the JSON file path starting from path. Visit here for JSON file format . Other parameters \u00b6 base_zindex:100 \u00b6 Set z-index value to floating panels and menus/tooltip. variantPageCall_snv:(arg)=>{...} \u00b6 A logo generator: by calling this function with appropriate arguments it generate a status logo for a given SNV/indel variant (e.g. telling the pathogenecity of the variant) Applicable to both SQLite-based dataset tracks and VCF tracks. Function argument is an object with following keys: chr:\"\" chromosome name position:INT 1-based position on the chromosome refallele:\"\" the reference allele altallele:\"\" the alternative allele The notation for ref/alt alleles will vary based on source of data in the track, could potentially cause error. Standard notation is required http://varnomen.hgvs.org/ container: A D3 element as the container of the logo selectsample_callback:(arg)=>{...} \u00b6 Provide a callback to handle selected sample IDs from within a dataset track. The dataset track must have \".sampleselectable\" set to true to be eligible for sample selection. This is a trick apply this only to Pediatric but not COSMIC on pecan.stjude.org. Currently only works for dataset tracks with a preconfigured SQLite-based track, but not VCF. Argument is an object, keys: samplelst :[] Array of sample ids basket :\"basket name\" Allowed values: \"gene\", \"expression\" note :\"\" ProteinPaint will try its best to tell the reason of selection","title":"Embedding ProteinPaint"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#quickstart","text":"Gallery: https://proteinpaint.stjude.org/examples/ Create an HTML file and display it in the web browser to see embedding in action: < html > < body > < script src = \"https://proteinpaint.stjude.org/bin/proteinpaint.js\" charset = \"utf-8\" ></ script > < div id = a style = \"margin:10px\" ></ div > < script > runproteinpaint ({ host : 'https://proteinpaint.stjude.org' , holder : document . getElementById ( 'a' ), parseurl : true , block : true , nobox : 1 , noheader : 1 , genome : 'hg19' , position : 'chr12:25334648-25426944' , nativetracks : 'RefGene' , tracks : [{ type : \"bigwig\" , url : \"http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phyloP100way/hg19.100way.phyloP100way.bw\" , \"name\" : \"UCSC phyloP 100ways\" , \"height\" : 100 }] }) </ script > </ body > </ html > View this example live at https://proteinpaint.stjude.org/examples/bigwig.html . This is all driven by a JavaScript function runproteinpaint() . This function accepts an object as input, which contain key-value pairs to do many things such as launching components and customizing looks. Parameter names are case-sensitive. If you want to use the \"heatmap\", you need to also include the \"sjcharts\": < html > < body > < script src = \"https://pecan.stjude.cloud/sjcharts/bin/sjcharts.js\" charset = \"utf-8\" ></ script > < script src = \"https://proteinpaint.stjude.org/bin/proteinpaint.js\" charset = \"utf-8\" ></ script > ... rest omitted ...","title":"Quickstart"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#required-parameters","text":"","title":"Required Parameters"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#holderdom","text":"A DOM object. Via jQuery, use as: holder:yourvariable[0], Via D3.js, use as: holder:yourvariable.node(),","title":"holder:&lt;dom&gt;"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#parseurltrue","text":"Value is boolean, if true, will attempt to parse parameter from URL from the parent web page.","title":"parseurl:true"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#noheadertrue","text":"Value is boolean, if true, will hide the default page header.","title":"noheader:true"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#genomehg19","text":"Name of the reference genome","title":"genome:'hg19'"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#genome-browser-view","text":"<!DOCTYPE html> < html > < head >< meta charset = \"utf-8\" ></ head > < body > < script src = \"https://proteinpaint.stjude.org/bin/proteinpaint.js\" charset = \"utf-8\" ></ script > < div id = a style = \"margin:20px\" ></ div > < script > runproteinpaint ({ host : 'https://proteinpaint.stjude.org' , holder : document . getElementById ( 'a' ), parseurl : true , block : true , nobox : 1 , noheader : 1 , genome : 'hg19' , position : 'chr12:25334648-25426944' , nativetracks : 'RefGene' , tracks : [{ \"type\" : \"bigwig\" , \"file\" : \"hg19/hg19.100way.phastCons.bw\" , \"name\" : \"UCSC phastCons 100ways\" , \"height\" : 100 }] }) </ script > </ body > </ html > View this example live at https://proteinpaint.stjude.org/examples/bigwig.html .","title":"Genome Browser View"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#blocktrue","text":"Value is \"true\". By setting this attribute it will require genome to be set.","title":"block:true"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#nativetracksrefgene","text":"Show one or more native tracks. The tracks must be available from this genome on this ProteinPaint server. Value can be following: Track names joined by comma, e.g. \"refgene\", or \"refgene,repeatmasker\" Array of track names, [\"refgene\", \"repeatmasker\"] Array of track objects, with custom settings, each track must have the \"name\" attribute {\"name\":\"refgene\", \"stackheight\":15} {\"name\":\"refgene\", \"stackheight\":15} All track names are case-insensitive, e.g. \"refgene\" and \"RefGene\" refers to the same track","title":"nativetracks:'RefGene'"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#tracks","text":"Provide one or more custom tracks. Tracks must be declared as JSON objects, as defined in this tutorial .","title":"tracks:[]"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#defining-view-range","text":"","title":"Defining view range"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#positionchr122222-33333","text":"Specify the genomic region to display by default. If not provided, will show the default region of this genome (pre-configured in ProteinPaint). Note that the genome browser will force a minimum 400 bp range centered on the input position. If this is undesired (e.g. to zoom in to finest level), use \"chr/start\" keys as below.","title":"position:'chr1:22222-33333'"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#positionbygenecrebbp","text":"A gene name or RefSeq accession may be given instead of \"position\" (genomic coordinate). Gene name is case insensitive.","title":"positionbygene:'crebbp'"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#chrchrstart12345","text":"Provide both \"chr\" and \"start\" keys to zoom into a nucleotide, at the finest possible resolution. Optionally, define \"stop\".","title":"chr:'chr?',start:12345,"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#url-parameters","text":"Example: http://host/yourpage.html?position=chr1:111-222&hlregion=.. In which \"yourpage.html\" the HTML file calls the embedding API from this section to launch a genome browser (block). The URL parameters will customize the ways the block is shown, without having to update anything inside the HTML file. The URL parameters are listed below.","title":"URL parameters"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#positionchrstart-stop","text":"Will change the default position.","title":"position=chr:start-stop"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#hlregionregion1region2","text":"To highlight the given regions. Requirements defined here .","title":"hlregion=region1,region2,..."},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#genome-browser-api","text":"By executing runproteinpaint() in your embedding code, it will return a promise and resolve to an object with the attribute \"block\". The block attribute is the genome browser object which provides the following methods so you can manipulate the genome browser through your code.","title":"Genome browser API"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#changing-view-range","text":"runproteinpaint ({ block : true , ... }) . then ( _ =>{ _ . block . jump_1basedcoordinate ( 'chr1:222-333' ) // above will enforce a minimum 400bp range // alternatively, use {chr,start} to zoom in to finest level _ . block . jump_1basedcoordinate ({ chr : 'chr1' , start : 222 }) })","title":"Changing view range"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#highlight-a-region","text":"runproteinpaint ({ block : true , ... }) . then ( _ =>{ _ . block . highlight_1basedcoordinate ( 'chr1:222-333' ) })","title":"Highlight a region"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#only-show-specific-tracks-for-a-track-type","text":"All the other tracks of the same type will be turned hidden. runproteinpaint ({ block : true , ... }) . then ( _ =>{ _ . block . showTrackByFile ([ { type : 'bam' , file : 'path/to/file1.bam' }, {... another file } ]} })","title":"Only show specific tracks for a track type"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#show-given-tracks","text":"runproteinpaint ({ block : true , ... }) . then ( _ =>{ _ . block . turnOnTrack ([ { type : 'bam' , file : 'path/to/file1.bam' }, {... another file } ]} })","title":"Show given tracks"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#hide-given-tracks","text":"runproteinpaint ({ block : true , ... }) . then ( _ =>{ _ . block . turnOffTrack ([ { type : 'bam' , file : 'path/to/file1.bam' }, {... another file } ]} })","title":"Hide given tracks"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#genomepaint","text":"","title":"GenomePaint"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#datasetqueries-dataset-querykey","text":"\"block:true\" is required for this parameter to work. This launches one or multiple official GenomePaint tracks, available for this genome. See this tutorial for launching custom track . The track is a combination of mutation, CNV, LOH, SV/fusion, FPKM etc. Works with gene view and genome browser view. Each JSON object defines a track backed by a GenomePaint dataset, along with customization options. dataset : STR querykey : STR Points to the official dataset available from this genome.","title":"datasetqueries:[ {dataset, querykey, ... } ]"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#customization-parameters","text":"Following parameters will change the default behavior of the track. singlesample : {} singlesample : { name : STR , waterfall : { inuse : true } } Optional. If provided, will launch the single sample view instead of the multi-sample view. \"name\" is the sample name, required. \"waterfall\" is optional. If provided, will apply the settings to the waterfall plot. Following attributes also works for defining custom track : isfull : BOOL isdense : BOOL Defines if to show in \"dense\" or \"expanded\" mode, works for multi-sample. This overrides the default setting on the dataset. sampleAttribute :{} sampleAttribute : { \"cancer_type\" : { hiddenvalues : [ \"NBL\" , \"RB\" ] } } Optional. If provided, will filter out samples if they match with given sample attribute key and values. vcf :{} hiddenclass: [ 'M', 'N', ... ] See hlaachange for list of SNV/indel classes .hide_cnvgain:true .hide_cnvloss:true Setting to true to hide either gain or loss cnv :{} hidden:1 upperlengthlimit: 0 loh :{} hidden:1 upperlengthlimit: 0 Set to 0 to show all LOH segments sv :{} hidden:1 fusion :{} hidden:1 itd :{} hidden:1 sampleset :[] sampleset : [ { name : 'Group1' , samples : [ 'sample1' , 'sample2' , ... ] }, { name : 'Group2' , samples : [ 'sampleA' , 'sampleB' , ... ] } } Optional. Provides one or more groups of samples to limit the view only to these samples.","title":"Customization parameters"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#mdssamplescatterplot-datasetxxx","text":"Launches the sample scatterplot view from a GenomePaint dataset. Only available for official datasets. See example .","title":"mdssamplescatterplot:{ dataset:'xxx' }"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#mdssurvivalplot","text":"Launches a set of Kaplan-Meier plots from a GenomePaint dataset, with customizations for each plot. Only available for official datasets. View instructions .","title":"mdssurvivalplot:{}"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#display_termdb","text":"Launch termdb. Refer to termdb document .","title":"display_termdb:{}"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#samplematrix","text":"Using an official dataset ( example ): samplematrix : { genome : 'hg19' , dslabel : 'Pediatric2' , ismutation_allsymbolic : true , limitsamplebyeitherannotation : [ { key : 'diagnosis_short' , value : 'NBL' } ], features : [ { label : 'MYCN' , ismutation : 1 , querykeylst : [ 'svcnv' , 'snvindel' ], width : 50 , position : 'chr2:16079110-16087476' , snvindel : { excludeclasses : { snv : 1 , Intron : 1 , E : 1 , mnv : 1 , Utr3 : 1 , Utr5 : 1 } } }, { ... another feature ... } ] } Using a custom dataset (to add example): samplematrix : { genome : 'hg38' , iscustom : true , querykey2tracks : { svcnv : { type : 'mdssvcnv' , url : 'https://pecan.stjude.cloud/static/hg38/tcga-gdc/DLBC/TCGA_DLBC.CNV.gz' , }, vcf : { type : 'mdsvcf' , url : 'https://pecan.stjude.cloud/static/hg38/tcga-gdc/DLBC/TCGA_DLBC.vcf.gz' } }, features : [ { label : 'CDKN2A/B' , ismutation : 1 , querykeylst : [ 'svcnv' , 'vcf' ], width : 50 , position : 'chr9:21843776-22119276' , snvindel : { excludeclasses : { Intron : 1 }} }, { ... another feature ... } ] }","title":"samplematrix:{}"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#gene-view","text":"","title":"Gene View"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#geneikzf1","text":"To launch a gene-view with the given gene. Value can be gene symbol (TP53) or isoform name (NM_000546), case-insensitive.","title":"gene:'ikzf1'"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#datasetclinvar","text":"Show built-in datasets, join multiple by comma, case-insensitive","title":"dataset:'clinvar'"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#hlaachangev617f","text":"Highlight given mutations (mostly AA change names but could be label of any other type), for the first dataset specified by the \"dataset\" parameter. Groups of mutations with any label matching this input will be shown as expanded, while the rest folded. Mutation label must be exact match, case-sensitive. This will only be effective for the first dataset to be rendered. Provide the variants as string, join multiple mutation names by comma. Unmatched ones won't be displayed: hlaachange: \"V617F,V392M\", Alternatively, provide an array of mutations. Each mutation is described using a few attributes, of which \"name\" is used for matching. In case no match can be found, the unmatched ones will be shown as a new track, thus the purpose of \"codon\" and \"class\". hlaachange: [ { name:'V617F',codon:617,class:'missense'}, { name:'new datapoint',codon:500,class:'nonsense'} ] Value of \"class\" can be either class code or label. See below for supported classes. Class code Class label M MISSENSE E EXON F FRAMESHIFT N NONSENSE S SILENT D PROTEINDEL I PROTEININS P SPLICE_REGION L SPLICE Intron INTRON Utr3 UTR_3 Utr5 UTR_5 X NONSTANDARD noncoding NONCODING snv SNV mnv MNV insertion insertion deletion Small deletion","title":"hlaachange:'V617F'"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#mset","text":"For adding one or multiple sets of predefined variants. mset : [ { name : 'Set 1' , mlst : [ { gene : 'BRAF' , isoform : 'NM_004333' , mname : 'V617F' , class : 'M' , chr : 'chr7' , pos : 140482900 , dt : 1 }, ... more variants ] }, ... more sets ] The value for \"class\" must be one of the class code from previous table. \"dt\":1 is a hardcoded attribute.","title":"mset:[]"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#hidedatasetexpressiontrue","text":"Value is \"true\". Only apply when \"dataset\" is provided. If set, will not display the gene expression panel accompanying the dataset, and will only show mutation data over the gene/protein.","title":"hidedatasetexpression:true"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#hidegenecontroltrue","text":"Value is \"true\". If set, will hide the control buttons atop the coordinate ruler when showing a gene.","title":"hidegenecontrol:true"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#hidegenelegendtrue","text":"Value is \"true\". If set, will hide all legends when showing a gene (mutation class, mutation origin, protein domains)","title":"hidegenelegend:true"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#prediction-of-motif-change-caused-by-mutation","text":"Given a sequence mutation, PP will run fimo to predict motifs using the reference sequence at the mutation site with a bit of flanking; then will mutate the sequence, and run fimo again on the mutated sequence. Predicted motif change will be rendered. At the embedding API, add the \"fimo\" attribute to the argument of runproteinpaint() function. fimo : { genome : 'hg19' , m : { chr : 'chr1' , pos : 47704967 , ref : 'A' , alt : 'AAAC' }, fimo_thresh : 1 e - 3 , factor_profiles : [ { profile1 }, { profile2 }, ... ] }","title":"Prediction of motif change caused by mutation"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#m","text":"Defines the variant, with 1-based position. Ref and alt allele sequences could be on the reverse strand. But is not allowed for one allele to be on forward, and the other allele on reverse. PP will carry out motif prediction on both strands.","title":".m:{}"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#factor_profiles","text":"Transcription factor profiles to be shown alongside predicted motifs.","title":".factor_profiles:[]"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#profile-isgenevalue","text":"{ isgenevalue : 1 , name : 'TALL FPKM' , mdslabel : 'Pediatric2' , querykey : 'genefpkm' , samplegroup_attrlst : [ { k : 'diagnosis_group_short' , kvalue : 'HM' }, { k : 'diagnosis_short' , kvalue : 'TALL' } ] },","title":"Profile: isgenevalue"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#profile-isgenevalueonesample","text":"{ isgenevalueonesample : 1 , name : 'SJALL015645_D1-PASYAJ FPKM' , mdslabel : 'Pediatric2' , querykey : 'genefpkm' , samplename : 'SJALL015645_D1-PASYAJ' , width : 200 , },","title":"Profile: isgenevalueonesample"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#differential-gene-expression-viewer","text":"","title":"Differential Gene Expression viewer"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#mavolcanoplot","text":"Will launch the differential gene expression viewer that renders the data in MA-plot and Volcano-plot. Keys: input:\"... ...\" A long string of differential gene expression data. url:\"...\" The URL of a single text file of the differential gene expression data, based on format specification . dataname:\"whatever\" Name of the dataset tracks:[] Optional. Provides a set of tracks to be displayed over the selected gene when clicking a gene in the MA/Volcano plot. Supported tracks: bigWig Stranded bigWig Refer to this tutorial for declaring tracks This requires the values in the \"gene\" column of the differential expression file to be valid gene names, so that the genomic position can be derived based on the gene name for launching the genome browser. Note for browsing stranded bigWig tracks on DNANexus: The bigWig format file must be named as following to be recognized: *.posStrand.bw *.negStrand.bw","title":"mavolcanoplot:{}"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#fusion-editor","text":"","title":"Fusion Editor"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#fusioneditor","text":"Will launch the Fusion Editor , value is an object, keys: input:\"... ...\" A long string of fusion gene data (from CICERO output). \\n as line break, tab separates columns, first line is header, refer to Format specification urls:[ URL1, URL2, ... ] List of URLs of text files as input, format of each file should match specification: Format specification \"urls\" will be ignored if \"input\" is set. dataname Name of this dataset Example: https://proteinpaint.stjude.org/examples/fusioneditor.html","title":"fusioneditor:{}"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#study-view","text":"","title":"Study View"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#studyview","text":"(this part is being updated) Loads a study view by accepting various types of data. For mutation data including SNV/indel, ITD, sv/fusion, truncation, intragenic deletion, CNV, data should be submitted as a string variable that contain the entire content of a text file. studyview : { snvindel : \"a string, \\n as line breaks, first line is header\" , svjson : \"sv/fusion/itd/trunctation/deletion data in json format ... \" , cnv : \"cnv data in tabular format, \\n as line breaks, first line is header \" , name : \"name of this dataset\" , genome : \"hg19\" , } The \"studyview\" object is very similar to the JSON definition of study , with most attributes applicable here, except these: mutationset : [] dbexpression : {}","title":"studyview:{}"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#studypathtostudyconfigfile","text":"Loads a study view from a server-side JSON file. Value is the JSON file path starting from path. Visit here for JSON file format .","title":"study:\"path/to/studyconfigfile\""},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#other-parameters","text":"","title":"Other parameters"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#base_zindex100","text":"Set z-index value to floating panels and menus/tooltip.","title":"base_zindex:100"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#variantpagecall_snvarg","text":"A logo generator: by calling this function with appropriate arguments it generate a status logo for a given SNV/indel variant (e.g. telling the pathogenecity of the variant) Applicable to both SQLite-based dataset tracks and VCF tracks. Function argument is an object with following keys: chr:\"\" chromosome name position:INT 1-based position on the chromosome refallele:\"\" the reference allele altallele:\"\" the alternative allele The notation for ref/alt alleles will vary based on source of data in the track, could potentially cause error. Standard notation is required http://varnomen.hgvs.org/ container: A D3 element as the container of the logo","title":"variantPageCall_snv:(arg)=&gt;{...}"},{"location":"guides/proteinpaint/developers-guide/embedding-proteinpaint/#selectsample_callbackarg","text":"Provide a callback to handle selected sample IDs from within a dataset track. The dataset track must have \".sampleselectable\" set to true to be eligible for sample selection. This is a trick apply this only to Pediatric but not COSMIC on pecan.stjude.org. Currently only works for dataset tracks with a preconfigured SQLite-based track, but not VCF. Argument is an object, keys: samplelst :[] Array of sample ids basket :\"basket name\" Allowed values: \"gene\", \"expression\" note :\"\" ProteinPaint will try its best to tell the reason of selection","title":"selectsample_callback:(arg)=&gt;{...}"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/","text":"A nicely-organized study. The study is expressed as a JSON file, which contains one single object. To debug JSON, try http://jsonlint.com/ . Example study: { \"genome\" : \"hg19\" , \"name\" : \"example study\" , \"mutationset\" : [{ \"snvindel\" : \"path/to/file.txt\" , \"name\" : \"DNA mutation\" }], \"show_genetable\" : 1 } Study attributes are listed below, they are case-sensitive. genome:\"\" \u00b6 Name of the reference genome, e.g. hg19 or hg38 name:\"\" \u00b6 The name of this study/cohort. Assay, tracks, and genome browser Assays, tracks, and genome browser \u00b6 \"assays\":[] \u00b6 Declares all assay names. Example: { \"assays\" : [ \"H3K4me3\" , \"RNA-seq\" , \"Splice junctions\" ], \"H3K4me3\" : { ... ... }, \"RNA-seq\" : { ... ... }, \"Splice junctions\" : { ... ... } } Assay names can be arbitrary words e.g. \"H3K4me3\" \"RNA-seq\" \"Splice junctions\" Do not use reserved words such as \"assay\" or \"genome\" Assay names are case-sensitive Each name should appear as an attribute in the study. Each assay is a set of tracks, organized by \"individual\" \u2192 \"sample type\" \u2192 track list There can be one or more \"sample type\" for an \"individual\" In case this is not applicable e.g. for cell lines, use cell line name for both individual and sample type (the hierarchy is hardcoded...) For each sample type, there can be one or multiple tracks associated with it If one track, the value is an object If multiple tracks, the value is an array of track objects Tracks in one assay should be the same type. Supported types: bigWig Splice junction VCF Allelic imbalance (todo) Assay tracks can be presented in a sample-by-assay matrix, so called \"facet table\". The facet table can be generated by default, and can be customized. See section on facet table. bigWig tracks \u00b6 Declare an assay type for the bigWig track, e.g.: \"RNA-seq\" : { \"config\" : { \"type\" : \"bigwig\" , \"pcolor\" : \"red\" , \"height\" : 70 , \"scale\" : { \"max\" : 500 , \"min\" : 0 } }, \"patient1\" : { \"sampletype1\" : { \"file\" : \"path/to/RNA-patient1-sampletype1.bw\" , \"pcolor\" : \"green\" }, \"sampletype2\" : [ ... a list of tracks ... ], .... more sample types }, ... more tracks }, config : { } config.type value must be \"bigwig\" The rest of config contains type-specific configurations that will be applied to every track in this assay. See below link for all available options. [ Patient name ] Name of the patient/individual, value is a hash of types of samples from this patient Note that the 2-level patient-sampletype arrangement is hard-coded and applies to any type of assay. [ Sample type ] Value could be an object or an array of objects Each object is a track The track object should contain \"file\" or \"url\" to point to the source of the track file The track object can contain any configurations and will override the ones in \"config\". Read bigWig track configuration options. Splice junction tracks \u00b6 Declare an assay type for the junction tracks, e.g.: \"junction\" : { \"config\" : { \"type\" : \"junction\" , \"categories\" : { \"known\" : { \"color\" : \"#9C9C9C\" , \"label\" : \"Known\" }, \"novel\" : { \"color\" : \"#cc0000\" , \"label\" : \"Novel\" } } }, \"patient1\" : { \"sampletype1\" : { \"file\" : \"path/to/RNA-patient1-sampletype1.gz\" }, .... more sample types }, ... more tracks }, Config.type value is \"junction\" Config.categories lists types of junctions and their rendering colors Read junction track configuration options. Read junction file format. VCF tracks \u00b6 Declare an assay type for the VCF tracks, e.g.: \"VCF\" : { \"config\" : { \"type\" : \"vcf\" }, \"patient1\" : { \"sampletype1\" : { \"file\" : \"path/to/patient1-sampletype1.vcf.gz\" }, .... more sample types }, ... more tracks }, VCF format specification Additional requirements on the VCF format in ProteinPaint Assay of AI (allelic imbalance) tracks \u00b6 Todo Assay of positional annotation tracks \u00b6 Todo In JSON-BED format E.g. called peaks ... Facet tables \u00b6 To define what samples and assays are to be used in making a facet table, use the \"trackfacets\" attribute. The value is an array, where each element defines one facet table. This way it allows multiple facet tables to be defined. { \"trackfacets\" : [ { \"name\" : \"name of this table\" , \"samples\" : [ \"sample1\" , \"sample2\" , ], \"assays\" : [ \"assay1\" , \"assay2\" ], \"nosortassay\" : 1 , \"nosortsample\" : 1 }, ... additional facet tables ... ] } Todo \"browserview\":{} \u00b6 Will launch a browser and show some tracks over the given position in the genome. \"browserview\" : { \"position\" : { \"chr\" : \"chr10\" , \"start\" : 8081012 , \"stop\" : 8103311 }, \"nativetracks\" : \"refgene,repeatmasker\" , \"assays\" : { \"my_rnaseq_assay\" : 1 , \"my_splicejunction_assay\" : { \"combined\" : 1 } }, \"defaultassaytracks\" : [ { \"assay\" : \"assayname1\" , \"level1\" : \"patientname\" }, { ... another track finder ... } ], \"tracks\" : [ { ... track 1 ... }, { ... track 2 ... } ] } browserview.position Optional. If not provided, will use default position of the genome. Value can be string or object: { chr :\"...\", start :..., stop :...} \"chr1:12345-67890\" Coordinates are 0-based browserview.nativetracks Specify what \"native\" tracks to be loaded by default, usually the gene track. Check with your ProteinPaint server to find out what tracks are available \"natively\" for that genome. Value can be: A string of track name A string of multiple track names, joined by comma, no space An array of track names Track names should match with what's specified for the tracks of that genome, but case-insensitive TODO: allow customizations browserview.assays : { } Optional. To show all tracks from specified assays. If you don't want to show all tracks of an assay, use \"assaytracks\" attributes instead (see below) Value is an object. Keys are assay names, and the name must exist in the \"assays\" array. Value to each assay can vary. In above example: By using value \"1\", all tracks from \"rna_seq\" will be displayed as separate tracks. By using value {\" combined \":1}, all tracks from this assay type will be aggregated into one track. This only applies to these track types: Junction VCF browserview.defaultassaytracks : [ {} ] Optional. To select a set of tracks from the assays defined in this study, and show them by default. Each element is a \"track finder\", with these attributes to pinpoint the track: \" assay \":\"\" The assay name, required. \" level1 \":\"\" Patient name, but here it's a generic name. Required. \" level2 \":\"\" Optional, the sample type. If specified, will use track from only this sample type of the patient as specified by \"level1\". Else, it will use all tracks from this patient. browserview.tracks : [ ] Optional. To provide a list of custom tracks. Custom tracks defined as JSON objects, see JSON format of tracks . This allows adding tracks in freedom, directly encoded, rather than systematic way of \"assays\". Such tracks are not associated with any assay type and won't show up in facet table. Mutation data in tabular format \u00b6 mutationset:[] \u00b6 Lists all mutation datasets for this cohort, and the mutation data files associated for each set. \"mutationset\" : [ { \"name\" : \"DNA somatic\" , \"snvindel\" : \"datadir/snvindel_dna\" , \"sv\" : \"datadir/sv\" , \"cnv\" : \"datadir/cnv\" }, { \"name\" : \"RNA-seq\" , \"snvindel\" : \"datadir/snvindel_rna\" , \"fusion\" : \"datadir/fusion\" } ], This example provides two sets of mutation for a cohort from both DNA and RNA, as indicated in the name. The name can be arbitrary string. In each dataset, different types of mutations are provided in the form of separate text files. The \"datadir\" from above example is relative to the ROOT directory. Mutation data type keys, each should point to a server-hosted text file. snvindel SNV/indel data, tabular text format sv fusion Structural variation OR fusion, they are in the same tabular text format Note that \"sv\" is used in \"DNA\", and \"fusion\" is used in \"RNA-seq\" svfusion JSON format data for sv/fusion/ITD/deletion/truncation, format is the same as the JSON file made by fusion editor export. cnv Copy number change, tabular text format deletion Intragenic deletion, tabular text format truncation Gene truncation, tabular text format Variant_gene_assoc No longer supported!! For describing genes associated with particular variants Per-sample based: each line is one variant from one sample. This will trigger a browser view for exploring variant and genes together. 7 columns: i. Chromosome ii. Position iii. Reference_allele iv. Mutant_allele v. Patient vi. Sampletype vii. geneset The \"geneset\" is a JSON array, representing associated genes from each sample, example: i. [{\"name\":\"TAL1\",\"isoform\":\"NM_003189\",\"position\":\"chr1:47681961-47698007\",\"score_1\":0.543,\"score_2\":0.543}, {... second gene ...} ] dbexpression:{} \u00b6 It provides a gene-level expression values over a group of samples from a database table on the server, and show it when the gene is shown in the protein-view. \"Dbexpression\" should work with \"mutationset\". \"dbexpression\" : { \"dbfile\" : \"path/to/data.db\" , \"tablename\" : \"[name of the table]\" , \"keyname\" : \"[name of the table field to query against, e.g. gene]\" , \"tidy\" : \"function(rows){rows.forEach(function(row){ ... })}\" , \"config\" : { \"name\" : \"RNA-seq\" , \"sampletype\" : \"sample\" , \"datatype\" : \"FPKM\" , \"ongene\" : true , \"hlcolor\" : \"#f53d00\" , \"hlcolor2\" : \"#FFBEA8\" , \"attrlst\" : [{ \"k\" : \"patient\" },{ \"k\" : \"sampletype\" }], \"cohort\" : { \"levels\" : [ { \"k\" : \"disease\" , \"label\" : \"Disease\" } ] } } }, dbexpression.dbfile Path to the SQLite database file. Must be relative to the directory. dbexpression.tablename Name of the database table to query against with dbexpression.tidy Provides a Javascript function in the form of a string, argument is an array of all records fetched from the database, the function will apply certain tidying operation on each of the record dbexpression.attrlst Note that the db table can contain data for samples that are not from this cohort, and they will still be displayed in the expression data panel. Gene-sample heatmap \u00b6 heatmapJSON:{} \u00b6 An JSON object that configures the heatmap layout. Refer to heatmap configuration tutorial. hardcodemap:[] \u00b6 Provides one or more \"hard-coded heatmap\". \"hardcodemap\" : [ { \"file\" : \"path/to/file.txt\" , \"rowh\" : 18 , \"rowspace\" : 1 , \"colw\" : 10 , \"colspace\" : 1 , \"metadata\" : { \"key1\" : { \"v1\" : { \"label\" : \"what\" , \"color\" : \"red\" }, \"v2\" : { \"label\" : \"what\" , \"color\" : \"blue\" } }, \"key2\" : { \"V3\" : { \"label\" : \"what\" , \"color\" : \"red\" }, \"V4\" : \"{\" label \":\" what \",\" color \":\" red \" } } } ], File format: Columns are samples Rows are items (e.g. genes, or other attributes describing samples) First line is header First column is metadata keys, the value must be found as one of the keys in hardcodemap.metadata Second column is row name Cell value is one of the values of each key (of that row). Join multiple values by semicolon. Metadata annotation \u00b6 (under development) \"patientannotation\":{} \u00b6 An object to define metadata annotation at patient level. This should also be used when there is only information on samples but not patients (in which case sample name/id should be expressed at \"patient\" level). patientannotation.annotation provides actual annotation of each patient/sample. patientannotation.metadata provides the list of metadata terms, and attributes associated with the term. \"patientannotation\" : { \"annotation\" : { \"patient1\" : { \"age\" : \"child\" , \"sex\" : \"m\" }, ... more patients ... }, \"metadata\" : [ { \"key\" : \"age\" , \"label\" : \"Age at diagnosis\" , \"values\" : [ { \"key\" : \"child\" , \"label\" : \"Child (<10yrs)\" , \"color\" : \"red\" }, { \"key\" : \"adult\" , \"label\" : \"Adult (>18yrs)\" , \"color\" : \"blue\" } ] }, { \"key\" : \"sex\" , \"label\" : \"Sex\" , \"values\" : [ { \"key\" : \"m\" , \"label\" : \"Male\" , \"color\" : \"red\" }, { \"key\" : \"f\" , \"label\" : \"Female\" , \"color\" : \"blue\" } ] }, ... more terms ... ] } Such metadata annotation can be applied to: Expression - PCA plot Splice junction track (TODO) \"annotations\":{} \u00b6 An object to define metadata annotation by input file. .idkey \"STRING\" \u00b6 The column value, typically \"sample\" or \"samplename\", to use for collecting annotations into an object .files [ARRAY] \u00b6 An array of string filepaths to use as metadata source data inputFormat \"STRING\" \u00b6 Indicates the format for parsing the source file, defaults to \"metadataTsv\" Expression - PCA plot \u00b6 \"e2pca\":[] \u00b6 A list of plots to be made, each defines an \"expression - PCA\" plot. More on Expression PCA plot. \"e2pca\" : [ { \"name\" : \"optional name of this plot\" , \"vectorfile\" : \"path/to/vectorfile.txt\" , \"dbfile\" : \"path/to/data.db\" , \"colorscale\" : { \"from\" : \"blue\" , \"to\" : \"red\" } }, ... one more plot ... ], Other controls \u00b6 sankey:{} \u00b6 An object of possible configurations to the disease-gene sankey diagram. Use sankey.genes:[] to define a set of genes to be used in the diagram: \"sankey\" : { \"genes\" : [ { \"name\" : \"ERG\" , \"color\" : \"red\" }, { \"name\" : \"ZEB2\" , \"color\" : \"red\" }, { \"name\" : \"MYC\" , \"color\" : \"red\" }, { \"name\" : \"MYCBP2\" , \"color\" : \"red\" }, .... ] }, Use sankey.geneset:[] to define gene sets to be used in the diagram, all genes in a set share the same color, legend will be rendered: \"sankey\" : { \"geneset\" : [ { \"name\" : \"gene set 1\" , \"color\" : \"red\" , \"genes\" : [ \"ERG\" , \"ZEB2\" ] }, { \"name\" : \"gene set 2\" , \"color\" : \"blue\" , \"genes\" : [ ...... ]} ] }, diseasecolor:{} \u00b6 An object to define rendering color for different diseases. Applies to sankey diagram and gene network chart. genenetwork:{} \u00b6 To provide one or more gene network diagrams. \"genenetwork\" : { \"list\" : [ { a JSON object representing a network }, { one more network } ] } Each network is defined as a JSON object, see example . no_defaultgeneset:1 \u00b6 Will not apply the genome-equipped gene set to generate the heatmap view, but rather, to use highly recurrent genes based on the data: Max 20 genes, all in one group. show_genetable:1 \u00b6 Will show the gene table by default. Only applicable when \"mutationset\" is used. Value is \"1\" for true. show_sampletable:1 \u00b6 Will show the sample table by default. Value is \"1\" for true. Samples can come from either \"mutationset\", or assays. disable_sampletable:1 \u00b6 Will hide the sample table. show_heatmap:1 \u00b6 Will show the heatmap by default. Value is \"1\" for true. show_browser:1 \u00b6 Will show the genome browser by default. Value is \"1\" for true. show_hardcodemap:1 \u00b6 Will show the hard-coded heatmap by default. \"show_e2pca\":1 \u00b6 Will show the expression - PCA plots by default. disable_genenetwork:1 \u00b6 Will hide the gene network function. hide_addnewfile:1 \u00b6 Will hide the \"+NEW FILE\" tab. hide_navigation:1 \u00b6 Will hide all navigation buttons on the left. individual_label_name:\"patient\" \u00b6 Will replace the default \"individual\" with the given word in the \"# individuals\" tab on left of the study view. Obsolete contents \u00b6 STOP HERE. Warning The rest of these contents are obsoletse. We're busy porting them to the new ProteinPaint. Attribute: aicheck (moved to \"assays\") \u00b6 This is the \"aicheck\" track. This is the integrative display of allelic frequency imbalance of variants or genetic markers, as well as DNA sequencing coverage over these markers. Adapted from the \"aicheck\" figure invented by Xiaotu Ma. Note that this is designed for tumor-normal matched paired samples only. \"aicheck\" : { \"20-PABLDZ\" : { \"sampletypes\" : [ \"relapse\" , \"diagnosis\" ], \"relapse\" : { \"file2\" : \"aml/ai_check_SJBALL013790_R1_G1.txt.gz\" , \"readdepthcutoff\" : 126 }, \"diagnosis\" : { \"file\" : \"aml/fullMaf_TARGET-20-PABLDZ-09A-02D_NormalVsPrimary.maf.txt.gz\" , \"readdepthcutoff\" : 126 } }, \"patient2\" : { ... }, ... more patients ... }, The \"samplekeys\" is an array of sample type. This is a relic of initial design and will be abandoned. By then it will be ignored by ProteinPaint. There are two file formats for aicheck, identified by \"file\" and \"file2\". \"file2\" format comes right off the CompBio pipeline (generated by one of Xiaotu's script). \"file\" columns chromosome name, must be \"chr1\" but not \"1\" coordinate, 1-based MinD: mutant allele read count in tumor DNA TinD: total read count in tumor DNA MinN: mutant allele read count in normal DNA TinN: total read count in normal DNA \"file2\" columns chromosome name, must be \"chr1\" but not \"1\" coordinate, 1-based SNP, value seems always is \"SNP\" rsNumber: dbSNP name TinD: total read count in tumor DNA dMAF: mutant allele frequency in tumor DNA TinN: total read count in normal DNA nMAF: mutant allele frequency in normal DNA The \"readdepthcutoff\" value defines the Y-axis max value of read depth track for both tumor and normal. It is pre-calculated by following Xiaotu's method below. User is free to use any other method. ######## to calculate trimmed media, in 1% to 99% range trimed.median <- function ( xx ) { cutt <- 0 dnn <- quantile ( xx , 0.01 ) upp <- quantile ( xx , 0.99 ) if ( sum ( xx > dnn & xx < upp ) > 2 ) { use <- ( xx > dnn & xx < upp ) cutt <- quantile ( xx [ use ], 0.98 ) } return ( as.numeric ( cutt )) } #Tumor medd.D <- trimed.median ( dt0 [, \"TinD\" ]) * 1.5 #Normal medd.G <- trimed.median ( dt0 [, \"TinN\" ]) * 1.5 if ( medd.D < 1 ) medd.D <- 1 if ( medd.G < 1 ) medd.G <- 1 #Maximum medd <- max ( medd.D , medd.G ) Broadly, there are two types of tracks that ProteinPaint can read: numerical, and positional. Bedgraph and bigWig are numerical track formats, the generic bed is the positional format. In the cohort definition, you have to first declare what the tracks are about, then the type/format of the track. The first layer is assay type, like RNA-seq, or it can be anything with a name. We will refer to it as \"assay type\". Assay types are predefined, allowed values are (case-sensitive): rnaseq Each assay type must be declared as a hash, with patient names as keys. Patients from different assay types may or may not be the same. There is always a reserved key called \"config\", providing configurations applicable to all tracks of this assay type. Each track can have its own configurations in order to be different from the \"global\" attributes in config. Numerical track Y-scale configuration \u00b6 percentile Value is positive integer from 1 to 99 If provided, the nth percentile value in the view range will be used to set Y-axis. This is useful for preventing large outlier values from skewing the display. When there are both positive and negative values in the view range, the percentile calculation will be applied separately to positive and negative values for calculating max and min values. min, max When valid values are provided for both, will set fixed scale. autoscale Apply auto-scale, will override percentile or min/max settings. File or URL? \u00b6 url HTTP or HTTPS, such as http://datahub.stjude.org/datasets/MBSE2016/hg19/tracks/1M1_H3K27Ac_treat_afterfiting_all.bw The hosting server must support byte-range request file A partial path to a file, such as \"path/to/track.gz\", relative to the Tumor Portrait root directory ProteinPaint will reject: absolute path (e.g. /etc/passwd) back-to-previous-level (e.g. ../../etc/passwd) Track: bedGraph \u00b6 bedGraph track example for RNA-seq \"rnaseq\" : { \"config\" : { \"name\" : \"RNA-seq coverage\" , \"tktype\" : \"bedgraph\" , \"pcolor\" : \"#006600\" , \"pcolor2\" : \"#CC00B8\" , \"percentile\" : 95 }, \"patient1\" : { \"diagnosis\" : { \"file\" : \"aml/SJAML040582_R1.gz\" }, \"relapse\" : { \"file\" : \"somewhere/xxxxx.gz\" } }, \"patient2\" : { ... }, ... more patients ... }, Track: bigWig \u00b6 bigWig example for RNA-seq \"rnaseq\" : { \"config\" : { \"name\" : \"RNA-seq coverage\" , \"tktype\" : \"bigwig\" , \"pcolor\" : \"#006600\" , \"pcolor2\" : \"#CC00B8\" , \"percentile\" : 95 }, \"patient1\" : { \"sampletype\" : { \"file\" : \"aml/SJAML040582_R1.bw\" } }, ... more ... }, Track: numeric2 (a pair of numerical tracks) \u00b6 Overlaying of two numerical tracks, noted by \"track1\" and \"track2\". Track 1 Displayed on foreground, axis on left Track 2 Displayed on background, axis on right rnaseq coverage-FPKM overlay example \"rnaseq\" : { \"config\" : { \"name\" : \"RNA-seq\" , \"tktype\" : \"numeric2\" , \"track1\" : { \"name\" : \"coverage\" , \"rangelimit\" : 10000000 , \"pcolor\" : \"#006600\" , \"pcolor2\" : \"#CC00B8\" , \"percentile\" : 95 }, \"track2\" : { \"pcolor\" : \"#FF9900\" , \"pcolor2\" : \"#CC7A00\" , \"name\" : \"FPKM\" , \"autoscale\" : \"on\" } }, \"patient1\" : { \"diagnosis\" : { \"file\" : \"aml/SJAML040582_R1.gz\" , \"file2\" : \"aml/10-PAPAIZ-diagnosis.gz\" } }, \"patient2\" : { ... }, ... more patients ... }, Track: junction (RNA-seq junction reads) \u00b6 junction example, along with a \"browserview\" trigger for displaying \"junction\" : { \"config\" : { \"type2color\" : { \"known\" : \"#9C9C9C\" , \"novel\" : \"#cc0000\" } }, \"30-PAIFXV\" : { \"diagnosis\" : { \"file\" : \"junction/targetNBL/30-PAIFXV-diagnosis-SJNBL017066_D1.gz\" } }, \"30-PAIPGU\" : { \"diagnosis\" : { \"file\" : \"junction/targetNBL/30-PAIPGU-diagnosis-SJNBL017070_D1.gz\" } }, ... }, \"browserview\" : { \"position\" : { \"chr\" : \"chr12\" , \"start\" : 25357723 , \"stop\" : 25403865 }, \"assays\" : { \"junction\" : { \"sum_view\" : { \"type\" : \"junction\" , \"name\" : \"NBL\" } } } } Each junction track file contains splicing junctions identified in ONE SAMPLE only. Primarily this is converted from the RNApeg output ( http://hc-wiki.stjude.org/display/compbio/How+to+count+novel+or+reference+junction+reads+in+an+RNA-Seq+BAM+using+RNApeg ). To convert an RNApeg output file into a track file to be displayed on ProteinPaint, run: node utils/rnapegjunction2tabix.js sample.RNApeg.output sample.junction The converted file has 5 columns: Chromosome name, e.g. \"chr1\" Start, 1-based position of the last exon nucleotide Stop, 1-based position of the first exon nucleotide Number of (high-quality) junction reads Type of junction a. RNApeg outputs two types of junction (known/novel). For displaying, arbitrary types can be used. Any used types should be stated in the config.jtype2color so they can be distinguished by color Track: VCF \u00b6 VCF examples, along with \"browserview\" trigger for displaying \"vcf_cohort\" : { \"file\" : \"vcf/scd_143_join.vcf.gz\" , \"name\" : \"Joint\" }, \"vcf\" : { \"SJSCD040763\" : { \"G1\" : { \"file\" : \"vcf/SJSCD040763_G1.vcf.gz\" } }, \"SJSCD040764\" : { \"G1\" : { \"file\" : \"vcf/SJSCD040764_G1.vcf.gz\" }}, ... }, \"browserview\" : { \"position\" : { \"chr\" : \"chr6\" , \"start\" : 135179289 , \"stop\" : 135183700 }, \"assays\" : { \"vcf_cohort\" : 1 , \"vcf\" : { \"sum_view\" : { \"type\" : \"vcf\" , \"name\" : \"Individual\" } } } } \"Vcf_cohort\" specifies one single VCF file. \"Vcf\" specifies the VCF file from each sample. Track: vafs1 (variant allele fraction of a single sample) \u00b6 vafs1 example \"vafs1\" : { \"person1\" : { \"sampletype1\" : { \"DNA\" : { \"file\" : \"variantgene/SJALL040467_D1.combine.WGS.goodmarkers.txt.gz\" }, \"RNA\" : { \"file\" : \"variantgene/SJALL040467_D1.combine.RNAseq.goodmarkers.txt.gz\" } }, \"sampletype2\" : { \"DNA\" : { \"file\" : \"variantgene/SJALL040467_R1.combine.WGS.goodmarkers.txt.gz\" }, \"RNA\" : { \"file\" : \"variantgene/SJALL040467_R1.combine.RNAseq.goodmarkers.txt.gz\" } } }, ... next person ... } Track file has 6 columns: Chromosome Position (1-based) Reference allele alternative allele Total reads Variant allele fraction Note that for one sample type, there can be multiple types of tracks (DNA/RNA in above example). The type names can be arbitrary. Track: BAM \u00b6 In progress ...","title":"Organizing Data into a Study View"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#genome","text":"Name of the reference genome, e.g. hg19 or hg38","title":"genome:\"\""},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#name","text":"The name of this study/cohort. Assay, tracks, and genome browser","title":"name:\"\""},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#assays-tracks-and-genome-browser","text":"","title":"Assays, tracks, and genome browser"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#assays","text":"Declares all assay names. Example: { \"assays\" : [ \"H3K4me3\" , \"RNA-seq\" , \"Splice junctions\" ], \"H3K4me3\" : { ... ... }, \"RNA-seq\" : { ... ... }, \"Splice junctions\" : { ... ... } } Assay names can be arbitrary words e.g. \"H3K4me3\" \"RNA-seq\" \"Splice junctions\" Do not use reserved words such as \"assay\" or \"genome\" Assay names are case-sensitive Each name should appear as an attribute in the study. Each assay is a set of tracks, organized by \"individual\" \u2192 \"sample type\" \u2192 track list There can be one or more \"sample type\" for an \"individual\" In case this is not applicable e.g. for cell lines, use cell line name for both individual and sample type (the hierarchy is hardcoded...) For each sample type, there can be one or multiple tracks associated with it If one track, the value is an object If multiple tracks, the value is an array of track objects Tracks in one assay should be the same type. Supported types: bigWig Splice junction VCF Allelic imbalance (todo) Assay tracks can be presented in a sample-by-assay matrix, so called \"facet table\". The facet table can be generated by default, and can be customized. See section on facet table.","title":"\"assays\":[]"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#bigwig-tracks","text":"Declare an assay type for the bigWig track, e.g.: \"RNA-seq\" : { \"config\" : { \"type\" : \"bigwig\" , \"pcolor\" : \"red\" , \"height\" : 70 , \"scale\" : { \"max\" : 500 , \"min\" : 0 } }, \"patient1\" : { \"sampletype1\" : { \"file\" : \"path/to/RNA-patient1-sampletype1.bw\" , \"pcolor\" : \"green\" }, \"sampletype2\" : [ ... a list of tracks ... ], .... more sample types }, ... more tracks }, config : { } config.type value must be \"bigwig\" The rest of config contains type-specific configurations that will be applied to every track in this assay. See below link for all available options. [ Patient name ] Name of the patient/individual, value is a hash of types of samples from this patient Note that the 2-level patient-sampletype arrangement is hard-coded and applies to any type of assay. [ Sample type ] Value could be an object or an array of objects Each object is a track The track object should contain \"file\" or \"url\" to point to the source of the track file The track object can contain any configurations and will override the ones in \"config\". Read bigWig track configuration options.","title":"bigWig tracks"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#splice-junction-tracks","text":"Declare an assay type for the junction tracks, e.g.: \"junction\" : { \"config\" : { \"type\" : \"junction\" , \"categories\" : { \"known\" : { \"color\" : \"#9C9C9C\" , \"label\" : \"Known\" }, \"novel\" : { \"color\" : \"#cc0000\" , \"label\" : \"Novel\" } } }, \"patient1\" : { \"sampletype1\" : { \"file\" : \"path/to/RNA-patient1-sampletype1.gz\" }, .... more sample types }, ... more tracks }, Config.type value is \"junction\" Config.categories lists types of junctions and their rendering colors Read junction track configuration options. Read junction file format.","title":"Splice junction tracks"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#vcf-tracks","text":"Declare an assay type for the VCF tracks, e.g.: \"VCF\" : { \"config\" : { \"type\" : \"vcf\" }, \"patient1\" : { \"sampletype1\" : { \"file\" : \"path/to/patient1-sampletype1.vcf.gz\" }, .... more sample types }, ... more tracks }, VCF format specification Additional requirements on the VCF format in ProteinPaint","title":"VCF tracks"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#assay-of-ai-allelic-imbalance-tracks","text":"Todo","title":"Assay of AI (allelic imbalance) tracks"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#assay-of-positional-annotation-tracks","text":"Todo In JSON-BED format E.g. called peaks ...","title":"Assay of positional annotation tracks"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#facet-tables","text":"To define what samples and assays are to be used in making a facet table, use the \"trackfacets\" attribute. The value is an array, where each element defines one facet table. This way it allows multiple facet tables to be defined. { \"trackfacets\" : [ { \"name\" : \"name of this table\" , \"samples\" : [ \"sample1\" , \"sample2\" , ], \"assays\" : [ \"assay1\" , \"assay2\" ], \"nosortassay\" : 1 , \"nosortsample\" : 1 }, ... additional facet tables ... ] } Todo","title":"Facet tables"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#browserview","text":"Will launch a browser and show some tracks over the given position in the genome. \"browserview\" : { \"position\" : { \"chr\" : \"chr10\" , \"start\" : 8081012 , \"stop\" : 8103311 }, \"nativetracks\" : \"refgene,repeatmasker\" , \"assays\" : { \"my_rnaseq_assay\" : 1 , \"my_splicejunction_assay\" : { \"combined\" : 1 } }, \"defaultassaytracks\" : [ { \"assay\" : \"assayname1\" , \"level1\" : \"patientname\" }, { ... another track finder ... } ], \"tracks\" : [ { ... track 1 ... }, { ... track 2 ... } ] } browserview.position Optional. If not provided, will use default position of the genome. Value can be string or object: { chr :\"...\", start :..., stop :...} \"chr1:12345-67890\" Coordinates are 0-based browserview.nativetracks Specify what \"native\" tracks to be loaded by default, usually the gene track. Check with your ProteinPaint server to find out what tracks are available \"natively\" for that genome. Value can be: A string of track name A string of multiple track names, joined by comma, no space An array of track names Track names should match with what's specified for the tracks of that genome, but case-insensitive TODO: allow customizations browserview.assays : { } Optional. To show all tracks from specified assays. If you don't want to show all tracks of an assay, use \"assaytracks\" attributes instead (see below) Value is an object. Keys are assay names, and the name must exist in the \"assays\" array. Value to each assay can vary. In above example: By using value \"1\", all tracks from \"rna_seq\" will be displayed as separate tracks. By using value {\" combined \":1}, all tracks from this assay type will be aggregated into one track. This only applies to these track types: Junction VCF browserview.defaultassaytracks : [ {} ] Optional. To select a set of tracks from the assays defined in this study, and show them by default. Each element is a \"track finder\", with these attributes to pinpoint the track: \" assay \":\"\" The assay name, required. \" level1 \":\"\" Patient name, but here it's a generic name. Required. \" level2 \":\"\" Optional, the sample type. If specified, will use track from only this sample type of the patient as specified by \"level1\". Else, it will use all tracks from this patient. browserview.tracks : [ ] Optional. To provide a list of custom tracks. Custom tracks defined as JSON objects, see JSON format of tracks . This allows adding tracks in freedom, directly encoded, rather than systematic way of \"assays\". Such tracks are not associated with any assay type and won't show up in facet table.","title":"\"browserview\":{}"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#mutation-data-in-tabular-format","text":"","title":"Mutation data in tabular format"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#mutationset","text":"Lists all mutation datasets for this cohort, and the mutation data files associated for each set. \"mutationset\" : [ { \"name\" : \"DNA somatic\" , \"snvindel\" : \"datadir/snvindel_dna\" , \"sv\" : \"datadir/sv\" , \"cnv\" : \"datadir/cnv\" }, { \"name\" : \"RNA-seq\" , \"snvindel\" : \"datadir/snvindel_rna\" , \"fusion\" : \"datadir/fusion\" } ], This example provides two sets of mutation for a cohort from both DNA and RNA, as indicated in the name. The name can be arbitrary string. In each dataset, different types of mutations are provided in the form of separate text files. The \"datadir\" from above example is relative to the ROOT directory. Mutation data type keys, each should point to a server-hosted text file. snvindel SNV/indel data, tabular text format sv fusion Structural variation OR fusion, they are in the same tabular text format Note that \"sv\" is used in \"DNA\", and \"fusion\" is used in \"RNA-seq\" svfusion JSON format data for sv/fusion/ITD/deletion/truncation, format is the same as the JSON file made by fusion editor export. cnv Copy number change, tabular text format deletion Intragenic deletion, tabular text format truncation Gene truncation, tabular text format Variant_gene_assoc No longer supported!! For describing genes associated with particular variants Per-sample based: each line is one variant from one sample. This will trigger a browser view for exploring variant and genes together. 7 columns: i. Chromosome ii. Position iii. Reference_allele iv. Mutant_allele v. Patient vi. Sampletype vii. geneset The \"geneset\" is a JSON array, representing associated genes from each sample, example: i. [{\"name\":\"TAL1\",\"isoform\":\"NM_003189\",\"position\":\"chr1:47681961-47698007\",\"score_1\":0.543,\"score_2\":0.543}, {... second gene ...} ]","title":"mutationset:[]"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#dbexpression","text":"It provides a gene-level expression values over a group of samples from a database table on the server, and show it when the gene is shown in the protein-view. \"Dbexpression\" should work with \"mutationset\". \"dbexpression\" : { \"dbfile\" : \"path/to/data.db\" , \"tablename\" : \"[name of the table]\" , \"keyname\" : \"[name of the table field to query against, e.g. gene]\" , \"tidy\" : \"function(rows){rows.forEach(function(row){ ... })}\" , \"config\" : { \"name\" : \"RNA-seq\" , \"sampletype\" : \"sample\" , \"datatype\" : \"FPKM\" , \"ongene\" : true , \"hlcolor\" : \"#f53d00\" , \"hlcolor2\" : \"#FFBEA8\" , \"attrlst\" : [{ \"k\" : \"patient\" },{ \"k\" : \"sampletype\" }], \"cohort\" : { \"levels\" : [ { \"k\" : \"disease\" , \"label\" : \"Disease\" } ] } } }, dbexpression.dbfile Path to the SQLite database file. Must be relative to the directory. dbexpression.tablename Name of the database table to query against with dbexpression.tidy Provides a Javascript function in the form of a string, argument is an array of all records fetched from the database, the function will apply certain tidying operation on each of the record dbexpression.attrlst Note that the db table can contain data for samples that are not from this cohort, and they will still be displayed in the expression data panel.","title":"dbexpression:{}"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#gene-sample-heatmap","text":"","title":"Gene-sample heatmap"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#heatmapjson","text":"An JSON object that configures the heatmap layout. Refer to heatmap configuration tutorial.","title":"heatmapJSON:{}"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#hardcodemap","text":"Provides one or more \"hard-coded heatmap\". \"hardcodemap\" : [ { \"file\" : \"path/to/file.txt\" , \"rowh\" : 18 , \"rowspace\" : 1 , \"colw\" : 10 , \"colspace\" : 1 , \"metadata\" : { \"key1\" : { \"v1\" : { \"label\" : \"what\" , \"color\" : \"red\" }, \"v2\" : { \"label\" : \"what\" , \"color\" : \"blue\" } }, \"key2\" : { \"V3\" : { \"label\" : \"what\" , \"color\" : \"red\" }, \"V4\" : \"{\" label \":\" what \",\" color \":\" red \" } } } ], File format: Columns are samples Rows are items (e.g. genes, or other attributes describing samples) First line is header First column is metadata keys, the value must be found as one of the keys in hardcodemap.metadata Second column is row name Cell value is one of the values of each key (of that row). Join multiple values by semicolon.","title":"hardcodemap:[]"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#metadata-annotation","text":"(under development)","title":"Metadata annotation"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#patientannotation","text":"An object to define metadata annotation at patient level. This should also be used when there is only information on samples but not patients (in which case sample name/id should be expressed at \"patient\" level). patientannotation.annotation provides actual annotation of each patient/sample. patientannotation.metadata provides the list of metadata terms, and attributes associated with the term. \"patientannotation\" : { \"annotation\" : { \"patient1\" : { \"age\" : \"child\" , \"sex\" : \"m\" }, ... more patients ... }, \"metadata\" : [ { \"key\" : \"age\" , \"label\" : \"Age at diagnosis\" , \"values\" : [ { \"key\" : \"child\" , \"label\" : \"Child (<10yrs)\" , \"color\" : \"red\" }, { \"key\" : \"adult\" , \"label\" : \"Adult (>18yrs)\" , \"color\" : \"blue\" } ] }, { \"key\" : \"sex\" , \"label\" : \"Sex\" , \"values\" : [ { \"key\" : \"m\" , \"label\" : \"Male\" , \"color\" : \"red\" }, { \"key\" : \"f\" , \"label\" : \"Female\" , \"color\" : \"blue\" } ] }, ... more terms ... ] } Such metadata annotation can be applied to: Expression - PCA plot Splice junction track (TODO)","title":"\"patientannotation\":{}"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#annotations","text":"An object to define metadata annotation by input file.","title":"\"annotations\":{}"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#idkey-string","text":"The column value, typically \"sample\" or \"samplename\", to use for collecting annotations into an object","title":".idkey \"STRING\""},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#files-array","text":"An array of string filepaths to use as metadata source data","title":".files [ARRAY]"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#inputformat-string","text":"Indicates the format for parsing the source file, defaults to \"metadataTsv\"","title":"inputFormat \"STRING\""},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#expression-pca-plot","text":"","title":"Expression - PCA plot"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#e2pca","text":"A list of plots to be made, each defines an \"expression - PCA\" plot. More on Expression PCA plot. \"e2pca\" : [ { \"name\" : \"optional name of this plot\" , \"vectorfile\" : \"path/to/vectorfile.txt\" , \"dbfile\" : \"path/to/data.db\" , \"colorscale\" : { \"from\" : \"blue\" , \"to\" : \"red\" } }, ... one more plot ... ],","title":"\"e2pca\":[]"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#other-controls","text":"","title":"Other controls"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#sankey","text":"An object of possible configurations to the disease-gene sankey diagram. Use sankey.genes:[] to define a set of genes to be used in the diagram: \"sankey\" : { \"genes\" : [ { \"name\" : \"ERG\" , \"color\" : \"red\" }, { \"name\" : \"ZEB2\" , \"color\" : \"red\" }, { \"name\" : \"MYC\" , \"color\" : \"red\" }, { \"name\" : \"MYCBP2\" , \"color\" : \"red\" }, .... ] }, Use sankey.geneset:[] to define gene sets to be used in the diagram, all genes in a set share the same color, legend will be rendered: \"sankey\" : { \"geneset\" : [ { \"name\" : \"gene set 1\" , \"color\" : \"red\" , \"genes\" : [ \"ERG\" , \"ZEB2\" ] }, { \"name\" : \"gene set 2\" , \"color\" : \"blue\" , \"genes\" : [ ...... ]} ] },","title":"sankey:{}"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#diseasecolor","text":"An object to define rendering color for different diseases. Applies to sankey diagram and gene network chart.","title":"diseasecolor:{}"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#genenetwork","text":"To provide one or more gene network diagrams. \"genenetwork\" : { \"list\" : [ { a JSON object representing a network }, { one more network } ] } Each network is defined as a JSON object, see example .","title":"genenetwork:{}"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#no_defaultgeneset1","text":"Will not apply the genome-equipped gene set to generate the heatmap view, but rather, to use highly recurrent genes based on the data: Max 20 genes, all in one group.","title":"no_defaultgeneset:1"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#show_genetable1","text":"Will show the gene table by default. Only applicable when \"mutationset\" is used. Value is \"1\" for true.","title":"show_genetable:1"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#show_sampletable1","text":"Will show the sample table by default. Value is \"1\" for true. Samples can come from either \"mutationset\", or assays.","title":"show_sampletable:1"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#disable_sampletable1","text":"Will hide the sample table.","title":"disable_sampletable:1"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#show_heatmap1","text":"Will show the heatmap by default. Value is \"1\" for true.","title":"show_heatmap:1"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#show_browser1","text":"Will show the genome browser by default. Value is \"1\" for true.","title":"show_browser:1"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#show_hardcodemap1","text":"Will show the hard-coded heatmap by default.","title":"show_hardcodemap:1"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#show_e2pca1","text":"Will show the expression - PCA plots by default.","title":"\"show_e2pca\":1"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#disable_genenetwork1","text":"Will hide the gene network function.","title":"disable_genenetwork:1"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#hide_addnewfile1","text":"Will hide the \"+NEW FILE\" tab.","title":"hide_addnewfile:1"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#hide_navigation1","text":"Will hide all navigation buttons on the left.","title":"hide_navigation:1"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#individual_label_namepatient","text":"Will replace the default \"individual\" with the given word in the \"# individuals\" tab on left of the study view.","title":"individual_label_name:\"patient\""},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#obsolete-contents","text":"STOP HERE. Warning The rest of these contents are obsoletse. We're busy porting them to the new ProteinPaint.","title":"Obsolete contents"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#attribute-aicheck-moved-to-assays","text":"This is the \"aicheck\" track. This is the integrative display of allelic frequency imbalance of variants or genetic markers, as well as DNA sequencing coverage over these markers. Adapted from the \"aicheck\" figure invented by Xiaotu Ma. Note that this is designed for tumor-normal matched paired samples only. \"aicheck\" : { \"20-PABLDZ\" : { \"sampletypes\" : [ \"relapse\" , \"diagnosis\" ], \"relapse\" : { \"file2\" : \"aml/ai_check_SJBALL013790_R1_G1.txt.gz\" , \"readdepthcutoff\" : 126 }, \"diagnosis\" : { \"file\" : \"aml/fullMaf_TARGET-20-PABLDZ-09A-02D_NormalVsPrimary.maf.txt.gz\" , \"readdepthcutoff\" : 126 } }, \"patient2\" : { ... }, ... more patients ... }, The \"samplekeys\" is an array of sample type. This is a relic of initial design and will be abandoned. By then it will be ignored by ProteinPaint. There are two file formats for aicheck, identified by \"file\" and \"file2\". \"file2\" format comes right off the CompBio pipeline (generated by one of Xiaotu's script). \"file\" columns chromosome name, must be \"chr1\" but not \"1\" coordinate, 1-based MinD: mutant allele read count in tumor DNA TinD: total read count in tumor DNA MinN: mutant allele read count in normal DNA TinN: total read count in normal DNA \"file2\" columns chromosome name, must be \"chr1\" but not \"1\" coordinate, 1-based SNP, value seems always is \"SNP\" rsNumber: dbSNP name TinD: total read count in tumor DNA dMAF: mutant allele frequency in tumor DNA TinN: total read count in normal DNA nMAF: mutant allele frequency in normal DNA The \"readdepthcutoff\" value defines the Y-axis max value of read depth track for both tumor and normal. It is pre-calculated by following Xiaotu's method below. User is free to use any other method. ######## to calculate trimmed media, in 1% to 99% range trimed.median <- function ( xx ) { cutt <- 0 dnn <- quantile ( xx , 0.01 ) upp <- quantile ( xx , 0.99 ) if ( sum ( xx > dnn & xx < upp ) > 2 ) { use <- ( xx > dnn & xx < upp ) cutt <- quantile ( xx [ use ], 0.98 ) } return ( as.numeric ( cutt )) } #Tumor medd.D <- trimed.median ( dt0 [, \"TinD\" ]) * 1.5 #Normal medd.G <- trimed.median ( dt0 [, \"TinN\" ]) * 1.5 if ( medd.D < 1 ) medd.D <- 1 if ( medd.G < 1 ) medd.G <- 1 #Maximum medd <- max ( medd.D , medd.G ) Broadly, there are two types of tracks that ProteinPaint can read: numerical, and positional. Bedgraph and bigWig are numerical track formats, the generic bed is the positional format. In the cohort definition, you have to first declare what the tracks are about, then the type/format of the track. The first layer is assay type, like RNA-seq, or it can be anything with a name. We will refer to it as \"assay type\". Assay types are predefined, allowed values are (case-sensitive): rnaseq Each assay type must be declared as a hash, with patient names as keys. Patients from different assay types may or may not be the same. There is always a reserved key called \"config\", providing configurations applicable to all tracks of this assay type. Each track can have its own configurations in order to be different from the \"global\" attributes in config.","title":"Attribute: aicheck (moved to \"assays\")"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#numerical-track-y-scale-configuration","text":"percentile Value is positive integer from 1 to 99 If provided, the nth percentile value in the view range will be used to set Y-axis. This is useful for preventing large outlier values from skewing the display. When there are both positive and negative values in the view range, the percentile calculation will be applied separately to positive and negative values for calculating max and min values. min, max When valid values are provided for both, will set fixed scale. autoscale Apply auto-scale, will override percentile or min/max settings.","title":"Numerical track Y-scale configuration"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#file-or-url","text":"url HTTP or HTTPS, such as http://datahub.stjude.org/datasets/MBSE2016/hg19/tracks/1M1_H3K27Ac_treat_afterfiting_all.bw The hosting server must support byte-range request file A partial path to a file, such as \"path/to/track.gz\", relative to the Tumor Portrait root directory ProteinPaint will reject: absolute path (e.g. /etc/passwd) back-to-previous-level (e.g. ../../etc/passwd)","title":"File or URL?"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#track-bedgraph","text":"bedGraph track example for RNA-seq \"rnaseq\" : { \"config\" : { \"name\" : \"RNA-seq coverage\" , \"tktype\" : \"bedgraph\" , \"pcolor\" : \"#006600\" , \"pcolor2\" : \"#CC00B8\" , \"percentile\" : 95 }, \"patient1\" : { \"diagnosis\" : { \"file\" : \"aml/SJAML040582_R1.gz\" }, \"relapse\" : { \"file\" : \"somewhere/xxxxx.gz\" } }, \"patient2\" : { ... }, ... more patients ... },","title":"Track: bedGraph"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#track-bigwig","text":"bigWig example for RNA-seq \"rnaseq\" : { \"config\" : { \"name\" : \"RNA-seq coverage\" , \"tktype\" : \"bigwig\" , \"pcolor\" : \"#006600\" , \"pcolor2\" : \"#CC00B8\" , \"percentile\" : 95 }, \"patient1\" : { \"sampletype\" : { \"file\" : \"aml/SJAML040582_R1.bw\" } }, ... more ... },","title":"Track: bigWig"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#track-numeric2-a-pair-of-numerical-tracks","text":"Overlaying of two numerical tracks, noted by \"track1\" and \"track2\". Track 1 Displayed on foreground, axis on left Track 2 Displayed on background, axis on right rnaseq coverage-FPKM overlay example \"rnaseq\" : { \"config\" : { \"name\" : \"RNA-seq\" , \"tktype\" : \"numeric2\" , \"track1\" : { \"name\" : \"coverage\" , \"rangelimit\" : 10000000 , \"pcolor\" : \"#006600\" , \"pcolor2\" : \"#CC00B8\" , \"percentile\" : 95 }, \"track2\" : { \"pcolor\" : \"#FF9900\" , \"pcolor2\" : \"#CC7A00\" , \"name\" : \"FPKM\" , \"autoscale\" : \"on\" } }, \"patient1\" : { \"diagnosis\" : { \"file\" : \"aml/SJAML040582_R1.gz\" , \"file2\" : \"aml/10-PAPAIZ-diagnosis.gz\" } }, \"patient2\" : { ... }, ... more patients ... },","title":"Track: numeric2 (a pair of numerical tracks)"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#track-junction-rna-seq-junction-reads","text":"junction example, along with a \"browserview\" trigger for displaying \"junction\" : { \"config\" : { \"type2color\" : { \"known\" : \"#9C9C9C\" , \"novel\" : \"#cc0000\" } }, \"30-PAIFXV\" : { \"diagnosis\" : { \"file\" : \"junction/targetNBL/30-PAIFXV-diagnosis-SJNBL017066_D1.gz\" } }, \"30-PAIPGU\" : { \"diagnosis\" : { \"file\" : \"junction/targetNBL/30-PAIPGU-diagnosis-SJNBL017070_D1.gz\" } }, ... }, \"browserview\" : { \"position\" : { \"chr\" : \"chr12\" , \"start\" : 25357723 , \"stop\" : 25403865 }, \"assays\" : { \"junction\" : { \"sum_view\" : { \"type\" : \"junction\" , \"name\" : \"NBL\" } } } } Each junction track file contains splicing junctions identified in ONE SAMPLE only. Primarily this is converted from the RNApeg output ( http://hc-wiki.stjude.org/display/compbio/How+to+count+novel+or+reference+junction+reads+in+an+RNA-Seq+BAM+using+RNApeg ). To convert an RNApeg output file into a track file to be displayed on ProteinPaint, run: node utils/rnapegjunction2tabix.js sample.RNApeg.output sample.junction The converted file has 5 columns: Chromosome name, e.g. \"chr1\" Start, 1-based position of the last exon nucleotide Stop, 1-based position of the first exon nucleotide Number of (high-quality) junction reads Type of junction a. RNApeg outputs two types of junction (known/novel). For displaying, arbitrary types can be used. Any used types should be stated in the config.jtype2color so they can be distinguished by color","title":"Track: junction (RNA-seq junction reads)"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#track-vcf","text":"VCF examples, along with \"browserview\" trigger for displaying \"vcf_cohort\" : { \"file\" : \"vcf/scd_143_join.vcf.gz\" , \"name\" : \"Joint\" }, \"vcf\" : { \"SJSCD040763\" : { \"G1\" : { \"file\" : \"vcf/SJSCD040763_G1.vcf.gz\" } }, \"SJSCD040764\" : { \"G1\" : { \"file\" : \"vcf/SJSCD040764_G1.vcf.gz\" }}, ... }, \"browserview\" : { \"position\" : { \"chr\" : \"chr6\" , \"start\" : 135179289 , \"stop\" : 135183700 }, \"assays\" : { \"vcf_cohort\" : 1 , \"vcf\" : { \"sum_view\" : { \"type\" : \"vcf\" , \"name\" : \"Individual\" } } } } \"Vcf_cohort\" specifies one single VCF file. \"Vcf\" specifies the VCF file from each sample.","title":"Track: VCF"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#track-vafs1-variant-allele-fraction-of-a-single-sample","text":"vafs1 example \"vafs1\" : { \"person1\" : { \"sampletype1\" : { \"DNA\" : { \"file\" : \"variantgene/SJALL040467_D1.combine.WGS.goodmarkers.txt.gz\" }, \"RNA\" : { \"file\" : \"variantgene/SJALL040467_D1.combine.RNAseq.goodmarkers.txt.gz\" } }, \"sampletype2\" : { \"DNA\" : { \"file\" : \"variantgene/SJALL040467_R1.combine.WGS.goodmarkers.txt.gz\" }, \"RNA\" : { \"file\" : \"variantgene/SJALL040467_R1.combine.RNAseq.goodmarkers.txt.gz\" } } }, ... next person ... } Track file has 6 columns: Chromosome Position (1-based) Reference allele alternative allele Total reads Variant allele fraction Note that for one sample type, there can be multiple types of tracks (DNA/RNA in above example). The type names can be arbitrary.","title":"Track: vafs1 (variant allele fraction of a single sample)"},{"location":"guides/proteinpaint/developers-guide/organizing-data-into-a-study-view/#track-bam","text":"In progress ...","title":"Track: BAM"},{"location":"guides/proteinpaint/developers-guide/url-parameters/","text":"URL parameter works in this way: https://proteinpaint.stjude.org/?genome=hg19&gene=ALK&dataset=pediatric It generates links of customized views that can be bookmarked or published. URL parameters consist of \"key=value\" pairs. The keys are listed below, they are case-insensitive. \"gene\" \u00b6 Generates view for a gene. Example: https://proteinpaint.stjude.org/?genome=hg19&gene=ALK&dataset=clinvar Display a gene by given name. Value can be gene symbol or isoform accession, value is case-insensitive Requires \" genome \" Optionally, specify built-in datasets using parameter \" dataset \": If more than 1, join by comma Dataset must be hosted on the PP server Value is case-insensitive Example to load the \"Pediatric\" dataset: https://proteinpaint.stjude.org/?genome=hg19&gene=ALK&dataset=pediatric When using datasets, highlight certain mutations matching with given name Effect: any groups of mutation showing a match with the given name will be shown as expanded. All the rest of groups are folded. This feature is only intended for point mutation AA change name. The provided name must exactly match with the content in the DB or VCF file Example: https://proteinpaint.stjude.org/?genome=hg19&gene=ALK&dataset=pediatric&hlaachange=G574R,F1174L All types of custom track parameters can be used as well, as defined in the \"block\" section below. block \u00b6 Launches a genome browser. Example: https://proteinpaint.stjude.org/?block=on&genome=hg19&position=chr17:7568451-7591984&bigwigurl=UCSC_phyloP,http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phyloP100way/hg19.100way.phyloP100way.bw genome \u00b6 Required. Provides reference genome name. Genomic regions \u00b6 Optional. Specify genomic regions. position \u00b6 Coordinates are 0-based, example ?block=on&genome=hg19&position=chr1:1234-5678 regions \u00b6 Using \" regions \" to join more than 1 region by comma ?block=on&genome=hg19&regions=chr1:111-222,chr2:333-444 There is a bug of incorrect genomic ruler rendering when providing multiple regions. hlregion \u00b6 Optional. Provide one or more regions to highlight. Each region is in the format of \"chr:start-stop\". Do not use commas in start or stop positions. Join multiple regions by comma. There is a bug that it will highlight regions that are outside of view range. Tracks \u00b6 Optional. There is no parameter called \"tracks\", but many different parameters to provide different types of tracks. bigwigfile \u00b6 bigwigurl \u00b6 To provide \"bigWig\" tracks. Learn how to generate a bigWig file Provide one or more bigwig tracks, each in the form of \"name,path-or-url\", all joined by comma. When using file, the files are hosted in the directory of the ProteinPaint server Example ?bigwigfile=[name1],[path/to/file1.bw],[name2],[path/to/file2.bw],.... ?bigwigurl=[name1],[url1],[name2],[url2] Note that this method won't allow setting Y scale or other configurations vcffile \u00b6 vcfurl \u00b6 Provide one or more VCF tracks. Requires VCF 4.2 format . Each in the form of \"name,path-or-url\", all joined by comma. URL format: ?vcffile=[name1],[path/to/file1],... ?vcfurl=[name1],[path/to/url1],... Example: junctionfile \u00b6 junctionurl \u00b6 Provide one or more junction tracks, see junction file format . Each in the form of \"name,path-or-url\", all joined by comma. URL format: ?junctionfile=[name1],[path/to/file1.gz],[name2],[path/to/file2.gz],.... Note that this method won't allow configuring the junction type. mdsjunctionfile \u00b6 \"MDS junction\" track is the v2.0 of the junction track, work-in-progress. This parameter will provide one or more tracks, the file of which are hosted on the ProteinPaint server. URL format: ?mdsjunctionfile=[name1],[path/to/file1.gz],[name2],[path/to/file2.gz],.... bedjfile \u00b6 bedjurl \u00b6 Provide one or more JSON-BED tracks, see JSON-BED file format . Each in the form of \"name,path-or-url\", all joined by comma. bampilefile \u00b6 bampile file format ?bampilefile=[name1],[path/to/file1.gz],[name2],[path/to/file2.gz],... aicheckfile \u00b6 aicheck file format ?aicheckfile=[name1],[path/to/file1.gz],[name2],[path/to/file2.gz],... svcnvfpkmurl \u00b6 svcnvfpkmfile \u00b6 Manuscript in prep... will add user tutorial later. Submits a custom GenomePaint track, must have the \"svcnv\" file. FPKM and VCF files are optional. URL format: ?svcnvfpkmurl=[track_name],svcnv,[URL to svcnv.gz file],fpkm,[URL to fpkm.gz file],vcf,[URL to vcf.gz file] mds \u00b6 Manuscript in prep... Launches an official GenomePaint track. URL format: ?mds=[dataset_label],[query_key] study \u00b6 Loads a study using the JSON file location. URL format: ?study=path/to/mystudy.json On PP server, the corresponding file is /path/to/mystudy.json View this tutorial on how to organize data into a study .","title":"URL Parameters"},{"location":"guides/proteinpaint/developers-guide/url-parameters/#gene","text":"Generates view for a gene. Example: https://proteinpaint.stjude.org/?genome=hg19&gene=ALK&dataset=clinvar Display a gene by given name. Value can be gene symbol or isoform accession, value is case-insensitive Requires \" genome \" Optionally, specify built-in datasets using parameter \" dataset \": If more than 1, join by comma Dataset must be hosted on the PP server Value is case-insensitive Example to load the \"Pediatric\" dataset: https://proteinpaint.stjude.org/?genome=hg19&gene=ALK&dataset=pediatric When using datasets, highlight certain mutations matching with given name Effect: any groups of mutation showing a match with the given name will be shown as expanded. All the rest of groups are folded. This feature is only intended for point mutation AA change name. The provided name must exactly match with the content in the DB or VCF file Example: https://proteinpaint.stjude.org/?genome=hg19&gene=ALK&dataset=pediatric&hlaachange=G574R,F1174L All types of custom track parameters can be used as well, as defined in the \"block\" section below.","title":"\"gene\""},{"location":"guides/proteinpaint/developers-guide/url-parameters/#block","text":"Launches a genome browser. Example: https://proteinpaint.stjude.org/?block=on&genome=hg19&position=chr17:7568451-7591984&bigwigurl=UCSC_phyloP,http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phyloP100way/hg19.100way.phyloP100way.bw","title":"block"},{"location":"guides/proteinpaint/developers-guide/url-parameters/#genome","text":"Required. Provides reference genome name.","title":"genome"},{"location":"guides/proteinpaint/developers-guide/url-parameters/#genomic-regions","text":"Optional. Specify genomic regions.","title":"Genomic regions"},{"location":"guides/proteinpaint/developers-guide/url-parameters/#position","text":"Coordinates are 0-based, example ?block=on&genome=hg19&position=chr1:1234-5678","title":"position"},{"location":"guides/proteinpaint/developers-guide/url-parameters/#regions","text":"Using \" regions \" to join more than 1 region by comma ?block=on&genome=hg19&regions=chr1:111-222,chr2:333-444 There is a bug of incorrect genomic ruler rendering when providing multiple regions.","title":"regions"},{"location":"guides/proteinpaint/developers-guide/url-parameters/#hlregion","text":"Optional. Provide one or more regions to highlight. Each region is in the format of \"chr:start-stop\". Do not use commas in start or stop positions. Join multiple regions by comma. There is a bug that it will highlight regions that are outside of view range.","title":"hlregion"},{"location":"guides/proteinpaint/developers-guide/url-parameters/#tracks","text":"Optional. There is no parameter called \"tracks\", but many different parameters to provide different types of tracks.","title":"Tracks"},{"location":"guides/proteinpaint/developers-guide/url-parameters/#bigwigfile","text":"","title":"bigwigfile"},{"location":"guides/proteinpaint/developers-guide/url-parameters/#bigwigurl","text":"To provide \"bigWig\" tracks. Learn how to generate a bigWig file Provide one or more bigwig tracks, each in the form of \"name,path-or-url\", all joined by comma. When using file, the files are hosted in the directory of the ProteinPaint server Example ?bigwigfile=[name1],[path/to/file1.bw],[name2],[path/to/file2.bw],.... ?bigwigurl=[name1],[url1],[name2],[url2] Note that this method won't allow setting Y scale or other configurations","title":"bigwigurl"},{"location":"guides/proteinpaint/developers-guide/url-parameters/#vcffile","text":"","title":"vcffile"},{"location":"guides/proteinpaint/developers-guide/url-parameters/#vcfurl","text":"Provide one or more VCF tracks. Requires VCF 4.2 format . Each in the form of \"name,path-or-url\", all joined by comma. URL format: ?vcffile=[name1],[path/to/file1],... ?vcfurl=[name1],[path/to/url1],... Example:","title":"vcfurl"},{"location":"guides/proteinpaint/developers-guide/url-parameters/#junctionfile","text":"","title":"junctionfile"},{"location":"guides/proteinpaint/developers-guide/url-parameters/#junctionurl","text":"Provide one or more junction tracks, see junction file format . Each in the form of \"name,path-or-url\", all joined by comma. URL format: ?junctionfile=[name1],[path/to/file1.gz],[name2],[path/to/file2.gz],.... Note that this method won't allow configuring the junction type.","title":"junctionurl"},{"location":"guides/proteinpaint/developers-guide/url-parameters/#mdsjunctionfile","text":"\"MDS junction\" track is the v2.0 of the junction track, work-in-progress. This parameter will provide one or more tracks, the file of which are hosted on the ProteinPaint server. URL format: ?mdsjunctionfile=[name1],[path/to/file1.gz],[name2],[path/to/file2.gz],....","title":"mdsjunctionfile"},{"location":"guides/proteinpaint/developers-guide/url-parameters/#bedjfile","text":"","title":"bedjfile"},{"location":"guides/proteinpaint/developers-guide/url-parameters/#bedjurl","text":"Provide one or more JSON-BED tracks, see JSON-BED file format . Each in the form of \"name,path-or-url\", all joined by comma.","title":"bedjurl"},{"location":"guides/proteinpaint/developers-guide/url-parameters/#bampilefile","text":"bampile file format ?bampilefile=[name1],[path/to/file1.gz],[name2],[path/to/file2.gz],...","title":"bampilefile"},{"location":"guides/proteinpaint/developers-guide/url-parameters/#aicheckfile","text":"aicheck file format ?aicheckfile=[name1],[path/to/file1.gz],[name2],[path/to/file2.gz],...","title":"aicheckfile"},{"location":"guides/proteinpaint/developers-guide/url-parameters/#svcnvfpkmurl","text":"","title":"svcnvfpkmurl"},{"location":"guides/proteinpaint/developers-guide/url-parameters/#svcnvfpkmfile","text":"Manuscript in prep... will add user tutorial later. Submits a custom GenomePaint track, must have the \"svcnv\" file. FPKM and VCF files are optional. URL format: ?svcnvfpkmurl=[track_name],svcnv,[URL to svcnv.gz file],fpkm,[URL to fpkm.gz file],vcf,[URL to vcf.gz file]","title":"svcnvfpkmfile"},{"location":"guides/proteinpaint/developers-guide/url-parameters/#mds","text":"Manuscript in prep... Launches an official GenomePaint track. URL format: ?mds=[dataset_label],[query_key]","title":"mds"},{"location":"guides/proteinpaint/developers-guide/url-parameters/#study","text":"Loads a study using the JSON file location. URL format: ?study=path/to/mystudy.json On PP server, the corresponding file is /path/to/mystudy.json View this tutorial on how to organize data into a study .","title":"study"},{"location":"guides/proteinpaint/file-formats/bampile/","text":"\"Bampile\" track \u00b6 File format \u00b6 The file has 3 columns: Chromosome name Basepair position, 0-based JSON object, e.g. {\"Raw_0\":{\"A\":8,\"C\":11,\"G\":5,\"T\":4050},\"Raw_30\":{\"A\":4,\"C\":7,\"G\":4,\"T\":3966},\"Raw_35\":{\"A\":3,\"C\":7,\"G\":3,\"T\":3771},\"Raw_38\":{\"A\":1,\"C\":5,\"G\":3,\"T\":3334},\"New_0\":{\"C\":4,\"T\":2652},\"New_30\":{\"C\":4,\"T\":2633},\"New_35\":{\"C\":4,\"T\":2598},\"New_38\":{\"C\":2,\"T\":2382}} Keys are various grades For each grade, read depth for each observed nucleotide is given in an object Prepare a track \u00b6 To prepare bampile track file from Xiaotu's output in St. Jude internal system: Node.js v6.0 and above is required. Linux binaries are available at https://nodejs.org/dist/v6.9.1/node-v6.9.1-linux-x64.tar.xz (Do not load Node.js using \"module load\", that's outdated) module load tabix cd /research/dept/compbio/common/proteinpaint-dev/tp/ultra node bampileparse.js SAMPLE.input.txt > tempfile sort -k1,1 -k2,2n tempfile > SAMPLE bgzip SAMPLE tabix -b 2 -e 2 -s 1 SAMPLE.gz This generates two files under \"tp/ultra/\" directory: - SAMPLE.gz - SAMPLE.gz.tbi Link the file to ProteinPaint by URL for display: http://proteinpaint-dev.stjude.org:3001/?block=on&genome= hg19 &position=chr13:48941549-48941948&bampilefile= SAMPLE,ultra/SAMPLE.gz In the URL parameter, set correct genome build version, initial display position, and name and path to the SAMPLE.gz file. - File path should start from but do not contain \"tp/\". - Name and path is joined by comma.","title":"Bampile"},{"location":"guides/proteinpaint/file-formats/bampile/#bampile-track","text":"","title":"\"Bampile\" track"},{"location":"guides/proteinpaint/file-formats/bampile/#file-format","text":"The file has 3 columns: Chromosome name Basepair position, 0-based JSON object, e.g. {\"Raw_0\":{\"A\":8,\"C\":11,\"G\":5,\"T\":4050},\"Raw_30\":{\"A\":4,\"C\":7,\"G\":4,\"T\":3966},\"Raw_35\":{\"A\":3,\"C\":7,\"G\":3,\"T\":3771},\"Raw_38\":{\"A\":1,\"C\":5,\"G\":3,\"T\":3334},\"New_0\":{\"C\":4,\"T\":2652},\"New_30\":{\"C\":4,\"T\":2633},\"New_35\":{\"C\":4,\"T\":2598},\"New_38\":{\"C\":2,\"T\":2382}} Keys are various grades For each grade, read depth for each observed nucleotide is given in an object","title":"File format"},{"location":"guides/proteinpaint/file-formats/bampile/#prepare-a-track","text":"To prepare bampile track file from Xiaotu's output in St. Jude internal system: Node.js v6.0 and above is required. Linux binaries are available at https://nodejs.org/dist/v6.9.1/node-v6.9.1-linux-x64.tar.xz (Do not load Node.js using \"module load\", that's outdated) module load tabix cd /research/dept/compbio/common/proteinpaint-dev/tp/ultra node bampileparse.js SAMPLE.input.txt > tempfile sort -k1,1 -k2,2n tempfile > SAMPLE bgzip SAMPLE tabix -b 2 -e 2 -s 1 SAMPLE.gz This generates two files under \"tp/ultra/\" directory: - SAMPLE.gz - SAMPLE.gz.tbi Link the file to ProteinPaint by URL for display: http://proteinpaint-dev.stjude.org:3001/?block=on&genome= hg19 &position=chr13:48941549-48941948&bampilefile= SAMPLE,ultra/SAMPLE.gz In the URL parameter, set correct genome build version, initial display position, and name and path to the SAMPLE.gz file. - File path should start from but do not contain \"tp/\". - Name and path is joined by comma.","title":"Prepare a track"},{"location":"guides/proteinpaint/file-formats/cnv/","text":"CNV format This format only works for gene-level CNV data. First line must be the header with following columns: Gene The gene name Cnv Allowed values: Amplification Gain Deletion loss Following columns are optional: Sample Patient Sampletype Disease Lines starting with '#' will be ignored.","title":"Copy Number Variants"},{"location":"guides/proteinpaint/file-formats/intragenic-deletion/","text":"Intragenic deletion First line must be the header line, with following columns. Separate columns by tab. Order of columns does not matter. gene Gene symbol. isoform RefSeq/Ensembl accession of the isoform. rnaPosition optional. RNA nucleotide position of the 5' end of the deleted region on the gene transcript, relative to transcription start site. 1-based. rnaDellength RNA nucleotide length of the deleted region, required if \"rnaPosition\" is used. chr Chromosome name, optional chr_start Start genomic position, required if \"chr\" is used. chr_stop Stop genomic position, required if \"chr\" is used. Other optional columns: Patient Sample Sampletype disease Data lines starting with \"#\" will be ignored.","title":"Intragenic deletion"},{"location":"guides/proteinpaint/file-formats/itd/","text":"ITD: internal tandem duplication First line must be the header line, with following columns. Order of columns does not matter. gene Gene symbol. isoform RefSeq/Ensembl accession of the isoform. rnaPosition optional RNA nucleotide position of the 5' end of the duplicated region on the gene transcript, relative to transcription start site. 1-based. rnaDuplength RNA nucleotide length of the duplicated region, required if rnaPosition is used. chr Chromosome name, optional chr_start Start genomic position, required if \"chr\" is used. Chr_stop Stop genomic position, required if \"chr\" is used. Other optional columns: Patient Sample Sampletype disease Data lines starting with \"#\" will be ignored.","title":"Internal tandem duplications"},{"location":"guides/proteinpaint/file-formats/json-bed/","text":"JSON-BED track format Todo example File format \u00b6 There are 4 columns, separated by tab : 1. Chromosome 2. Start position (0-based) 3. Stop position (not including the ending base) 4. JSON string Each line is a genomic feature. The feature can be richly described in the JSON string. Prepare and use a track \u00b6 sort -k1,1 -k2,2n [file] > [file.sorted] mv [file.sorted] [file] bgzip [file] tabix -p bed [file].gz To host the track on a web server: put both .gz and .gz.tbi files at the same directory on the web server. Obtain the URL to the .gz file and submit it to the browser. To host the track on ProteinPaint server: put both .gz and .gz.tbi files at the same directory under the directory. Obtain the relative path to the .gz file and submit it to browser. JSON object for a BED item \u00b6 The content is a string representation of an object (key-value pairs). Examples: { \"name\" : \"CTCF1\" , \"strand\" : \"+\" } { \"name\" : \"MIR6859-1\" , \"isoform\" : \"NR_106918\" , \"strand\" : \"-\" , \"exon\" : [[ 17368 , 17436 ]], \"rnalen\" : 68 } Format requirements: - No line breaks in the JSON text - Must include braces {} - Use double quotes for strings - Don't use quotes for numerical values - Keys are case-sensitive - Following names cannot be used as keys and will be ignored: - chr - start - stop - canvas See full JSON spec at http://json.org/ \"name\": STR \u00b6 Value is a string. For genes, \"name\" is gene symbol. When \" itemurl_appendname \" is specified, \"name\" is required to enable clicking on an item from track display and trigger a URL . \"isoform\": STR \u00b6 Gene isoform accession, e.g. NM_000546 or ENST00000269305 Both name and isoform can appear in the tooltip when hovering cursor over the track display. \"strand\": STR \u00b6 \"+\" or \"-\". Unstranded if not provided. \"exon\":[] \u00b6 Array of two-number arrays, e.g. [[665562,665731],[665277,665335],[661138,665184]]. Must be present for genes. All positions are 0-based. The stop position of an exon is the nucleotide next to the last exonic nucleotide, similar to the UCSC BED format. For coding genes: For coding genes: Value should be a union of UTRs and CDS. For noncoding genes: Value should be all exons. Despite there are already \"utr5\", \"utr3\", \"coding\", \"intron\" attributes, the \"exon\" attribute is still required. \"intron\":[] \u00b6 Same format as \"exon\". Required for native gene tracks. The stop position of an intron is the first nucleotide in the exon. \"utr5\":[] \u00b6 Same format as \"exon\". Required for any 5' UTRs in coding genes. \"utr3\":[] \u00b6 Same format as \"exon\". Required for any 3' UTRs in coding genes. \"rnalen\": INT \u00b6 Base-pair length of RNA transcript. Required for all genes. \"cdslen\": INT \u00b6 Base-pair length of coding region length of an mRNA transcript. Required for coding gene. Do not use for noncoding gene. \"codingstart\": INT \u00b6 Genomic position of the smaller boundary of the coding sequence. Required for coding gene. Do not use for noncoding gene. \"codingstop\": INT \u00b6 Genomic position of the bigger boundary of the coding sequence. Required for coding gene. \"coding\":[] \u00b6 Same as \"exon\", for coding exons only. Set \"translatecoding\" to true in the track object to enable gene translation according to the coding exons as well as coding frame defined by the \"coding:[]\" attribute. The translation can happen when the browser is at sufficient resolution. \"description\": STR \u00b6 Some text, e.g. gene function. \"color\": STR \u00b6 Rendering color of this item. Use follow color names: Names such as \"red\" \"green\" listed in https://en.wikipedia.org/wiki/Web_colors FF0000 rgb(255,0,0) \"category\": STR \u00b6 Value is string or integer. Value must be a key of the \"categories\" attribute of the track object. Declaring a track as a JSON object \u00b6 { \"type\" : \"bedj\" , \"name\" : \"gene track\" , \"file\" : \"anno/gencode.v24.hg19.gz\" , \"stackheight\" : 14 , \"stackspace\" : 1 } stackheight :20 Height of rows in number of pixels. All rows share the same height. For gene tracks, this height will be the thickness of coding exons, while UTRs and noncoding exons will have height reduced by 4 pixels. stackspace :1 Spacing distance between rows. color :\"blue\" Track rendering color for lines, boxes, and text labels. Per-item color defined in the track file will override this setting. onerow :true Value is \"1\" for true. Forces all items in the view range to be displayed in the same row, and item names will be hidden. Useful for making compact representation of certain tracks, e.g. chromHMM. Delete this attribute to cancel the effect. categories :{} List of categories, each item in the track will belong to one category and will be colored accordingly {\"1\":{\"color\":\"red\",\"label\":\"type 1\"}, \"2\":{\"color\":\"blue\",\"label\":\"type 2\"}, ... } translatecoding :1 Will translate genes when the resolution is fine enough. This requires the .coding[] attribute in the JSON objects of BED items. itemurl_appendname : URL Allows clicking on an item from the track and open up a URL customized by the name of that item; item's name will be appended to the end of the URL as the value of a parameter. Example: given URL of \"[ http://google.com?query=]{.underline}](http://google.com?query= )\". When clicked on an item named \"HOX\", this URL will be triggered: [ http://google.com?query=HOX","title":"JSON-BED"},{"location":"guides/proteinpaint/file-formats/json-bed/#file-format","text":"There are 4 columns, separated by tab : 1. Chromosome 2. Start position (0-based) 3. Stop position (not including the ending base) 4. JSON string Each line is a genomic feature. The feature can be richly described in the JSON string.","title":"File format"},{"location":"guides/proteinpaint/file-formats/json-bed/#prepare-and-use-a-track","text":"sort -k1,1 -k2,2n [file] > [file.sorted] mv [file.sorted] [file] bgzip [file] tabix -p bed [file].gz To host the track on a web server: put both .gz and .gz.tbi files at the same directory on the web server. Obtain the URL to the .gz file and submit it to the browser. To host the track on ProteinPaint server: put both .gz and .gz.tbi files at the same directory under the directory. Obtain the relative path to the .gz file and submit it to browser.","title":"Prepare and use a track"},{"location":"guides/proteinpaint/file-formats/json-bed/#json-object-for-a-bed-item","text":"The content is a string representation of an object (key-value pairs). Examples: { \"name\" : \"CTCF1\" , \"strand\" : \"+\" } { \"name\" : \"MIR6859-1\" , \"isoform\" : \"NR_106918\" , \"strand\" : \"-\" , \"exon\" : [[ 17368 , 17436 ]], \"rnalen\" : 68 } Format requirements: - No line breaks in the JSON text - Must include braces {} - Use double quotes for strings - Don't use quotes for numerical values - Keys are case-sensitive - Following names cannot be used as keys and will be ignored: - chr - start - stop - canvas See full JSON spec at http://json.org/","title":"JSON object for a BED item"},{"location":"guides/proteinpaint/file-formats/json-bed/#name-str","text":"Value is a string. For genes, \"name\" is gene symbol. When \" itemurl_appendname \" is specified, \"name\" is required to enable clicking on an item from track display and trigger a URL .","title":"\"name\": STR"},{"location":"guides/proteinpaint/file-formats/json-bed/#isoform-str","text":"Gene isoform accession, e.g. NM_000546 or ENST00000269305 Both name and isoform can appear in the tooltip when hovering cursor over the track display.","title":"\"isoform\": STR"},{"location":"guides/proteinpaint/file-formats/json-bed/#strand-str","text":"\"+\" or \"-\". Unstranded if not provided.","title":"\"strand\": STR"},{"location":"guides/proteinpaint/file-formats/json-bed/#exon","text":"Array of two-number arrays, e.g. [[665562,665731],[665277,665335],[661138,665184]]. Must be present for genes. All positions are 0-based. The stop position of an exon is the nucleotide next to the last exonic nucleotide, similar to the UCSC BED format. For coding genes: For coding genes: Value should be a union of UTRs and CDS. For noncoding genes: Value should be all exons. Despite there are already \"utr5\", \"utr3\", \"coding\", \"intron\" attributes, the \"exon\" attribute is still required.","title":"\"exon\":[]"},{"location":"guides/proteinpaint/file-formats/json-bed/#intron","text":"Same format as \"exon\". Required for native gene tracks. The stop position of an intron is the first nucleotide in the exon.","title":"\"intron\":[]"},{"location":"guides/proteinpaint/file-formats/json-bed/#utr5","text":"Same format as \"exon\". Required for any 5' UTRs in coding genes.","title":"\"utr5\":[]"},{"location":"guides/proteinpaint/file-formats/json-bed/#utr3","text":"Same format as \"exon\". Required for any 3' UTRs in coding genes.","title":"\"utr3\":[]"},{"location":"guides/proteinpaint/file-formats/json-bed/#rnalen-int","text":"Base-pair length of RNA transcript. Required for all genes.","title":"\"rnalen\": INT"},{"location":"guides/proteinpaint/file-formats/json-bed/#cdslen-int","text":"Base-pair length of coding region length of an mRNA transcript. Required for coding gene. Do not use for noncoding gene.","title":"\"cdslen\": INT"},{"location":"guides/proteinpaint/file-formats/json-bed/#codingstart-int","text":"Genomic position of the smaller boundary of the coding sequence. Required for coding gene. Do not use for noncoding gene.","title":"\"codingstart\": INT"},{"location":"guides/proteinpaint/file-formats/json-bed/#codingstop-int","text":"Genomic position of the bigger boundary of the coding sequence. Required for coding gene.","title":"\"codingstop\": INT"},{"location":"guides/proteinpaint/file-formats/json-bed/#coding","text":"Same as \"exon\", for coding exons only. Set \"translatecoding\" to true in the track object to enable gene translation according to the coding exons as well as coding frame defined by the \"coding:[]\" attribute. The translation can happen when the browser is at sufficient resolution.","title":"\"coding\":[]"},{"location":"guides/proteinpaint/file-formats/json-bed/#description-str","text":"Some text, e.g. gene function.","title":"\"description\": STR"},{"location":"guides/proteinpaint/file-formats/json-bed/#color-str","text":"Rendering color of this item. Use follow color names: Names such as \"red\" \"green\" listed in https://en.wikipedia.org/wiki/Web_colors","title":"\"color\": STR"},{"location":"guides/proteinpaint/file-formats/json-bed/#category-str","text":"Value is string or integer. Value must be a key of the \"categories\" attribute of the track object.","title":"\"category\": STR"},{"location":"guides/proteinpaint/file-formats/json-bed/#declaring-a-track-as-a-json-object","text":"{ \"type\" : \"bedj\" , \"name\" : \"gene track\" , \"file\" : \"anno/gencode.v24.hg19.gz\" , \"stackheight\" : 14 , \"stackspace\" : 1 } stackheight :20 Height of rows in number of pixels. All rows share the same height. For gene tracks, this height will be the thickness of coding exons, while UTRs and noncoding exons will have height reduced by 4 pixels. stackspace :1 Spacing distance between rows. color :\"blue\" Track rendering color for lines, boxes, and text labels. Per-item color defined in the track file will override this setting. onerow :true Value is \"1\" for true. Forces all items in the view range to be displayed in the same row, and item names will be hidden. Useful for making compact representation of certain tracks, e.g. chromHMM. Delete this attribute to cancel the effect. categories :{} List of categories, each item in the track will belong to one category and will be colored accordingly {\"1\":{\"color\":\"red\",\"label\":\"type 1\"}, \"2\":{\"color\":\"blue\",\"label\":\"type 2\"}, ... } translatecoding :1 Will translate genes when the resolution is fine enough. This requires the .coding[] attribute in the JSON objects of BED items. itemurl_appendname : URL Allows clicking on an item from the track and open up a URL customized by the name of that item; item's name will be appended to the end of the URL as the value of a parameter. Example: given URL of \"[ http://google.com?query=]{.underline}](http://google.com?query= )\". When clicked on an item named \"HOX\", this URL will be triggered: [ http://google.com?query=HOX","title":"Declaring a track as a JSON object"},{"location":"guides/proteinpaint/file-formats/pgv/","text":"The Profile-Gene-Value track (PGV) The PGV track is a combination of genomic profiling results and gene-level numerical values over a set of samples. Here is a screenshot of chromatin states and the expression level for one gene over a set of samples. A live example: https://pecan.stjude.org/proteinpaint/study/retina2017 Gene-value track \u00b6 Example lines from a gene-value track: chr1 3205900 3671498 { \"sample\" : \"sample1\" , \"value\" : 1.83479 , \"gene\" : \"Gm37363\" } chr1 3205900 3671498 { \"sample\" : \"sample1\" , \"value\" : 1.87122 , \"gene\" : \"Gm37180\" } chr1 3205900 3671498 { \"sample\" : \"sample2\" , \"value\" : 2.10581 , \"gene\" : \"Gm37329\" } chr1 3205900 3671498 { \"sample\" : \"sample3\" , \"value\" : 3.21379 , \"gene\" : \"Gm19938\" } The file has four columns: 1. Chromosome name 2. Start position of the gene (feature), 0-based 3. Stop position of the gene (feature), 0-based 4. JSON object a. Required keys: i. \" sample \":STR ii. \" gene \": STR iii. \" value \": FLOAT 1. Currently, only nonnegative values are supported b. The chromosomal position should match with the gene. It's totally okay to describe other type of genomic features rather than genes, but the \"gene\" key should still be used for the moment. Each line represents a numerical value for a gene in a sample. The gene chromosome positions are for indexing purpose. The gene-value track should be compressed and indexed, and hosted in the same way as the JSON-BED track . Track format with single type of gene-value \u00b6 This format is suitable for just one type of gene-value in PGV track, e.g. expression. Example: { \"type\" : \"profilegenevalue\" , \"genevaluetrack\" : { \"file\" : \"rhb/fpkm.db\" }, \"genevaluetype\" : \"FPKM\" , \"genevaluematchname\" : \"sampleID\" , \"legendimg\" : { \"file\" : \"rhb/chromhmm.png\" , }, \"name\" : \"RHB chromHMM\" , \"tracks\" : [ { \"type\" : \"bedj\" , \"file\" : \"rhb/fq21.gz\" , \"stackheight\" : 20 , \"stackspace\" : 1 , \"name\" : \"sample1\" , \"sampleID\" : \"sample1\" }, { \"type\" : \"bigwig\" , \"file\" : \"path/to/file.bw\" , \"height\" : 20 , \"name\" : \"sample2\" , \"sampleID\" : \"sample2\" , \"scale\" : { \"auto\" : 1 }, \"pcolor\" : \"blue\" }, ... more member tracks ... ] } genevaluetrack A JSON-BED file that stores numerical data per gene per sample . When the file is stored on the ProteinPaint server, use \"file\" to provide path. Otherwise, provide the URL with the \"url\" keyword. The file follows JSON-BED format and needs to be compressed by bgzip and indexed by tabix. Each line stores one numerical value for one gene in one sample. The JSON part should be an object with following attributes: gene the name of gene sample the name of sample, should match one of the member tracks (but not required to be so) value the numerical value genevaluetype The type of the gene value, e.g. \"FPKM\", will be displayed on the track genevaluematchname Optional. If not provided: The \"name\" of each member track will be used for sample name matching with the \"genevaluetrack\" If provided: Value can be arbitrary string, and will be an attribute for member tracks E.g. \"genevaluematchname\":\"sampleID\", then the \"sampleID\" attribute should exist for member tracks, and the value of \"sampleID\" of each track will be used for sample name matching legendimg File Relative path to an PNG image as the legend of this track. E.g. a state-by-assay heatmap for the case of chromHMM tracks. Image URL is not supported yet. The image will be displayed in the LEGEND section at the bottom. tracks : [ ] An array of member tracks Each member track is one JSON object, which must be properly defined according to its type. Supported types are: JSON-BED bigWig Each member track must have the \"name\" attribute, the name value must be unique Track format for multiple types of gene values \u00b6 This format should be used for multiple types of gene values in a PGV track, e.g. RNA expression + proteomics. Notably, this format uses \"genevaluetklst\" to store a set of gene value tracks. Thus it's also able to replace the single-track format discussed above. { \"type\" : \"profilegenevalue\" , \"name\" : \"RHB chromHMM\" , \"genevaluetklst\" : [ { \"file\" : \"path/to/fpkm_file.gz\" , \"name\" : \"Gene FPKM\" , \"matchname\" : \"RNAsampleID\" , }, { \"file\" : \"path/to/proteomics_file.gz\" , \"name\" : \"Proteomics\" , \"matchname\" : \"PROTEINsampleID\" , } }, \"tracks\" : [ ... member tracks ... ] } Track format for having multiple types of data points in one of the gene-value track \u00b6 With application for protein phosphorylation. In such case the value types will be specific to genes. May also support fixed set of types. { \"type\" : \"profilegenevalue\" , \"name\" : \"RHB chromHMM\" , \"genevaluetklst\" : [ { \"file\" : \"path/to/phosphorylation.gz\" , \"name\" : \"phosphorylation\" , \"multivaluekey\" : \"site\" , \"axistickformat\" : \".0e\" , } }, \"tracks\" : [ ... member tracks ... ] } Example rows of the phosphorylation data file: chr1 879582 894689 {\"sample\":\"MAST 118\",\"value\":149697.325,\"gene\":\"NOC2L\",\"site\":\"S56\"} chr1 879582 894689 {\"sample\":\"MAST 118\",\"value\":3463144.33,\"gene\":\"NOC2L\",\"site\":\"S673\"} chr1 879582 894689 {\"sample\":\"MAST 118\",\"value\":4299136.975,\"gene\":\"NOC2L\",\"site\":\"S672\"} chr1 879582 894689 {\"sample\":\"MAST 118\",\"value\":86552.805,\"gene\":\"NOC2L\",\"site\":\"S49\"} chr1 879582 894689 {\"sample\":\"MAST 35\",\"value\":106901.32,\"gene\":\"NOC2L\",\"site\":\"S56\"} In such phosphorylation data, each row represents the phosphorylation value for one specific amino acid residue (denoted by the \"site\" key), in one gene, of one sample. Note that the genomic coordinates are of genes.","title":"Profile-Gene-Value"},{"location":"guides/proteinpaint/file-formats/pgv/#gene-value-track","text":"Example lines from a gene-value track: chr1 3205900 3671498 { \"sample\" : \"sample1\" , \"value\" : 1.83479 , \"gene\" : \"Gm37363\" } chr1 3205900 3671498 { \"sample\" : \"sample1\" , \"value\" : 1.87122 , \"gene\" : \"Gm37180\" } chr1 3205900 3671498 { \"sample\" : \"sample2\" , \"value\" : 2.10581 , \"gene\" : \"Gm37329\" } chr1 3205900 3671498 { \"sample\" : \"sample3\" , \"value\" : 3.21379 , \"gene\" : \"Gm19938\" } The file has four columns: 1. Chromosome name 2. Start position of the gene (feature), 0-based 3. Stop position of the gene (feature), 0-based 4. JSON object a. Required keys: i. \" sample \":STR ii. \" gene \": STR iii. \" value \": FLOAT 1. Currently, only nonnegative values are supported b. The chromosomal position should match with the gene. It's totally okay to describe other type of genomic features rather than genes, but the \"gene\" key should still be used for the moment. Each line represents a numerical value for a gene in a sample. The gene chromosome positions are for indexing purpose. The gene-value track should be compressed and indexed, and hosted in the same way as the JSON-BED track .","title":"Gene-value track"},{"location":"guides/proteinpaint/file-formats/pgv/#track-format-with-single-type-of-gene-value","text":"This format is suitable for just one type of gene-value in PGV track, e.g. expression. Example: { \"type\" : \"profilegenevalue\" , \"genevaluetrack\" : { \"file\" : \"rhb/fpkm.db\" }, \"genevaluetype\" : \"FPKM\" , \"genevaluematchname\" : \"sampleID\" , \"legendimg\" : { \"file\" : \"rhb/chromhmm.png\" , }, \"name\" : \"RHB chromHMM\" , \"tracks\" : [ { \"type\" : \"bedj\" , \"file\" : \"rhb/fq21.gz\" , \"stackheight\" : 20 , \"stackspace\" : 1 , \"name\" : \"sample1\" , \"sampleID\" : \"sample1\" }, { \"type\" : \"bigwig\" , \"file\" : \"path/to/file.bw\" , \"height\" : 20 , \"name\" : \"sample2\" , \"sampleID\" : \"sample2\" , \"scale\" : { \"auto\" : 1 }, \"pcolor\" : \"blue\" }, ... more member tracks ... ] } genevaluetrack A JSON-BED file that stores numerical data per gene per sample . When the file is stored on the ProteinPaint server, use \"file\" to provide path. Otherwise, provide the URL with the \"url\" keyword. The file follows JSON-BED format and needs to be compressed by bgzip and indexed by tabix. Each line stores one numerical value for one gene in one sample. The JSON part should be an object with following attributes: gene the name of gene sample the name of sample, should match one of the member tracks (but not required to be so) value the numerical value genevaluetype The type of the gene value, e.g. \"FPKM\", will be displayed on the track genevaluematchname Optional. If not provided: The \"name\" of each member track will be used for sample name matching with the \"genevaluetrack\" If provided: Value can be arbitrary string, and will be an attribute for member tracks E.g. \"genevaluematchname\":\"sampleID\", then the \"sampleID\" attribute should exist for member tracks, and the value of \"sampleID\" of each track will be used for sample name matching legendimg File Relative path to an PNG image as the legend of this track. E.g. a state-by-assay heatmap for the case of chromHMM tracks. Image URL is not supported yet. The image will be displayed in the LEGEND section at the bottom. tracks : [ ] An array of member tracks Each member track is one JSON object, which must be properly defined according to its type. Supported types are: JSON-BED bigWig Each member track must have the \"name\" attribute, the name value must be unique","title":"Track format with single type of gene-value"},{"location":"guides/proteinpaint/file-formats/pgv/#track-format-for-multiple-types-of-gene-values","text":"This format should be used for multiple types of gene values in a PGV track, e.g. RNA expression + proteomics. Notably, this format uses \"genevaluetklst\" to store a set of gene value tracks. Thus it's also able to replace the single-track format discussed above. { \"type\" : \"profilegenevalue\" , \"name\" : \"RHB chromHMM\" , \"genevaluetklst\" : [ { \"file\" : \"path/to/fpkm_file.gz\" , \"name\" : \"Gene FPKM\" , \"matchname\" : \"RNAsampleID\" , }, { \"file\" : \"path/to/proteomics_file.gz\" , \"name\" : \"Proteomics\" , \"matchname\" : \"PROTEINsampleID\" , } }, \"tracks\" : [ ... member tracks ... ] }","title":"Track format for multiple types of gene values"},{"location":"guides/proteinpaint/file-formats/pgv/#track-format-for-having-multiple-types-of-data-points-in-one-of-the-gene-value-track","text":"With application for protein phosphorylation. In such case the value types will be specific to genes. May also support fixed set of types. { \"type\" : \"profilegenevalue\" , \"name\" : \"RHB chromHMM\" , \"genevaluetklst\" : [ { \"file\" : \"path/to/phosphorylation.gz\" , \"name\" : \"phosphorylation\" , \"multivaluekey\" : \"site\" , \"axistickformat\" : \".0e\" , } }, \"tracks\" : [ ... member tracks ... ] } Example rows of the phosphorylation data file: chr1 879582 894689 {\"sample\":\"MAST 118\",\"value\":149697.325,\"gene\":\"NOC2L\",\"site\":\"S56\"} chr1 879582 894689 {\"sample\":\"MAST 118\",\"value\":3463144.33,\"gene\":\"NOC2L\",\"site\":\"S673\"} chr1 879582 894689 {\"sample\":\"MAST 118\",\"value\":4299136.975,\"gene\":\"NOC2L\",\"site\":\"S672\"} chr1 879582 894689 {\"sample\":\"MAST 118\",\"value\":86552.805,\"gene\":\"NOC2L\",\"site\":\"S49\"} chr1 879582 894689 {\"sample\":\"MAST 35\",\"value\":106901.32,\"gene\":\"NOC2L\",\"site\":\"S56\"} In such phosphorylation data, each row represents the phosphorylation value for one specific amino acid residue (denoted by the \"site\" key), in one gene, of one sample. Note that the genomic coordinates are of genes.","title":"Track format for having multiple types of data points in one of the gene-value track"},{"location":"guides/proteinpaint/file-formats/snv-and-indel/","text":"SNV/Indel Data Format File uploading procedure \u00b6 See the uploading procedure here. General notes \u00b6 Input file is a tabular text file, with specified columns described below. First line must be the header line. Order of columns does not matter. Extra columns are allowed and can be viewed in mutation table. Lines starting with \"#\" are ignored. Patient name and sample types are case sensitive. Please keep them consistent. Required columns \u00b6 gene The gene symbol, e.g. \"TP53\" refseq The RefSeq accession of the gene isoform, e.g. \"NM_000546\" (but not version name NM_000546.5) chromosome Can be either \"chr1\" or \"1\", case-insensitive start Genomic coordinate, 1-based aachange A string describing the amino acid change caused by the mutation, can be any string, will be displayed as-is as the label on the right of the discs class Mutation class about the amino acid change, will allow ProteinPaint to render the mutation using predefined colors. Names of supported classes: missense nonsense representing stoploss, nonstop, and stopgain frameshift silent proteinDel in-frame deletion proteinIns in-frame insertion splice splice_region utr_3 utr_5 intron noncoding. Optional columns describing samples \u00b6 disease Name of the disease, if provided, the disease listing will be available upon loading the file origin The variant origin, supported values are listed below, case insensitive: somatic germline relapse germline pathogenic germline non-pathogenic patient Name of patient, required if sample type is specified. sample Sample name. sampletype A special field for distinguish multiple samples of the same patient or individual, e.g. \"diagnosis\" or \"relapse\". Not to be confused with variant origin. If sampletype is specified, patient name should be provided, so that multiple samples from the same patient can be correctly identified. In this case, sample name becomes optional. When not provided, ProteinPaint will combine patient name and sample type to get sample name. If provided, ProteinPaint requires that different samples from the same patient must have different sample names. Optional columns describing mutations \u00b6 mutant_in_tumor Number of reads with the mutant allele in tumor sample total_in_tumor Total number of reads in tumor sample over the mutation locus By providing \"mutant_in_tumor\" and \"total_in_tumor\", the \"maf-coverage\" plot can be generated. mutant_in_normal Number of reads with the mutant allele in normal sample total_in_normal Total number of reads in normal sample over the mutation locus REF Reference allele ALT Alternative allele VAF Variant fraction VCF format \u00b6 Please check out the VCF format if you want to submit the SNV/indel data in the form of a VCF track.","title":"SNV and Indel"},{"location":"guides/proteinpaint/file-formats/snv-and-indel/#file-uploading-procedure","text":"See the uploading procedure here.","title":"File uploading procedure"},{"location":"guides/proteinpaint/file-formats/snv-and-indel/#general-notes","text":"Input file is a tabular text file, with specified columns described below. First line must be the header line. Order of columns does not matter. Extra columns are allowed and can be viewed in mutation table. Lines starting with \"#\" are ignored. Patient name and sample types are case sensitive. Please keep them consistent.","title":"General notes"},{"location":"guides/proteinpaint/file-formats/snv-and-indel/#required-columns","text":"gene The gene symbol, e.g. \"TP53\" refseq The RefSeq accession of the gene isoform, e.g. \"NM_000546\" (but not version name NM_000546.5) chromosome Can be either \"chr1\" or \"1\", case-insensitive start Genomic coordinate, 1-based aachange A string describing the amino acid change caused by the mutation, can be any string, will be displayed as-is as the label on the right of the discs class Mutation class about the amino acid change, will allow ProteinPaint to render the mutation using predefined colors. Names of supported classes: missense nonsense representing stoploss, nonstop, and stopgain frameshift silent proteinDel in-frame deletion proteinIns in-frame insertion splice splice_region utr_3 utr_5 intron noncoding.","title":"Required columns"},{"location":"guides/proteinpaint/file-formats/snv-and-indel/#optional-columns-describing-samples","text":"disease Name of the disease, if provided, the disease listing will be available upon loading the file origin The variant origin, supported values are listed below, case insensitive: somatic germline relapse germline pathogenic germline non-pathogenic patient Name of patient, required if sample type is specified. sample Sample name. sampletype A special field for distinguish multiple samples of the same patient or individual, e.g. \"diagnosis\" or \"relapse\". Not to be confused with variant origin. If sampletype is specified, patient name should be provided, so that multiple samples from the same patient can be correctly identified. In this case, sample name becomes optional. When not provided, ProteinPaint will combine patient name and sample type to get sample name. If provided, ProteinPaint requires that different samples from the same patient must have different sample names.","title":"Optional columns describing samples"},{"location":"guides/proteinpaint/file-formats/snv-and-indel/#optional-columns-describing-mutations","text":"mutant_in_tumor Number of reads with the mutant allele in tumor sample total_in_tumor Total number of reads in tumor sample over the mutation locus By providing \"mutant_in_tumor\" and \"total_in_tumor\", the \"maf-coverage\" plot can be generated. mutant_in_normal Number of reads with the mutant allele in normal sample total_in_normal Total number of reads in normal sample over the mutation locus REF Reference allele ALT Alternative allele VAF Variant fraction","title":"Optional columns describing mutations"},{"location":"guides/proteinpaint/file-formats/snv-and-indel/#vcf-format","text":"Please check out the VCF format if you want to submit the SNV/indel data in the form of a VCF track.","title":"VCF format"},{"location":"guides/proteinpaint/file-formats/splice-junction/","text":"Splice junction with read count The track can be used to represent RNA splice junction data from RNA-seq assays. Each file can contain information for 1 or more samples. File format of single sample data \u00b6 The file has 6 required columns: Chromosome name, e.g. \"chr1\" Start, 0-based position of the last nucleotide of the upstream exon Stop, 0-based position of the first nucleotide of the downstream exon Strand, \u00b1 Type of junction, if not available, use empty string a. It can be arbitrary text value, e.g. \"known\" or \"novel\". Any used types should be stated in the .categories{} attribute of the track so they can be distinguished by color. Read count, integer value Steps to convert the tabular text file to a junction track \u00b6 sort -k1,1 -k2,2n textfile > textfile.sorted bgzip textfile.sorted tabix -p bed textfile.sorted.gz This generates two files: textfile.sorted.gz textfile.sorted.gz.tbi Put both files in the same directory on the server, and use the file path (or URL) to the .gz file for submitting. Refer to this document for declaring the junction track in JSON format . File format for multiple samples \u00b6 The first five columns are the same as single sample file. The 6 th column is the read count for the first sample, the 7 th column is the second sample, so that arbitrary number of samples can be represented in this way. Optionally, provide a header line to denote sample names, e.g.: #chr start stop strand type sample1 sample2 ... Header line must begin with \"#\". Bgzip this file in the same way. To index this file, run tabix with additional parameter: tabix -p bed -c \"#\" multisample.gz Sample names like \"sample1\" and \"sample2\" in the header of above example can be replaced by JSON object strings, as a way of encoding additional information on samples in the track file. {\"patient\":\"SJACT001\",\"sample\":\"SJACT001_D\",\"sampletype\":\"DIAGNOSIS\",\"diagnosis_group_short\":\"ST\",\"diagnosis_group_full\":\"Solid Tumor\",\"diagnosis_short\":\"ACT\",\"diagnosis_full\":\"Adrenocortical Carcinoma\",\"diagnosis_subtype_short\":\"TP53-mut\",\"diagnosis_subtype_full\":\"TP53-mut\"} {\"patient\":\"SJACT002\",\"sample\":\"SJACT002_D\",\"sampletype\":\"DIAGNOSIS\",\"diagnosis_group_short\":\"ST\",\"diagnosis_group_full\":\"Solid Tumor\",\"diagnosis_short\":\"ACT\",\"diagnosis_full\":\"Adrenocortical Carcinoma\",\"diagnosis_subtype_short\":\"TP53-mut\",\"diagnosis_subtype_full\":\"TP53-mut\"} This can allow plotting samples by different colors. To do so, add \"cohortsetting\" attribute to track object when using the embedding API: runproteinpaint ({ ... other parameters ... tracks : [ { type : 'junction' , name : 'track name' , file : 'path/to/file.gz' , cohortsetting : { uselevelidx : 0 , cohort : { levels : [ { k : 'diagnosis_group_short' , label : 'cancer' } ] } } } ], })","title":"Splice Junction"},{"location":"guides/proteinpaint/file-formats/splice-junction/#file-format-of-single-sample-data","text":"The file has 6 required columns: Chromosome name, e.g. \"chr1\" Start, 0-based position of the last nucleotide of the upstream exon Stop, 0-based position of the first nucleotide of the downstream exon Strand, \u00b1 Type of junction, if not available, use empty string a. It can be arbitrary text value, e.g. \"known\" or \"novel\". Any used types should be stated in the .categories{} attribute of the track so they can be distinguished by color. Read count, integer value","title":"File format of single sample data"},{"location":"guides/proteinpaint/file-formats/splice-junction/#steps-to-convert-the-tabular-text-file-to-a-junction-track","text":"sort -k1,1 -k2,2n textfile > textfile.sorted bgzip textfile.sorted tabix -p bed textfile.sorted.gz This generates two files: textfile.sorted.gz textfile.sorted.gz.tbi Put both files in the same directory on the server, and use the file path (or URL) to the .gz file for submitting. Refer to this document for declaring the junction track in JSON format .","title":"Steps to convert the tabular text file to a junction track"},{"location":"guides/proteinpaint/file-formats/splice-junction/#file-format-for-multiple-samples","text":"The first five columns are the same as single sample file. The 6 th column is the read count for the first sample, the 7 th column is the second sample, so that arbitrary number of samples can be represented in this way. Optionally, provide a header line to denote sample names, e.g.: #chr start stop strand type sample1 sample2 ... Header line must begin with \"#\". Bgzip this file in the same way. To index this file, run tabix with additional parameter: tabix -p bed -c \"#\" multisample.gz Sample names like \"sample1\" and \"sample2\" in the header of above example can be replaced by JSON object strings, as a way of encoding additional information on samples in the track file. {\"patient\":\"SJACT001\",\"sample\":\"SJACT001_D\",\"sampletype\":\"DIAGNOSIS\",\"diagnosis_group_short\":\"ST\",\"diagnosis_group_full\":\"Solid Tumor\",\"diagnosis_short\":\"ACT\",\"diagnosis_full\":\"Adrenocortical Carcinoma\",\"diagnosis_subtype_short\":\"TP53-mut\",\"diagnosis_subtype_full\":\"TP53-mut\"} {\"patient\":\"SJACT002\",\"sample\":\"SJACT002_D\",\"sampletype\":\"DIAGNOSIS\",\"diagnosis_group_short\":\"ST\",\"diagnosis_group_full\":\"Solid Tumor\",\"diagnosis_short\":\"ACT\",\"diagnosis_full\":\"Adrenocortical Carcinoma\",\"diagnosis_subtype_short\":\"TP53-mut\",\"diagnosis_subtype_full\":\"TP53-mut\"} This can allow plotting samples by different colors. To do so, add \"cohortsetting\" attribute to track object when using the embedding API: runproteinpaint ({ ... other parameters ... tracks : [ { type : 'junction' , name : 'track name' , file : 'path/to/file.gz' , cohortsetting : { uselevelidx : 0 , cohort : { levels : [ { k : 'diagnosis_group_short' , label : 'cancer' } ] } } } ], })","title":"File format for multiple samples"},{"location":"guides/proteinpaint/file-formats/sv-and-fusion/","text":"Tabular data format for SV and fusion events First line must be the header line, with following columns. gene_a gene on 5' end of a fusion. Do not apply value for intergenic break-end. isoform_a The RefSeq/Ensembl accession of gene_a. Leave blank for intergenic break-end. chr_a Chromosome name of gene_a. In case of intergenic translocation, use the 5' end of the break point. Use name \"chr10\" but not \"10\". position_a Chromosomal position of the 5' end break point, 0-based. strand_a or - gene_b Gene on 3' end of a fusion. In case of intergenic translocation, leave unspecified. isoform_b The RefSeq/Ensembl accession of gene_b. Leave blank for intergenic break-end. chr_b Chromosome name of gene_b. In case of intergenic translocation, use the 3' end of the break point. position_b Chromosomal position of the 3' end break point, 0-based. strand_b or - Optional columns: Patient Sample Sampletype Order of column doesn't matter. Lines starting with \"#\" will be ignored.","title":"SV and fusion transcript"},{"location":"guides/proteinpaint/file-formats/truncation/","text":"Truncation of gene transcript Truncation of the gene transcript that can lead to either N or C-terminus loss of the protein. First line must be the header line, with following columns gene Gene symbol. isoform RefSeq/Ensembl accession of the isoform. rnaPosition RNA nucleotide position of the break point on this gene. Losstype \"n\" for N-loss, \"c\" for C-loss. Optional columns: Patient Sample Sampletype disease Data lines starting with \"#\" will be ignored.","title":"Trunction, N-loss or C-loss"},{"location":"guides/studies/","text":"Studies Study pages discuss how St. Jude has generated and used a particular dataset. St. Jude Cloud currently hosts datasets from the following studies: Pediatric Cancer Genome Project (PCGP) St. Jude Lifetime (SJLIFE) Clinical Genomics (Clinical Pilot and G4K) Sickle Cell Genome Project (SGP) Childhood Cancer Survivor Study (CCSS) Click on a link above to navigate to the corresponding Study page. On each Study page you will find general information about the project such as the goal of the study, demographics and other information about study participants, study design and sequencing technology used, as well as how to cite the study. For complete citation guidelines across datasets, please review the citing St. Jude Cloud page .","title":"About"},{"location":"guides/studies/sickle-cell/","text":"The Sickle Cell Genomics Portal contains two viewers for the exploration of data from the Sickle Cell Genome Project (SGP) dataset . Genome Browser \u00b6 Overview \u00b6 Upon launching the browser, you will see an image similar to the one shown here. A description of the elements of the browser are as follows: # Description 1 Navigation tools and track selector. ( See Navigation Buttons section ) 2 DNase hypersensitivity tracks. By default, four epigenetic tracks are shown. These are DNAse hypersensitivity tracks for Hematopoeitic stem cells (HSC), T Cells, Monocytes, and B Cells. Additional tracks can be viewed by selecting the \u2018Tracks\u2019 button (See Adding/Removing Tracks section below) 3 RefSeq genes. Gene models from the RefSeq database are displayed in this tracks. 4 -log10 of the p-value of the association of each variants with pain rate in individuals with Sickle Cell Disease. The analysis has only been performed around the KIAA1109/Tenr/IL2/IL21 region. Each dot on the track represents a genomic variant (Single Nucleotide Variant (SNV) or small insertion/deletion (INDEL)). The Y-axis for the track represents the -log10 of the p-value. The higher the value, the more statistically significant the association between the variant and pain rate is. Clicking on a variant will open op a window that gives further details about the variant. (See Figure 3). 5 -log10 of the p-value of the association of each variants with age of first vaso-occlusive crisis in individuals with Sickle Cell Disease. See (4) above for more information on this type of track. 6 Filters: Filters allow variants within tracks to be filtered by numerous citeria. See Filter description Navigation buttons \u00b6 # Description a Location/Locus entry field. One can enter genomic coordinates in the form of chromosome:start-end (for example chr1:12345-9876), or a gene name or a SNP rs ID. b Browser zoom in and out c Tracks: Add or hide tracks (See section below on adding/hiding tracks) d More: Save svg image of browser, get DNA sequence or highlight regions of the browser. Filters \u00b6 # Description a Filters for pain rate p-value track b Filters for age of first vaso-occlusive crisis (VOC) p-value c The highlighted filter shows which value is used for the Y-axis on the browser track. The value can be changed. d A highlighted value within a filter shows which filter value is set. The number next to the filter represents the number of individuals that meet the filter criteria. Getting Started \u00b6 Finding a variant of interest \u00b6 A user can navigate to a gene or to a variant ID. Enter in the variant ID rs13140464 into the search text field at the top of the browser. (See below) Pressing enter will center the browser of the selected variant. (see below) Zooming in and out \u00b6 One can use the buttons next to the search field to zoom in and out along the genome. Press the x50 button to zoom out 50 fold This will show a larger region of the chromosome. One can now see three DNase peaks (1) around the rs13140464 variant(2). In addition there is another variant (3) seen near one of the DNase peaks. Obtaining additional variant information \u00b6 Left clicking a variant (see red circle below), will cause a new window to pop up in the browser that will contain additional information about the variant. Adding and removing tracks \u00b6 Select the tracks button from the top of the genome browser. A window displaying selected tracks and tracks available for selection will pop up. One can scroll down to see additional tracks. Try selecting and unselecting various tracks and observe the updated tracks on the browser. Getting DNA sequence \u00b6 Select the 'More' button at the top of the browser. Several options will be available. Select the DNA sequence button. You will be shown the DNA sequence for the region. Variants and Phenotype Viewer \u00b6 Overview \u00b6 When the Variants and Phenotype Viewer is launched, the user will be presented with the following visualization. The different elements of the view are as follows. # Description 1 Settings and sort buttons. In addition a link to this help document. 2 Legend for different tracks in the viewer 3 Phenotypic data displayed with an individual represented in each column 4 Genotypic data displayed with an individual represented in each column Labels \u00b6 See glossary for further details # Description Hb Hemoglobin HbF Fetal Hemoglobin HbA2 Variant of hemoglobin that contains two alpha subunits and two delta subunits MCV Mean corpuscular volume. This is the average size of red blood cells PainRate Number of hospitalizations per year over a two year period. Sickle cell genotype (SS_Genotype in legend. Whether patient is SS or SB0 Alpha deletion Whether the individual has an alpha globin deletion (het=1 deleted allele, homo=2 deleted alleles) rs###### Several variants that we have found to be associated with pain in Sickle Cell Disease Getting Started \u00b6 Sorting \u00b6 Hover your mouse over the MCV label in the graph. A box will pop up with several icons. Select the triangle that is pointed to the left to sort individuals by MCV. The following graph shows individuals sorted by MCV. Blank columns represent no data available. Note that PainRate, Sickle cell genotype and alpha deletion status appear to correlate with MCV values. View values for all patients \u00b6 Hovering over one column will enable the viewing of all phenotypic values for that patient. Undo \u00b6 While exploring the data, one may inadvertently sort or remove data. One can undo the changes by selecting the undo button at the top of the viewer. The redo button will revert the undo. Glossary \u00b6 Fetal hemoglobin (HbF) Fetal hemoglobin contains two subunits of gamma-globin and two units of alpha-globin, while adult hemoglobin contains two subunits of beta-globin and two units of alpha-globin. Heriditary persistence of fetal hemoglobin (HPFH) Individuals with HPFH have elevated levels of fetal hemoglobin. These elevated levels reduce or eliminate many of the symptoms of Sickle Cell Disease. Principal Component Analysis (PCA) A method for reducing high dimensional data into low-dimensional representations. SC An individual with one copy of the sickle cell allele rs334 and one copy of hemoglobin C . S\u03b2 + An individual with beta-thalassemia who has one copy of the sickle cell allele rs334 and one copy of a beta-globin gene that has reduced expression. S\u03b2 0 An individual with beta-thalassemia who has one copy of the sickle cell allele rs334 and one copy of a beta-globin gene that is not expressed or is deleted. SS An individual with sickle cell disease who is homozygous for the sickle cell allele rs334 . SCCRIP The Sickle Cell Research and Intervention Program .","title":"Sickle Cell"},{"location":"guides/studies/sickle-cell/#genome-browser","text":"","title":"Genome Browser"},{"location":"guides/studies/sickle-cell/#overview","text":"Upon launching the browser, you will see an image similar to the one shown here. A description of the elements of the browser are as follows: # Description 1 Navigation tools and track selector. ( See Navigation Buttons section ) 2 DNase hypersensitivity tracks. By default, four epigenetic tracks are shown. These are DNAse hypersensitivity tracks for Hematopoeitic stem cells (HSC), T Cells, Monocytes, and B Cells. Additional tracks can be viewed by selecting the \u2018Tracks\u2019 button (See Adding/Removing Tracks section below) 3 RefSeq genes. Gene models from the RefSeq database are displayed in this tracks. 4 -log10 of the p-value of the association of each variants with pain rate in individuals with Sickle Cell Disease. The analysis has only been performed around the KIAA1109/Tenr/IL2/IL21 region. Each dot on the track represents a genomic variant (Single Nucleotide Variant (SNV) or small insertion/deletion (INDEL)). The Y-axis for the track represents the -log10 of the p-value. The higher the value, the more statistically significant the association between the variant and pain rate is. Clicking on a variant will open op a window that gives further details about the variant. (See Figure 3). 5 -log10 of the p-value of the association of each variants with age of first vaso-occlusive crisis in individuals with Sickle Cell Disease. See (4) above for more information on this type of track. 6 Filters: Filters allow variants within tracks to be filtered by numerous citeria. See Filter description","title":"Overview"},{"location":"guides/studies/sickle-cell/#navigation-buttons","text":"# Description a Location/Locus entry field. One can enter genomic coordinates in the form of chromosome:start-end (for example chr1:12345-9876), or a gene name or a SNP rs ID. b Browser zoom in and out c Tracks: Add or hide tracks (See section below on adding/hiding tracks) d More: Save svg image of browser, get DNA sequence or highlight regions of the browser.","title":"Navigation buttons"},{"location":"guides/studies/sickle-cell/#filters","text":"# Description a Filters for pain rate p-value track b Filters for age of first vaso-occlusive crisis (VOC) p-value c The highlighted filter shows which value is used for the Y-axis on the browser track. The value can be changed. d A highlighted value within a filter shows which filter value is set. The number next to the filter represents the number of individuals that meet the filter criteria.","title":"Filters"},{"location":"guides/studies/sickle-cell/#getting-started","text":"","title":"Getting Started"},{"location":"guides/studies/sickle-cell/#finding-a-variant-of-interest","text":"A user can navigate to a gene or to a variant ID. Enter in the variant ID rs13140464 into the search text field at the top of the browser. (See below) Pressing enter will center the browser of the selected variant. (see below)","title":"Finding a variant of interest"},{"location":"guides/studies/sickle-cell/#zooming-in-and-out","text":"One can use the buttons next to the search field to zoom in and out along the genome. Press the x50 button to zoom out 50 fold This will show a larger region of the chromosome. One can now see three DNase peaks (1) around the rs13140464 variant(2). In addition there is another variant (3) seen near one of the DNase peaks.","title":"Zooming in and out"},{"location":"guides/studies/sickle-cell/#obtaining-additional-variant-information","text":"Left clicking a variant (see red circle below), will cause a new window to pop up in the browser that will contain additional information about the variant.","title":"Obtaining additional variant information"},{"location":"guides/studies/sickle-cell/#adding-and-removing-tracks","text":"Select the tracks button from the top of the genome browser. A window displaying selected tracks and tracks available for selection will pop up. One can scroll down to see additional tracks. Try selecting and unselecting various tracks and observe the updated tracks on the browser.","title":"Adding and removing tracks"},{"location":"guides/studies/sickle-cell/#getting-dna-sequence","text":"Select the 'More' button at the top of the browser. Several options will be available. Select the DNA sequence button. You will be shown the DNA sequence for the region.","title":"Getting DNA sequence"},{"location":"guides/studies/sickle-cell/#variants-and-phenotype-viewer","text":"","title":"Variants and Phenotype Viewer"},{"location":"guides/studies/sickle-cell/#overview_1","text":"When the Variants and Phenotype Viewer is launched, the user will be presented with the following visualization. The different elements of the view are as follows. # Description 1 Settings and sort buttons. In addition a link to this help document. 2 Legend for different tracks in the viewer 3 Phenotypic data displayed with an individual represented in each column 4 Genotypic data displayed with an individual represented in each column","title":"Overview"},{"location":"guides/studies/sickle-cell/#labels","text":"See glossary for further details # Description Hb Hemoglobin HbF Fetal Hemoglobin HbA2 Variant of hemoglobin that contains two alpha subunits and two delta subunits MCV Mean corpuscular volume. This is the average size of red blood cells PainRate Number of hospitalizations per year over a two year period. Sickle cell genotype (SS_Genotype in legend. Whether patient is SS or SB0 Alpha deletion Whether the individual has an alpha globin deletion (het=1 deleted allele, homo=2 deleted alleles) rs###### Several variants that we have found to be associated with pain in Sickle Cell Disease","title":"Labels"},{"location":"guides/studies/sickle-cell/#getting-started_1","text":"","title":"Getting Started"},{"location":"guides/studies/sickle-cell/#sorting","text":"Hover your mouse over the MCV label in the graph. A box will pop up with several icons. Select the triangle that is pointed to the left to sort individuals by MCV. The following graph shows individuals sorted by MCV. Blank columns represent no data available. Note that PainRate, Sickle cell genotype and alpha deletion status appear to correlate with MCV values.","title":"Sorting"},{"location":"guides/studies/sickle-cell/#view-values-for-all-patients","text":"Hovering over one column will enable the viewing of all phenotypic values for that patient.","title":"View values for all patients"},{"location":"guides/studies/sickle-cell/#undo","text":"While exploring the data, one may inadvertently sort or remove data. One can undo the changes by selecting the undo button at the top of the viewer. The redo button will revert the undo.","title":"Undo"},{"location":"guides/studies/sickle-cell/#glossary","text":"Fetal hemoglobin (HbF) Fetal hemoglobin contains two subunits of gamma-globin and two units of alpha-globin, while adult hemoglobin contains two subunits of beta-globin and two units of alpha-globin. Heriditary persistence of fetal hemoglobin (HPFH) Individuals with HPFH have elevated levels of fetal hemoglobin. These elevated levels reduce or eliminate many of the symptoms of Sickle Cell Disease. Principal Component Analysis (PCA) A method for reducing high dimensional data into low-dimensional representations. SC An individual with one copy of the sickle cell allele rs334 and one copy of hemoglobin C . S\u03b2 + An individual with beta-thalassemia who has one copy of the sickle cell allele rs334 and one copy of a beta-globin gene that has reduced expression. S\u03b2 0 An individual with beta-thalassemia who has one copy of the sickle cell allele rs334 and one copy of a beta-globin gene that is not expressed or is deleted. SS An individual with sickle cell disease who is homozygous for the sickle cell allele rs334 . SCCRIP The Sickle Cell Research and Intervention Program .","title":"Glossary"},{"location":"guides/visualization-community/","text":"Visualization Community In St. Jude Cloud's Visualization Community app , we provide genomic and phenomic data in cloud-based, dynamic visualizations generated by combining world class visualization software with high quality next-generation sequencing datasets, both generated and developed at St. Jude Children's Research Hospital. We aim to share these visualizations to encourage discovery amongst researchers; accessing raw data and having to start at the beginning isn't always most efficient. You can search interactive visualizations by Name, Tool , Research Domain , or chronological order. Visualization Tools \u00b6 ProteinPaint is the flagship protein-based visualization tool created at St. Jude. You can use it to examine the domains of genes, known isoforms of a given gene, hotspot mutations for single nucleotide variations (SNVs), insertions and deletions (Indels), and structual variations (SVs) in both pediatric and adult cancers, and RNA-seq expression of a given protein in different tumour types. See the documentation here. GenomePaint visualizes somatic coding and noncoding alterations from ~3,800 pediatric trumors, along with multi-omics information to reveal oncogene activation by noncoding alterations, enhancer hijacking, aberrant splicing, mutual-exclusivity, mutation signature, and perform Kaplan-Meier analysis. It can be used to visualize your own data with easy customization and embedding on your own page. See the documentation here. SJCharts is a collection of plotting libraries useful in creating individual or summary level views of somatic and germline variation. It includes facilities for generating dynamic heatmaps variation in a cohort, Circos-like plot to summarize individual or cohort-level data (such as the one shown here), ribbon plots to visualize gene-pathway-diagnosis relationships, and much more. (Documentation coming soon.)","title":"Getting Started"},{"location":"guides/visualization-community/#visualization-tools","text":"ProteinPaint is the flagship protein-based visualization tool created at St. Jude. You can use it to examine the domains of genes, known isoforms of a given gene, hotspot mutations for single nucleotide variations (SNVs), insertions and deletions (Indels), and structual variations (SVs) in both pediatric and adult cancers, and RNA-seq expression of a given protein in different tumour types. See the documentation here. GenomePaint visualizes somatic coding and noncoding alterations from ~3,800 pediatric trumors, along with multi-omics information to reveal oncogene activation by noncoding alterations, enhancer hijacking, aberrant splicing, mutual-exclusivity, mutation signature, and perform Kaplan-Meier analysis. It can be used to visualize your own data with easy customization and embedding on your own page. See the documentation here. SJCharts is a collection of plotting libraries useful in creating individual or summary level views of somatic and germline variation. It includes facilities for generating dynamic heatmaps variation in a cohort, Circos-like plot to summarize individual or cohort-level data (such as the one shown here), ribbon plots to visualize gene-pathway-diagnosis relationships, and much more. (Documentation coming soon.)","title":"Visualization Tools"},{"location":"guides/visualization-community/faq/","text":"Frequently Asked Questions Will I be charged for using St. Jude Cloud Visualization Community? Will I be charged for using St. Jude Cloud Visualization Community? \u00b6 You will not incur any costs except in the following situations: When data driving a visualization is stored in St. Jude Cloud Genomics Platform or DNAnexus, a monthly fee will be incurred for storage costs. See your DNAnexus billing information for the cost per GB.","title":"Frequently Asked Questions"},{"location":"guides/visualization-community/faq/#will-i-be-charged-for-using-st-jude-cloud-visualization-community","text":"You will not incur any costs except in the following situations: When data driving a visualization is stored in St. Jude Cloud Genomics Platform or DNAnexus, a monthly fee will be incurred for storage costs. See your DNAnexus billing information for the cost per GB.","title":"Will I be charged for using St. Jude Cloud Visualization Community?"},{"location":"guides/visualization-community/genomepaint/","text":"GenomePaint GenomePaint is a visualization browser for simultaneously viewing genomic, transcriptomic, and epigenomic pediatric cancer mutation datasets across a multitude of disease cohorts. GenomePaint datasets include WGS, WES, RNA-Seq, SNP-chip, ChIP-Seq, and Hi-C data visualized over the hg19 reference genome. You can use GenomePaint to interpret the impact of somatic coding and noncoding alterations from ~3,800 pediatric tumors, make novel discoveries through visual exploration, and create publication ready figures! Getting Started \u00b6 The GenomePaint browser homepage lands on a dense cohort view of the TAL1 gene region of chromosome 1. Each section of the display can be interacted with by clicking, dragging, or hovering. Filter the information displayed on the tracks by clicking buttons in the legend. Customize the legend display by hiding/showing classes. Click CONFIG to the right of tracks for additional display customization. To navigate tracks, Pan left or right by clicking on the middle part of the track and dragging Zoom in by dragging the genomic coordinate ruler on top or zoom in 1 fold by clicking on the IN button Zoom out by x fold by clicking on an OUT button. You can even zoom in to display mutations at bp resolution. GenomePaint offers three different views: cohort view, sample view, and matrix view. The figure below summarizes how each view is connected. Cohort View \u00b6 The cohort view shows mutations from all samples over a genomic region, along with the gene expression ranks for each of the samples. By default the mutation track displays the cohort view in dense mode, a compact display showing density plots for SVs and SNV/indels. You can toggle the view to expanded mode by clicking the CONFIG button to the right of the mutation track and then clicking Expanded. In Expanded mode (see below) all types of mutations are shown for each sample, one row per sample. Circles represent SV/fusion breakpoints, and x marks represent SNV/indels, each of which are displayed together with CNV/LOH. SNV/indels and breakpoints are always shown on top of CNV and LOH. Text labels can be shown for SV/fusion/SNV/indel, if available. Sample View \u00b6 The sample view shows mutations for one sample alone, along with any available genomic assay tracks. You can open a sample view from the expanded cohort view by clicking on any type of single mutation within the sample, and then selecting Focus . This brings up a new browser view showing data tracks from this sample in the region surrounding the mutation. On the sample view you can explore expression rank, tumor mutations, structural variants, splice junctions, WES coverage, and RNA-Seq coverage. Customize the display by zooming in/out, hiding and/or rearranging tracks, or editing CONFIG options. Matrix View \u00b6 The matrix view combines the mutation profiles of multiple genomic regions in one view, in the form of a sample-by-region matrix. Such a matrix can be generated for samples from one cancer type. To open a matrix view, select a disease cohort from the cohort view and then select Matrix view. This organizes the selected cohort tumors with mutations in the genomic region you are viewing into a single-column matrix. Next, go back to the cohort view and type another gene or region of interest into the genome coordinate box and press ENTER. The cohort view will now show data at the new genomic location. Click on the same disease cohort and then select Matrix view. This will add the new genomic variant as a second column in the matrix. You can continue adding columns to this matrix in the same manner. Advanced Customizations \u00b6 There are several more advanced customizations you can leverage with GenomePaint such as creating custom tracks, importing your own data, and embedding interactive visualizations on your web page. For instructions on these topics, please see our detailed tutorial . Please excuse the different location and formatting as we work to incorporate this into our main documentation pages.","title":"GenomePaint"},{"location":"guides/visualization-community/genomepaint/#getting-started","text":"The GenomePaint browser homepage lands on a dense cohort view of the TAL1 gene region of chromosome 1. Each section of the display can be interacted with by clicking, dragging, or hovering. Filter the information displayed on the tracks by clicking buttons in the legend. Customize the legend display by hiding/showing classes. Click CONFIG to the right of tracks for additional display customization. To navigate tracks, Pan left or right by clicking on the middle part of the track and dragging Zoom in by dragging the genomic coordinate ruler on top or zoom in 1 fold by clicking on the IN button Zoom out by x fold by clicking on an OUT button. You can even zoom in to display mutations at bp resolution. GenomePaint offers three different views: cohort view, sample view, and matrix view. The figure below summarizes how each view is connected.","title":"Getting Started"},{"location":"guides/visualization-community/genomepaint/#cohort-view","text":"The cohort view shows mutations from all samples over a genomic region, along with the gene expression ranks for each of the samples. By default the mutation track displays the cohort view in dense mode, a compact display showing density plots for SVs and SNV/indels. You can toggle the view to expanded mode by clicking the CONFIG button to the right of the mutation track and then clicking Expanded. In Expanded mode (see below) all types of mutations are shown for each sample, one row per sample. Circles represent SV/fusion breakpoints, and x marks represent SNV/indels, each of which are displayed together with CNV/LOH. SNV/indels and breakpoints are always shown on top of CNV and LOH. Text labels can be shown for SV/fusion/SNV/indel, if available.","title":"Cohort View"},{"location":"guides/visualization-community/genomepaint/#sample-view","text":"The sample view shows mutations for one sample alone, along with any available genomic assay tracks. You can open a sample view from the expanded cohort view by clicking on any type of single mutation within the sample, and then selecting Focus . This brings up a new browser view showing data tracks from this sample in the region surrounding the mutation. On the sample view you can explore expression rank, tumor mutations, structural variants, splice junctions, WES coverage, and RNA-Seq coverage. Customize the display by zooming in/out, hiding and/or rearranging tracks, or editing CONFIG options.","title":"Sample View"},{"location":"guides/visualization-community/genomepaint/#matrix-view","text":"The matrix view combines the mutation profiles of multiple genomic regions in one view, in the form of a sample-by-region matrix. Such a matrix can be generated for samples from one cancer type. To open a matrix view, select a disease cohort from the cohort view and then select Matrix view. This organizes the selected cohort tumors with mutations in the genomic region you are viewing into a single-column matrix. Next, go back to the cohort view and type another gene or region of interest into the genome coordinate box and press ENTER. The cohort view will now show data at the new genomic location. Click on the same disease cohort and then select Matrix view. This will add the new genomic variant as a second column in the matrix. You can continue adding columns to this matrix in the same manner.","title":"Matrix View"},{"location":"guides/visualization-community/genomepaint/#advanced-customizations","text":"There are several more advanced customizations you can leverage with GenomePaint such as creating custom tracks, importing your own data, and embedding interactive visualizations on your web page. For instructions on these topics, please see our detailed tutorial . Please excuse the different location and formatting as we work to incorporate this into our main documentation pages.","title":"Advanced Customizations"},{"location":"guides/visualization-community/proteinpaint/","text":"ProteinPaint ProteinPaint is a web application for simultaneously visualizing genetic lesions (including sequence mutations and gene fusions) and RNA expression in pediatric cancers. You can find the ProteinPaint paper here . Overview \u00b6 The image below shows an example ProteinPaint of the gene TP53 annotated with descriptions of the many interactive elements of a ProteinPaint visualization. As you can see, there is a lot to explore. Glossary of Classes \u00b6 The list below summarizes all classes of mutations used by ProteinPaint. Mutation Class Description MISSENSE a substitution variant in the coding region resulting in altered protein coding FRAMESHIFT an insertion or deletion variant that alters the protein coding frame NONSENSE a variant altering protein coding to produce a premature stopgain or stoploss. PROTEINDEL a deletion resulting in a loss of one or more codons from the product, but not altering the protein coding frame PROTEININS an insertion introducing one or more codons into the product, but not altering the protein coding frame SPLICE a variant near an exon edge that may affect splicing functionality SILENT a substitution variant in the coding region that does not alter protein coding SPLICE_REGION a variant in an intron within 10 nt of an exon boundary UTR_5 a variant in the 5' untranslated region UTR_3 a variant in the 3' untranslated region EXON a variant in the exon of a non-coding RNA INTRON an intronic variant Glossary of Origins \u00b6 The list below summarizes all origins of mutations used by ProteinPaint. Mutation Origin Description Germline a variant found in a normal sample of a cancer patient. Somatic a variant found only in a tumor sample. Relapse a variant that arose in recurrence tumor. Advanced Customizations \u00b6 There are several more advanced customizations you can leverage with ProteinPaint such as creating custom tracks, importing your own data, and embedding interactive visualizations on your web page. For instructions on these topics, please see our detailed tutorial . Please excuse the different location and formatting as we work to incorporate this into our main documentation pages.","title":"ProteinPaint"},{"location":"guides/visualization-community/proteinpaint/#overview","text":"The image below shows an example ProteinPaint of the gene TP53 annotated with descriptions of the many interactive elements of a ProteinPaint visualization. As you can see, there is a lot to explore.","title":"Overview"},{"location":"guides/visualization-community/proteinpaint/#glossary-of-classes","text":"The list below summarizes all classes of mutations used by ProteinPaint. Mutation Class Description MISSENSE a substitution variant in the coding region resulting in altered protein coding FRAMESHIFT an insertion or deletion variant that alters the protein coding frame NONSENSE a variant altering protein coding to produce a premature stopgain or stoploss. PROTEINDEL a deletion resulting in a loss of one or more codons from the product, but not altering the protein coding frame PROTEININS an insertion introducing one or more codons into the product, but not altering the protein coding frame SPLICE a variant near an exon edge that may affect splicing functionality SILENT a substitution variant in the coding region that does not alter protein coding SPLICE_REGION a variant in an intron within 10 nt of an exon boundary UTR_5 a variant in the 5' untranslated region UTR_3 a variant in the 3' untranslated region EXON a variant in the exon of a non-coding RNA INTRON an intronic variant","title":"Glossary of Classes"},{"location":"guides/visualization-community/proteinpaint/#glossary-of-origins","text":"The list below summarizes all origins of mutations used by ProteinPaint. Mutation Origin Description Germline a variant found in a normal sample of a cancer patient. Somatic a variant found only in a tumor sample. Relapse a variant that arose in recurrence tumor.","title":"Glossary of Origins"},{"location":"guides/visualization-community/proteinpaint/#advanced-customizations","text":"There are several more advanced customizations you can leverage with ProteinPaint such as creating custom tracks, importing your own data, and embedding interactive visualizations on your web page. For instructions on these topics, please see our detailed tutorial . Please excuse the different location and formatting as we work to incorporate this into our main documentation pages.","title":"Advanced Customizations"},{"location":"guides/visualization-community/sjcharts/","text":"SJ Charts","title":"SJ Charts"}]}